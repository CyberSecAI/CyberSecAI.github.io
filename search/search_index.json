{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Your guide to using AI for CyberSecurity <p>Why Read this Guide?</p> <p>This guide shows how cybersecurity professionals can get up and running quickly with AI tools.</p> <p>Large Language Models (hosted and open source), and BERT-based language models tools will be covered e.g.</p> <ol> <li>NotebookLM</li> <li>Prompts and Prompt Techniques applied to Cybersecurity </li> <li>BERTopic</li> <li>Embeddings for CyberSecurity</li> <li>SetFIT + LAGoNN</li> <li>Named Entity Recognition GliNER and CyberSecurity NER models</li> <li>AI Agents for orchestrated workflows</li> </ol>"},{"location":"NotebookLM/NotebookLM/","title":"NotebookLM","text":"<p>Overview</p> <p>LLMs change the information retrieval paradigm. Instead of searching for information where we go to the information, we can chat with our documents and ask questions of them, so that the information comes to us in the form of an answer. </p> <p>In this section, we'll use NotebookLM, and we just need to import our documents to be able to chat with them. </p> <p>ChatGPT4o is also used for comparison to highlight where one is better applied than the other depending on the context.</p> <ul> <li>Both tools use LLMs, but NoteBookLM uses a \"Closed System\" (only the document sources you provide), versus ChatGPT4o which bases it answers on the open internet content at the time it was trained, and additionally the documents you provide.</li> </ul> <p>Tip</p> <p>Your responses from NotebookLM may be different than the examples shown here. LLMs will give different responses to the same question.</p>"},{"location":"NotebookLM/NotebookLM/#notebooklm_1","title":"NotebookLM","text":"<p>Quote</p> <p>NotebookLM lets you read, take notes, ask questions, organize your ideas, and much more -- all with the power of Google AI helping you at every step of the way.</p> <p>Quote</p> <p>It runs on the company\u2019s Gemini 1.5 Pro model (released Dec 2023), the same AI that powers the Gemini Advanced chatbot.  (ref)</p>"},{"location":"NotebookLM/NotebookLM/#key-features-and-benefits-of-gemini-15-models","title":"Key Features and Benefits of Gemini 1.5 Models","text":"<p>Per Gemini 1.5 Technical Report, the Key Features and Benefits of Gemini 1.5 Models are</p> <ol> <li>Highly Compute-Efficient Multimodal Models<ol> <li>Capable of recalling and reasoning over fine-grained information from millions of tokens of context, including long documents, videos, and audio.</li> </ol> </li> <li>Benchmark Performance<ol> <li>Outperforms other models such as Claude 3.0 (200k tokens) and GPT-4 Turbo (128k tokens) in next-token prediction and retrieval up to 10M tokens (approximately 7M words).</li> </ol> </li> <li>Unprecedented Context Handling<ol> <li>Handles extremely long contexts, up to at least 10M tokens (approximately 7M words).</li> <li>Capable of processing long-form mixed-modality inputs, including entire document collections, multiple hours of video, and almost five days of audio.</li> <li>Near-perfect recall on long-context retrieval tasks across various modalities.</li> </ol> </li> <li>Realistic Multimodal Long-Context Benchmarks<ol> <li>Excels in tasks requiring retrieval and reasoning over multiple parts of the context.</li> <li>Outperforms all competing models across all modalities, even those augmented with external retrieval methods.</li> </ol> </li> </ol> <p>These features make Gemini 1.5 models a generational leap over existing models, offering unparalleled performance in processing and understanding extensive and complex multimodal information.</p> <p>Tip</p> <p>Such systems map document content to vectors (numeric representations of words or tokens in multi-dimensional space).</p> <p>Queries are based on similarity (proximity in vector space).</p>"},{"location":"NotebookLM/NotebookLM/#document-loading","title":"Document Loading","text":"<p>Documents are loaded via GoogleDrive, PDFs, Text files, Copied text, Web page URL.</p> <p>Tip</p> <p>Any sources can be used e.g. Books in PDF format, websites, text files.</p> <p>Using a file of site content (if available) e.g.a PDF, is generally more reliable than using a URL to that site; it ensures all the content is ingested.</p>"},{"location":"NotebookLM/NotebookLM/#closed-system","title":"Closed System","text":"<p>These documents become the corpus where information is retrieved from, with references to the document(s) the information was retrieved from.</p> <p>Quote</p> <p>\u201cNotebookLM is a closed system.\u201d This means the AI won\u2019t perform any web searches beyond what you, the user, give it in a prompt. Every response it generates pertains only to the information it has on hand. (ref)</p> <p>Quote</p> <p>\u201csource-grounded AI\u201d: you define a set of documents that are important to your work\u2014called \u201csources\u201d in the NotebookLM parlance\u2014and from that point on, you can have an open-ended conversation with the language model where its answers will be \u201cgrounded\u201d in the information you\u2019ve selected. It is as if you are giving the AI instant expertise in whatever domain you happen to be working in. (ref)</p>"},{"location":"NotebookLM/NotebookLM/#what-is-a-dog","title":"What is a dog?","text":"<p>This is illustrated with a simple example of asking our Notebook on CWEs \"what is a dog?\":</p> <p>Quote</p> <p>The sources provided do not contain any information about dogs. Therefore, the query \"what is a dog?\" cannot be answered from the given sources.</p> <p></p>"},{"location":"NotebookLM/NotebookLM/#sharing","title":"Sharing","text":"<p>Unlike Google Docs, it is not possible to share a NotebookLM publicly - sharing is done directly via email addresses.</p>"},{"location":"NotebookLM/NotebookLM/#how-to-use-notebooklm","title":"How To Use NotebookLM","text":""},{"location":"NotebookLM/NotebookLM/#references","title":"References","text":"<ol> <li>Introducing NotebookLM, Oct 19, 2023, Steven Johnson who contributed to NotebookLM</li> <li>Getting The Most Out Of Notes In NotebookLM, Mar 18, 2024, Steven Johnson</li> <li>How To Use NotebookLM As A Research Tool, Feb 19, 2024, Steven Johnson</li> <li>Google's NotebookLM is now an even smarter assistant and better fact-checker, June 7, 2024 </li> <li>Using Google\u2019s NotebookLM for Data Science: A Comprehensive Guide, Dec 7, 2023 </li> <li>How to use Google\u2019s genAI-powered note-taking app, Feb 15, 2024 </li> </ol>"},{"location":"NotebookLM/NotebookLM/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM is a powerful free solution from Google that allows users to quickly and easily build a source-grounded AI (where users define the set of documents) and then have an open-ended conversation with the language model where its answers will be \u201cgrounded\u201d in the information users selected.</li> <li>The support for large contexts means that large documents can be processed - as demonstrated in the following sections.</li> <li>I found it a useful tool / companion for the research I was doing on vulnerability management to augment my knowledge and capabilities.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Attack/","title":"NotebookLM ATTACK","text":"<p>Overview</p> <p>As part of Proactive Software Supply Chain Risk Management (P-SSCRM) Framework that I've been collaborating on, we wanted to apply MITRE ATT&amp;CK. It's a detailed specification, so NotebookLM can help us.</p> <p>In this chapter, we'll use NotebookLM to ingest the MITRE ATT&amp;CK Enterprise Tactics. </p> <ul> <li>In the current version, MITRE ATT&amp;CK Matrix for Enterprise consists of 14 tactics, 559 Total Attack Patterns. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the MITRE ATT&amp;CK Matrix and ask questions, so that the information comes to us in the form of an answer. </p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Attack/#data-sources","title":"Data Sources","text":"<p>The MITRE ATTACK Tactics and Techniques are available online at https://attack.mitre.org/tactics/enterprise/ as 1 webpage for each of the 14 Tactics.</p> <ul> <li>However, loading these webpages (or the \"Version Permalink\" pages) into NotebookLM did not work.</li> </ul> <p>MITRE ATTACK is also available as an Excel file from https://attack.mitre.org/resources/attack-data-and-tools/</p> <ul> <li>https://attack.mitre.org/docs/enterprise-attack-v15.1/enterprise-attack-v15.1.xlsx</li> <li>Note: The data is also available as JSON. </li> </ul> <p>So we can convert that to a text file and load those as follows:</p> <ol> <li>Open the Excel file</li> <li>For the tabs we want (e.g. Tactics, Techniques, Mitigations), delete the columns we don't want </li> <li>Export each tab as a csv file</li> <li>Transpose the data to a text file</li> <li>Import the text files</li> </ol> <p>Data Sources</p> <p>The MITRE ATTACK csv and text files, and script to convert, are available in https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/Notebook_Attack</p>"},{"location":"NotebookLM/NotebookLM_Attack/#convert-mitre-attack-to-a-text-file-for-import","title":"Convert MITRE ATTACK to a Text File for Import","text":"<p>Claude 3.5 Sonnet Prompt: <pre><code>i have a csv file with these columns ID    name description    tactics    detection    \"data sources\"    \"is sub-technique\"    \"sub-technique of\"\nI want to extract the content into a document to read. \nEach row should be extracted as follows: the name of the first column, then the ccontent for the first column. Then the second column name and content.\nAnd so on for each column.\nAnd do this for all rows\n\nI want python code to do this\n</code></pre></p> <p>The LLM generated generic code that was applied to convert each csv file to a text file.</p>"},{"location":"NotebookLM/NotebookLM_Attack/#load-each-text-file","title":"Load each text file","text":"<p>So we can just load each one to NoteBookLM as a text file:</p> <ul> <li>MITRE_ATTACK_mitigations.txt</li> <li>MITRE_ATTACK_tactics.txt</li> <li>MITRE_ATTACK_techniques.txt</li> </ul>"},{"location":"NotebookLM/NotebookLM_Attack/#tell-me-about-mitre-techniques-related-to-supply-chain","title":"Tell me about MITRE techniques related to supply chain","text":""},{"location":"NotebookLM/NotebookLM_Attack/#notebooklm-answer","title":"NotebookLM Answer","text":""},{"location":"NotebookLM/NotebookLM_Attack/#claude-sonnet-35-answer","title":"Claude Sonnet 3.5 Answer","text":""},{"location":"NotebookLM/NotebookLM_Attack/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>Any data or document in text format can be converted to a format suitable for import to an LM.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Capec/","title":"NotebookLM CAPEC","text":"<p>Overview</p> <p>In this chapter, we'll use NotebookLM to ingest the Common Attack Pattern Enumeration and Classification (CAPEC) list. </p> <ul> <li>In the current version (CAPEC List Version 3.9 as at June 2024), there are 559 Total Attack Patterns. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the CAPEC document and ask questions, so that the information comes to us in the form of an answer. </p> <p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol> <p>Note that CAPEC appears a lot less than CWE on the internet so an LLM will have a lot less context for CAPEC.</p>"},{"location":"NotebookLM/NotebookLM_Capec/#data-sources","title":"Data Sources","text":"<p>https://capec.mitre.org/data/downloads.html offers various formats (XML, CSV, HTML), and views:</p> <ul> <li>Mechanisms of Attack: https://capec.mitre.org/data/slices/1000.html</li> <li>Domains of Attack: https://capec.mitre.org/data/slices/3000.html<ul> <li>We'll use this one.</li> </ul> </li> </ul> <p>NotebookLM - Upload from - Web page URL - Paste website link - https://capec.mitre.org/data/slices/3000.html</p>"},{"location":"NotebookLM/NotebookLM_Capec/#what-is-the-capec-id-that-related-to-xss","title":"what is the CAPEC ID that related to xss","text":""},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o did not provide all the CWEs that NotebookLM did.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer-with-hallucination","title":"ChatGPT4o Answer with Hallucination","text":"<p>Failure</p> <p>Hallucination</p> <p>\"CAPEC-633: Client-Side XSS using Content-Security-Policy Bypass\" is not valid https://capec.mitre.org/data/definitions/633.html</p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer-with-hallucination-with-uploaded-capec-file","title":"ChatGPT4o Answer with Hallucination with Uploaded CAPEC File","text":"<p>ChatGPT4o UI did not process the CAPEC HTML file, and the UI does not accept URLs, so the CSV file was uploaded instead.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-validate-the-hallucination","title":"ChatGPT4o Validate the Hallucination","text":"<p>In a different ChatGPT4o session (new context to avoid the hallucination), we ask ChatGPT4o to validate the CAPEC. </p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-review-and-rate-the-responses-from-notebooklm-and-chatgpt4o","title":"ChatGPT4o Review and Rate the Responses from NotebookLM and ChatGPT4o","text":"<p>ChatGPT4o was used to review and rate both responses (copied directly from the NoteBookLM and ChatGPT4o responses)</p> <p></p> <p></p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>For less common or referenced text like CAPEC, ChatGPT4o can hallucinate even when the CAPEC list is uploaded to it.</li> <li>NotebookLM did not hallucinate (a benefit of the \"Closed System\" approach).</li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/","title":"NotebookLM Config","text":"<p>Overview</p> <p>I came across this via https://tldrsec.com/p/tldr-sec-237 (an excellent newsletter) in the \"AI + Security\" section, and it piqued my interest! </p> <p>One area of research is using LLMs for infrastructure configuration as detailed in https://www.coguard.io/post/coguard-uses-openai-cybersecurity-grant-to-automate-infrastructure-security and the associated repo.</p> <p>Here we take on the first task [C1]: Extraction of security and uptime-relevant configuration parameters from manuals; for the example provided in the repo: Apache Spark</p>"},{"location":"NotebookLM/NotebookLM_Config/#details","title":"Details","text":""},{"location":"NotebookLM/NotebookLM_Config/#task","title":"Task","text":"<p>Quote</p> <p>[C1] Extraction of security and uptime-relevant configuration parameters from manuals. The goal of this component is simple to describe, but hard to accomplish. Given a manual for a software component, extract the configuration parameters and define the security relevant ones from it.</p> <p>Example: For Apache Spark, the manual is provided on the general configuration page online, i.e. in HTML format, and there is also a specific security page. The expectation would be to at least extract the parameters from the security page, as well as some log-related items from the general page. In total, when manually examining the configuration parameters, it totals approximately 80 parameters that are security relevant. You can find these in the Appendix A.</p>"},{"location":"NotebookLM/NotebookLM_Config/#original-prompt","title":"Original Prompt","text":"<p>The original prompt used is per https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#extraction-of-security-relevant-parameters-in-c1</p> <p>Quote</p> <p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>"},{"location":"NotebookLM/NotebookLM_Config/#expected-answer","title":"Expected Answer","text":"<p>The expected answer is per https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#appendix-a. </p> <p>Quote</p> <p>The following parameters were identified by the CoGuard team by hand as relevant from a security point of view.</p> <pre><code>spark.yarn.shuffle.server.recovery.disabled\nspark.authenticate\nspark.authenticate.secret\nspark.authenticate.secret.file\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.network.crypto.enabled\nspark.network.crypto.config.*\nspark.network.crypto.saslFallback\nspark.authenticate.enableSaslEncryption\nspark.network.sasl.serverAlwaysEncrypt\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.io.encryption.commons.config.*\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.modify.acls\nspark.modify.acls.groups\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.user.groups.mapping\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.ssl.enabled\nspark.ssl.port\nspark.ssl.enabledAlgorithms\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.protocol\nspark.ssl.needClientAuth\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.port\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.protocol\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.standalone.enabled\nspark.ssl.standalone.port\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.protocol\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.port\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ui.xXssProtection\nspark.ui.xContentTypeOptions.enabled\nspark.ui.strictTransportSecurity\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#data-sources","title":"Data Sources","text":"<p>The data sources are per above:</p> <ol> <li>https://spark.apache.org/docs/latest/configuration.html</li> <li>https://spark.apache.org/docs/latest/security.html</li> </ol> <p>Data Sources</p> <p>Copies of the html files are available in https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/Notebook_Attack</p>"},{"location":"NotebookLM/NotebookLM_Config/#setup","title":"Setup","text":""},{"location":"NotebookLM/NotebookLM_Config/#prepare-validation-file","title":"Prepare Validation File","text":"<ol> <li>CopyNPaste the Expected answer to a text file ./data/NotebookLM_Config/security_parameters_manual.txt.</li> <li>Sort alphabetically to allow diff comparison with answer from NotebookLM.</li> </ol> <pre><code>    cat ./data/NotebookLM_Config/security_parameters_manual.txt | sort &gt; ./data/NotebookLM_Config/security_parameters_manual_sorted.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#attempt-1-use-the-provided-prompt","title":"Attempt 1: Use the Provided Prompt","text":""},{"location":"NotebookLM/NotebookLM_Config/#create-a-new-notebooklm-with-the-2-data-sources-only","title":"Create A New Notebooklm With The 2 Data Sources Only","text":"<p>New NotebookLM. Sources - Upload from - Web page URL for the 2 Data Sources listed above.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Config/#submit-the-prompt","title":"Submit the prompt","text":"<p>Quote</p> <p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>"},{"location":"NotebookLM/NotebookLM_Config/#save-the-result","title":"Save The Result","text":"<ol> <li>Click the Copy button.</li> <li>Create a new file security_parameters.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li> <li>Sort the answer</li> </ol> <pre><code>jq -r '.[]' ./data/NotebookLM_Config/security_parameters.json | sort &gt; ./data/NotebookLM_Config/security_parameters.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer","title":"Compare The Answer With The Expected Answer","text":"<ol> <li>60 parameters were retrieved</li> <li>We can see that the main difference relates to \"spark.ssl.\" parameters.</li> <li>Searching manually in the 2 Data Sources above reveals that these config strings are not actually listed in the documentation e.g. \"spark.ssl.ui.needClientAuth\" directly - but using placeholders.</li> <li>The LLM didn't understand that - so we'll let it know - then ask it again.</li> <li>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt   </li> </ol> <pre><code>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt                 \n1c1,4\n&lt; spark.yarn.shuffle.server.recovery.disabled\n---\n&gt; hadoop.security.credential.provider.path\n&gt; spark.acls.enable\n&gt; spark.admin.acls\n&gt; spark.admin.acls.groups\n2a6\n&gt; spark.authenticate.enableSaslEncryption\n4d7\n&lt; spark.authenticate.secret.file\n7,11c10,14\n&lt; spark.network.crypto.enabled\n&lt; spark.network.crypto.config.*\n&lt; spark.network.crypto.saslFallback\n&lt; spark.authenticate.enableSaslEncryption\n&lt; spark.network.sasl.serverAlwaysEncrypt\n---\n&gt; spark.authenticate.secret.file\n&gt; spark.history.ui.acls.enable\n&gt; spark.history.ui.admin.acls\n&gt; spark.history.ui.admin.acls.groups\n&gt; spark.io.encryption.commons.config.*\n15,20c18,29\n&lt; spark.io.encryption.commons.config.*\n&lt; spark.ui.allowFramingFrom\n&lt; spark.ui.filters\n&lt; spark.acls.enable\n&lt; spark.admin.acls\n&lt; spark.admin.acls.groups\n---\n&gt; spark.kerberos.access.hadoopFileSystems\n&gt; spark.kerberos.keytab\n&gt; spark.kerberos.principal\n&gt; spark.kubernetes.hadoop.configMapName\n&gt; spark.kubernetes.kerberos.krb5.configMapName\n&gt; spark.kubernetes.kerberos.krb5.path\n&gt; spark.kubernetes.kerberos.tokenSecret.itemKey\n&gt; spark.kubernetes.kerberos.tokenSecret.name\n&gt; spark.mesos.driver.secret.envkeys\n&gt; spark.mesos.driver.secret.filenames\n&gt; spark.mesos.driver.secret.names\n&gt; spark.mesos.driver.secret.values\n23,28c32,39\n&lt; spark.ui.view.acls\n&lt; spark.ui.view.acls.groups\n&lt; spark.user.groups.mapping\n&lt; spark.history.ui.acls.enable\n&lt; spark.history.ui.admin.acls\n&lt; spark.history.ui.admin.acls.groups\n---\n&gt; spark.network.crypto.config.*\n&gt; spark.network.crypto.enabled\n&gt; spark.network.crypto.saslFallback\n&gt; spark.network.sasl.serverAlwaysEncrypt\n&gt; spark.redaction.regex\n&gt; spark.redaction.string.regex\n&gt; spark.security.credentials.${service}.enabled\n&gt; spark.sql.redaction.options.regex\n30d40\n&lt; spark.ssl.port\n36d45\n&lt; spark.ssl.protocol\n37a47,48\n&gt; spark.ssl.port\n&gt; spark.ssl.protocol\n41,77c52,57\n&lt; spark.ssl.ui.enabled\n&lt; spark.ssl.ui.port\n&lt; spark.ssl.ui.enabledAlgorithms\n&lt; spark.ssl.ui.keyPassword\n&lt; spark.ssl.ui.keyStore\n&lt; spark.ssl.ui.keyStorePassword\n&lt; spark.ssl.ui.keyStoreType\n&lt; spark.ssl.ui.protocol\n&lt; spark.ssl.ui.needClientAuth\n&lt; spark.ssl.ui.trustStore\n&lt; spark.ssl.ui.trustStorePassword\n&lt; spark.ssl.ui.trustStoreType\n&lt; spark.ssl.standalone.enabled\n&lt; spark.ssl.standalone.port\n&lt; spark.ssl.standalone.enabledAlgorithms\n&lt; spark.ssl.standalone.keyPassword\n&lt; spark.ssl.standalone.keyStore\n&lt; spark.ssl.standalone.keyStorePassword\n&lt; spark.ssl.standalone.keyStoreType\n&lt; spark.ssl.standalone.protocol\n&lt; spark.ssl.standalone.needClientAuth\n&lt; spark.ssl.standalone.trustStore\n&lt; spark.ssl.standalone.trustStorePassword\n&lt; spark.ssl.standalone.trustStoreType\n&lt; spark.ssl.historyServer.enabled\n&lt; spark.ssl.historyServer.port\n&lt; spark.ssl.historyServer.enabledAlgorithms\n&lt; spark.ssl.historyServer.keyPassword\n&lt; spark.ssl.historyServer.keyStore\n&lt; spark.ssl.historyServer.keyStorePassword\n&lt; spark.ssl.historyServer.keyStoreType\n&lt; spark.ssl.historyServer.protocol\n&lt; spark.ssl.historyServer.needClientAuth\n&lt; spark.ssl.historyServer.trustStore\n&lt; spark.ssl.historyServer.trustStorePassword\n&lt; spark.ssl.historyServer.trustStoreType\n&lt; spark.ui.xXssProtection\n---\n&gt; spark.ssl.useNodeLocalConf\n&gt; spark.ui.allowFramingFrom\n&gt; spark.ui.filters\n&gt; spark.ui.strictTransportSecurity\n&gt; spark.ui.view.acls\n&gt; spark.ui.view.acls.groups\n79c59,60\n&lt; spark.ui.strictTransportSecurity\n\\ No newline at end of file\n---\n&gt; spark.ui.xXssProtection\n&gt; spark.user.groups.mapping\n</code></pre> <p>Note</p> <p>In the next section, we'll use an LLM to do the comparison.</p> <p>Here we used traditional methods i.e. diff.</p>"},{"location":"NotebookLM/NotebookLM_Config/#attempt-2-explain-about-config-namespace-placeholders","title":"Attempt 2: Explain about Config Namespace Placeholders","text":"<p>The LLM did not understand from the documents about Config Namespace placeholders:</p> <p></p> <p>So this time, we explain as part of the prompt about Config Namespace placeholders.</p>"},{"location":"NotebookLM/NotebookLM_Config/#submit-the-prompt_1","title":"Submit The Prompt","text":"<p>Quote</p> <p>Note that Config Namespace placeholders are used for some security configurations. These are placeholders \"\\({ns}\" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: \"\\).enabled\", \"spark.ssl.enabled\" and \"spark.ssl.historyServer\" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns</p> <p>Note</p> <p>Note the duplication in the prompt to emphasize what we want</p> <p>Quote</p> <p>\"list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns\" in the prompt.</p> <p>security_parameters_ns.json is the resulting file that has 96 config parameters - more than the expected answer config parameters as generated by humans.</p>"},{"location":"NotebookLM/NotebookLM_Config/#save-the-result_1","title":"Save The Result","text":"<ol> <li>Click the Copy button.</li> <li>Create a new file security_parameters_ns.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li> <li>Sort the answer and ensure there's no duplicates.</li> </ol> <pre><code>jq -r '.[]' ./data/NotebookLM_Config/security_parameters_ns.json | sort | uniq &gt; ./data/NotebookLM_Config/security_parameters_ns.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer_1","title":"Compare The Answer With The Expected Answer","text":"<p>In this case, we use ChatGPT4o to do the diff, copy and pasting the values from each file:</p> <ul> <li>./data/NotebookLM_Config/security_parameters_manual.txt: the expected answers</li> <li>./data/NotebookLM_Config/security_parameters_ns.txt: the actual answers</li> </ul>"},{"location":"NotebookLM/NotebookLM_Config/#prompt","title":"Prompt","text":"<pre><code>List the values that are in ===manual===  but not in ===notebooklm===\nList the values that are in ===notebooklm===  but not in ===manual===\n\n===manual=== \nspark.yarn.shuffle.server.recovery.disabled\nspark.authenticate\nspark.authenticate.secret\nspark.authenticate.secret.file\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.network.crypto.enabled\nspark.network.crypto.config.*\nspark.network.crypto.saslFallback\nspark.authenticate.enableSaslEncryption\nspark.network.sasl.serverAlwaysEncrypt\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.io.encryption.commons.config.*\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.modify.acls\nspark.modify.acls.groups\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.user.groups.mapping\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.ssl.enabled\nspark.ssl.port\nspark.ssl.enabledAlgorithms\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.protocol\nspark.ssl.needClientAuth\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.port\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.protocol\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.standalone.enabled\nspark.ssl.standalone.port\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.protocol\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.port\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ui.xXssProtection\nspark.ui.xContentTypeOptions.enabled\nspark.ui.strictTransportSecurity\n\n\n===notebooklm===\nhadoop.security.credential.provider.path\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.authenticate\nspark.authenticate.enableSaslEncryption\nspark.authenticate.secret\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.authenticate.secret.file\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.io.encryption.commons.config.*\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.kerberos.access.hadoopFileSystems\nspark.kerberos.keytab\nspark.kerberos.principal\nspark.kubernetes.hadoop.configMapName\nspark.kubernetes.kerberos.krb5.configMapName\nspark.kubernetes.kerberos.krb5.path\nspark.kubernetes.kerberos.tokenSecret.itemKey\nspark.kubernetes.kerberos.tokenSecret.name\nspark.mesos.driver.secret.envkeys\nspark.mesos.driver.secret.filenames\nspark.mesos.driver.secret.names\nspark.mesos.driver.secret.values\nspark.modify.acls\nspark.modify.acls.groups\nspark.network.crypto.config.*\nspark.network.crypto.enabled\nspark.network.crypto.saslFallback\nspark.network.sasl.serverAlwaysEncrypt\nspark.redaction.regex\nspark.redaction.string.regex\nspark.security.credentials.${service}.enabled\nspark.sql.redaction.options.regex\nspark.ssl.enabled\nspark.ssl.enabledAlgorithms\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.port\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.needClientAuth\nspark.ssl.port\nspark.ssl.protocol\nspark.ssl.standalone.enabled\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.port\nspark.ssl.standalone.protocol\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.port\nspark.ssl.ui.protocol\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.useNodeLocalConf\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.ui.strictTransportSecurity\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.ui.xContentTypeOptions.enabled\nspark.ui.xXssProtection\nspark.user.groups.mapping\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#response","title":"Response","text":"<pre><code>Values in ===manual=== but not in ===notebooklm===\nspark.yarn.shuffle.server.recovery.disabled\nValues in ===notebooklm=== but not in ===manual===\nhadoop.security.credential.provider.path\nspark.kerberos.access.hadoopFileSystems\nspark.kerberos.keytab\nspark.kerberos.principal\nspark.kubernetes.hadoop.configMapName\nspark.kubernetes.kerberos.krb5.configMapName\nspark.kubernetes.kerberos.krb5.path\nspark.kubernetes.kerberos.tokenSecret.itemKey\nspark.kubernetes.kerberos.tokenSecret.name\nspark.mesos.driver.secret.envkeys\nspark.mesos.driver.secret.filenames\nspark.mesos.driver.secret.names\nspark.mesos.driver.secret.values\nspark.redaction.regex\nspark.redaction.string.regex\nspark.security.credentials.${service}.enabled\nspark.sql.redaction.options.regex\nspark.ssl.useNodeLocalConf\n</code></pre> <p>Observation</p> <ol> <li>NotebookLM did not understand the concept of placeholder config parameters from the source documents. Since there are several config parameters per placeholder, it missed many config parameters (Attempt 1).</li> <li>When the prompt explained about placeholder config parameters, NotebookLM found all but 1 of the 79 configuration parameters related to security (Attempt 2).<ol> <li>NotebookLM found 18 config parameters related to security that were not found by humans as part of the expected answers and these appear to be valid configuration parameters related to security based on my review.</li> </ol> </li> <li>1 config parameter was not found by NotebookLM, and it's not obvious why: <code>spark.yarn.shuffle.server.recovery.disabled</code> </li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#chatgpt4o","title":"ChatGPT4o","text":""},{"location":"NotebookLM/NotebookLM_Config/#original-prompt_1","title":"Original Prompt","text":"<pre><code>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings\nUsing only the documentation of Apache Spark from the URLs below (and no other source), which configuration parameters are relevant from a security perspective?\n\nThe data sources are :\n1. https://spark.apache.org/docs/latest/configuration.html\n2. https://spark.apache.org/docs/latest/security.html\n</code></pre> <pre><code>[\n    \"spark.authenticate\",\n    \"spark.authenticate.secret\",\n    \"spark.authenticate.secret.file\",\n    \"spark.authenticate.secret.driver.file\",\n    \"spark.authenticate.secret.executor.file\",\n    \"spark.network.crypto.enabled\",\n    \"spark.network.crypto.config.*\",\n    \"spark.network.crypto.saslFallback\",\n    \"spark.authenticate.enableSaslEncryption\",\n    \"spark.network.sasl.serverAlwaysEncrypt\",\n    \"spark.io.encryption.enabled\",\n    \"spark.io.encryption.keySizeBits\",\n    \"spark.io.encryption.keygen.algorithm\",\n    \"spark.io.encryption.commons.config.*\",\n    \"spark.ui.allowFramingFrom\",\n    \"spark.ui.filters\",\n    \"spark.acls.enable\",\n    \"spark.admin.acls\",\n    \"spark.admin.acls.groups\",\n    \"spark.modify.acls\",\n    \"spark.modify.acls.groups\",\n    \"spark.ui.view.acls\",\n    \"spark.ui.view.acls.groups\",\n    \"spark.user.groups.mapping\",\n    \"spark.history.ui.acls.enable\",\n    \"spark.history.ui.admin.acls\",\n    \"spark.history.ui.admin.acls.groups\",\n    \"spark.ssl.enabled\",\n    \"spark.ssl.port\",\n    \"spark.ssl.enabledAlgorithms\",\n    \"spark.ssl.keyPassword\",\n    \"spark.ssl.keyStore\",\n    \"spark.ssl.keyStorePassword\",\n    \"spark.ssl.keyStoreType\",\n    \"spark.ssl.protocol\",\n    \"spark.ssl.needClientAuth\",\n    \"spark.ssl.trustStore\",\n    \"spark.ssl.trustStorePassword\",\n    \"spark.ssl.trustStoreType\",\n    \"spark.ui.xXssProtection\",\n    \"spark.ui.xContentTypeOptions.enabled\",\n    \"spark.ui.strictTransportSecurity\",\n    \"spark.kerberos.access.hadoopFileSystems\",\n    \"spark.security.credentials.${service}.enabled\"\n]\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#prompt-explaining-config-namespace-placeholders","title":"Prompt Explaining Config Namespace placeholders","text":"<pre><code>Note that Config Namespace placeholders are used for some security configurations. These are placeholders \"${ns}\" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: \"${ns}.enabled\", \"spark.ssl.enabled\" and \"spark.ssl.historyServer\" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns\n</code></pre> <pre><code>[\n    \"spark.ssl.enabled\",\n    \"spark.ssl.historyServer.enabled\",\n    \"spark.security.credentials.enabled\",\n    \"spark.ssl.port\",\n    \"spark.ssl.historyServer.port\",\n    \"spark.security.credentials.port\",\n    \"spark.ssl.enabledAlgorithms\",\n    \"spark.ssl.historyServer.enabledAlgorithms\",\n    \"spark.security.credentials.enabledAlgorithms\",\n    \"spark.ssl.keyPassword\",\n    \"spark.ssl.historyServer.keyPassword\",\n    \"spark.security.credentials.keyPassword\",\n    \"spark.ssl.keyStore\",\n    \"spark.ssl.historyServer.keyStore\",\n    \"spark.security.credentials.keyStore\",\n    \"spark.ssl.keyStorePassword\",\n    \"spark.ssl.historyServer.keyStorePassword\",\n    \"spark.security.credentials.keyStorePassword\",\n    \"spark.ssl.keyStoreType\",\n    \"spark.ssl.historyServer.keyStoreType\",\n    \"spark.security.credentials.keyStoreType\",\n    \"spark.ssl.protocol\",\n    \"spark.ssl.historyServer.protocol\",\n    \"spark.security.credentials.protocol\",\n    \"spark.ssl.needClientAuth\",\n    \"spark.ssl.historyServer.needClientAuth\",\n    \"spark.security.credentials.needClientAuth\",\n    \"spark.ssl.trustStore\",\n    \"spark.ssl.historyServer.trustStore\",\n    \"spark.security.credentials.trustStore\",\n    \"spark.ssl.trustStorePassword\",\n    \"spark.ssl.historyServer.trustStorePassword\",\n    \"spark.security.credentials.trustStorePassword\",\n    \"spark.ssl.trustStoreType\",\n    \"spark.ssl.historyServer.trustStoreType\",\n    \"spark.security.credentials.trustStoreType\",\n    \"spark.ssl.historyServer\",\n    \"spark.ssl.historyServer.historyServer\",\n    \"spark.security.credentials.historyServer\",\n    \"spark.authenticate\",\n    \"spark.authenticate.secret\",\n    \"spark.authenticate.secret.file\",\n    \"spark.authenticate.secret.driver.file\",\n    \"spark.authenticate.secret.executor.file\",\n    \"spark.network.crypto.enabled\",\n    \"spark.network.crypto.config.*\",\n    \"spark.network.crypto.saslFallback\",\n    \"spark.authenticate.enableSaslEncryption\",\n    \"spark.network.sasl.serverAlwaysEncrypt\",\n    \"spark.io.encryption.enabled\",\n    \"spark.io.encryption.keySizeBits\",\n    \"spark.io.encryption.keygen.algorithm\",\n    \"spark.io.encryption.commons.config.*\",\n    \"spark.ui.allowFramingFrom\",\n    \"spark.ui.filters\",\n    \"spark.acls.enable\",\n    \"spark.admin.acls\",\n    \"spark.admin.acls.groups\",\n    \"spark.modify.acls\",\n    \"spark.modify.acls.groups\",\n    \"spark.ui.view.acls\",\n    \"spark.ui.view.acls.groups\",\n    \"spark.user.groups.mapping\",\n    \"spark.history.ui.acls.enable\",\n    \"spark.history.ui.admin.acls\",\n    \"spark.history.ui.admin.acls.groups\",\n    \"spark.ui.xXssProtection\",\n    \"spark.ui.xContentTypeOptions.enabled\",\n    \"spark.ui.strictTransportSecurity\",\n    \"spark.kerberos.access.hadoopFileSystems\",\n    \"spark.security.credentials.${service}.enabled\"\n]\n``` &amp;#8203;:citation[oaicite:0]{index=0}&amp;#8203;\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer_2","title":"Compare The Answer With The Expected Answer","text":"<ol> <li>ChatGPT4o missed these 2 config placeholders (these were not provided in the example in the prompt - only the first and last one were provided)<ol> <li>spark.ssl.ui</li> <li>spark.ssl.standalone   </li> </ol> </li> <li>ChatGPT4o wrongly interpreted spark.security.credentials.${service}.enabled as being the same as ${ns} placeholder, and appended the parameters for ${ns} placeholder to spark.security.credentials.</li> </ol> <pre><code>{\n    \"manual_not_in_chatgpt4o\": [\n        \"spark.yarn.shuffle.server.recovery.disabled\",\n        \"spark.ssl.ui.enabled\",\n        \"spark.ssl.ui.port\",\n        \"spark.ssl.ui.enabledAlgorithms\",\n        \"spark.ssl.ui.keyPassword\",\n        \"spark.ssl.ui.keyStore\",\n        \"spark.ssl.ui.keyStorePassword\",\n        \"spark.ssl.ui.keyStoreType\",\n        \"spark.ssl.ui.protocol\",\n        \"spark.ssl.ui.needClientAuth\",\n        \"spark.ssl.ui.trustStore\",\n        \"spark.ssl.ui.trustStorePassword\",\n        \"spark.ssl.ui.trustStoreType\",\n        \"spark.ssl.standalone.enabled\",\n        \"spark.ssl.standalone.port\",\n        \"spark.ssl.standalone.enabledAlgorithms\",\n        \"spark.ssl.standalone.keyPassword\",\n        \"spark.ssl.standalone.keyStore\",\n        \"spark.ssl.standalone.keyStorePassword\",\n        \"spark.ssl.standalone.keyStoreType\",\n        \"spark.ssl.standalone.protocol\",\n        \"spark.ssl.standalone.needClientAuth\",\n        \"spark.ssl.standalone.trustStore\",\n        \"spark.ssl.standalone.trustStorePassword\",\n        \"spark.ssl.standalone.trustStoreType\"\n    ],\n    \"chatgpt4o_not_in_manual\": [\n        \"spark.security.credentials.enabled\",\n        \"spark.security.credentials.port\",\n        \"spark.security.credentials.enabledAlgorithms\",\n        \"spark.security.credentials.keyPassword\",\n        \"spark.security.credentials.keyStore\",\n        \"spark.security.credentials.keyStorePassword\",\n        \"spark.security.credentials.keyStoreType\",\n        \"spark.security.credentials.protocol\",\n        \"spark.security.credentials.needClientAuth\",\n        \"spark.security.credentials.trustStore\",\n        \"spark.security.credentials.trustStorePassword\",\n        \"spark.security.credentials.trustStoreType\",\n        \"spark.security.credentials.historyServer\",\n        \"spark.security.credentials.${service}.enabled\"\n    ]\n}\n</code></pre> <p>Observation</p> <ol> <li><code>spark.yarn.shuffle.server.recovery.disabled</code> was not found by ChatGPT4o (or NotebookLM).     </li> <li>ChatGPT4o found 44 parameters in the first prompt.</li> <li>When the concept of placeholder config parameters was explained in the second prompt, ChatGPT made 2 mistakes and thereby got many config parameters wrong<ol> <li>it did not extend the example to all the placeholder config parameters</li> <li>it appended the {ns} placeholder parameters to a different placeholder {service}</li> </ol> </li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#claude-sonnet-35","title":"Claude Sonnet 3.5","text":"<p>Note</p> <p>Claude Sonnet 3.5 Pro was used as both documents were too large for the free version.</p>"},{"location":"NotebookLM/NotebookLM_Config/#original-prompt_2","title":"Original Prompt","text":"<pre><code>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings\nUsing only the documentation of Apache Spark from the URLs below (and no other source), which configuration parameters are relevant from a security perspective?\n\nThe data sources are :\n1. https://spark.apache.org/docs/latest/configuration.html\n2. https://spark.apache.org/docs/latest/security.html\n</code></pre> <pre><code>Based on my analysis of the Apache Spark documentation, here is a JSON list of configuration parameters that are relevant from a security perspective:\n[\n\"spark.authenticate\",\n\"spark.authenticate.secret\",\n\"spark.network.crypto.enabled\",\n\"spark.network.crypto.saslFallback\",\n\"spark.authenticate.enableSaslEncryption\",\n\"spark.network.sasl.serverAlwaysEncrypt\",\n\"spark.io.encryption.enabled\",\n\"spark.io.encryption.keySizeBits\",\n\"spark.io.encryption.keygen.algorithm\",\n\"spark.ssl.enabled\",\n\"spark.ssl.keyStore\",\n\"spark.ssl.keyStorePassword\",\n\"spark.ssl.keyPassword\",\n\"spark.ssl.trustStore\",\n\"spark.ssl.trustStorePassword\",\n\"spark.ssl.protocol\",\n\"spark.ssl.enabledAlgorithms\",\n\"spark.ui.filters\",\n\"spark.acls.enable\",\n\"spark.admin.acls\",\n\"spark.admin.acls.groups\",\n\"spark.modify.acls\",\n\"spark.modify.acls.groups\",\n\"spark.ui.view.acls\",\n\"spark.ui.view.acls.groups\",\n\"spark.eventLog.enabled\",\n\"spark.eventLog.dir\",\n\"spark.history.kerberos.enabled\",\n\"spark.history.kerberos.principal\",\n\"spark.history.kerberos.keytab\",\n\"spark.kerberos.principal\",\n\"spark.kerberos.keytab\",\n\"spark.hadoop.security.authentication\",\n\"spark.yarn.security.tokens.hbase.enabled\",\n\"spark.yarn.security.tokens.hive.enabled\",\n\"spark.yarn.security.credentials.hadoop.enabled\",\n\"spark.redaction.regex\",\n\"spark.ui.proxyRedirectUri\",\n\"spark.driver.log.dfsDir\"\n]\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#prompt-explaining-config-namespace-placeholders_1","title":"Prompt Explaining Config Namespace placeholders","text":"<pre><code>Note that Config Namespace placeholders are used for some security configurations. These are placeholders \"${ns}\" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: \"${ns}.enabled\", \"spark.ssl.enabled\" and \"spark.ssl.historyServer\" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns\n</code></pre> <pre><code>I understand. Here's a revised JSON list of configuration parameters relevant from a security perspective, with namespace placeholders expanded and repeated patterns included:\n[\n\"spark.authenticate\",\n\"spark.authenticate.secret\",\n\"spark.network.crypto.enabled\",\n\"spark.network.crypto.saslFallback\",\n\"spark.authenticate.enableSaslEncryption\",\n\"spark.network.sasl.serverAlwaysEncrypt\",\n\"spark.io.encryption.enabled\",\n\"spark.io.encryption.keySizeBits\",\n\"spark.io.encryption.keygen.algorithm\",\n\"spark.ssl.enabled\",\n\"spark.ssl.ui.enabled\",\n\"spark.ssl.standalone.enabled\",\n\"spark.ssl.historyServer.enabled\",\n\"spark.ssl.keyStore\",\n\"spark.ssl.ui.keyStore\",\n\"spark.ssl.standalone.keyStore\",\n\"spark.ssl.historyServer.keyStore\",\n\"spark.ssl.keyStorePassword\",\n\"spark.ssl.ui.keyStorePassword\",\n\"spark.ssl.standalone.keyStorePassword\",\n\"spark.ssl.historyServer.keyStorePassword\",\n\"spark.ssl.keyPassword\",\n\"spark.ssl.ui.keyPassword\",\n\"spark.ssl.standalone.keyPassword\",\n\"spark.ssl.historyServer.keyPassword\",\n\"spark.ssl.trustStore\",\n\"spark.ssl.ui.trustStore\",\n\"spark.ssl.standalone.trustStore\",\n\"spark.ssl.historyServer.trustStore\",\n\"spark.ssl.trustStorePassword\",\n\"spark.ssl.ui.trustStorePassword\",\n\"spark.ssl.standalone.trustStorePassword\",\n\"spark.ssl.historyServer.trustStorePassword\",\n\"spark.ssl.protocol\",\n\"spark.ssl.ui.protocol\",\n\"spark.ssl.standalone.protocol\",\n\"spark.ssl.historyServer.protocol\",\n\"spark.ssl.enabledAlgorithms\",\n\"spark.ssl.ui.enabledAlgorithms\",\n\"spark.ssl.standalone.enabledAlgorithms\",\n\"spark.ssl.historyServer.enabledAlgorithms\",\n\"spark.ui.filters\",\n\"spark.acls.enable\",\n\"spark.admin.acls\",\n\"spark.admin.acls.groups\",\n\"spark.modify.acls\",\n\"spark.modify.acls.groups\",\n\"spark.ui.view.acls\",\n\"spark.ui.view.acls.groups\",\n\"spark.eventLog.enabled\",\n\"spark.eventLog.dir\",\n\"spark.history.kerberos.enabled\",\n\"spark.history.kerberos.principal\",\n\"spark.history.kerberos.keytab\",\n\"spark.kerberos.principal\",\n\"spark.kerberos.keytab\",\n\"spark.hadoop.security.authentication\",\n\"spark.yarn.security.tokens.hbase.enabled\",\n\"spark.yarn.security.tokens.hive.enabled\",\n\"spark.yarn.security.credentials.hadoop.enabled\",\n\"spark.redaction.regex\",\n\"spark.ui.proxyRedirectUri\",\n\"spark.driver.log.dfsDir\",\n\"spark.ssl.keyStoreType\",\n\"spark.ssl.ui.keyStoreType\",\n\"spark.ssl.standalone.keyStoreType\",\n\"spark.ssl.historyServer.keyStoreType\",\n\"spark.ssl.trustStoreType\",\n\"spark.ssl.ui.trustStoreType\",\n\"spark.ssl.standalone.trustStoreType\",\n\"spark.ssl.historyServer.trustStoreType\",\n\"spark.ssl.needClientAuth\",\n\"spark.ssl.ui.needClientAuth\",\n\"spark.ssl.standalone.needClientAuth\",\n\"spark.ssl.historyServer.needClientAuth\",\n\"spark.ui.allowFramingFrom\",\n\"spark.ui.xXssProtection\",\n\"spark.ui.xContentTypeOptions.enabled\",\n\"spark.ui.strictTransportSecurity\"\n]\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer_3","title":"Compare The Answer With The Expected Answer","text":"<pre><code>Values in ===manual=== but not in ===claude35===:\n\nspark.yarn.shuffle.server.recovery.disabled\nspark.authenticate.secret.file\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.network.crypto.config.*\nspark.io.encryption.commons.config.*\nspark.user.groups.mapping\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.ssl.port\nspark.ssl.ui.port\nspark.ssl.standalone.port\nspark.ssl.historyServer.port\n\nValues in ===claude35=== but not in ===manual===:\n\nspark.eventLog.enabled\nspark.eventLog.dir\nspark.history.kerberos.enabled\nspark.history.kerberos.principal\nspark.history.kerberos.keytab\nspark.kerberos.principal\nspark.kerberos.keytab\nspark.hadoop.security.authentication\nspark.yarn.security.tokens.hbase.enabled\nspark.yarn.security.tokens.hive.enabled\nspark.yarn.security.credentials.hadoop.enabled\nspark.redaction.regex\nspark.ui.proxyRedirectUri\nspark.driver.log.dfsDir\n</code></pre> <p>Observation</p> <ol> <li><code>spark.yarn.shuffle.server.recovery.disabled</code> was not found by Claude3.5 (or ChatGPT4o or NotebookLM).     </li> <li>Claude3.5 found 39 parameters in the first prompt.</li> <li>When the concept of placeholder config parameters was explained in the second prompt, Claude3.5 understood it.</li> <li>Claude3.5 found 14 parameters more than the human-generated answer, including several parameters that the other LLMs did not find.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM, ChatGPT4o and Claude3.5 Pro did reasonably well at extracting the config parameters related to security</li> <li>NotebookLM performed best, missing just 1, and finding 18 more than the human-generated answer.</li> <li>Claude3.5 found 79 parameters, missed 14, and found 14 more than the human-generated answer.</li> <li>ChatGPT 4o found 71 parameters.</li> <li>Overall, with everything-as-code (infrastructure, policy, LLM answers, ....), and LLMs being able to process code, there's a lot of benefit and promise in applying LLMs.</li> <li>The feedback to CoGuard is via https://github.com/coguardio/coguard_openai_rule_auto_generation_research/issues/2 </li> </ol>"},{"location":"NotebookLM/NotebookLM_Cwe/","title":"NotebookLM CWE","text":"<p>Overview</p> <p>In this chapter, we'll use NotebookLM to ingest the Common Weakness Enumeration (CWE) list. </p> <ul> <li>In the current version (CWE Version 4.14 2024-02-29 as at June 2024), there are over 1400 CWEs, and 2789 pages in the PDF version of the list. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the CWE document and ask questions, so that the information comes to us in the form of an answer. </p> <p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol> <p>Success</p> <p>This content and approach was presented to the CWE Root Cause Mapping Working Group mid July.</p> <p>The feedback was very positive!</p>"},{"location":"NotebookLM/NotebookLM_Cwe/#data-sources","title":"Data Sources","text":"<p>cwe_latest.pdf  from https://cwe.mitre.org/data/downloads.html has 2789 pages (version CWE Version 4.14 2024-02-29).</p> <ul> <li>This is too big for NotebookLM to ingest.</li> <li>So the PDF is split into 10 smaller PDFs of 280 pages each using this script.</li> <li>These 10 smaller PDFs are then ingested into NotebookLM.</li> </ul> <pre><code>pagesper=280 file=./data/NotebookLM_CweCapec/cwe_latest.pdf ./pdfsplit.sh  \n</code></pre> <p>Data Sources</p> <p>A copy of the original cwe_latest.pdf, and the 10 smaller PDFs it is split into, are available in https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_Cwe/</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#cwe-assigned-to-cve-2024-0042","title":"CWE assigned to CVE-2024-0042","text":"<p>I was reading a post on LinkedIn and the CWE assigned by CISA ADP looked wrong.</p> <p>So I used my NotebookLM CWE notebook, and other GPTs, to determine the appropriate CWE.</p> <p>I then raised an issue: https://github.com/cisagov/vulnrichment/issues/84.</p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-cwe-ids-are-associated-with-buffer-overflow","title":"what cwe ids are associated with buffer overflow?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o did not provide all the CWEs that NotebookLM did.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer-with-uploaded-cwe-document","title":"ChatGPT4o Answer with uploaded CWE document","text":"<p>ChatGPT4o required some additional prompting to provide a comparable list of CWEs to what NotebookLM gave.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-cwe-ids-are-associated-with-xss","title":"what cwe ids are associated with xss?","text":"The Sources sidebar is no longer shown in this and the following examples"},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-parent-weakness-or-cwe-for-xss-and-csrf","title":"what is the parent weakness or cwe for xss and csrf?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#what-are-the-different-types-of-xss","title":"what are the different types of xss?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer_1","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o provided the same types - but gave a much richer answer than NotebookLM did because it has access to a lot more documents on XSS.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-cwe-associated-with-cve-2021-27104-accellion-fta-os-command-injection-vulnerability","title":"what is the CWE associated with CVE-2021-27104 \"Accellion FTA OS Command Injection Vulnerability\"","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-cwe-associated-with-cve-2019-1653-cisco-small-business-rv320-and-rv325-routers-information-disclosure-vulnerability","title":"what is the CWE associated with CVE-2019-1653 \"Cisco Small Business RV320 and RV325 Routers Information Disclosure Vulnerability\"","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer_2","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o provided one CWE ID.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>I found it useful, quick, and convenient to be able to ask questions of the CWE list, as a compliment to the traditional search method I've used in the past.</li> <li>The large CWE document could not be uploaded to NoteBookLM as one PDF document, but had to be split into smaller PDFs.<ol> <li>The same document could be uploaded to ChatGPT4o (without splitting).</li> </ol> </li> <li>Based on the extremely limited test cases here (your experience may vary):<ol> <li>NoteBookLM provides better answers on the provided source documents.</li> <li>ChatGPT provides richer answers to questions that can be answered outside of the provided source documents.</li> </ol> </li> <li>The Vulnrichment chapter covers a much more detailed use case - and NoteBookLM performed better than other LLMs.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Secure_Code/","title":"NotebookLM Secure Code","text":"<p>Overview</p> <p>In two separate conversations recently, the topic of using LLMs for secure coding came up. One of the concerns that is often raised is that GenAI Code is not secure because GenAI is trained on arbitrary code on the internet.</p> <p>I was curious how NotebookLM would work for generating or reviewing secure code i.e. A closed system that has been provide a lot of guidance on secure code (and not arbitrary examples).</p> <p>Claude Sonnet 3.5 was also used for comparison.</p>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#vulnerability-types","title":"Vulnerability Types","text":"<p>Secure Programming with Static Analysis, classifies vulnerability types as follows:</p> <p></p> <p>LLMs go beyond understanding syntax to understanding semantics and may be effective in the 3 quadrants that traditional static analysis isn't.</p> <p>But in this simple test case below, the focus is on Generic defects visible in the code, as an initial proof of concept.</p>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#data-sources","title":"Data Sources","text":"<p>Two books I had on Java were loaded to NotebookLM:</p> <ol> <li>The CERT Oracle Secure Coding Standard for Java<ol> <li>The same material is available on https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java</li> </ol> </li> <li>Java Coding Guidelines: 75 Recommendations for Reliable and Secure Programs</li> </ol>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#test-data","title":"Test Data","text":"<p>NIST Software Assurance Reference Dataset (SARD) was used as the test dataset.</p> <p>Quote</p> <p>The Software Assurance Reference Dataset (SARD) is a growing collection of test programs with documented weaknesses. Test cases vary from small synthetic programs to large applications. The programs are in C, C++, Java, PHP, and C#, and cover over 150 classes of weaknesses.</p> <p>e.g. CWE: 191 Integer Underflow https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4</p>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#setup","title":"Setup","text":"<ol> <li>Import both PDFs into a new NotebookLM.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#test","title":"Test","text":""},{"location":"NotebookLM/NotebookLM_Secure_Code/#test-code-cwe-191-integer-underflow","title":"Test Code CWE: 191 Integer Underflow","text":"<p> https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4</p>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#review-test-code","title":"Review Test Code","text":"<p>Comments are removed from https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4 so the code fits in the prompt window.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Secure_Code/#claude-35","title":"Claude 3.5","text":""},{"location":"NotebookLM/NotebookLM_Secure_Code/#generate-code-write-secure-code-to-multiply-2-numbers","title":"Generate Code: Write Secure Code to Multiply 2 numbers","text":""},{"location":"NotebookLM/NotebookLM_Secure_Code/#use-biginteger-instead","title":"Use BigInteger Instead","text":""},{"location":"NotebookLM/NotebookLM_Secure_Code/#claude-35_1","title":"Claude 3.5","text":""},{"location":"NotebookLM/NotebookLM_Secure_Code/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM with 2 Secure Code Java references performed well in these simple test cases.</li> </ol>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/","title":"NotebookLM Vulnerability Standards","text":"<p>Overview</p> <p>In this chapter, we'll feed the main vulnerability standards to NotebookLM.</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#data-sources","title":"Data Sources","text":"<p>These files are available in docs/NotebookLM/InputDocs for convenience.</p> Content Page with link to content Direct Link Risk Based Prioritization Guide https://riskbasedprioritization.github.io/print_page/ Print - Save to PDF CVSS 3.1 User Guide https://www.first.org/cvss/v3.1/user-guide https://www.first.org/cvss/v3-1/cvss-v31-user-guide_r1.pdf CVSS 3.1 Specification https://www.first.org/cvss/v3.1/specification-document https://www.first.org/cvss/v3-1/cvss-v31-specification_r1.pdf CVSS 4.0 User Guide https://www.first.org/cvss/v4.0/user-guide https://www.first.org/cvss/v4-0/cvss-v40-user-guide.pdf CVSS 4.0 Specification Document https://www.first.org/cvss/v4.0/specification-document https://www.first.org/cvss/v4-0/cvss-v40-specification.pdf Exploit Prediction Scoring System (EPSS) FAQ https://www.first.org/epss/faq https://www.first.org/epss/faq Exploit Prediction Scoring System (EPSS) latest published paper https://www.first.org/epss/model https://arxiv.org/pdf/2302.14172 Stakeholder-Specific Vulnerability Categorization (SSVC) latest published paper https://github.com/CERTCC/SSVC/tree/main/pdfs https://github.com/CERTCC/SSVC/blob/main/pdfs/ssvc_2_1_draft.pdf CISA KEV https://www.cisa.gov/known-exploited-vulnerabilities copy and paste text to a file cisakev.txt because NotebookLM cannot pull content directly from the page <p>Data Sources</p> <p>The vulnerability standards PDFs are available in https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_VulnerabilityStandards</p> <p></p> The initial screen after the documents are loaded.CISA KEV was then loaded as a text file. <p>Quote</p> <p>write an introductory article in less than 250 words that gives an overview of all these sources and how they fit together</p> <p></p> <p>Each circled-number is a clickable link to the reference text in the original sources.</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#i-want-to-rank-vulnerabilities-by-exploitation","title":"I want to rank vulnerabilities by Exploitation","text":"<p>Quote</p> <p>I am currently using CVSS to rank vulnerabilities. I also want to rank based on exploitation as I heard only a small percentage of CVEs are actually exploited. What standard should I use. How should I use them. Provide an answer with rationale and examples.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#explain-risk-like-im-a-5-year-old","title":"Explain risk like I'm a 5 year old","text":"<p>Quote</p> <p>I want to prioritize vulnerabilities by risk. But I don't understand risk and the components or factors of risk. Can you explain that to me like I'm a 5 year old. Then explain how I can use that for my risk based prioritization approach. Please provide a rationale</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#cvss-base-parameters-for-cvss-v3-and-v4","title":"CVSS Base Parameters for CVSS v3 and v4","text":"<p>Quote</p> <p>what parameters contribute to the CVSS base parameter score? How do these parameters differ in CVSS 3 versus CVSS 4</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#chatgpt4o-response","title":"ChatGPT4o Response","text":"<p>Failure</p> <p>Hallucination Remediation Level (RL) is NOT part of the Exploitability Metrics</p> <p>Quote</p> <p>Remediation Level (RL): New metric considering how available and effective remediation methods are (Not Defined, Official Fix, Temporary Fix, Workaround, Unavailable).</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#chatgpt4o-check-response","title":"ChatGPT4o Check Response","text":""},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM does a good job assimilating these verbose standards and was competently able to answer specific factual questions, and broader opinionated questions.</li> <li>Lots of references to the source material were provided in the answers which help understand and validate the answers.</li> </ol>"},{"location":"TopicModeling/BertTopic/","title":"BERTopic","text":"<p>Overview</p> <p>Topic modeling can be used to discover the underlying themes and patterns in a collection of documents (e.g. CVE Descriptions, or CWE Descriptions,...).</p> <p>It is an unsupervised machine learning technique that\u2019s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize the set of documents.</p> <p>The output is collections of documents that the algorithm has grouped together, as well as clusters of words and expressions that it used to infer these relations.</p>"},{"location":"TopicModeling/BertTopic/#bertopic_1","title":"BERTopic","text":"<p>BERTopic is a topic modeling technique that leverages \ud83e\udd17 transformers and c-TF-IDF. In general, it outperforms other methods (statistical vs Language Model based) e.g. LSA, LDA. </p> <p>Quote</p> <p>Before diving into a classification task, text clustering allows for getting an intuitive understanding of the task but also of its complexity.</p> <p>BERTopic is a topic modeling technique that assumes that clusters of semantically similar documents are a powerful way of generating and describing clusters. The documents in each cluster are expected to describe a major theme and combined they might represent a topic.</p> <p>Extracts from book co-authored by BertTopic creator: https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/</p>"},{"location":"TopicModeling/BertTopic/#topic-model-cwes","title":"Topic Model CWEs","text":"<p>I've used BERTopic to Topic Model lots of datasets to quickly get an intuition for the data.</p> <p>In this example, we'll look at CWEs. </p> <ul> <li>Specifically, generate a Topic Model of the ~1400 CWEs in 1400 View, so we can better understand the underlying patterns and themes.</li> </ul> <p>I did this initially as part of a Linked Thread, to illustrate Topic Modeling as a solution, but also the ease and speed at which it could be done.</p>"},{"location":"TopicModeling/BertTopic/#code","title":"Code","text":"<p>Source Code</p> <p>The starting point code is deliberately chosen as unrelated to CyberSecurity: https://github.com/splevine/harnessing-nlp-cx-demo Mar 2024 (where this repo gives an excellent overview of NLP and BERTopic and SetFit).</p> <p>The main changes I made were:</p> <ol> <li>Don't use wandb (Weights and Balances) service as it was not needed for the demo</li> <li>Use the 1400 CWE view 1400.csv as the input Data</li> <li>Use SentenceTransformer(\"basel/ATTACK-BERT\") as the embedding_model so that CyberSecurity embeddings are used.</li> </ol> <p>The code and visualizations are available here: https://colab.research.google.com/drive/168i3oHekL4Cva2s2w01KMq6mnffDgxIS?usp=sharing No effort was made to optimize the topic modeling i.e. it was completely unsupervised.</p>"},{"location":"TopicModeling/BertTopic/#topic-model-of-the-1400-cwes-in-1400-view","title":"Topic Model of the ~1400 CWEs in 1400 View","text":"<p> The top level categorizations of CVE 1400 per https://cwe.mitre.org/data/definitions/1400.html.</p> <p> The Topic Model of 1400 CWE view 1400.csv with the top level categorizations overlayed in bold to allow comparison of the top level groupings assigned by MITRE and the Topic Modeling.</p> <p>Other visualizations are available in the Colab Notebook.</p>"},{"location":"TopicModeling/BertTopic/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>Topic Modeling with BERTopic is a powerful unsupervised learning approach to quickly and easily get an intuition for a set of documents.</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/","title":"CISA Vulnrichment","text":"<p>Overview</p> <p>An incorrect CWE assignment caught my eye while reading a post</p> <p>I was reading a post on LinkedIn and the CWE assigned by CISA ADP looked wrong so...</p> <ul> <li>I used my NotebookLM CWE notebook, and other LLMs, to determine the appropriate CWE.</li> <li>I then raised an issue: https://github.com/cisagov/vulnrichment/issues/84.</li> <li>I then decided to dig a bit more into this... specifically the CWEs assigned by CISA ADP.</li> </ul> <p>Using LLMs to find incorrect CWE assignments at scale</p> <p>I used langchain to create a consensus of LLMs to review all CWEs assigned by CISA ADP to find issues:</p> <ul> <li>These issues were found automatically by a consensus of 3 LLMs: (current state-of-the-art) ChatGPT4o, Gemini 1.5 Pro, Claude 3.5 Sonnet who were asked to review CWEs assigned to CVEs by CISA ADP.</li> <li> <p>The consensus output was then reviewed by a human (me).</p> </li> <li> <p>I created 3 Vulnrichment Github Issues initially and these were accepted by CISA Vulnrichment and resolved promptly!</p> </li> <li> <p>I then provided a report to CISA Vulnrichment for all CWEs that were incorrect based on the consensus.</p> </li> </ul> <p>Using LLMs to assign correct CWEs</p> <p>Finally, I showed how NotebookLM can be used for CWE assignment</p> <ul> <li>It avoids the problem of<ul> <li>training language models on bad data (existing CVE CWE assignments)</li> <li>training humans on the detailed CWE standard (though a basic understanding is still required)</li> </ul> </li> <li>NotebookLM did well in recommending a CWE given a CVE Description.... and providing a supporting CVE from the CWE Observed Examples in the CWE standard.<ul> <li>NotebookLM has a large context window which allows it to digest the large CWE standard, and it is source-grounded as described in the NotebookLM chapter.</li> <li>NotebookLM_Cwe describes how to create this NotebookLM for CWEs</li> </ul> </li> </ul> <p>The different approaches used (and the subscription plan used):</p> <ol> <li>code: <ol> <li>ChatGPT4o OpenAI Batch API (Plus Plan)</li> <li>langchain calling 2 LLMs via APIs: Gemini 1.5 Pro, Claude 3.5 Sonnet (ChatGPT4 or ChatGPT4o is also supported in the code (but commented out) if your plan supports that)</li> </ol> </li> <li>no-code using the browser chat interface is not shown here but it is useful for initial evaluation<ol> <li>Gemini 1.5 Pro (subscription)</li> <li>Claude 3.5 Sonnet (prepay)</li> </ol> </li> </ol> <p>Success</p> <p>The approach described here resulted in successfully identifying incorrectly assigned CWEs, and identifying the correct CWEs, and a report to CISA Vulnrichment.</p>"},{"location":"Vulnrichment/Vulnrichment/#consensus-of-3-llms","title":"Consensus of 3 LLMs","text":"<p>Source Code</p> <p>https://github.com/CyberSecAI/CWEMap</p>"},{"location":"Vulnrichment/Vulnrichment/#cisa-vulnrichment_1","title":"CISA Vulnrichment","text":"<p>Quote</p> <p>The CISA Vulnrichment project is the public repository of CISA's enrichment of public CVE records through CISA's ADP (Authorized Data Publisher) container. In this phase of the project, CISA is assessing new and recent CVEs and adding key SSVC decision points. Once scored, some higher-risk CVEs will also receive enrichment of CWE, CVSS, and CPE data points, where possible.</p> <p>https://github.com/cisagov/vulnrichment</p> <p>I have great admiration for CISA and their pragmatic initiatives like CISA KEV and SSVC and have spoken about them and applied them in production.</p> <p>Tip</p> <p>One of the many benefits of this Vulnrichment project is that feedback can be provided as GitHub issues and the team is VERY responsive \u2705  \ud83d\ude4c</p> <ul> <li>The 'Bug' label was assigned the same day to the 3 issues I submitted: https://github.com/cisagov/vulnrichment/issues?q=is%3Aissue+author%3ACrashedmind+is%3Aclosed.</li> <li>The changes were accepted and applied the next working day and a comment was added to the ticket which was then closed.</li> </ul> <p>My overall goal here was to </p> <ul> <li>Show that LLMs could augment human analysts where vulnerability enrichment today is largely done manually.</li> <li>Show how to use them for this purpose.</li> <li>Get people to use LLMs to improve the quality of the CVE data in general, and in this specific example case, the CWE data.</li> <li>Maximize the value of the CISA ADP data and enrichment by improving CWE-assignment quality.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#get-cves-enriched-by-cisa-adp","title":"Get CVEs Enriched by CISA ADP","text":""},{"location":"Vulnrichment/Vulnrichment/#approach-to-using-language-models","title":"Approach to using Language Models","text":"<ul> <li>All CVE Descriptions and assigned CWEs were sent to all 3 LLMs.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#dont-train-a-model-on-bad-data","title":"Don't Train A Model On Bad Data!","text":"<p>It is possible to train a Language Model as a Classifier to assign CWEs to a CVE - and there are several research papers that took that approach e.g.</p> <ul> <li>V2W-BERT: A Framework for Effective Hierarchical Multiclass Classification of Software Vulnerabilities </li> <li>Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses</li> </ul> <p>The problems with this approach:</p> <ol> <li> <p>It's delusional based on my research and experience of incorrect assigned CWEs in general - Garbage In Garbage Out</p> <ol> <li>Per Steve Christey Coley, CWE tech lead: </li> </ol> <p>Quote</p> <p>There has been significant interest in using AI/ML in various applications to use and/or map to CWE, but in my opinion there are a number of significant hurdles, e.g. you can't train on \"bad mappings\" to learn how to do good mappings.</p> </li> <li> <p>It removes a lot of the context that could be available to an LM by reducing the reference target down to a set of values or classes (for the given input CVE Descriptions)</p> </li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#train-on-good-data-and-the-full-standard","title":"Train on Good Data and the Full Standard","text":"<p>We can \"train\" on \"good mappings\".</p> <ol> <li>The CWE standard includes known \"good mappings\" e.g. CWE-917 Observed Examples includes CVE-2021-44228 and its Description.<ol> <li>The count of these CVE Observed Examples varies significantly per CWE. </li> <li>There's ~3000 CVE Observed Examples in the CWE standard.</li> </ol> </li> <li>We can use the full CWE standard and associated known good CVE assignments in the standard (CVE Observed Examples for a given CWE) as the target, allowing an LLM to compare the CVE Description (and other data) to this.<ol> <li>And moreover, prompt the LLM to provide similar CVEs to support its rationale for the CWE assignment</li> </ol> </li> </ol> <p>Tip</p> <p>Rather than train a model on bad data, we can ask a model to assign / validate a CWE based on its understanding of the CWEs available (and its understanding of CWEs assigned to similar CVEs based on the Observed Examples for each CWE in the standard)</p> <p>We can use a Closed or Open Model:</p> <ol> <li>a closed-model with access to the CWE specification only (and no other data) e.g. NotebookLM</li> <li>an open-model with access to the CWE specification and other data</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#what-to-ask-the-llms","title":"What to ask the LLMs?","text":"<p>Different approaches are possible when providing the CVE Description to the LLM:</p> <ol> <li>provide the CWE assigned as part of the CVE, and ask the LLM if it agrees or not, and only if not, why<ol> <li>This reduces the output token count/cost by only outputting the verbose rationale in case of disagreement</li> </ol> </li> <li>ask the LLM to assign one or more CWEs, with rationale</li> </ol> <p>The first approach is easier and simpler and cheaper (in terms of token use i.e. shorter response output), and better as a first pass option to get the low hanging fruit.</p> <p>The second approach could be used at the time of CWE assignment to get a second opinion.</p>"},{"location":"Vulnrichment/Vulnrichment/#consensus","title":"Consensus","text":"<p>To minimize human effort, 3 LLMs are used and the consensus is reviewed</p> <ul> <li>The LLMs are state-of-the-art models from different providers i.e. the best available and reasonably independent.</li> <li>The results are sorted by consensus i.e. 3 models in agreement, then 2 models in agreement,.... and by the LLM's confidence in their responses</li> <li>A Human (me) then reviewed (sorted by consensus and confidence) and made the final decision.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#recipe","title":"Recipe","text":"<ol> <li>Get the Vulnrichment subset of CVEs where CISA ADP assigned a CWE (regardless of whether the CWE was the same or different than that assigned by the CNA) into a sheet/CSV file.<ol> <li>~1.8K (CISA ADP Assigned CWEs) of ~~10K CVEs (in Vulnrichment)</li> </ol> </li> <li>As a dry-run submit e.g. 50 CVE Descriptions, CWEs to each of the 3 LLMs to review via the chat UI in one prompt</li> <li>Ask ChatGPT4o (via Batch API) to Agree (Yes/No) with the assigned CWE (and provide a Confidence score, and rationale if not)<ol> <li>Sort these by Confidence score i.e. start with the highest Confidence ones.</li> </ol> </li> <li>Assign the same task to Gemini and Claude via APIs driven by langchain</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#create-a-prompt","title":"Create a Prompt","text":""},{"location":"Vulnrichment/Vulnrichment/#chat-interface-table-output","title":"Chat Interface - Table Output","text":"<pre><code>caption_system_prompt =\nYou are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.\nYour goal is is to say if you Agree with the assigned CWE ID or not.\nYou will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.\n\nPlease provide the response in a table 'cve_id', 'CWE_ID', 'Agree'. \"Rationale\", Confidence' where\n1. Agree: string // Yes or No\n2. Rationale: string // Only if you do not Agree, provide a rationale why not\n3. Confidence: string // a confidence score between 0 and 1\n</code></pre> <p>The table output allows copy-and-pasting by a human into a sheet.</p> <p>The prompt consists of these parts:</p> <ol> <li>Role + Task: which is the same for the Chat and API interface</li> <li>Output format: which is different for the Chat and API interface</li> <li>A binary value Agree is requested</li> <li>The rationale only if there is disagreement. This saves on output tokens.</li> <li>A Confidence score to limit impacts of hallucinations, and as a way to assess and prioritize responses by confidence.</li> <li>No (Few-shot) examples are provided. Based on the results, these were not necessary.<ol> <li>If Few-shot examples were required, I'd submit multiple CVEs in a single batch request (because putting the examples in each single CVE request would add a LOT of input tokens)</li> </ol> </li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#batch-api-interface-json-output","title":"Batch API Interface - JSON Output","text":"<p><pre><code>caption_system_prompt =\nYou are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.\nYour goal is is to say if you Agree with the assigned CWE ID or not.\nYou will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.\n\nYou will output a json object containing the following information:\n{\n    Agree: string // Yes or No\n    Rationale: string // Only if you do not Agree, provide a rationale why not\n    Confidence: string // a confidence score between 0 and 1\n}\n</code></pre> The JSON output allows processing by machines.</p> <p>Use JSON Mode</p> <p>ChatGPT and Gemini 1.5 support JSON mode that always outputs valid JSON. Use it!</p> <ul> <li>See details of Latest Gemini features support in LangChain4j 0.32.0.</li> </ul> <p>While you can prompt an LLM to output JSON, it may not always output valid JSON and you're left with a cleanup exercise (a friend of mine had that experience when they first tried this \ud83d\ude09)</p> <p>Claude doesn't have a formal \"JSON Mode\" though, in my usage, it always produced valid JSON.</p> <p>Tip</p> <p>It is possible to submit multiple CVEs in one prompt for each batch entry i.e. similar to what is done when using the Chat interface.</p> <ul> <li>This is what is done here. 10 CVE CWE assignments are sent per batch (though the OpenAI Batch API example contains 1 entry only)</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#llms","title":"LLMs","text":""},{"location":"Vulnrichment/Vulnrichment/#gemini-15-pro-api-via-langchain","title":"Gemini 1.5 Pro API via Langchain","text":"<p>The API interface (via Langchain) was used in this example submitting multiple CVEs in one prompt.</p>"},{"location":"Vulnrichment/Vulnrichment/#claude-35-sonnet-api-via-langchain","title":"Claude 3.5 Sonnet API via Langchain","text":""},{"location":"Vulnrichment/Vulnrichment/#model","title":"Model","text":"<p>Currently: Claude 3.5 Sonnet was used as it has the best performance vs cost for Claude models.</p> <p> https://docs.anthropic.com/en/docs/welcome </p>"},{"location":"Vulnrichment/Vulnrichment/#interface","title":"Interface","text":"<p>Currently: Claude does not support a native Batch API interface - though  Amazon Bedrock supports batching of prompts to models including Claude.</p> <p>The API interface (via Langchain) was used in this example submitting multiple CVEs in one prompt.</p>"},{"location":"Vulnrichment/Vulnrichment/#chatgpt4o-batch-api","title":"ChatGPT4o Batch API","text":""},{"location":"Vulnrichment/Vulnrichment/#model_1","title":"Model","text":"<p>gpt-4o</p>"},{"location":"Vulnrichment/Vulnrichment/#plan","title":"Plan","text":"<p>The Plus plan subscription was used.</p> <p>Quote</p> <p>There are some restrictions:</p> <ul> <li>The file can contain up to 50,000 requests.</li> <li>The file cannot be more than 100 MB in size.</li> </ul> <p>Enqueued token limit reached for gpt-4o in organization XYZ. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.'</p>"},{"location":"Vulnrichment/Vulnrichment/#interface_1","title":"Interface","text":"<p>Batch Interface API.</p> <p>The ~1800 ADP CVE-CWE pairs were split into 15 files of 100 CVE-CWE pair prompts to comfortably fit under this token limit.</p> <ul> <li>very little effort was spent to optimize the file size (number of prompts per batch), or the prompt size.</li> <li>The cost to process the ~1800 ADP CVE-CWE pairs: ~$2.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#observations","title":"Observations","text":""},{"location":"Vulnrichment/Vulnrichment/#leak","title":"Leak","text":"<p>Several CVE Descriptions that include \"leak\" were incorrectly assigned \"CWE-200 Exposure of Sensitive Information to an Unauthorized Actor\".</p> <p>These were actually resource leaks (memory, program objects like handles etc...), not leakage of sensitive data.</p>"},{"location":"Vulnrichment/Vulnrichment/#gemini-15-pro-hallucinations","title":"Gemini 1.5 Pro Hallucinations","text":"<p>Failure</p> <p>From a sample of 30 assigned CWEs, Gemini 1.5 Pro had 3 hallucinations when asked to provide a rationale for its response (response text shown below, with hallucination in bold).</p> <p>Quote</p> <ol> <li>While CWE-400 (Uncontrolled Resource Consumption) could be a potential consequence, the core issue described in the CVE is about improper handling of the Python crash handler within a chroot environment. This misconfiguration could allow an attacker to potentially escape the chroot and execute code in the context of the Apport process.  A more appropriate CWE might be CWE-247 (Improper Handling of Chroot Environments) or CWE-22 (Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')).<ol> <li>CWE-247: DEPRECATED: Reliance on DNS Lookups in a Security Decision</li> <li>CWE-243: Creation of chroot Jail Without Changing Working Directory is the closest to \"Improper Handling of Chroot Environments\"</li> </ol> </li> <li>The assigned CWE-436 (Unspecified Encoding or Escaping of Output) doesn't fit well. The description argues that the plugin itself doesn't handle file uploads, making it a matter of what WordPress allows to be uploaded. If the core WordPress installation doesn't prevent polyglot files, it's not directly the plugin's fault. A more suitable CWE might be CWE-284 (Improper Access Control) if the plugin fails to restrict access to already uploaded polyglot files, allowing unauthorized viewing or download.<ol> <li>CWE-116 is the correct CWE: CWE-116: Improper Encoding or Escaping of Output</li> </ol> </li> <li>While CWE-57 (Relative Path Traversal) could be a factor in exploiting this vulnerability, the description more directly aligns with CWE-664: Improper Control of File Deletion or Renaming Operations. The vulnerability allows attackers to delete arbitrary files, which is the core characteristic of CWE-664. Relative path traversal might be a means to reach different files, but the primary issue is the improper control over file deletion.<ol> <li>CWE-664 correct title is CWE-664: Improper Control of a Resource Through its Lifetime</li> </ol> </li> </ol> <p>Tip</p> <p>While Gemini 1.5 Pro is the backend for NotebookLM, no hallucinations were detected in NotebookLM (the benefit of a source-grounded closed system).</p>"},{"location":"Vulnrichment/Vulnrichment/#notebooklm","title":"NotebookLM","text":"<p>NotebookLM works very well for suggesting a relevant CWE for a given CVE Description (or reviewing an assigned CWE)</p> <ul> <li>It suggests related CVEs to support the CWE it suggests (sometimes prompting is required). These CVEs are part of the \"Observed Examples\" CVEs that are listed under a CWE in the CWE standard.</li> <li>The numbered grey circles in the diagram below are links to references from the CWE standard.</li> </ul> <p> CVE-2024-35059</p> <p> CVE-2023-49224</p> <p>Note</p> <p>The NotebookLM prompts above are deliberately not applying prompt engineering principles to show that NotebookLM still provides a useful response.</p>"},{"location":"Vulnrichment/Vulnrichment/#refinements","title":"Refinements","text":"<p>Note: Some refinements are possible, but were not implemented in this first pass to minimize Time-To-Value</p> <ol> <li>The full CWE standard was used here for illustration purposes (and to take on the harder problem of a large specification)<ol> <li>A subset of CWEs could be used if that is desired. </li> <li>In practice, several hundred CWEs are assigned to CVEs.</li> </ol> </li> <li>The text from the references in the CVE \"References to Advisories, Solutions, and Tools\" was not retrieved and fed to the LLM as part of the CVE Description for CWE review or assignment.<ol> <li>These references were reviewed manually (for the consensus of incorrect CWE assignments)</li> <li>In some cases, this has additional text available that can inform the CWE assignment beyond the CVE Description alone</li> <li>It is relatively easy to retrieve this content automatically but this content varies significantly by type (text, image, pdf), quality, structure.</li> <li>Separately, it is common that these links break because the original website or post is removed, or it's not in the latest version in Github,... - so it would be useful to have the extracted text at the time of CWE assignment.  </li> </ol> </li> <li>Additional known good CVE descriptions and CWE assignments could be incorporated into the corpus, to augment the limited CVE observed examples that are part of the CWE standard.</li> <li>Reducing the set of CWEs to the desired population, or providing guidance in the prompt on what CWEs to use (e.g. \"don't use CWE's marked as Discouraged\")</li> <li>As I was interested in comparing LLM responses, I did not optimize the LLM usage (all LLMs were fed all CVE-CWEs)<ol> <li>This can be done in several ways e.g. <ol> <li>Ask each LLM in turn to review the previous assessments by LLMs</li> <li>Sampling</li> </ol> </li> </ol> </li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li> <p>The value of CVE data depends on its quality. </p> <ol> <li>For all published CVEs to date, the quality of CWEs assigned is questionable.</li> <li>A large part of that is that humans can't grok 1000+ CWEs. LLMs can.</li> </ol> </li> <li> <p>Using LLMs to suggest or validate CWEs can reduce the manual effort and error in CWE assignment.</p> </li> <li>LLMs can validate CWEs at scale e.g. using Batch mode, or multiple CVEs per prompt, or both.</li> <li>LLMs perform well at this task and, given they can be automated, can augment the human manual effort, and improve the quality of assigned CWEs.</li> <li>Langchain makes it easier to have generic code that works across multiple LLMs.</li> <li>LLM JSON Mode should be used where possible to reduce bad JSON output and subsequent cleanup.</li> <li>Based on a manual review of the subset where all 3 LLMs disagreed with the CWE assignment, &gt; 75% of these CWEs were incorrect (and a report with these was submitted to CISA Vulnrichment)<ol> <li>I did not dig into the subset where 2 of 3 LLMs disagreed.</li> </ol> </li> <li>Using LLMs to suggest or validate CWEs can reduce the manual effort and error in CWE assignment.</li> <li>A closed-system that is grounded on the CWE standard only e.g. NotebookLM, performs very well for assigning CWEs, or reviewing assigned CWEs (though it does not have an API so can't do this at scale), and no hallucinations were observed.</li> </ol>"},{"location":"annex/Glossary/","title":"Glossary","text":"<p>~: shorthand for \"approximately\"</p> <p>~~: shorthand for \"very approximately\"</p>"},{"location":"annex/Learning/","title":"Learning","text":""},{"location":"annex/Learning/#books","title":"Books","text":"<ul> <li>AI Agents in Action, Publication in Early 2025 (estimated)</li> <li>Prompt Engineering in Practice, Publication in Spring 2025 (estimated)</li> <li>LLMs in Production From language models to successful products</li> <li>AI Apps with LangChain </li> <li>Natural Language Processing in Action, 2nd ed.</li> <li>Data Storytelling with Generative AI using Altair and Python</li> <li>langchain in your pocket</li> </ul>"},{"location":"introduction/Introduction/","title":"Introduction","text":"<p>About this Guide</p> <p>This guide is in an initial early access state currently and is written to organize my play time as I play with, and apply, these tools.</p> <p>The content is about solving real problems e.g. how to </p> <ul> <li>view the main topics in a set of documents</li> <li>validate assigned CWEs, and suggest CWEs to assign </li> <li>chat with large documents </li> <li>extract configuration parameters from user manuals.</li> </ul> <p>These examples were driven by a user need. </p> <p>While the examples focus on specific areas, they can be applied in general to many areas.</p> <p>After reading this guide you should be able to</p> <ol> <li>Apply Language Models to augment and amplify your skills.</li> <li>Understand the types of problems that suit Language Models, and those that don't</li> </ol>"},{"location":"introduction/Introduction/#overview","title":"Overview","text":""},{"location":"introduction/Introduction/#intended-audience","title":"Intended Audience","text":"<p>The intended audience is people wanting to go beyond the hype and basics of Large Language Models.</p> <p>No prior knowledge is assumed to read the guide - it provides just enough information to understand the advanced topics covered.</p> <p>A basic knowledge of Jupyter Python is required to run the code (with the data provided or on your data).</p>"},{"location":"introduction/Introduction/#how-to-use-this-guide","title":"How to Use This Guide","text":""},{"location":"introduction/Introduction/#how-to-contribute-to-this-guide","title":"How to Contribute to This Guide","text":"<p>You can contribute content or suggest changes:</p> <ul> <li>\ud83d\udcac Discuss content</li> <li>\ud83d\udca1 Suggest content</li> <li>\ud83e\udeb2 Report Errors, typos</li> </ul>"},{"location":"introduction/Introduction/#writing-style","title":"Writing Style","text":"<p>The \"writing style\" in this guide is succinct, and leads with an opinion, with data and code to back it up i.e. data analysis plots (with source code where possible) and observations and takeaways that you can assess - and apply to your data and environment. This allows the reader to assess the opinion and the code/data and rationale behind it.</p> <p>Different, and especially opposite, opinions with the data to back them up, are especially welcome! - and will help shape this guide.</p> <p>Quote</p> <p>If we have data, let\u2019s look at data. If all we have are opinions, let\u2019s go with mine.</p> <p>Jim Barksdale, former CEO of Netscape </p>"},{"location":"introduction/Introduction/#notes","title":"Notes","text":"<p>Notes</p> <ol> <li>This guide is not affiliated with any Tool/Company/Vendor/Standard/Forum/Data source. <ol> <li>Mention of a vendor in this guide is not a recommendation or endorsement of that vendor. </li> </ol> </li> <li>This guide is a living document i.e. it will change and grow over time - with your input.</li> </ol> <p>This guide is not about which tool is better than the other</p> <p>\"Don't fall in love with models: they're expendable. Fall in love with data!\" </p> <p>Julien Simon, Chief Evangelist, Hugging Face</p> <p>Warning</p> <p>You are responsible for your data and where it goes. </p> <p>If you don't understand where your data goes, and what happens to it for a given model or tool, then find out before you use private or personal data.</p> <p>To evaluate models and tools, you can start with public data.</p>"},{"location":"introduction/Preface/","title":"Preface","text":"<p>Language Models are powerful tools that can be applied to CyberSecurity.</p> <p>I enjoy learning about, playing with, and applying these tools to better solve problems:</p> <ul> <li>I wrote this guide for me, to organize my thoughts and my play time as I play with, and apply, Language Models.</li> <li>I've found by putting something out there, you get something back.</li> <li>It's the guide I wish existed already.</li> </ul> <p>This approach worked well for the Risk-Based Prioritization guide...</p> <p>You may find it useful.</p> <p>Chris Madden</p>"},{"location":"prompt_engineering/Fabric/","title":"Fabric","text":"<p>Overview</p> <p>One of Fabric's primary features is helping people collect and integrate prompts</p>"},{"location":"prompt_engineering/Fabric/#fabric-prompt-collection-and-framework","title":"Fabric Prompt Collection and Framework","text":"<p>https://github.com/danielmiessler/fabric/tree/main </p> <p>Quote</p> <p>Since the start of 2023 and GenAI we've seen a massive number of AI applications for accomplishing tasks. It's powerful, but it's not easy to integrate this functionality into our lives.</p> <p>In other words, AI doesn't have a capabilities problem\u2014it has an integration problem. Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.</p> <p>One of fabric's primary features is helping people collect and integrate prompts, which we call Patterns, into various parts of their lives.</p> <p>The prompts (aka Patterns) are available at https://github.com/danielmiessler/fabric/tree/main/patterns</p>"},{"location":"prompt_engineering/Fabric/#fabric-prompts-for-cybersecurity","title":"Fabric Prompts for CyberSecurity","text":"<p>Fabric has Prompts that are specific to CyberSecurity e.g.</p> <ul> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/create_threat_model/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_logs/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_malware/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report_trends/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/write_hackerone_report/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/write_semgrep_rule/system.md </li> </ul>"},{"location":"prompt_engineering/Fabric/#fabric-prompt-to-improve-prompts","title":"Fabric Prompt to Improve Prompts","text":"<p>https://github.com/danielmiessler/fabric/blob/main/patterns/improve_prompt/system.md</p>"},{"location":"prompt_engineering/Fabric/#fabric-extract-wisdom","title":"Fabric Extract Wisdom","text":"<p>We'll take Goldman Sachs, Top of Mind, Gen AI: Too Much Spend, Too Little Benefit?, June 2024 as the example content to extract wisdom from. It's a 30 page report that is dense and varied.</p> <p>Below the summary by Claude 3.5 Sonnet using the extract_article_wisdom prompt.   </p> <pre><code>SUMMARY\nGoldman Sachs analyzes AI's economic impact, discussing potential benefits, challenges, and investment implications in their \"Top of Mind\" report.\n\nIDEAS\n\nAI could increase US productivity by 9% and GDP growth by 6.1% over the next decade.\nThe current AI investment boom may be unsustainable, with potential for a market correction.\nPower demand from AI data centers could lead to a significant energy crunch in the coming years.\nAI's economic impact may be more limited than many expect, with only 4.6% of tasks potentially automated within a decade.\nThe semiconductor industry faces supply constraints that could limit AI growth in the near term.\nUtilities companies are emerging as unexpected beneficiaries of the AI boom due to increased power demand.\nAI technology may struggle to replicate human cognitive abilities, limiting its transformative potential.\nThe cost of AI infrastructure is currently high, raising questions about return on investment.\nAI's impact on corporate profitability will be crucial for long-term equity returns.\nThe AI theme in the stock market may have room to run despite recent gains.\nData centers could consume up to 8% of total US power demand by 2030.\nAI development is outpacing the ability of power infrastructure to support it.\nThe US may struggle to build the necessary infrastructure to support AI growth.\nAI spending by tech giants is not seen as irrational exuberance by some analysts.\nThe AI investment cycle is still in the infrastructure buildout phase, with applications yet to emerge.\nEuropean power demand could increase by 40-50% over the next decade due to AI and electrification.\nAI data centers can consume up to 10 times more energy than traditional data centers.\nThe US utility industry has not experienced significant load growth in almost two decades.\nAI chip demand is outstripping supply, particularly for High-Bandwidth Memory technology.\nThe pace of AI model improvements may be slower than many anticipate.\n\nQUOTES\n\n\"Given the focus and architecture of generative AI technology today... truly transformative changes won't happen quickly and few\u2014if any\u2014will likely occur within the next 10 years.\" - Daron Acemoglu\n\"AI technology is exceptionally expensive, and to justify those costs, the technology must be able to solve complex problems, which it isn't designed to do.\" - Jim Covello\n\"Spending is certainly high today in absolute dollar terms. But this capex cycle seems more promising than even previous capex cycles.\" - Kash Rangan\n\"The devil is ultimately in the details. So, I don't have a strong prior as to how much of the current investment boom will be wasted vs. productive. But I expect both will happen.\" - Daron Acemoglu\n\"Until we reach a level of saturation in terms of human capacity to consume data, any amount of efficiency gains will undoubtedly be gobbled up by even more demand.\" - Brian Janous\n\"The risk that our children or grandchildren in 2074 accuse us of moving too slowly in 2024 at the expense of growth seems far lower than the risk that we end up moving too quickly and destroy institutions, democracy, and beyond in the process.\" - Daron Acemoglu\n\"I'm loathe to use the word 'bubble' because I don't believe that AI is a bubble, but most bubbles in history ended either because the cost of capital changed dramatically or end-demand deteriorated and affected companies' ability to deploy capital, not because companies retreated from investing in a technology where the payoff was taking longer than expected.\" - Eric Sheridan\n\"Utilities have not experienced a period of load growth in almost two decades and are not prepared for\u2014or even capable of matching\u2014the speed at which AI technology is developing.\" - Brian Janous\n\"The US has unfortunately lost the ability to build large infrastructure projects\u2014this is a task better suited for 1930s America, not 2030s America.\" - Brian Janous\n\"Every human invention should be celebrated, and generative AI is a true human invention. But too much optimism and hype may lead to the premature use of technologies that are not yet ready for prime time.\" - Daron Acemoglu\n\nFACTS\n\nData centers currently account for only about 1% of global power demand.\nThe US utility industry has not experienced significant load growth in almost two decades.\n60% of workers today are employed in occupations that did not exist in 1940.\nThe US corporate profit share of GDP is near its highest levels since World War II.\nNorthern Virginia is home to the most data centers in the US.\nCommercial power consumption in Virginia rose 37% from 2016 to 2023.\nAI data centers can consume up to 10 times more energy than traditional data centers.\nThe average power usage effectiveness (PUE) of cloud data centers declined by only 0.2 over the course of a decade.\nWait times for power projects to connect to the grid currently range from 40-70 months.\nThe High-Bandwidth Memory market is expected to grow at a ~100% compound annual growth rate over the next few years.\nThe S&amp;P 500 Shiller P/E ratio is currently in the 97th percentile since 1900.\nUtilities returned 16% between March and May, making them the best-performing sector in the S&amp;P 500.\nEuropean electricity consumption has declined by around 10% from its 2008 peak.\nTSMC's Chip-on-Wafer-on-Substrate packaging capacity is expected to more than double in 2024.\nThe US is expected to add nearly 800 gigawatts of wind and solar over the coming 10-15 years.\n\nREFERENCES\n\nChatGPT\nGlobal Macro Research by Goldman Sachs\nMIT's Daron Acemoglu's research\nJim Covello's analysis\nJoseph Briggs' economic forecasts\nKash Rangan and Eric Sheridan's market analysis\nBrian Janous' insights on power infrastructure\nCarly Davenport's utility sector analysis\nToshiya Hari, Anmol Makkar, and David Balaban's semiconductor industry research\nRyan Hammond's equity market analysis\nChristian Mueller-Glissmann's long-term return forecasting framework\nAlberto Gandolfi's European utilities analysis\nHongcen Wei's power consumption analysis\nDavid Autor's research on technological innovation and employment\nRobert Shiller's P/E ratio data\nEIA (Energy Information Administration) data\nCensus Bureau data\nFactSet financial data\nTSMC's capacity projections\nREPowerEU Plan\n\nRECOMMENDATIONS\n\nInvestors should remain invested in AI infrastructure providers despite high valuations.\nUtilities companies should find ways to extract more efficiencies from the current power system.\nPolicymakers should focus on investing in America's transmission infrastructure.\nCompanies should tie AI spending to visible revenue growth to maintain investor confidence.\nInvestors should consider \"Electrification Compounders\" in the utilities sector as potential beneficiaries of AI growth.\nThe US should prioritize expanding long-duration energy storage to meet growing power demand.\nTech companies should prepare for potential power constraints when planning AI infrastructure.\nInvestors should monitor the emergence of AI's \"killer application\" as a sign of the technology's maturity.\nPolicymakers should address regulatory lags and interconnection constraints in the power sector.\nCompanies should be cautious about premature use of AI technologies that are not yet fully developed.\nInvestors should watch for signs of corporate profitability decline as a potential trigger for reduced AI spending.\nThe semiconductor industry should focus on expanding High-Bandwidth Memory and advanced packaging capacity.\nUtilities should prepare for a potential doubling of grid capacity in some regions over the next decade.\nInvestors should consider the impact of AI on corporate profitability when assessing long-term equity returns.\nPolicymakers should balance the need for AI innovation with potential risks to institutions and democracy.\n</code></pre>"},{"location":"prompt_engineering/Fabric/#process-youtube-transcripts","title":"Process Youtube Transcripts","text":"<p>Fabric, and LLMs in general, can process Youtube Transcripts (which are text).</p> <p>The Youtube Transcript for a video can be retrieved in different ways e.g. https://www.youtube.com/watch?v=oMZN810xfck:</p> <ul> <li>Click the Transcript button under a video and copy and paste, or download, to a text file</li> <li>Use Fabric helper function: installer/client/cli/yt.py (or other tool)</li> </ul> <p><pre><code>yt --transcript https://www.youtube.com/watch?v=oMZN810xfck\n</code></pre> The text can then be processed with an LLM.</p> <p>This download and processing can be done in one command with Fabric <pre><code>yt --transcript https://www.youtube.com/watch?v=oMZN810xfck | fabric -sp extract_wisdom\n</code></pre> where</p> <ul> <li>-s is for streaming</li> <li>-p is for pattern</li> <li>extract_wisdom is the Fabric prompt that extracts wisdom from any text. It addresses the problem of too much content and too little time.</li> </ul>"},{"location":"prompt_engineering/Fabric/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>Fabric is a good resource for prompts with many being related to CyberSecurity.</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/","title":"Prompt Engineering","text":"<p>Overview</p> <p>A large part of working LLMs is knowing how to prompt them to get the information you want.</p> <p>ChatGPTo will be used here but the techniques apply in general to any LLM.</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-guides","title":"Prompt Guides","text":"<p>There are many books, guides, and articles on Prompt Engineering. Some of the better ones are listed here:</p> <ol> <li>Prompt Engineering Guide </li> <li>OpenAI Prompt Engineering Guide </li> <li>Best practices for prompt Engineering with the OpenAI API</li> <li>Google Gemini Prompting guide 101 - A quick-start handbook for effective prompts, April 2024 edition</li> <li>How I Won Singapore\u2019s GPT-4 Prompt Engineering Competition, Dec 2023</li> <li>Prompt Engineering for Generative AI Book, May 2024</li> <li>Google Prompt design strategies </li> <li>Anthropic Prompt Engineering overview </li> <li>Best Prompt Techniques for Best LLM Responses, Feb 2024</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy","title":"Prompt Taxonomy","text":""},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy-turn-expression-level-of-details-role","title":"Prompt Taxonomy Turn, Expression, Level of Details, Role","text":"<p>The above proposed Prompt Taxonomy is TELeR: Turn, Expression, Level of Details, Role from  TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy-26-guiding-principles","title":"Prompt Taxonomy 26 Guiding Principles","text":"<p>The above \"26 guiding principles designed to streamline the process of querying and prompting large language models\" is from Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-tactics","title":"Prompt Tactics","text":"<p>Some tactics I find particularly useful:</p> <ol> <li>Ask the LLM to generate the prompt.<ol> <li>Do this in 2 parts (task decomposition)<ol> <li>Ask the LLM what techniques are best to use for effective prompt engineering</li> <li>Ask the LLM to create a prompt using these techniques for the objective and example you specify</li> </ol> </li> </ol> </li> <li>Ask the LLM to provide a confidence score for their answer. <ol> <li>People can be fooled by the fluency of LLMs aka hallucinations </li> <li>LLMs know how confident they are in their answer.</li> <li>So asking an LLM to rate their confidence in the answer can reduce blind trust.</li> </ol> </li> <li>Ask the LLM (or a different LLM) to review the answer and provide improvements.</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-generate-the-prompt","title":"Ask the LLM to generate the prompt","text":""},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-what-techniques-are-best-to-use-for-effective-prompt-engineering","title":"Ask the LLM what techniques are best to use for effective prompt engineering?","text":""},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-create-a-prompt-using-these-techniques-for-the-objective-and-example-you-specify","title":"Ask the LLM to create a prompt using these techniques for the objective and example you specify","text":"<pre><code>_functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.\n\n\n#CVE# _functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.\n#IMPACT# Remote Code Execution, Information Disclosure, Security Bypass\n#RATIONALE# The description specifies multiple potential impacts:\n1. **Remote Code Execution**: The ability to \"execute arbitrary PHP code\" directly implies a high severity impact where an attacker can run malicious code on the affected system.\n2. **Information Disclosure**: The mention of \"read arbitrary files\" suggests that attackers can access sensitive information stored in files.\n3. **Security Bypass**: The bypass of a protection mechanism to conduct remote file inclusion and directory traversal attacks implies that security controls are being circumvented.\n#CONFIDENCE# 95\n</code></pre>"},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-review-the-answer-and-provide-improvements","title":"Ask the LLM to review the answer and provide improvements.","text":""},{"location":"prompt_engineering/prompt_engineering/#llm-tools-to-improve-prompts","title":"LLM Tools to Improve Prompts","text":"<p>In addition to using LLMs to generate prompts (aka Meta Prompts), and review prompts in an adhoc manner via the chat interface, there are various tools that use LLMs to improve prompts:</p> <ol> <li>Fabric Prompt to Improve Prompts</li> <li>Anthropic Console supports testing and improving prompts (for Anthropic - but likely the resulting prompt would be portable to other LLMs)<ol> <li>Claude can generate prompts, create test variables, and show you the outputs of prompts side by side.</li> <li>https://x.com/AnthropicAI/status/1810747792807342395</li> </ol> </li> </ol> <p>Takeaways</p> <ol> <li>Getting the right prompt to get what you want out of an LLM can sometimes feel like art or interrogation. There are several options covered here:<ol> <li>Prompt Templates</li> <li>Prompt Frameworks</li> <li>Ask an LLM to generate a prompt</li> <li>LLM-based tools for prompt refinement</li> </ol> </li> </ol>"},{"location":"research/research/","title":"Talks and Research","text":"<p>Overview</p> <p>This section highlights relevant talks and research.</p> Title Venue Author(s) Date (YYYY/M) Microsoft New Future of Work Report 2023 Report Microsoft 2023/12"}]}
{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Your guide to using AI for CyberSecurity <p>Why Read this Guide?</p> <p>This guide shows how cybersecurity professionals can get up and running quickly with AI tools.</p> <p>It's in an initial raw state currently and is largely written by me for me... to organize my play time as I play with, and apply, these tools.</p> <p>Large Language Models (hosted and open source), and BERT-based language models tools will be covered e.g.</p> <ol> <li>NotebookLM</li> <li>Prompts and Prompt Techniques applied to Cybersecurity </li> <li>BERTopic</li> <li>Embeddings for CyberSecurity</li> <li>SetFIT + LAGoNN</li> <li>Named Entity Recognition GliNER and CyberSecurity NER models</li> <li>AI Agents for orchestrated workflows</li> </ol>"},{"location":"NotebookLM/NotebookLM/","title":"NotebookLM","text":"<p>Overview</p> <p>LLMs change the information retrieval paradigm. Instead of searching for information where we go to the information, we can chat with our documents and ask questions of them, so that the information comes to us in the form of an answer. </p> <p>In this section, we'll use NotebookLM, and we just need to import our documents to be able to chat with them. </p> <p>ChatGPT4o is also used for comparison to highlight where one is better applied than the other depending on the context.</p> <ul> <li>Both tools use LLMs, but NoteBookLM uses a \"Closed System\" (only the document sources you provide), versus ChatGPT4o which bases it answers on the open internet content at the time it was trained, and additionally the documents you provide.</li> </ul> <p>Tip</p> <p>Your responses from NotebookLM may be different than the examples shown here. LLMs will give different responses to the same question.</p>"},{"location":"NotebookLM/NotebookLM/#notebooklm_1","title":"NotebookLM","text":"<p>Quote</p> <p>NotebookLM lets you read, take notes, ask questions, organize your ideas, and much more -- all with the power of Google AI helping you at every step of the way.</p> <p>Quote</p> <p>It runs on the company\u2019s Gemini 1.5 Pro model (released Dec 2023), the same AI that powers the Gemini Advanced chatbot.  (ref)</p>"},{"location":"NotebookLM/NotebookLM/#key-features-and-benefits-of-gemini-15-models","title":"Key Features and Benefits of Gemini 1.5 Models","text":"<p>Per Gemini 1.5 Technical Report, the Key Features and Benefits of Gemini 1.5 Models are</p> <ol> <li>Highly Compute-Efficient Multimodal Models<ol> <li>Capable of recalling and reasoning over fine-grained information from millions of tokens of context, including long documents, videos, and audio.</li> </ol> </li> <li>Benchmark Performance<ol> <li>Outperforms other models such as Claude 3.0 (200k tokens) and GPT-4 Turbo (128k tokens) in next-token prediction and retrieval up to 10M tokens (approximately 7M words).</li> </ol> </li> <li>Unprecedented Context Handling<ol> <li>Handles extremely long contexts, up to at least 10M tokens (approximately 7M words).</li> <li>Capable of processing long-form mixed-modality inputs, including entire document collections, multiple hours of video, and almost five days of audio.</li> <li>Near-perfect recall on long-context retrieval tasks across various modalities.</li> </ol> </li> <li>Realistic Multimodal Long-Context Benchmarks<ol> <li>Excels in tasks requiring retrieval and reasoning over multiple parts of the context.</li> <li>Outperforms all competing models across all modalities, even those augmented with external retrieval methods.</li> </ol> </li> </ol> <p>These features make Gemini 1.5 models a generational leap over existing models, offering unparalleled performance in processing and understanding extensive and complex multimodal information.</p>"},{"location":"NotebookLM/NotebookLM/#document-loading","title":"Document Loading","text":"<p>Documents are loaded via GoogleDrive, PDFs, Text files, Copied text, Web page URL.</p> <p>Tip</p> <p>Any sources can be used e.g. Books in PDF format, websites, text files.</p> <p>Using a file of site content (if available) e.g.a PDF, is generally more reliable than using a URL to that site; it ensures all the content is ingested.</p>"},{"location":"NotebookLM/NotebookLM/#closed-system","title":"Closed System","text":"<p>These documents become the corpus where information is retrieved from, with references to the document(s) the information was retrieved from.</p> <p>Quote</p> <p>\u201cNotebookLM is a closed system.\u201d This means the AI won\u2019t perform any web searches beyond what you, the user, give it in a prompt. Every response it generates pertains only to the information it has on hand. (ref)</p> <p>Quote</p> <p>\u201csource-grounded AI\u201d: you define a set of documents that are important to your work\u2014called \u201csources\u201d in the NotebookLM parlance\u2014and from that point on, you can have an open-ended conversation with the language model where its answers will be \u201cgrounded\u201d in the information you\u2019ve selected. It is as if you are giving the AI instant expertise in whatever domain you happen to be working in. (ref)</p>"},{"location":"NotebookLM/NotebookLM/#what-is-a-dog","title":"What is a dog?","text":"<p>This is illustrated with a simple example of asking our Notebook on CWEs \"what is a dog?\":</p> <p>Quote</p> <p>The sources provided do not contain any information about dogs. Therefore, the query \"what is a dog?\" cannot be answered from the given sources.</p> <p></p>"},{"location":"NotebookLM/NotebookLM/#sharing","title":"Sharing","text":"<p>Unlike Google Docs, it is not possible to share a NotebookLM publicly - sharing is done directly via email addresses.</p>"},{"location":"NotebookLM/NotebookLM/#how-to-use-notebooklm","title":"How To Use NotebookLM","text":""},{"location":"NotebookLM/NotebookLM/#references","title":"References","text":"<ol> <li>Introducing NotebookLM, Oct 19, 2023, Steven Johnson who contributed to NotebookLM</li> <li>Getting The Most Out Of Notes In NotebookLM, Mar 18, 2024, Steven Johnson</li> <li>How To Use NotebookLM As A Research Tool, Feb 19, 2024, Steven Johnson</li> <li>Google's NotebookLM is now an even smarter assistant and better fact-checker, June 7, 2024 </li> <li>Using Google\u2019s NotebookLM for Data Science: A Comprehensive Guide, Dec 7, 2023 </li> <li>How to use Google\u2019s genAI-powered note-taking app, Feb 15, 2024 </li> </ol>"},{"location":"NotebookLM/NotebookLM/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM is a powerful free solution from Google that allows users to quickly and easily build a source-grounded AI (where users define the set of documents) and then have an open-ended conversation with the language model where its answers will be \u201cgrounded\u201d in the information users selected.</li> <li>The support for large contexts means that large documents can be processed - as demonstrated in the following sections.</li> <li>I found it a useful tool / companion for the research I was doing on vulnerability management to augment my knowledge and capabilities.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Attack/","title":"NotebookLM","text":"<p>Overview</p> <p>In this chapter, we'll use NotebookLM to ingest the MITRE ATT&amp;CK Enterprise Tactics. </p> <ul> <li>In the current version, MITRE ATT&amp;CK Matrix for Enterprise consists of 14 tactics, 559 Total Attack Patterns. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the MITRE ATT&amp;CK Matrix and ask questions, so that the information comes to us in the form of an answer. </p> <p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Attack/#data-sources","title":"Data Sources","text":"<p>The MITRE ATTACK Tactics and Techniques are available online at https://attack.mitre.org/tactics/enterprise/ as 1 webpage for each of the 14 Tactics.</p> <ul> <li>However, loading these webpages (or the \"Version Permalink\" pages did not work).</li> </ul> <p>MITRE ATTACK is also available as an Excel file from https://attack.mitre.org/resources/attack-data-and-tools/</p> <ul> <li>https://attack.mitre.org/docs/enterprise-attack-v15.1/enterprise-attack-v15.1.xlsx</li> </ul> <p>So we can convert that to a text file as follows:</p> <ol> <li>Open the Excel file</li> <li>For the tabs we want (e.g. Tactics, Techniques, Mitigations), delete the columns we don't want </li> <li>Export each tab as a csv file</li> <li>Transpose the data to a text file</li> <li>Import the text files</li> </ol> <p>Note: The data is also available as JSON: https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json.</p>"},{"location":"NotebookLM/NotebookLM_Attack/#convert-mitre-attack-to-a-text-file-for-import","title":"Convert MITRE ATTACK to a Text File for Import","text":"<p>Claude 3.5 Sonnet Prompt: <pre><code>i have a csv file with these columns ID    name description    tactics    detection    \"data sources\"    \"is sub-technique\"    \"sub-technique of\"\nI want to extract the content into a document to read. \nEach row should be extracted as follows: the name of the first column, then the ccontent for the first column. Then the second column name and content.\nAnd so on for each column.\nAnd do this for all rows\n\nI want python code to do this\n</code></pre></p> <p>The LLM generated generic code that was applied to convert each csv file to a text file.</p>"},{"location":"NotebookLM/NotebookLM_Attack/#load-each-text-file","title":"Load each text file","text":"<p>So we can just load each one to NoteBookLM as a text file:</p> <ul> <li>MITRE_ATTACK_mitigations.txt</li> <li>MITRE_ATTACK_tactics.txt</li> <li>MITRE_ATTACK_techniques.txt</li> </ul>"},{"location":"NotebookLM/NotebookLM_Attack/#tell-me-about-mitre-techniques-related-to-supply-chain","title":"Tell me about MITRE techniques related to supply chain","text":""},{"location":"NotebookLM/NotebookLM_Attack/#notebooklm-answer","title":"NotebookLM Answer","text":""},{"location":"NotebookLM/NotebookLM_Attack/#claude-sonnet-35-answer","title":"Claude Sonnet 3.5 Answer","text":""},{"location":"NotebookLM/NotebookLM_Attack/#takeaways","title":"Takeaways","text":"<p>Takeaways</p>"},{"location":"NotebookLM/NotebookLM_Capec/","title":"NotebookLM","text":"<p>Overview</p> <p>In this chapter, we'll use NotebookLM to ingest the Common Attack Pattern Enumeration and Classification (CAPEC) list. </p> <ul> <li>In the current version (CAPEC List Version 3.9 as at June 2024), there are 559 Total Attack Patterns. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the CAPEC document and ask questions, so that the information comes to us in the form of an answer. </p> <p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol> <p>Note that CAPEC appears a lot less than CWE on the internet so an LLM will have a lot less context for CAPEC.</p>"},{"location":"NotebookLM/NotebookLM_Capec/#data-sources","title":"Data Sources","text":"<p>https://capec.mitre.org/data/downloads.html offers various formats (XML, CSV, HTML), and views:</p> <ul> <li>Mechanisms of Attack: https://capec.mitre.org/data/slices/1000.html</li> <li>Domains of Attack: https://capec.mitre.org/data/slices/3000.html<ul> <li>We'll use this one.</li> </ul> </li> </ul> <p>NotebookLM - Upload from - Web page URL - Paste website link - https://capec.mitre.org/data/slices/3000.html</p>"},{"location":"NotebookLM/NotebookLM_Capec/#what-is-the-capec-id-that-related-to-xss","title":"what is the CAPEC ID that related to xss","text":""},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o did not provide all the CWEs that NotebookLM did.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer-with-hallucination","title":"ChatGPT4o Answer with Hallucination","text":"<p>Failure</p> <p>Hallucination</p> <p>\"CAPEC-633: Client-Side XSS using Content-Security-Policy Bypass\" is not valid https://capec.mitre.org/data/definitions/633.html</p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-answer-with-hallucination-with-uploaded-capec-file","title":"ChatGPT4o Answer with Hallucination with Uploaded CAPEC File","text":"<p>ChatGPT4o UI did not process the CAPEC HTML file, and the UI does not accept URLs, so the CSV file was uploaded instead.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-validate-the-hallucination","title":"ChatGPT4o Validate the Hallucination","text":"<p>In a different ChatGPT4o session (new context to avoid the hallucination), we ask ChatGPT4o to validate the CAPEC. </p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#chatgpt4o-review-and-rate-the-responses-from-notebooklm-and-chatgpt4o","title":"ChatGPT4o Review and Rate the Responses from NotebookLM and ChatGPT4o","text":"<p>ChatGPT4o was used to review and rate both responses (copied directly from the NoteBookLM and ChatGPT4o responses)</p> <p></p> <p></p> <p></p>"},{"location":"NotebookLM/NotebookLM_Capec/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>For less common or referenced text like CAPEC, ChatGPT4o can hallucinate even when the CAPEC list is uploaded to it.</li> <li>NotebookLM did not hallucinate (a benefit of the \"Closed System\" approach).</li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/","title":"NotebookLM","text":"<p>Overview</p> <p>I came across this via https://tldrsec.com/p/tldr-sec-237 (an excellent newsletter) in the \"AI + Security\" section, and it piqued my interest! </p> <p>One area of research is using LLMs for infrastructure configuration as detailed in https://www.coguard.io/post/coguard-uses-openai-cybersecurity-grant-to-automate-infrastructure-security and the associated repo.</p> <p>Here we take on the first task [C1]: Extraction of security and uptime-relevant configuration parameters from manuals; for the example provided in the repo: Apache Spark</p>"},{"location":"NotebookLM/NotebookLM_Config/#details","title":"Details","text":""},{"location":"NotebookLM/NotebookLM_Config/#task","title":"Task","text":"<p>Quote</p> <p>[C1] Extraction of security and uptime-relevant configuration parameters from manuals. The goal of this component is simple to describe, but hard to accomplish. Given a manual for a software component, extract the configuration parameters and define the security relevant ones from it.</p> <p>Example: For Apache Spark, the manual is provided on the general configuration page online, i.e. in HTML format, and there is also a specific security page. The expectation would be to at least extract the parameters from the security page, as well as some log-related items from the general page. In total, when manually examining the configuration parameters, it totals approximately 80 parameters that are security relevant. You can find these in the Appendix A.</p>"},{"location":"NotebookLM/NotebookLM_Config/#original-prompt","title":"Original Prompt","text":"<p>The original prompt used is per https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#extraction-of-security-relevant-parameters-in-c1</p> <p>Quote</p> <p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>"},{"location":"NotebookLM/NotebookLM_Config/#expected-answer","title":"Expected Answer","text":"<p>The expected answer is per https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#appendix-a. </p> <p>Quote</p> <p>The following parameters were identified by the CoGuard team by hand as relevant from a security point of view.</p> <pre><code>spark.yarn.shuffle.server.recovery.disabled\nspark.authenticate\nspark.authenticate.secret\nspark.authenticate.secret.file\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.network.crypto.enabled\nspark.network.crypto.config.*\nspark.network.crypto.saslFallback\nspark.authenticate.enableSaslEncryption\nspark.network.sasl.serverAlwaysEncrypt\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.io.encryption.commons.config.*\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.modify.acls\nspark.modify.acls.groups\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.user.groups.mapping\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.ssl.enabled\nspark.ssl.port\nspark.ssl.enabledAlgorithms\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.protocol\nspark.ssl.needClientAuth\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.port\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.protocol\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.standalone.enabled\nspark.ssl.standalone.port\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.protocol\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.port\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ui.xXssProtection\nspark.ui.xContentTypeOptions.enabled\nspark.ui.strictTransportSecurity\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#data-sources","title":"Data Sources","text":"<p>The data sources are per above:</p> <ol> <li>https://spark.apache.org/docs/latest/configuration.html</li> <li>https://spark.apache.org/docs/latest/security.html</li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#setup","title":"Setup","text":""},{"location":"NotebookLM/NotebookLM_Config/#prepare-validation-file","title":"Prepare Validation File","text":"<ol> <li>CopyNPaste the Expected answer to a text file ./data/NotebookLM_Config/security_parameters_manual.txt.</li> <li>Sort alphabetically to allow diff comparison with answer from NotebookLM.</li> </ol> <pre><code>    cat ./data/NotebookLM_Config/security_parameters_manual.txt | sort &gt; ./data/NotebookLM_Config/security_parameters_manual_sorted.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#attempt-1-use-the-provided-prompt","title":"Attempt 1: Use the Provided Prompt","text":""},{"location":"NotebookLM/NotebookLM_Config/#create-a-new-notebooklm-with-the-2-data-sources-only","title":"Create A New Notebooklm With The 2 Data Sources Only","text":"<p>New NotebookLM. Sources - Upload from - Web page URL for the 2 Data Sources listed above.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Config/#submit-the-prompt","title":"Submit the prompt","text":"<p>Quote</p> <p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>"},{"location":"NotebookLM/NotebookLM_Config/#save-the-result","title":"Save The Result","text":"<ol> <li>Click the Copy button.</li> <li>Create a new file security_parameters.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li> <li>Sort the answer</li> </ol> <pre><code>jq -r '.[]' ./data/NotebookLM_Config/security_parameters.json | sort &gt; ./data/NotebookLM_Config/security_parameters.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer","title":"Compare The Answer With The Expected Answer","text":"<ol> <li>60 parameters were retrieved</li> <li>We can see that the main difference relates to \"spark.ssl.\" parameters.</li> <li>Searching manually in the 2 Data Sources above reveals that these config strings are not actually listed in the documentation e.g. \"spark.ssl.ui.needClientAuth\" directly - but using placeholders.</li> <li>The LLM didn't understand that - so we'll let it know - then ask it again.</li> <li>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt   </li> </ol> <pre><code>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt                 \n1c1,4\n&lt; spark.yarn.shuffle.server.recovery.disabled\n---\n&gt; hadoop.security.credential.provider.path\n&gt; spark.acls.enable\n&gt; spark.admin.acls\n&gt; spark.admin.acls.groups\n2a6\n&gt; spark.authenticate.enableSaslEncryption\n4d7\n&lt; spark.authenticate.secret.file\n7,11c10,14\n&lt; spark.network.crypto.enabled\n&lt; spark.network.crypto.config.*\n&lt; spark.network.crypto.saslFallback\n&lt; spark.authenticate.enableSaslEncryption\n&lt; spark.network.sasl.serverAlwaysEncrypt\n---\n&gt; spark.authenticate.secret.file\n&gt; spark.history.ui.acls.enable\n&gt; spark.history.ui.admin.acls\n&gt; spark.history.ui.admin.acls.groups\n&gt; spark.io.encryption.commons.config.*\n15,20c18,29\n&lt; spark.io.encryption.commons.config.*\n&lt; spark.ui.allowFramingFrom\n&lt; spark.ui.filters\n&lt; spark.acls.enable\n&lt; spark.admin.acls\n&lt; spark.admin.acls.groups\n---\n&gt; spark.kerberos.access.hadoopFileSystems\n&gt; spark.kerberos.keytab\n&gt; spark.kerberos.principal\n&gt; spark.kubernetes.hadoop.configMapName\n&gt; spark.kubernetes.kerberos.krb5.configMapName\n&gt; spark.kubernetes.kerberos.krb5.path\n&gt; spark.kubernetes.kerberos.tokenSecret.itemKey\n&gt; spark.kubernetes.kerberos.tokenSecret.name\n&gt; spark.mesos.driver.secret.envkeys\n&gt; spark.mesos.driver.secret.filenames\n&gt; spark.mesos.driver.secret.names\n&gt; spark.mesos.driver.secret.values\n23,28c32,39\n&lt; spark.ui.view.acls\n&lt; spark.ui.view.acls.groups\n&lt; spark.user.groups.mapping\n&lt; spark.history.ui.acls.enable\n&lt; spark.history.ui.admin.acls\n&lt; spark.history.ui.admin.acls.groups\n---\n&gt; spark.network.crypto.config.*\n&gt; spark.network.crypto.enabled\n&gt; spark.network.crypto.saslFallback\n&gt; spark.network.sasl.serverAlwaysEncrypt\n&gt; spark.redaction.regex\n&gt; spark.redaction.string.regex\n&gt; spark.security.credentials.${service}.enabled\n&gt; spark.sql.redaction.options.regex\n30d40\n&lt; spark.ssl.port\n36d45\n&lt; spark.ssl.protocol\n37a47,48\n&gt; spark.ssl.port\n&gt; spark.ssl.protocol\n41,77c52,57\n&lt; spark.ssl.ui.enabled\n&lt; spark.ssl.ui.port\n&lt; spark.ssl.ui.enabledAlgorithms\n&lt; spark.ssl.ui.keyPassword\n&lt; spark.ssl.ui.keyStore\n&lt; spark.ssl.ui.keyStorePassword\n&lt; spark.ssl.ui.keyStoreType\n&lt; spark.ssl.ui.protocol\n&lt; spark.ssl.ui.needClientAuth\n&lt; spark.ssl.ui.trustStore\n&lt; spark.ssl.ui.trustStorePassword\n&lt; spark.ssl.ui.trustStoreType\n&lt; spark.ssl.standalone.enabled\n&lt; spark.ssl.standalone.port\n&lt; spark.ssl.standalone.enabledAlgorithms\n&lt; spark.ssl.standalone.keyPassword\n&lt; spark.ssl.standalone.keyStore\n&lt; spark.ssl.standalone.keyStorePassword\n&lt; spark.ssl.standalone.keyStoreType\n&lt; spark.ssl.standalone.protocol\n&lt; spark.ssl.standalone.needClientAuth\n&lt; spark.ssl.standalone.trustStore\n&lt; spark.ssl.standalone.trustStorePassword\n&lt; spark.ssl.standalone.trustStoreType\n&lt; spark.ssl.historyServer.enabled\n&lt; spark.ssl.historyServer.port\n&lt; spark.ssl.historyServer.enabledAlgorithms\n&lt; spark.ssl.historyServer.keyPassword\n&lt; spark.ssl.historyServer.keyStore\n&lt; spark.ssl.historyServer.keyStorePassword\n&lt; spark.ssl.historyServer.keyStoreType\n&lt; spark.ssl.historyServer.protocol\n&lt; spark.ssl.historyServer.needClientAuth\n&lt; spark.ssl.historyServer.trustStore\n&lt; spark.ssl.historyServer.trustStorePassword\n&lt; spark.ssl.historyServer.trustStoreType\n&lt; spark.ui.xXssProtection\n---\n&gt; spark.ssl.useNodeLocalConf\n&gt; spark.ui.allowFramingFrom\n&gt; spark.ui.filters\n&gt; spark.ui.strictTransportSecurity\n&gt; spark.ui.view.acls\n&gt; spark.ui.view.acls.groups\n79c59,60\n&lt; spark.ui.strictTransportSecurity\n\\ No newline at end of file\n---\n&gt; spark.ui.xXssProtection\n&gt; spark.user.groups.mapping\n</code></pre> <p>Note</p> <p>In the next section, we'll use an LLM to do the comparison.</p> <p>Here we used traditional methods i.e. diff.</p>"},{"location":"NotebookLM/NotebookLM_Config/#attempt-2-explain-about-config-namespace-placeholders","title":"Attempt 2: Explain about Config Namespace Placeholders","text":"<p>The LLM did not understand from the documents about Config Namespace placeholders:</p> <p></p> <p>So this time, we explain as part of the prompt about Config Namespace placeholders.</p>"},{"location":"NotebookLM/NotebookLM_Config/#submit-the-prompt_1","title":"Submit The Prompt","text":"<p>Quote</p> <p>Note that Config Namespace placeholders are used for some security configurations. These are placeholders \"\\({ns}\" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: \"\\).enabled\", \"spark.ssl.enabled\" and \"spark.ssl.historyServer\" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns</p> <p>Note</p> <p>Note the duplication in the prompt to emphasize what we want</p> <p>Quote</p> <p>\"list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns\" in the prompt.</p> <p>security_parameters_ns.json is the resulting file that has 96 config parameters - more than the expected answer config parameters as generated by humans.</p>"},{"location":"NotebookLM/NotebookLM_Config/#save-the-result_1","title":"Save The Result","text":"<ol> <li>Click the Copy button.</li> <li>Create a new file security_parameters_ns.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li> <li>Sort the answer and ensure there's no duplicates.</li> </ol> <pre><code>jq -r '.[]' ./data/NotebookLM_Config/security_parameters_ns.json | sort | uniq &gt; ./data/NotebookLM_Config/security_parameters_ns.txt\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer_1","title":"Compare The Answer With The Expected Answer","text":"<p>In this case, we use ChatGPT4o to do the diff, copy and pasting the values from each file:</p> <ul> <li>./data/NotebookLM_Config/security_parameters_manual.txt: the expected answers</li> <li>./data/NotebookLM_Config/security_parameters_ns.txt: the actual answers</li> </ul>"},{"location":"NotebookLM/NotebookLM_Config/#prompt","title":"Prompt","text":"<pre><code>List the values that are in ===manual===  but not in ===notebooklm===\nList the values that are in ===notebooklm===  but not in ===manual===\n\n===manual=== \nspark.yarn.shuffle.server.recovery.disabled\nspark.authenticate\nspark.authenticate.secret\nspark.authenticate.secret.file\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.network.crypto.enabled\nspark.network.crypto.config.*\nspark.network.crypto.saslFallback\nspark.authenticate.enableSaslEncryption\nspark.network.sasl.serverAlwaysEncrypt\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.io.encryption.commons.config.*\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.modify.acls\nspark.modify.acls.groups\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.user.groups.mapping\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.ssl.enabled\nspark.ssl.port\nspark.ssl.enabledAlgorithms\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.protocol\nspark.ssl.needClientAuth\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.port\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.protocol\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.standalone.enabled\nspark.ssl.standalone.port\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.protocol\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.port\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ui.xXssProtection\nspark.ui.xContentTypeOptions.enabled\nspark.ui.strictTransportSecurity\n\n\n===notebooklm===\nhadoop.security.credential.provider.path\nspark.acls.enable\nspark.admin.acls\nspark.admin.acls.groups\nspark.authenticate\nspark.authenticate.enableSaslEncryption\nspark.authenticate.secret\nspark.authenticate.secret.driver.file\nspark.authenticate.secret.executor.file\nspark.authenticate.secret.file\nspark.history.ui.acls.enable\nspark.history.ui.admin.acls\nspark.history.ui.admin.acls.groups\nspark.io.encryption.commons.config.*\nspark.io.encryption.enabled\nspark.io.encryption.keySizeBits\nspark.io.encryption.keygen.algorithm\nspark.kerberos.access.hadoopFileSystems\nspark.kerberos.keytab\nspark.kerberos.principal\nspark.kubernetes.hadoop.configMapName\nspark.kubernetes.kerberos.krb5.configMapName\nspark.kubernetes.kerberos.krb5.path\nspark.kubernetes.kerberos.tokenSecret.itemKey\nspark.kubernetes.kerberos.tokenSecret.name\nspark.mesos.driver.secret.envkeys\nspark.mesos.driver.secret.filenames\nspark.mesos.driver.secret.names\nspark.mesos.driver.secret.values\nspark.modify.acls\nspark.modify.acls.groups\nspark.network.crypto.config.*\nspark.network.crypto.enabled\nspark.network.crypto.saslFallback\nspark.network.sasl.serverAlwaysEncrypt\nspark.redaction.regex\nspark.redaction.string.regex\nspark.security.credentials.${service}.enabled\nspark.sql.redaction.options.regex\nspark.ssl.enabled\nspark.ssl.enabledAlgorithms\nspark.ssl.historyServer.enabled\nspark.ssl.historyServer.enabledAlgorithms\nspark.ssl.historyServer.keyPassword\nspark.ssl.historyServer.keyStore\nspark.ssl.historyServer.keyStorePassword\nspark.ssl.historyServer.keyStoreType\nspark.ssl.historyServer.needClientAuth\nspark.ssl.historyServer.port\nspark.ssl.historyServer.protocol\nspark.ssl.historyServer.trustStore\nspark.ssl.historyServer.trustStorePassword\nspark.ssl.historyServer.trustStoreType\nspark.ssl.keyPassword\nspark.ssl.keyStore\nspark.ssl.keyStorePassword\nspark.ssl.keyStoreType\nspark.ssl.needClientAuth\nspark.ssl.port\nspark.ssl.protocol\nspark.ssl.standalone.enabled\nspark.ssl.standalone.enabledAlgorithms\nspark.ssl.standalone.keyPassword\nspark.ssl.standalone.keyStore\nspark.ssl.standalone.keyStorePassword\nspark.ssl.standalone.keyStoreType\nspark.ssl.standalone.needClientAuth\nspark.ssl.standalone.port\nspark.ssl.standalone.protocol\nspark.ssl.standalone.trustStore\nspark.ssl.standalone.trustStorePassword\nspark.ssl.standalone.trustStoreType\nspark.ssl.trustStore\nspark.ssl.trustStorePassword\nspark.ssl.trustStoreType\nspark.ssl.ui.enabled\nspark.ssl.ui.enabledAlgorithms\nspark.ssl.ui.keyPassword\nspark.ssl.ui.keyStore\nspark.ssl.ui.keyStorePassword\nspark.ssl.ui.keyStoreType\nspark.ssl.ui.needClientAuth\nspark.ssl.ui.port\nspark.ssl.ui.protocol\nspark.ssl.ui.trustStore\nspark.ssl.ui.trustStorePassword\nspark.ssl.ui.trustStoreType\nspark.ssl.useNodeLocalConf\nspark.ui.allowFramingFrom\nspark.ui.filters\nspark.ui.strictTransportSecurity\nspark.ui.view.acls\nspark.ui.view.acls.groups\nspark.ui.xContentTypeOptions.enabled\nspark.ui.xXssProtection\nspark.user.groups.mapping\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#response","title":"Response","text":"<pre><code>Values in ===manual=== but not in ===notebooklm===\nspark.yarn.shuffle.server.recovery.disabled\nValues in ===notebooklm=== but not in ===manual===\nhadoop.security.credential.provider.path\nspark.kerberos.access.hadoopFileSystems\nspark.kerberos.keytab\nspark.kerberos.principal\nspark.kubernetes.hadoop.configMapName\nspark.kubernetes.kerberos.krb5.configMapName\nspark.kubernetes.kerberos.krb5.path\nspark.kubernetes.kerberos.tokenSecret.itemKey\nspark.kubernetes.kerberos.tokenSecret.name\nspark.mesos.driver.secret.envkeys\nspark.mesos.driver.secret.filenames\nspark.mesos.driver.secret.names\nspark.mesos.driver.secret.values\nspark.redaction.regex\nspark.redaction.string.regex\nspark.security.credentials.${service}.enabled\nspark.sql.redaction.options.regex\nspark.ssl.useNodeLocalConf\n</code></pre> <p>Observation</p> <ol> <li>NotebookLM did not understand the concept of placeholder config parameters from the source documents. Since there are several config parameters per placeholder, it missed many config parameters (Attempt 1).</li> <li>When the prompt explained about placeholder config parameters, NotebookLM found all but 1 of the 79 configuration parameters related to security (Attempt 2).<ol> <li>NotebookLM found 18 config parameters related to security that were not found by humans as part of the expected answers and these appear to be valid configuration parameters related to security based on my review.</li> </ol> </li> <li>1 config parameter was not found by NotebookLM, and it's not obvious why: <code>spark.yarn.shuffle.server.recovery.disabled</code> </li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#chatgpt4o","title":"ChatGPT4o","text":""},{"location":"NotebookLM/NotebookLM_Config/#original-prompt_1","title":"Original Prompt","text":"<pre><code>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings\nUsing only the documentation of Apache Spark from the URLs below (and no other source), which configuration parameters are relevant from a security perspective?\n\nThe data sources are :\n1. https://spark.apache.org/docs/latest/configuration.html\n2. https://spark.apache.org/docs/latest/security.html\n</code></pre> <pre><code>[\n    \"spark.authenticate\",\n    \"spark.authenticate.secret\",\n    \"spark.authenticate.secret.file\",\n    \"spark.authenticate.secret.driver.file\",\n    \"spark.authenticate.secret.executor.file\",\n    \"spark.network.crypto.enabled\",\n    \"spark.network.crypto.config.*\",\n    \"spark.network.crypto.saslFallback\",\n    \"spark.authenticate.enableSaslEncryption\",\n    \"spark.network.sasl.serverAlwaysEncrypt\",\n    \"spark.io.encryption.enabled\",\n    \"spark.io.encryption.keySizeBits\",\n    \"spark.io.encryption.keygen.algorithm\",\n    \"spark.io.encryption.commons.config.*\",\n    \"spark.ui.allowFramingFrom\",\n    \"spark.ui.filters\",\n    \"spark.acls.enable\",\n    \"spark.admin.acls\",\n    \"spark.admin.acls.groups\",\n    \"spark.modify.acls\",\n    \"spark.modify.acls.groups\",\n    \"spark.ui.view.acls\",\n    \"spark.ui.view.acls.groups\",\n    \"spark.user.groups.mapping\",\n    \"spark.history.ui.acls.enable\",\n    \"spark.history.ui.admin.acls\",\n    \"spark.history.ui.admin.acls.groups\",\n    \"spark.ssl.enabled\",\n    \"spark.ssl.port\",\n    \"spark.ssl.enabledAlgorithms\",\n    \"spark.ssl.keyPassword\",\n    \"spark.ssl.keyStore\",\n    \"spark.ssl.keyStorePassword\",\n    \"spark.ssl.keyStoreType\",\n    \"spark.ssl.protocol\",\n    \"spark.ssl.needClientAuth\",\n    \"spark.ssl.trustStore\",\n    \"spark.ssl.trustStorePassword\",\n    \"spark.ssl.trustStoreType\",\n    \"spark.ui.xXssProtection\",\n    \"spark.ui.xContentTypeOptions.enabled\",\n    \"spark.ui.strictTransportSecurity\",\n    \"spark.kerberos.access.hadoopFileSystems\",\n    \"spark.security.credentials.${service}.enabled\"\n]\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#prompt-explaining-config-namespace-placeholders","title":"Prompt Explaining Config Namespace placeholders","text":"<pre><code>Note that Config Namespace placeholders are used for some security configurations. These are placeholders \"${ns}\" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: \"${ns}.enabled\", \"spark.ssl.enabled\" and \"spark.ssl.historyServer\" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns\n</code></pre> <pre><code>[\n    \"spark.ssl.enabled\",\n    \"spark.ssl.historyServer.enabled\",\n    \"spark.security.credentials.enabled\",\n    \"spark.ssl.port\",\n    \"spark.ssl.historyServer.port\",\n    \"spark.security.credentials.port\",\n    \"spark.ssl.enabledAlgorithms\",\n    \"spark.ssl.historyServer.enabledAlgorithms\",\n    \"spark.security.credentials.enabledAlgorithms\",\n    \"spark.ssl.keyPassword\",\n    \"spark.ssl.historyServer.keyPassword\",\n    \"spark.security.credentials.keyPassword\",\n    \"spark.ssl.keyStore\",\n    \"spark.ssl.historyServer.keyStore\",\n    \"spark.security.credentials.keyStore\",\n    \"spark.ssl.keyStorePassword\",\n    \"spark.ssl.historyServer.keyStorePassword\",\n    \"spark.security.credentials.keyStorePassword\",\n    \"spark.ssl.keyStoreType\",\n    \"spark.ssl.historyServer.keyStoreType\",\n    \"spark.security.credentials.keyStoreType\",\n    \"spark.ssl.protocol\",\n    \"spark.ssl.historyServer.protocol\",\n    \"spark.security.credentials.protocol\",\n    \"spark.ssl.needClientAuth\",\n    \"spark.ssl.historyServer.needClientAuth\",\n    \"spark.security.credentials.needClientAuth\",\n    \"spark.ssl.trustStore\",\n    \"spark.ssl.historyServer.trustStore\",\n    \"spark.security.credentials.trustStore\",\n    \"spark.ssl.trustStorePassword\",\n    \"spark.ssl.historyServer.trustStorePassword\",\n    \"spark.security.credentials.trustStorePassword\",\n    \"spark.ssl.trustStoreType\",\n    \"spark.ssl.historyServer.trustStoreType\",\n    \"spark.security.credentials.trustStoreType\",\n    \"spark.ssl.historyServer\",\n    \"spark.ssl.historyServer.historyServer\",\n    \"spark.security.credentials.historyServer\",\n    \"spark.authenticate\",\n    \"spark.authenticate.secret\",\n    \"spark.authenticate.secret.file\",\n    \"spark.authenticate.secret.driver.file\",\n    \"spark.authenticate.secret.executor.file\",\n    \"spark.network.crypto.enabled\",\n    \"spark.network.crypto.config.*\",\n    \"spark.network.crypto.saslFallback\",\n    \"spark.authenticate.enableSaslEncryption\",\n    \"spark.network.sasl.serverAlwaysEncrypt\",\n    \"spark.io.encryption.enabled\",\n    \"spark.io.encryption.keySizeBits\",\n    \"spark.io.encryption.keygen.algorithm\",\n    \"spark.io.encryption.commons.config.*\",\n    \"spark.ui.allowFramingFrom\",\n    \"spark.ui.filters\",\n    \"spark.acls.enable\",\n    \"spark.admin.acls\",\n    \"spark.admin.acls.groups\",\n    \"spark.modify.acls\",\n    \"spark.modify.acls.groups\",\n    \"spark.ui.view.acls\",\n    \"spark.ui.view.acls.groups\",\n    \"spark.user.groups.mapping\",\n    \"spark.history.ui.acls.enable\",\n    \"spark.history.ui.admin.acls\",\n    \"spark.history.ui.admin.acls.groups\",\n    \"spark.ui.xXssProtection\",\n    \"spark.ui.xContentTypeOptions.enabled\",\n    \"spark.ui.strictTransportSecurity\",\n    \"spark.kerberos.access.hadoopFileSystems\",\n    \"spark.security.credentials.${service}.enabled\"\n]\n``` &amp;#8203;:citation[oaicite:0]{index=0}&amp;#8203;\n</code></pre>"},{"location":"NotebookLM/NotebookLM_Config/#compare-the-answer-with-the-expected-answer_2","title":"Compare The Answer With The Expected Answer","text":"<ol> <li>ChatGPT4o missed these 2 config placeholders (these were not provided in the example in the prompt - only the first and last one were provided)<ol> <li>spark.ssl.ui</li> <li>spark.ssl.standalone   </li> </ol> </li> <li>ChatGPT4o wrongly interpreted spark.security.credentials.${service}.enabled as being the same as ${ns} placeholder, and appended the parameters for ${ns} placeholder to spark.security.credentials.</li> </ol> <pre><code>{\n    \"manual_not_in_chatgpt4o\": [\n        \"spark.yarn.shuffle.server.recovery.disabled\",\n        \"spark.ssl.ui.enabled\",\n        \"spark.ssl.ui.port\",\n        \"spark.ssl.ui.enabledAlgorithms\",\n        \"spark.ssl.ui.keyPassword\",\n        \"spark.ssl.ui.keyStore\",\n        \"spark.ssl.ui.keyStorePassword\",\n        \"spark.ssl.ui.keyStoreType\",\n        \"spark.ssl.ui.protocol\",\n        \"spark.ssl.ui.needClientAuth\",\n        \"spark.ssl.ui.trustStore\",\n        \"spark.ssl.ui.trustStorePassword\",\n        \"spark.ssl.ui.trustStoreType\",\n        \"spark.ssl.standalone.enabled\",\n        \"spark.ssl.standalone.port\",\n        \"spark.ssl.standalone.enabledAlgorithms\",\n        \"spark.ssl.standalone.keyPassword\",\n        \"spark.ssl.standalone.keyStore\",\n        \"spark.ssl.standalone.keyStorePassword\",\n        \"spark.ssl.standalone.keyStoreType\",\n        \"spark.ssl.standalone.protocol\",\n        \"spark.ssl.standalone.needClientAuth\",\n        \"spark.ssl.standalone.trustStore\",\n        \"spark.ssl.standalone.trustStorePassword\",\n        \"spark.ssl.standalone.trustStoreType\"\n    ],\n    \"chatgpt4o_not_in_manual\": [\n        \"spark.security.credentials.enabled\",\n        \"spark.security.credentials.port\",\n        \"spark.security.credentials.enabledAlgorithms\",\n        \"spark.security.credentials.keyPassword\",\n        \"spark.security.credentials.keyStore\",\n        \"spark.security.credentials.keyStorePassword\",\n        \"spark.security.credentials.keyStoreType\",\n        \"spark.security.credentials.protocol\",\n        \"spark.security.credentials.needClientAuth\",\n        \"spark.security.credentials.trustStore\",\n        \"spark.security.credentials.trustStorePassword\",\n        \"spark.security.credentials.trustStoreType\",\n        \"spark.security.credentials.historyServer\",\n        \"spark.security.credentials.${service}.enabled\"\n    ]\n}\n</code></pre> <p>Observation</p> <ol> <li><code>spark.yarn.shuffle.server.recovery.disabled</code> was not found by ChatGPT4o (or NotebookLM).     </li> <li>ChatGPT4o found 44 parameters in the first prompt.</li> <li>When the concept of placeholder config parameters was explained in the second prompt, ChatGPT made 2 mistakes and thereby got many config parameters wrong<ol> <li>it did not extend the example to all the placeholder config parameters</li> <li>it appended the {ns} placeholder parameters to a different placeholder {service}</li> </ol> </li> </ol>"},{"location":"NotebookLM/NotebookLM_Config/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM and ChatGPT4o did reasonably well at extracting the config parameters related to security - with NotebookLM performing better, missing just 1, and finding 18 more than the human-generated answer.</li> <li>Overall, with everything-as-code (infrastructure, policy, LLM answers, ....), and LLMs being able to process code, there's a lot of benefit and promise in applying LLMs.</li> <li>The feedback to CoGuard is via https://github.com/coguardio/coguard_openai_rule_auto_generation_research/issues/2 </li> </ol>"},{"location":"NotebookLM/NotebookLM_Cwe/","title":"NotebookLM","text":"<p>Overview</p> <p>In this chapter, we'll use NotebookLM to ingest the Common Weakness Enumeration (CWE) list. </p> <ul> <li>In the current version (CWE Version 4.14 2024-02-29 as at June 2024), there are over 1400 CWEs, and 2789 pages in the PDF version of the list. </li> <li>It can be unwieldy to navigate or assimilate this information. </li> </ul> <p>Using NotebookLM, we can chat with the CWE document and ask questions, so that the information comes to us in the form of an answer. </p> <p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p> <ol> <li>without uploading any documents to it.</li> <li>uploading a document to it.</li> </ol>"},{"location":"NotebookLM/NotebookLM_Cwe/#data-sources","title":"Data Sources","text":"<p>cwe_latest.pdf  from https://cwe.mitre.org/data/downloads.html has 2789 pages (version CWE Version 4.14 2024-02-29).</p> <ul> <li>This is too big for NotebookLM to ingest.</li> <li>So the PDF is split into 10 smaller PDFs of 280 pages each using this script.</li> <li>These 10 smaller PDFs are then ingested into NotebookLM.</li> </ul> <pre><code>pagesper=280 file=./data/NotebookLM_CweCapec/cwe_latest.pdf ./pdfsplit.sh  \n</code></pre> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#cwe-assigned-to-cve-2024-0042","title":"CWE assigned to CVE-2024-0042","text":"<p>I was reading a post on LinkedIn and the CWE assigned by CISA ADP looked wrong.</p> <p>So I used my NotebookLM CWE notebook, and other GPTs, to determine the appropriate CWE.</p> <p>I then raised an issue: https://github.com/cisagov/vulnrichment/issues/84.</p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-cwe-ids-are-associated-with-buffer-overflow","title":"what cwe ids are associated with buffer overflow?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o did not provide all the CWEs that NotebookLM did.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer-with-uploaded-cwe-document","title":"ChatGPT4o Answer with uploaded CWE document","text":"<p>ChatGPT4o required some additional prompting to provide a comparable list of CWEs to what NotebookLM gave.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-cwe-ids-are-associated-with-xss","title":"what cwe ids are associated with xss?","text":"The Sources sidebar is no longer shown in this and the following examples"},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-parent-weakness-or-cwe-for-xss-and-csrf","title":"what is the parent weakness or cwe for xss and csrf?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#what-are-the-different-types-of-xss","title":"what are the different types of xss?","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer_1","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o provided the same types - but gave a much richer answer than NotebookLM did because it has access to a lot more documents on XSS.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-cwe-associated-with-cve-2021-27104-accellion-fta-os-command-injection-vulnerability","title":"what is the CWE associated with CVE-2021-27104 \"Accellion FTA OS Command Injection Vulnerability\"","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#what-is-the-cwe-associated-with-cve-2019-1653-cisco-small-business-rv320-and-rv325-routers-information-disclosure-vulnerability","title":"what is the CWE associated with CVE-2019-1653 \"Cisco Small Business RV320 and RV325 Routers Information Disclosure Vulnerability\"","text":""},{"location":"NotebookLM/NotebookLM_Cwe/#chatgpt4o-answer_2","title":"ChatGPT4o Answer","text":"<p>ChatGPT4o provided the same types - but gave a much richer answer than NotebookLM did because it has access to a lot more documents on XSS.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_Cwe/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>I found it useful, quick, and convenient to be able to ask questions of the CWE list, as a compliment to the traditional search method I've used in the past.</li> <li>The large CWE document could not be uploaded to NoteBookLM as one PDF document, but had to be split into smaller PDFs.<ol> <li>The same document could be uploaded to ChatGPT4o (without splitting).</li> </ol> </li> <li>Based on the extremely limited test cases here (your experience may vary):<ol> <li>NoteBookAI provides better answers on the provided source documents.</li> <li>ChatGPT provides richer answers to questions that can be answered outside of the provided source documents.</li> </ol> </li> </ol>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/","title":"NotebookLM","text":"<p>Overview</p> <p>In this chapter, we'll feed the main vulnerability standards to NotebookLM.</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#data-sources","title":"Data Sources","text":"<p>These files are available in docs/NotebookLM/InputDocs for convenience.</p> Content Page with link to content Direct Link Risk Based Prioritization Guide https://riskbasedprioritization.github.io/print_page/ Print - Save to PDF CVSS 3.1 User Guide https://www.first.org/cvss/v3.1/user-guide https://www.first.org/cvss/v3-1/cvss-v31-user-guide_r1.pdf CVSS 3.1 Specification https://www.first.org/cvss/v3.1/specification-document https://www.first.org/cvss/v3-1/cvss-v31-specification_r1.pdf CVSS 4.0 User Guide https://www.first.org/cvss/v4.0/user-guide https://www.first.org/cvss/v4-0/cvss-v40-user-guide.pdf CVSS 4.0 Specification Document https://www.first.org/cvss/v4.0/specification-document https://www.first.org/cvss/v4-0/cvss-v40-specification.pdf Exploit Prediction Scoring System (EPSS) FAQ https://www.first.org/epss/faq https://www.first.org/epss/faq Exploit Prediction Scoring System (EPSS) latest published paper https://www.first.org/epss/model https://arxiv.org/pdf/2302.14172 Stakeholder-Specific Vulnerability Categorization (SSVC) latest published paper https://github.com/CERTCC/SSVC/tree/main/pdfs https://github.com/CERTCC/SSVC/blob/main/pdfs/ssvc_2_1_draft.pdf CISA KEV https://www.cisa.gov/known-exploited-vulnerabilities copy and paste text to a file cisakev.txt because NotebookLM cannot pull content directly from the page <p></p> The initial screen after the documents are loaded.CISA KEV was then loaded as a text file. <p>Quote</p> <p>write an introductory article in less than 250 words that gives an overview of all these sources and how they fit together</p> <p></p> <p>Each circled-number is a clickable link to the reference text in the original sources.</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#i-want-to-rank-vulnerabilities-by-exploitation","title":"I want to rank vulnerabilities by Exploitation","text":"<p>Quote</p> <p>I am currently using CVSS to rank vulnerabilities. I also want to rank based on exploitation as I heard only a small percentage of CVEs are actually exploited. What standard should I use. How should I use them. Provide an answer with rationale and examples.</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#explain-risk-like-im-a-5-year-old","title":"Explain risk like I'm a 5 year old","text":"<p>Quote</p> <p>I want to prioritize vulnerabilities by risk. But I don't understand risk and the components or factors of risk. Can you explain that to me like I'm a 5 year old. Then explain how I can use that for my risk based prioritization approach. Please provide a rationale</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#cvss-base-parameters-for-cvss-v3-and-v4","title":"CVSS Base Parameters for CVSS v3 and v4","text":"<p>Quote</p> <p>what parameters contribute to the CVSS base parameter score? How do these parameters differ in CVSS 3 versus CVSS 4</p> <p></p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#chatgpt4o-response","title":"ChatGPT4o Response","text":"<p>Failure</p> <p>Hallucination Remediation Level (RL) is NOT part of the Exploitability Metrics</p> <p>Quote</p> <p>Remediation Level (RL): New metric considering how available and effective remediation methods are (Not Defined, Official Fix, Temporary Fix, Workaround, Unavailable).</p>"},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#chatgpt4o-check-response","title":"ChatGPT4o Check Response","text":""},{"location":"NotebookLM/NotebookLM_VulnerabilityStandards/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>NotebookLM does a good job assimilating these verbose standards and was competently able to answer specific factual questions, and broader opinionated questions.</li> <li>Lots of references to the source material were provided in the answers which help understand and validate the answers.</li> </ol>"},{"location":"TopicModeling/BertTopic/","title":"BERTopic","text":"<p>Overview</p> <p>Topic modeling can be used to discover the underlying themes and patterns in a collection of documents (e.g. CVE Descriptions, or CWE Descriptions,...).</p> <p>It is an unsupervised machine learning technique that\u2019s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize the set of documents.</p> <p>The output is collections of documents that the algorithm has grouped together, as well as clusters of words and expressions that it used to infer these relations.</p>"},{"location":"TopicModeling/BertTopic/#bertopic_1","title":"BERTopic","text":"<p>BERTopic is a topic modeling technique that leverages \ud83e\udd17 transformers and c-TF-IDF. In general, it outperforms other methods (statistical vs Language Model based) e.g. LSA, LDA. </p> <p>Quote</p> <p>Before diving into a classification task, text clustering allows for getting an intuitive understanding of the task but also of its complexity.</p> <p>BERTopic is a topic modeling technique that assumes that clusters of semantically similar documents are a powerful way of generating and describing clusters. The documents in each cluster are expected to describe a major theme and combined they might represent a topic.</p> <p>Extracts from book co-authored by BertTopic creator: https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/</p>"},{"location":"TopicModeling/BertTopic/#topic-model-cwes","title":"Topic Model CWEs","text":"<p>I've used BERTopic to Topic Model lots of datasets to quickly get an intuition for the data.</p> <p>In this example, we'll look at CWEs. </p> <ul> <li>Specifically, generate a Topic Model of the ~1400 CWEs in 1400 View, so we can better understand the underlying patterns and themes.</li> </ul> <p>I did this initially as part of a Linked Thread, to illustrate Topic Modeling as a solution, but also the ease and speed at which it could be done.</p>"},{"location":"TopicModeling/BertTopic/#code","title":"Code","text":"<p>The starting point code is deliberately chosen as unrelated to CyberSecurity: https://github.com/splevine/harnessing-nlp-cx-demo Mar 2024 (where this repo gives an excellent overview of NLP and BERTopic and SetFit).</p> <p>The main changes I made were:</p> <ol> <li>Don't use wandb (Weights and Balances) service as it was not needed for the demo</li> <li>Use the 1400 CWE view 1400.csv as the input Data</li> <li>Use SentenceTransformer(\"basel/ATTACK-BERT\") as the embedding_model so that CyberSecurity embeddings are used.</li> </ol> <p>The code and visualizations is available here: https://colab.research.google.com/drive/168i3oHekL4Cva2s2w01KMq6mnffDgxIS?usp=sharing No effort was made to optimize the topic modeling i.e. it was completely unsupervised.</p>"},{"location":"TopicModeling/BertTopic/#topic-model-of-the-1400-cwes-in-1400-view","title":"Topic Model of the ~1400 CWEs in 1400 View","text":"<p> The top level categorizations of CVE 1400 per https://cwe.mitre.org/data/definitions/1400.html.</p> <p> The Topic Model of 1400 CWE view 1400.csv with the top level categorizations overlayed in bold to allow comparison of the top level groupings assigned by MITRE and the Topic Modeling.</p> <p>Other visualizations are available in the Colab Notebook.</p>"},{"location":"TopicModeling/BertTopic/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>Topic Modeling with BERTopic is a powerful unsupervised learning approach to quickly and easily get an intuition for a set of documents.</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/","title":"CISA Vulnrichment","text":"<p>Overview</p> <p>I was reading a post on LinkedIn and the CWE assigned by CISA ADP looked wrong so...</p> <ul> <li>I used my NotebookLM CWE notebook, and other LLMs, to determine the appropriate CWE.</li> <li>I then raised an issue: https://github.com/cisagov/vulnrichment/issues/84.</li> </ul> <p>I then decided to dig a bit more into this... specifically the CWEs assigned by CISA ADP.</p> <p>I used a consensus of LLMs to review all CWEs assigned by CISA ADP to find issues:</p> <ul> <li>These issues were found automatically by a consensus of 3 LLMs: ChatGPT4o, Gemini 1.5 Pro, Claude 3.5 Sonnet who were asked to review CWEs assigned to CVEs assigned by CISA ADP.</li> <li>The consensus output was then reviewed by a human (me).</li> <li>I created 3 Issues initially (though there are a lot more) and these were accepted by CISA Vulnrichment and resolved promptly!</li> </ul> <p>This section shows the different approaches used (and the subscription plan used):</p> <ol> <li>no-code using the browser chat interface: <ol> <li>Gemini 1.5 Pro (subscription)</li> <li>Claude 3.5 Sonnet (prepay)</li> </ol> </li> <li>code: <ol> <li>ChatGPT4o OpenAI Batch API (Plus Plan)</li> <li>langchain calling 3 LLMs via APIs: Gemini 1.5 Pro, Claude 3.5 Sonnet, ChatGPT4</li> </ol> </li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#cisa-vulnrichment_1","title":"CISA Vulnrichment","text":"<p>Quote</p> <p>The CISA Vulnrichment project is the public repository of CISA's enrichment of public CVE records through CISA's ADP (Authorized Data Publisher) container. In this phase of the project, CISA is assessing new and recent CVEs and adding key SSVC decision points. Once scored, some higher-risk CVEs will also receive enrichment of CWE, CVSS, and CPE data points, where possible.</p> <p>https://github.com/cisagov/vulnrichment</p> <p>I have great admiration for CISA and their pragmatic initiatives like CISA KEV and SSVC and have spoken about them and applied them in production.</p> <p>Tip</p> <p>One of the many benefits of this Vulnrichment project is that feedback can be provided as GitHub issues and the team is VERY responsive \u2705  \ud83d\ude4c</p> <ul> <li>The 'Bug' label was assigned the same day to the 3 issues I submitted: https://github.com/cisagov/vulnrichment/issues?q=is%3Aissue+author%3ACrashedmind+is%3Aclosed.</li> <li>The changes were accepted and applied the next working day and a comment was added to the ticket which was then closed.</li> </ul> <p>My overall goal here was to </p> <ul> <li>Show that LLMs could augment human analysts where vulnerability enrichment today is largely done manually.</li> <li>Show how to use them for this purpose.</li> <li>Get people to use LLMs to improve the quality of the CVE data in general, and in this specific example case, the CWE data.</li> <li>Maximize the value of the CISA ADP data and enrichment by improving CWE-assignment quality.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#get-cves-enriched-by-cisa-adp","title":"Get CVEs Enriched by CISA ADP","text":""},{"location":"Vulnrichment/Vulnrichment/#approach-to-using-llms","title":"Approach to using LLMs","text":"<p>The recipe focuses on Time-To-Value - and minimization of human effort - to find the most inappropriate assigned CWEs ASAP.</p> <ul> <li>A more complete and costly approach would be to submit all CVE Descriptions to all 3 LLMs.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#dont-train-a-model-on-bad-data","title":"Don't Train A Model On Bad Data!","text":"<p>It is possible to train a Language Model as a Classifier to assign CWEs to a CVE - and there are several research papers that took that approach (with limited success).</p> <ul> <li>This approach is delusional based on my research and experience of assigned CWEs.</li> </ul> <p>Per Steve Christey Coley, CWE tech lead:</p> <p>Quote</p> <p>There has been significant interest in using AI/ML in various applications to use and/or map to CWE, but in my opinion there are a number of significant hurdles, e.g. you can't train on \"bad mappings\" to learn how to do good mappings.</p> <p>So, rather than train a model on bad data, we can ask a model to assign / validate a CWE based on its understanding of the CWEs available e.g.</p> <ol> <li>a closed-model with access to the CWE specification only (and no other data)</li> <li>an open-model with access to the CWE specification and other data</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#validate-with-llms","title":"Validate with LLMs","text":"<p>Different approaches are possible when providing the CVE Description to the LLM:</p> <ol> <li>provide the CWE assigned as part of the CVE, and ask the LLM if it agrees or not, and if not why</li> <li>ask the LLM to assign one or more CWEs</li> </ol> <p>The first approach is easier and simpler and cheaper (in terms of token use i.e. shorter response output), and better as a first pass option to get the low hanging fruit.</p> <p>The second approach could be used at the time of CWE assignment to get a second opinion.</p>"},{"location":"Vulnrichment/Vulnrichment/#consensus","title":"Consensus","text":"<p>To minimize human effort, 3 LLMs are used and the consensus is reviewed</p> <ul> <li>The LLMs are state-of-the-art models from different providers i.e. the best available and reasonably independent.</li> <li>The results are sorted by consensus i.e. 3 models in agreement, then 2 models in agreement,....</li> <li>A Human (me) then reviewed (sorted by consensus) and made the final decision.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#recipe","title":"Recipe","text":"<ol> <li>Get the Vulnrichment subset of CVEs where CISA ADP assigned a CWE (regardless of whether the CWE was the same or different than that assigned by the CNA)<ol> <li>~1.5K (CISA ADP Assigned CWEs) of ~~8K CVEs (in Vulnrichment)</li> </ol> </li> <li>Ask ChatGPT4o (via Batch API) to Agree (Yes/No) with the assigned CWE (and provide a Confidence score, and rationale if not)<ol> <li>~700 (No) of ~1.5K </li> <li>Sort these by Confidence score i.e. start with the highest Confidence ones.</li> </ol> </li> <li>Then ask Gemini and Claude to review. This can be done in several ways e.g. </li> <li>For the subset where ChatGPT4o disagrees, ask Gemini and Claude to assess the human-assigned CWEs</li> <li>Ask each LLM in turn to review the previous assessments by LLMs</li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#create-a-prompt","title":"Create a Prompt","text":""},{"location":"Vulnrichment/Vulnrichment/#chat-interface-table-output","title":"Chat Interface - Table Output","text":"<pre><code>caption_system_prompt =\nYou are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.\nYour goal is is to say if you Agree with the assigned CWE ID or not.\nYou will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.\n\nPlease provide the response in a table 'cve_id', 'CWE_ID', 'Agree'. \"Rationale\", Confidence' where\n1. Agree: string // Yes or No\n2. Rationale: string // Only if you do not Agree, provide a rationale why not\n3. Confidence: string // a confidence score between 0 and 1\n</code></pre> <p>The table output allows copy-and-pasting by a human into a sheet.</p>"},{"location":"Vulnrichment/Vulnrichment/#batch-api-interface-json-output","title":"Batch API Interface - JSON Output","text":"<p><pre><code>caption_system_prompt =\nYou are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.\nYour goal is is to say if you Agree with the assigned CWE ID or not.\nYou will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.\n\nYou will output a json object containing the following information:\n{\n    Agree: string // Yes or No\n    Rationale: string // Only if you do not Agree, provide a rationale why not\n    Confidence: string // a confidence score between 0 and 1\n}\n</code></pre> The JSON output allows processing by machines.</p> <p>Note</p> <p>It is possible to submit multiple CVEs in one prompt for each batch entry i.e. similar to what is done when using the Chat interface.</p> <ul> <li>But this is not done in this example; each batch request contains a single CVE only (per the OpenAI Batch API example)</li> </ul> <p>The prompt consists of these parts:</p> <ol> <li>Role + Task: which is the same for the Chat and API interface</li> <li>Output format: which is different for the Chat and API interface</li> <li>A binary value Agree is requested</li> <li>The rationale only if there is disagreement. This saves on output tokens.</li> <li>A Confidence score to limit impacts of hallucinations, and as a way to assess and prioritize responses by confidence.</li> <li>No (Few-shot) examples are provided. Based on the results, these were not necessary.<ol> <li>If Few-shot examples were required, I'd submit multiple CVEs in a single batch request (because putting the examples in each single CVE request would add a LOT of input tokens)</li> </ol> </li> </ol>"},{"location":"Vulnrichment/Vulnrichment/#prompt-llms","title":"Prompt LLMs","text":""},{"location":"Vulnrichment/Vulnrichment/#gemini-15-pro-browser-chat-interface","title":"Gemini 1.5 Pro Browser Chat Interface","text":"<p>The chat interface was used in this example submitting multiple CVEs in one prompt.</p>"},{"location":"Vulnrichment/Vulnrichment/#claude-35-sonnet-browser-chat-interface","title":"Claude 3.5 Sonnet Browser Chat Interface","text":""},{"location":"Vulnrichment/Vulnrichment/#model","title":"Model","text":"<p>Currently: Claude 3.5 Sonnet was used as it has the best performance vs cost for Claude models.</p> <p> https://docs.anthropic.com/en/docs/welcome </p>"},{"location":"Vulnrichment/Vulnrichment/#interface","title":"Interface","text":"<p>Currently: Claude does not support a native Batch API interface - though  Amazon Bedrock supports batching of prompts to models including Claude.</p> <p>The chat interface was used in this example submitting multiple CVEs in one prompt.</p>"},{"location":"Vulnrichment/Vulnrichment/#openai-batch-api","title":"OpenAI Batch API","text":""},{"location":"Vulnrichment/Vulnrichment/#model_1","title":"Model","text":"<p>gpt-4o</p>"},{"location":"Vulnrichment/Vulnrichment/#plan","title":"Plan","text":"<p>The Plus plan subscription was used.</p> <p>Quote</p> <p>There are some restrictions:</p> <ul> <li>The file can contain up to 50,000 requests.</li> <li>The file cannot be more than 100 MB in size.</li> </ul> <p>Enqueued token limit reached for gpt-4o in organization XYZ. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.'</p>"},{"location":"Vulnrichment/Vulnrichment/#interface_1","title":"Interface","text":"<p>Batch Interface API.</p> <p>The ~1500 ADP CVE-CWE pairs were split into 15 files of 100 CVE-CWE pair prompts to comfortably fit under this token limit.</p> <ul> <li>very little effort was spent to optimize the file size (number of prompts per batch), or the prompt size.</li> <li>The cost to process the ~1500 ADP CVE-CWE pairs: ~$1.50.</li> </ul>"},{"location":"Vulnrichment/Vulnrichment/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>The value of CVE data depends on its quality. </li> <li>For all published CVEs to date, the quality of CWEs assigned is questionable.</li> <li>A large part of that is that humans can't grok 1000+ CWEs. LLMs can.</li> <li>Using LLMs to suggest or validate CWEs can reduce the manual effort and error in CWE assignment.</li> <li>LLMs can validate CWEs at scale e.g. using Batch mode, or multiple CVEs per prompt, or both.</li> <li>LLMs perform well at this task and, given they can be automated, can augment the human manual effort, and improve the quality of assigned CWEs.</li> </ol>"},{"location":"annex/Glossary/","title":"Glossary","text":"<p>~: shorthand for \"approximately\"</p> <p>~~: shorthand for \"very approximately\"</p>"},{"location":"introduction/Introduction/","title":"Introduction","text":"<p>About this Guide</p> <p>This guide is in an initial raw state currently and is largely written by me for me... to organize my play time as I play with, and apply, these tools.</p> <p>But you might find it useful.</p> <p>After reading this guide you should be able to</p> <ol> <li>....</li> </ol>"},{"location":"introduction/Introduction/#overview","title":"Overview","text":""},{"location":"introduction/Introduction/#intended-audience","title":"Intended Audience","text":"<p>The intended audience is people wanting to go beyond the hype and basics of Large Language Models.</p> <p>No prior knowledge is assumed to read the guide - it provides just enough information to understand the advanced topics covered.</p> <p>A basic knowledge of Jupyter Python is required to run the code (with the data provided or on your data).</p>"},{"location":"introduction/Introduction/#how-to-use-this-guide","title":"How to Use This Guide","text":""},{"location":"introduction/Introduction/#how-to-contribute-to-this-guide","title":"How to Contribute to This Guide","text":"<p>You can contribute content or suggest changes:</p> <ul> <li>\ud83d\udcac Discuss content</li> <li>\ud83d\udca1 Suggest content</li> <li>\ud83e\udeb2 Report Errors, typos</li> </ul>"},{"location":"introduction/Introduction/#writing-style","title":"Writing Style","text":"<p>The \"writing style\" in this guide is succinct, and leads with an opinion, with data and code to back it up i.e. data analysis plots (with source code where possible) and observations and takeaways that you can assess - and apply to your data and environment. This allows the reader to assess the opinion and the code/data and rationale behind it.</p> <p>Different, and especially opposite, opinions with the data to back them up, are especially welcome! - and will help shape this guide.</p> <p>Quote</p> <p>If we have data, let\u2019s look at data. If all we have are opinions, let\u2019s go with mine.</p> <p>Jim Barksdale, former CEO of Netscape </p>"},{"location":"introduction/Introduction/#notes","title":"Notes","text":"<p>Notes</p> <ol> <li>This guide is not affiliated with any Tool/Company/Vendor/Standard/Forum/Data source. <ol> <li>Mention of a vendor in this guide is not a recommendation or endorsement of that vendor. </li> </ol> </li> <li>This guide is a living document i.e. it will change and grow over time - with your input.</li> </ol> <p>This guide is not about which tool is better than the other</p> <p>\"Don't fall in love with models: they're expendable. Fall in love with data!\" </p> <p>Julien Simon, Chief Evangelist, Hugging Face</p> <p>Warning</p> <p>You are responsible for your data and where it goes. </p> <p>If you don't understand where your data goes, and what happens to it for a given model or tool, then find out before you use private or personal data.</p> <p>To evaluate models and tools, you can start with public data.</p>"},{"location":"introduction/Preface/","title":"Preface","text":"<p>Language Models are powerful tools that can be applied to CyberSecurity.</p> <p>I enjoy learning about, playing with, and applying these tools to better solve problems:</p> <ul> <li>I wrote this guide for me, to organize my thoughts and my play time as I play with, and apply, Language Models.</li> <li>You may find it useful.</li> <li>I've found by putting something out there, you get something back.</li> </ul> <p>This approach worked well for the Risk-Based Prioritization guide...</p> <p>Chris Madden</p>"},{"location":"prompt_engineering/Fabric/","title":"Fabric","text":"<p>Overview</p> <p>One of Fabric's primary features is helping people collect and integrate prompts</p>"},{"location":"prompt_engineering/Fabric/#fabric-prompt-collection-and-framework","title":"Fabric Prompt Collection and Framework","text":"<p>https://github.com/danielmiessler/fabric/tree/main </p> <p>Quote</p> <p>Since the start of 2023 and GenAI we've seen a massive number of AI applications for accomplishing tasks. It's powerful, but it's not easy to integrate this functionality into our lives.</p> <p>In other words, AI doesn't have a capabilities problem\u2014it has an integration problem. Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.</p> <p>One of fabric's primary features is helping people collect and integrate prompts, which we call Patterns, into various parts of their lives.</p> <p>The prompts (aka Patterns) are available at https://github.com/danielmiessler/fabric/tree/main/patterns</p>"},{"location":"prompt_engineering/Fabric/#fabric-prompts-for-cybersecurity","title":"Fabric Prompts for CyberSecurity","text":"<p>Fabric has Prompts that are specific to CyberSecurity e.g.</p> <ul> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/create_threat_model/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_logs/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_malware/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report_trends/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/write_hackerone_report/system.md</li> <li>https://github.com/danielmiessler/fabric/blob/main/patterns/write_semgrep_rule/system.md </li> </ul>"},{"location":"prompt_engineering/Fabric/#fabric-prompt-to-improve-prompts","title":"Fabric Prompt to Improve Prompts","text":"<p>https://github.com/danielmiessler/fabric/blob/main/patterns/improve_prompt/system.md</p>"},{"location":"prompt_engineering/Fabric/#takeaways","title":"Takeaways","text":"<p>Takeaways</p> <ol> <li>ToDo</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/","title":"Prompt Engineering","text":"<p>Overview</p> <p>A large part of working LLMs is knowing how to prompt them to get the information you want.</p> <p>ChatGPTo will be used here but the techniques apply in general to any LLM.</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-guides","title":"Prompt Guides","text":"<p>There are many books, guides, and articles on Prompt Engineering. Some of the better ones are listed here:</p> <ol> <li>Prompt Engineering Guide </li> <li>OpenAI Prompt Engineering Guide </li> <li>Best practices for prompt Engineering with the OpenAI API</li> <li>Google Gemini Prompting guide 101 - A quick-start handbook for effective prompts, April 2024 edition</li> <li>How I Won Singapore\u2019s GPT-4 Prompt Engineering Competition, Dec 2023</li> <li>Prompt Engineering for Generative AI Book, May 2024</li> <li>Google Prompt design strategies </li> <li>Anthropic Prompt Engineering overview </li> <li>Best Prompt Techniques for Best LLM Responses, Feb 2024</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy","title":"Prompt Taxonomy","text":""},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy-turn-expression-level-of-details-role","title":"Prompt Taxonomy Turn, Expression, Level of Details, Role","text":"<p>The above proposed Prompt Taxonomy is TELeR: Turn, Expression, Level of Details, Role from  TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-taxonomy-26-guiding-principles","title":"Prompt Taxonomy 26 Guiding Principles","text":"<p>The above \"26 guiding principles designed to streamline the process of querying and prompting large language models\" is from Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</p>"},{"location":"prompt_engineering/prompt_engineering/#prompt-tactics","title":"Prompt Tactics","text":"<p>Some tactics I find particularly useful:</p> <ol> <li>Ask the LLM to generate the prompt.<ol> <li>Do this in 2 parts (task decomposition)<ol> <li>Ask the LLM what techniques are best to use for effective prompt engineering</li> <li>Ask the LLM to create a prompt using these techniques for the objective and example you specify</li> </ol> </li> </ol> </li> <li>Ask the LLM to provide a confidence score for their answer. <ol> <li>People can be fooled by the fluency of LLMs aka hallucinations </li> <li>LLMs know how confident they are in their answer.</li> <li>So asking an LLM to rate their confidence in the answer can reduce blind trust.</li> </ol> </li> <li>Ask the LLM (or a different LLM) to review the answer and provide improvements.</li> </ol>"},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-generate-the-prompt","title":"Ask the LLM to generate the prompt","text":""},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-what-techniques-are-best-to-use-for-effective-prompt-engineering","title":"Ask the LLM what techniques are best to use for effective prompt engineering?","text":""},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-create-a-prompt-using-these-techniques-for-the-objective-and-example-you-specify","title":"Ask the LLM to create a prompt using these techniques for the objective and example you specify","text":"<pre><code>_functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.\n\n\n#CVE# _functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.\n#IMPACT# Remote Code Execution, Information Disclosure, Security Bypass\n#RATIONALE# The description specifies multiple potential impacts:\n1. **Remote Code Execution**: The ability to \"execute arbitrary PHP code\" directly implies a high severity impact where an attacker can run malicious code on the affected system.\n2. **Information Disclosure**: The mention of \"read arbitrary files\" suggests that attackers can access sensitive information stored in files.\n3. **Security Bypass**: The bypass of a protection mechanism to conduct remote file inclusion and directory traversal attacks implies that security controls are being circumvented.\n#CONFIDENCE# 95\n</code></pre>"},{"location":"prompt_engineering/prompt_engineering/#ask-the-llm-to-review-the-answer-and-provide-improvements","title":"Ask the LLM to review the answer and provide improvements.","text":""},{"location":"prompt_engineering/prompt_engineering/#llm-tools-to-improve-prompts","title":"LLM Tools to Improve Prompts","text":"<p>In addition to using LLMs to generate prompts (aka Meta Prompts), and review prompts in an adhoc manner via the chat interface, there are various tools that use LLMs to improve prompts:</p> <ol> <li>Fabric Prompt to Improve Prompts</li> <li>Anthropic Console supports testing and improving prompts (for Anthropic - but likely the resulting prompt would be portable to other LLMs)<ol> <li>Claude can generate prompts, create test variables, and show you the outputs of prompts side by side.</li> <li>https://x.com/AnthropicAI/status/1810747792807342395</li> </ol> </li> </ol> <p>Takeaways</p> <ol> <li>ToDo</li> </ol>"},{"location":"research/research/","title":"Talks and Research","text":"<p>Overview</p> <p>This section highlights relevant talks and research.</p> Title Venue Author(s) Date (YYYY/M) Microsoft New Future of Work Report 2023 Report Microsoft 2023/12"}]}
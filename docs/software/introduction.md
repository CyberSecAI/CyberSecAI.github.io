# How Software Engineering Is Changing with AI

# Overview

!!! abstract "Overview"

    There is a LOT more to Software Engineering than Code Generation. 
Software 2.0
    https://karpathy.medium.com/software-2-0-a64152b37c35 
Andrej Karpathy, 2017
Software (1.0) is eating the world, and now AI (Software 2.0) is eating software.

Software 1.0 is code we write. Software 2.0 is code written by the optimization based on an evaluation criterion (such as “classify this training data correctly”). It is likely that any setting where the program is not obvious but one can repeatedly evaluate the performance of it (e.g. — did you classify some images correctly? do you win games of Go?) will be subject to this transition, because the optimization can find much better code than what a human can write.




## Design Thinking & Rapid Feedback
<figure markdown>
![](../assets/images/doublediamondprocess.png)
</figure>

!!! tip

    AI accelerates feedback loops: ideas → prototypes → validation happen in minutes, not weeks.

!!! tip

    See the Design Council’s [Systemic Design Framework](https://medium.com/design-council/developing-our-new-systemic-design-framework-e0f74fe118f7) for an evolution of the Double Diamond that  recognises the importance of the ‘invisible activities’ that sit around the design process: orientation and value setting, continuing the journey, collaboration and connection, and leadership and storytelling.



## Shift Left

!!! quote

    “Software 1.0 is code we write. Software 2.0 is code written by optimization based on an evaluation criterion.”  
    [Software 2.0 — Andrej Karpathy, 2017](https://karpathy.medium.com/software-2-0-a64152b37c35)  

While Code Generation grabs headlines, **the true value** lies in the _upstream artifacts_—architecture ADRs, user-story requirements, API contracts—that shape AI-driven workflows.

| Aspect               | Software 1.0                          | Software 2.0                                  |
|----------------------|---------------------------------------|-----------------------------------------------|
| Source               | Human-authored code                   | AI-generated via optimization                 |
| Primary Artifact     | Code                                  | Prompts, data schemas, contracts              |
| Change History       | Git commits tied to human edits       | AI “commits” less meaningful to trace         |
| Skill Focus          | Syntax, algorithms, manual design     | Requirements, architecture & validation |




!!! quote

    “**In agent-driven workflows, code becomes a byproduct—like a compiled artifact—while high-level inputs become the core deliverable.** Code becomes the byproduct of those inputs, more like a compiled artifact than a manually authored source. Git, in this world, starts to function less as a workspace and more as an artifact log — a place to track not just what changed, but why and by whom. We may begin to layer in richer metadata, such as which agent or model made a change, which sections are protected, and where human oversight is required”  
    [Nine Emerging Developer Patterns for the AI Era — a16z](https://a16z.com/nine-emerging-developer-patterns-for-the-ai-era/)  


This suggests a future where developers will spend less time on the minutiae of code writing and more on defining high-level system intent, designing robust architectures, and validating the outputs generated by AI. 

This evolution also implies a potential shift in required developer skill sets, moving towards expertise in high-level architectural design and sophisticated prompt engineering

IAC, diagrams as code, and other artifacts are becoming more important.


Furthermore, the increasing involvement of AI agents is expanding the "audience" for code. Traditionally, code was written primarily by and for human developers, with a strong emphasis on readability and maintainability for human comprehension. However, code intended to be generated or maintained by AI agents may prioritize different qualities to align with an AI's interpretive capabilities. 1 This can lead to a preference for thorough comments, verbose naming conventions, and highly regular code structures, even if a human developer might consider these practices "over-documentation" or overly explicit. This adjustment in coding best practices is driven by the need to ensure AI agents can correctly parse and manipulate the code. This means that the definition of "clean code" may evolve to balance human readability with optimal AI parseability. Organizations will likely need to establish new guidelines for "AI-optimized code" to ensure that their systems can be effectively maintained and evolved by autonomous agents. This also suggests that documentation will transition from passive information repositories to active instructions that AI agents can directly interpret and act upon. 2
[Coding for AI Agents vs. Humans — Ikangai](https://www.ikangai.com/coding-for-ai-agents-vs-coding-for-human-developers/)  


## “Programming Language” → Natural Language
!!! quote 

    “The hottest new programming language is English.”  
    
    —[Andrej Karpathy on X/Twitter, 2023](https://x.com/karpathy/status/1617979122625712128)  

Natural-language prompts are now first-class citizens in our toolchains.

## Pre-Coding Artifacts: Contracts Become King


| Artifact Category         | Examples                                             | AI-Centric Need                             |
|---------------------------|------------------------------------------------------|----------------------------------------------|
| **Requirements**          | User stories, functional & non-functional specs      | Clear acceptance criteria for evaluation     |
| **Architecture & Design** | ADRs, UML/component diagrams, API contracts          | Unambiguous intents for prompt templates     |
| **Data & Schemas**        | Training datasets, JSON/YAML schemas                 | Consistent structure for model generation    |
| **Security & Compliance** | Threat models, audit reports                        | Automated guardrails for AI outputs          |

## Leveraging AI to Improve Software Engineering

Tracy Bannon's excellent talk [Applying AI to the SDLC: New Ideas and Gotchas! - Leveraging AI to Improve Software Engineering](https://www.infoq.com/presentations/ai-sdlc/) includes a model for where AI can be used with DevSecOps.

<figure markdown>
![](../assets/images/ai_devsecops.png)
</figure>

Tracy Bannon’s model outlines opportunities from planning to monitoring: [Applying AI to the SDLC — InfoQ](https://www.infoq.com/presentations/ai-sdlc/) 

| Phase         | AI Use Case                                    |
|---------------|------------------------------------------------|
| Plan & Design | Generate design variants, review ADRs          |
| Code          | Autocomplete, synthesis from prompts          |
| Test & QA     | Auto-generate test cases, fuzzing              |
| Deploy & Ops  | Predictive scaling, anomaly detection          |
| Monitor       | Automated root-cause analysis                  |


## Evolving “Clean Code” for AI Agents
> “Code for AI agents may prefer _verbose naming_, thorough comments, and highly regular structures—even if that feels like over-documentation to humans.”  
> — Ikangai, 2024[^5]

**New Guidelines**  
- **Naming:** Explicit, unambiguous  
- **Comments:** Machine-readable annotations  
- **Formatting:** Consistent AST-friendly style  

## Conclusion
AI is reframing software engineering: _upstream artifacts_ become the true deliverables, and “code” is an executable byproduct. Success demands mastery of requirements, architecture, and prompt-engineering as much as traditional coding skills.












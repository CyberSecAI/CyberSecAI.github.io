
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://github.com/CyberSecAI/CyberSecAI.github.io/print_page/">
      
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.33">
    
    
      
        <title>Print Site - CyberSecAI</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.3cba04c6.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/print-site-enum-headings1.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings2.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings3.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings4.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings5.css">
    
      <link rel="stylesheet" href="../css/print-site-enum-headings6.css">
    
      <link rel="stylesheet" href="../css/print-site.css">
    
      <link rel="stylesheet" href="../css/print-site-material.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("/CyberSecAI/CyberSecAI.github.io/",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-NMMB0KXVGQ"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-NMMB0KXVGQ",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-NMMB0KXVGQ",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  
        <script type="text/javascript">
        document.addEventListener('DOMContentLoaded', function () {
            remove_material_navigation();remove_mkdocs_theme_navigation();generate_toc();
        })
        </script>
        </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
  THIS GUIDE IS UNDER CONSTRUCTION... BUT AVAILABLE HERE FOR EARLY ACCESS REVIEW & FEEDBACK. 

          </div>
          
        </aside>
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="CyberSecAI" class="md-header__button md-logo" aria-label="CyberSecAI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 3C9.2 3 6.2 5.9 6 9.7l-1.9 2.5c-.2.3 0 .8.4.8H6v3c0 1.1.9 2 2 2h1v3h7v-4.7c2.4-1.1 4-3.5 4-6.3 0-3.9-3.1-7-7-7m4 7h-3v3h-2v-3H9V8h3V5h2v3h3v2Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            CyberSecAI
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Print Site
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="cyan" data-md-color-accent="purple"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7 0-.24-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91 1.61 0 2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08Z"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="CyberSecAI" class="md-nav__button md-logo" aria-label="CyberSecAI" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 3C9.2 3 6.2 5.9 6 9.7l-1.9 2.5c-.2.3 0 .8.4.8H6v3c0 1.1.9 2 2 2h1v3h7v-4.7c2.4-1.1 4-3.5 4-6.3 0-3.9-3.1-7-7-7m4 7h-3v3h-2v-3H9V8h3V5h2v3h3v2Z"/></svg>

    </a>
    CyberSecAI
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Introduction
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/Preface/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Preface
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/Introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model Types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction/cybsersecurity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LLMs for CyberSecurity
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    NotebookLM
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            NotebookLM
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM_VulnerabilityStandards/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM Vulnerability Standards
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM_Capec/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM CAPEC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM_Attack/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM ATTACK
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM_Config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM Config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../NotebookLM/NotebookLM_Secure_Code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM Secure Code
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Grounded Closed System
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            Grounded Closed System
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Grounded/grounding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Grounding
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CWE Assignment
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            CWE Assignment
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CWE_Assignment/cwe_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CWE_Assignment/cwe_gpt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT CWE GPT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CWE_Assignment/NotebookLM_Cwe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NotebookLM CWE
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CWE_Assignment/vertex_ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Vertex AI CWE Agent
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../CWE_Assignment/Vulnrichment/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m13 18.9 6.1-6.1 2.1 2.1-6.1 6.1H13v-2.1m8.4-7.6 1.3 1.3c.2.2.2.5 0 .7l-1 1-2.1-2 1-1c.1-.1.2-.2.4-.2s.3 0 .4.2M11 21H5c-.5 0-1-.2-1.4-.6-.4-.4-.6-.9-.6-1.4V5c0-.5.2-1 .6-1.4C4 3.2 4.5 3 5 3h14c1.1 0 2 .9 2 2v4h-2V5H5v14h6v2m4-9-5-4v8l5-4Z"/></svg>
  
  <span class="md-ellipsis">
    CISA Vulnrichment
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Context Engineering
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Context Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../context_engineering/context/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Context Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_6_2" >
        
          
          <label class="md-nav__link" for="__nav_6_2" id="__nav_6_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Prompt Engineering
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_6_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6_2">
            <span class="md-nav__icon md-icon"></span>
            Prompt Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../prompt_engineering/prompt_engineering/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Prompt Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../prompt_engineering/Fabric/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fabric
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7" >
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Engineering
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            Software Engineering
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Engineering
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/software_assurance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Assurance
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/software_artifacts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Artifacts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_5" >
        
          
          <label class="md-nav__link" for="__nav_7_5" id="__nav_7_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Engineering Agents
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_5">
            <span class="md-nav__icon md-icon"></span>
            Software Engineering Agents
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/code/code_assistant_agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Assistant vs. Autonomous Coding Agents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/swe_agents_report/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Engineering Agents Report
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/swe_agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Engineering Agents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/code/leaderboards/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Leaderboards
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_7_6" >
        
          
          <label class="md-nav__link" for="__nav_7_6" id="__nav_7_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Software Engineering 1.0 Redux
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_7_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7_6">
            <span class="md-nav__icon md-icon"></span>
            Software Engineering 1.0 Redux
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/swe_redux/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m13 18.9 6.1-6.1 2.1 2.1-6.1 6.1H13v-2.1m8.4-7.6 1.3 1.3c.2.2.2.5 0 .7l-1 1-2.1-2 1-1c.1-.1.2-.2.4-.2s.3 0 .4.2M11 21H5c-.5 0-1-.2-1.4-.6-.4-.4-.6-.9-.6-1.4V5c0-.5.2-1 .6-1.4C4 3.2 4.5 3 5 3h14c1.1 0 2 .9 2 2v4h-2V5H5v14h6v2m4-9-5-4v8l5-4Z"/></svg>
  
  <span class="md-ellipsis">
    Software Engineering 1.0 Redux
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/swe_redux_security/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Software Engineering Security
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/pre_post_policy_as_code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Policy As Code Served Pre and Post Code
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/aixcc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AIxCC
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/threat_model/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m13 18.9 6.1-6.1 2.1 2.1-6.1 6.1H13v-2.1m8.4-7.6 1.3 1.3c.2.2.2.5 0 .7l-1 1-2.1-2 1-1c.1-.1.2-.2.4-.2s.3 0 .4.2M11 21H5c-.5 0-1-.2-1.4-.6-.4-.4-.6-.9-.6-1.4V5c0-.5.2-1 .6-1.4C4 3.2 4.5 3 5 3h14c1.1 0 2 .9 2 2v4h-2V5H5v14h6v2m4-9-5-4v8l5-4Z"/></svg>
  
  <span class="md-ellipsis">
    Threat Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../software/claude_code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Claude Code
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_8" >
        
          
          <label class="md-nav__link" for="__nav_8" id="__nav_8_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    CyberSecurity Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_8">
            <span class="md-nav__icon md-icon"></span>
            CyberSecurity Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cti_models/cyber_security_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CyberSecurity LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/Agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Agents
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/Build_agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Build Agents
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_9" >
        
          
          <label class="md-nav__link" for="__nav_9" id="__nav_9_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    TopicModeling
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_9">
            <span class="md-nav__icon md-icon"></span>
            TopicModeling
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../TopicModeling/BertTopic/" class="md-nav__link">
        
  
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m13 18.9 6.1-6.1 2.1 2.1-6.1 6.1H13v-2.1m8.4-7.6 1.3 1.3c.2.2.2.5 0 .7l-1 1-2.1-2 1-1c.1-.1.2-.2.4-.2s.3 0 .4.2M11 21H5c-.5 0-1-.2-1.4-.6-.4-.4-.6-.9-.6-1.4V5c0-.5.2-1 .6-1.4C4 3.2 4.5 3 5 3h14c1.1 0 2 .9 2 2v4h-2V5H5v14h6v2m4-9-5-4v8l5-4Z"/></svg>
  
  <span class="md-ellipsis">
    BertTopic
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_10" >
        
          
          <label class="md-nav__link" for="__nav_10" id="__nav_10_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    References
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_10">
            <span class="md-nav__icon md-icon"></span>
            References
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../research/research/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Research
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_11" >
        
          
          <label class="md-nav__link" for="__nav_11" id="__nav_11_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Annex
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_11">
            <span class="md-nav__icon md-icon"></span>
            Annex
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../annex/Learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../annex/Glossary/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Glossary
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../research/research/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Research
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#" class="md-nav__link">
    <span class="md-ellipsis">
      1. Home
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      I. Introduction
    </span>
  </a>
  
    <nav class="md-nav" aria-label="I. Introduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#introduction-preface" class="md-nav__link">
    <span class="md-ellipsis">
      2. Preface
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      3. Introduction
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction-models" class="md-nav__link">
    <span class="md-ellipsis">
      4. Model Types
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#introduction-cybsersecurity" class="md-nav__link">
    <span class="md-ellipsis">
      5. LLMs for CyberSecurity
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-notebooklm" class="md-nav__link">
    <span class="md-ellipsis">
      II. NotebookLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="II. NotebookLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm" class="md-nav__link">
    <span class="md-ellipsis">
      6. NotebookLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm_vulnerabilitystandards" class="md-nav__link">
    <span class="md-ellipsis">
      7. NotebookLM Vulnerability Standards
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm_capec" class="md-nav__link">
    <span class="md-ellipsis">
      8. NotebookLM CAPEC
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm_attack" class="md-nav__link">
    <span class="md-ellipsis">
      9. NotebookLM ATTACK
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm_config" class="md-nav__link">
    <span class="md-ellipsis">
      10. NotebookLM Config
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#notebooklm-notebooklm_secure_code" class="md-nav__link">
    <span class="md-ellipsis">
      11. NotebookLM Secure Code
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-grounded-closed-system" class="md-nav__link">
    <span class="md-ellipsis">
      III. Grounded Closed System
    </span>
  </a>
  
    <nav class="md-nav" aria-label="III. Grounded Closed System">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#grounded-grounding" class="md-nav__link">
    <span class="md-ellipsis">
      12. Grounding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-cwe-assignment" class="md-nav__link">
    <span class="md-ellipsis">
      IV. CWE Assignment
    </span>
  </a>
  
    <nav class="md-nav" aria-label="IV. CWE Assignment">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cwe_assignment-cwe_overview" class="md-nav__link">
    <span class="md-ellipsis">
      13. Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cwe_assignment-cwe_gpt" class="md-nav__link">
    <span class="md-ellipsis">
      14. ChatGPT CWE GPT
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cwe_assignment-notebooklm_cwe" class="md-nav__link">
    <span class="md-ellipsis">
      15. NotebookLM CWE
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cwe_assignment-vertex_ai" class="md-nav__link">
    <span class="md-ellipsis">
      16. Vertex AI CWE Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cwe_assignment-vulnrichment" class="md-nav__link">
    <span class="md-ellipsis">
      17. CISA Vulnrichment
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-context-engineering" class="md-nav__link">
    <span class="md-ellipsis">
      V. Context Engineering
    </span>
  </a>
  
    <nav class="md-nav" aria-label="V. Context Engineering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#context_engineering-context" class="md-nav__link">
    <span class="md-ellipsis">
      18. Context Engineering
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-software-engineering" class="md-nav__link">
    <span class="md-ellipsis">
      VI. Software Engineering
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VI. Software Engineering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#software-overview" class="md-nav__link">
    <span class="md-ellipsis">
      19. Overview
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#software-introduction" class="md-nav__link">
    <span class="md-ellipsis">
      20. Software Engineering
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#software-software_assurance" class="md-nav__link">
    <span class="md-ellipsis">
      21. Software Assurance
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#software-software_artifacts" class="md-nav__link">
    <span class="md-ellipsis">
      22. Software Artifacts
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-cybersecurity-models" class="md-nav__link">
    <span class="md-ellipsis">
      VII. CyberSecurity Models
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VII. CyberSecurity Models">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cti_models-cyber_security_models" class="md-nav__link">
    <span class="md-ellipsis">
      23. CyberSecurity LLMs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agents-agents" class="md-nav__link">
    <span class="md-ellipsis">
      24. Agents
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#agents-build_agents" class="md-nav__link">
    <span class="md-ellipsis">
      25. Build Agents
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-topicmodeling" class="md-nav__link">
    <span class="md-ellipsis">
      VIII. TopicModeling
    </span>
  </a>
  
    <nav class="md-nav" aria-label="VIII. TopicModeling">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#topicmodeling-berttopic" class="md-nav__link">
    <span class="md-ellipsis">
      26. BertTopic
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-references" class="md-nav__link">
    <span class="md-ellipsis">
      IX. References
    </span>
  </a>
  
    <nav class="md-nav" aria-label="IX. References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#research-research" class="md-nav__link">
    <span class="md-ellipsis">
      27. Research
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#section-annex" class="md-nav__link">
    <span class="md-ellipsis">
      X. Annex
    </span>
  </a>
  
    <nav class="md-nav" aria-label="X. Annex">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#annex-learning" class="md-nav__link">
    <span class="md-ellipsis">
      28. Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#annex-glossary" class="md-nav__link">
    <span class="md-ellipsis">
      29. Glossary
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#research-research" class="md-nav__link">
    <span class="md-ellipsis">
      30. Research
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<div id="print-site-page" class="print-site-enumerate-headings print-site-enumerate-figures">
        <section class="print-page">
            <div id="print-page-toc" data-toc-depth="3">
                <nav role='navigation' class='print-page-toc-nav'>
                <h1 class='print-page-toc-title'>Table of Contents</h1>
                </nav>
            </div>
        </section>
        <section class="print-page" id="index"><figure>
<p><img alt="Guide" src="../assets/images/index.webp" width="700" /></p>
<figcaption>Your guide to using AI for CyberSecurity</figcaption>
</figure>
<div class="admonition tip">
<p class="admonition-title">Why Read this Guide?</p>
<p>This guide shows how cybersecurity professionals can get up and running quickly with AI tools to:</p>
<ul>
<li>augment your skills and amplify your impact</li>
<li>reduce your toil</li>
</ul>
<p>Large Language Models (hosted and open source), and BERT-based language models tools will be covered e.g.</p>
<ol>
<li>NotebookLM</li>
<li>Prompts and Prompt Techniques applied to Cybersecurity </li>
<li>BERTopic</li>
<li>Embeddings for CyberSecurity</li>
<li>AI Agents for orchestrated workflows</li>
</ol>
</div>
<div class="admonition tip">
<p class="admonition-title"><abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr> Based Prioritization Guide</p>
<p>Check out another guide I co-wrote with various thought leaders in vulnerability management 
<a href="https://riskbasedprioritization.github.io/">https://riskbasedprioritization.github.io/</a> </p>
<p>The <abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr> Based Prioritization described in this guide significantly reduces the </p>
<ul>
<li>cost of vulnerability management </li>
<li>risk by reducing the time adversaries have access to vulnerable systems they are trying to exploit.</li>
</ul>
</div></section>
                        <h1 class='nav-section-title' id='section-introduction'>
                            Introduction <a class='headerlink' href='#section-introduction' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="introduction-preface"><h1 id="introduction-preface-preface">Preface<a class="headerlink" href="#introduction-preface-preface" title="Permanent link">&para;</a></h1>
<p>Language Models are powerful tools that can be applied to CyberSecurity.</p>
<p>I enjoy learning about, playing with, and applying these tools to better solve problems:</p>
<ul>
<li>I wrote this guide for me, to organize my thoughts and my play time as I play with, and apply, Language Models.</li>
<li>I've found by putting something out there, you get something back.</li>
<li>It's the guide I wish existed already.</li>
</ul>
<p>This approach worked well for the <a href="https://www.linkedin.com/posts/chrisamadden_cybersecurity-riskmanagement-vulnerabilitymanagement-activity-7179915292775452673-5ucc/"><abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr>-Based Prioritization guide</a>...</p>
<p>You may find it useful.</p>
<p><a href="https://www.linkedin.com/in/chrisamadden/">Chris Madden</a></p></section><section class="print-page" id="introduction-introduction"><h1 id="introduction-introduction-introduction">Introduction<a class="headerlink" href="#introduction-introduction-introduction" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">About this Guide</p>
<p>This guide is in an initial early access state currently and is written to organize my play time as I play with, and apply, these tools.</p>
<p>The content is about solving real problems e.g. how to </p>
<ul>
<li>view the main topics in a set of documents</li>
<li>validate assigned <a href="https://cwe.mitre.org/">CWEs</a>, and suggest <a href="https://cwe.mitre.org/">CWEs</a> to assign </li>
<li>chat with large documents </li>
<li>extract configuration parameters from user manuals.</li>
</ul>
<p>These examples were driven by a user need. </p>
<p>While the examples focus on specific areas, they can be applied in general to many areas.</p>
</div>
<div class="admonition success">
<p class="admonition-title">After reading this guide you should be able to</p>
<ol>
<li>Apply Language Models to augment and amplify your skills.</li>
<li>Understand the types of problems that suit Language Models, and those that don't</li>
</ol>
</div>
<h2 id="introduction-introduction-overview">Overview<a class="headerlink" href="#introduction-introduction-overview" title="Permanent link">&para;</a></h2>
<h2 id="introduction-introduction-intended-audience">Intended Audience<a class="headerlink" href="#introduction-introduction-intended-audience" title="Permanent link">&para;</a></h2>
<p>The intended audience is people wanting to go beyond the hype and basics of Large Language Models.</p>
<p>No prior knowledge is assumed to read the guide - it provides just enough information to understand the advanced topics covered.</p>
<p>A basic knowledge of Jupyter Python is required to run the code (with the data provided or on your data).</p>
<h2 id="introduction-introduction-how-to-use-this-guide">How to Use This Guide<a class="headerlink" href="#introduction-introduction-how-to-use-this-guide" title="Permanent link">&para;</a></h2>
<h2 id="introduction-introduction-how-to-contribute-to-this-guide">How to Contribute to This Guide<a class="headerlink" href="#introduction-introduction-how-to-contribute-to-this-guide" title="Permanent link">&para;</a></h2>
<p>You can contribute content or suggest changes:</p>
<ul>
<li>ðŸ’¬ <a href="https://github.com/CyberSecAI/CyberSecAI.github.io/discussions">Discuss content</a></li>
<li>ðŸ’¡ <a href="https://github.com/CyberSecAI/CyberSecAI.github.io/issues/">Suggest content</a></li>
<li>ðŸª² <a href="https://github.com/CyberSecAI/CyberSecAI.github.io/issues/">Report Errors, typos</a></li>
</ul>
<h2 id="introduction-introduction-writing-style">Writing Style<a class="headerlink" href="#introduction-introduction-writing-style" title="Permanent link">&para;</a></h2>
<p>The "writing style" in this guide is succinct, and leads with an opinion, with data and code to back it up i.e. data analysis plots (with source code where possible) and observations and takeaways that you can assess - and apply to your data and environment. This allows the reader to assess the opinion and the code/data and rationale behind it.</p>
<p>Different, and especially opposite, opinions with the data to back them up, are especially welcome! - and will help shape this guide.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>If we have data, letâ€™s look at data. If all we have are opinions, letâ€™s go with mine.</p>
<p><a href="https://www.goodreads.com/quotes/655987-if-we-have-data-let-s-look-at-data-if-all">Jim Barksdale, former CEO of Netscape</a> </p>
</div>
<h2 id="introduction-introduction-notes">Notes<a class="headerlink" href="#introduction-introduction-notes" title="Permanent link">&para;</a></h2>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<ol>
<li>This guide is not affiliated with any Tool/Company/Vendor/Standard/Forum/Data source. <ol>
<li>Mention of a vendor in this guide is not a recommendation or endorsement of that vendor. </li>
</ol>
</li>
<li>This guide is a living document i.e. it will change and grow over time - with your input.</li>
</ol>
</div>
<div class="admonition quote">
<p class="admonition-title">This guide is not about which tool is better than the other</p>
<p>"Don't fall in love with models: they're expendable. Fall in love with data!" </p>
<p>Julien Simon, Chief Evangelist, Hugging Face</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This space is rapidly evolving so the content in this guide may become no longer current or accurate.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You are responsible for your data and where it goes. </p>
<p>If you don't understand where your data goes, and what happens to it for a given model or tool, then find out before you use private or personal data.</p>
<p>To evaluate models and tools, you can start with public data.</p>
</div></section><section class="print-page" id="introduction-models"><h1 id="introduction-models-model-types">Model Types<a class="headerlink" href="#introduction-models-model-types" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section gives an overview of different model types.</p>
</div>
<h2 id="introduction-models-introduction">Introduction<a class="headerlink" href="#introduction-models-introduction" title="Permanent link">&para;</a></h2>
<p>Different types of text models are designed with varying architectures, training data, and optimization goals, leading to distinct capabilities and best-fit use cases. </p>
<p>While many models focus primarily on text, an increasing number are becoming multimodal, capable of processing and generating information across different types of data, such as text, images, audio, and even video.</p>
<p>Today, these different types of models are generally accessed by selecting the specific model or API endpoint provided by developers (versus the user accessing the same interface that figures out the best type of model).</p>
<h2 id="introduction-models-deep-research">Deep Research<a class="headerlink" href="#introduction-models-deep-research" title="Permanent link">&para;</a></h2>
<p>Models in this category are typically designed for in-depth information retrieval, synthesis, and report generation from vast amounts of data, often involving Browse and analyzing multiple sources. They aim to provide comprehensive and well-supported answers to complex queries.</p>
<p><strong>Key Insights:</strong></p>
<ul>
<li><strong>Extensive Information Gathering:</strong> Excel at searching and processing information from large and diverse datasets, including the web or private document repositories.</li>
<li><strong>Synthesis and Structuring:</strong> Capable of synthesizing information from various sources into coherent and structured reports or summaries.</li>
<li><strong>Handling Complexity:</strong> Designed to tackle complex, multi-faceted research questions that require connecting information across different domains.</li>
<li><strong>Citation and Verification:</strong> Often include features for citing sources, allowing users to verify the information presented.</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Generating detailed reports on niche or complex topics.</li>
<li>Performing market research by analyzing industry trends and competitor information.</li>
<li>Assisting academics and researchers in literature reviews and synthesizing findings.</li>
<li>Providing comprehensive answers to complex legal, medical, or scientific questions.</li>
<li>Analyzing large volumes of internal documents to extract insights.</li>
</ul>
<p><strong>Examples:</strong> Perplexity Deep Research, ChatGPT Deep Research, Gemini Deep Research, HuggingFace Open Deep Research, Claude 3 Opus</p>
<h2 id="introduction-models-reasoning">Reasoning<a class="headerlink" href="#introduction-models-reasoning" title="Permanent link">&para;</a></h2>
<p>Reasoning-focused models are optimized to perform complex logical deductions, solve problems requiring multiple steps, and understand intricate relationships between concepts. They are built to "think" through problems rather than just retrieving information or generating text based on patterns.</p>
<p><strong>Key Insights:</strong></p>
<ul>
<li><strong>Logical Deduction:</strong> Strong capabilities in applying logical rules and deriving conclusions from given premises.</li>
<li><strong>Multi-Step Problem Solving:</strong> Can break down complex problems into smaller, manageable steps and follow a chain of thought to reach a solution.</li>
<li><strong>Mathematical and Scientific Reasoning:</strong> Often perform well on mathematical problems, coding challenges, and scientific inquiries that require step-by-step analysis.</li>
<li><strong>Reduced Hallucination in Complex Tasks:</strong> While still a challenge for all LLMs, models focused on reasoning aim to reduce the likelihood of generating false or inconsistent information in complex scenarios by showing their work or using techniques like self-correction.</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Solving complex mathematical equations or proofs.</li>
<li>Debugging code and suggesting logical fixes.</li>
<li>Analyzing data and drawing reasoned conclusions.</li>
<li>Assisting in strategic planning by evaluating scenarios and predicting outcomes.</li>
<li>Providing step-by-step explanations for complex concepts or solutions.</li>
<li>Excelling at benchmarks requiring logical inference and problem-solving.</li>
</ul>
<p><strong>Examples:</strong> DeepSeek-R1, OpenAIâ€™s GPT-4, Googleâ€™s Gemini Ultra, Anthropicâ€™s Claude 3 Sonnet, Metaâ€™s Llama 3</p>
<h2 id="introduction-models-general-purpose">General Purpose<a class="headerlink" href="#introduction-models-general-purpose" title="Permanent link">&para;</a></h2>
<p>General-purpose LLMs are designed to be versatile and handle a wide array of natural language tasks. They are trained on broad datasets to provide a good balance of capabilities across different domains without being specifically optimized for one.</p>
<p><strong>Key Insights:</strong></p>
<ul>
<li><strong>Versatility:</strong> Capable of performing a wide range of tasks, including text generation, summarization, translation, question answering, and creative writing.</li>
<li><strong>Broad Knowledge:</strong> Possess a vast amount of general knowledge from their diverse training data.</li>
<li><strong>Adaptability:</strong> Can often adapt to different styles and formats based on the prompt.</li>
<li><strong>Accessibility:</strong> Typically the most widely available and accessible models for everyday use.</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Drafting emails, articles, and other written content.</li>
<li>Summarizing documents or long texts.</li>
<li>Translating text between languages.</li>
<li>Answering general knowledge questions.</li>
<li>Brainstorming ideas and assisting in creative writing.</li>
<li>Powering chatbots and virtual assistants for a variety of inquiries.</li>
</ul>
<p><strong>Examples:</strong> GPT-4 Turbo, Gemini Pro, Claude 3 Haiku, Mistral Large, Cohere Command R+</p>
<h2 id="introduction-models-code">Code<a class="headerlink" href="#introduction-models-code" title="Permanent link">&para;</a></h2>
<p>Code-focused models are specifically trained on large datasets of code from various programming languages and sources. They are designed to understand, generate, and assist with programming tasks.</p>
<p><strong>Key Insights:</strong></p>
<ul>
<li><strong>Code Generation:</strong> Can generate code snippets, functions, or even entire programs based on natural language descriptions or prompts.</li>
<li><strong>Code Completion:</strong> Provide intelligent suggestions for completing code as developers type.</li>
<li><strong>Code Explanation and Documentation:</strong> Can explain how code works and generate documentation.</li>
<li><strong>Debugging and Error Detection:</strong> Assist in identifying potential errors and suggesting fixes in code.</li>
<li><strong>Code Translation:</strong> Translate code between different programming languages.</li>
<li><strong>Support for Multiple Languages:</strong> Trained on a wide variety of programming languages.</li>
</ul>
<p><strong>Use Cases:</strong></p>
<ul>
<li>Speeding up software development by generating boilerplate code.</li>
<li>Assisting developers in learning new programming languages or frameworks.</li>
<li>Automating repetitive coding tasks.</li>
<li>Improving code quality through suggestions and error detection.</li>
<li>Generating test cases for software.</li>
<li>Helping non-programmers understand or modify code.</li>
</ul>
<p><strong>Examples:</strong> CodeLlama (Meta), StarCoder (ServiceNow), Codex (OpenAI), DeepSeek Coder, Googleâ€™s Codey</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>This <a href="https://www.qodo.ai/blog/comparison-of-claude-sonnet-3-5-gpt-4o-o1-and-gemini-1-5-pro-for-coding/">blog</a> gives a good overview of different models' capabilities for code and echoes my experience.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Code Generation is a small part of <a href="#software-introduction">Software Engineering</a>.</p>
<p>Different model types are suitable for different <a href="#software-software_artifacts">Software Engineering Artifacts</a></p>
</div></section><section class="print-page" id="introduction-cybsersecurity"><h1 id="introduction-cybsersecurity-llms-for-cybersecurity">LLMs for CyberSecurity<a class="headerlink" href="#introduction-cybsersecurity-llms-for-cybersecurity" title="Permanent link">&para;</a></h1>
<h2 id="introduction-cybsersecurity-llms-for-cybersecurity-users-and-use-cases">LLMs for CyberSecurity Users and Use Cases<a class="headerlink" href="#introduction-cybsersecurity-llms-for-cybersecurity-users-and-use-cases" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/LLMS4_cybersec.png" /></p>
</figure>
<p>Image from <a href="https://arxiv.org/pdf/2405.12750">Generative AI and Large Language Models for Cyber Security: All Insights You Need</a>. </p>
<h3 id="introduction-cybsersecurity-empathy-map">Empathy Map<a class="headerlink" href="#introduction-cybsersecurity-empathy-map" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/empathy_map.jpeg" /></p>
</figure>
<p>See <a href="https://www.linkedin.com/posts/davegray_ever-wonder-what-executives-really-think-activity-7333196966530584576-lBxz?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAABWk8gB0ZomDiP_SswS-WaTp-lhgZEPxlI">Original Post</a>.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See also MITREâ€™s Innovation Toolkit <a href="https://itk.mitre.org/toolkit/tools-at-a-glance/">https://itk.mitre.org/toolkit/tools-at-a-glance/</a> a collection of proven and repeatable problem-solving methods to help you and your team do something different that makes a difference.</p>
</div>
<h3 id="introduction-cybsersecurity-targeted-premortem-for-trustworthy-ai">Targeted PreMortem for Trustworthy AI<a class="headerlink" href="#introduction-cybsersecurity-targeted-premortem-for-trustworthy-ai" title="Permanent link">&para;</a></h3>
<p>In general, it is good practice to start with the end in mind ala <a href="https://framework.scaledagile.com/portfolio-vision/">"Destination Postcard" from the book Switch, Dan and Chip Heath</a> which looks at the aspirational positive outcomes.</p>
<p>This is also useful for Premortems to proactively identify failures so they can be avoided, to ensure the positive outcomes.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The Targeted Premortem (TPM) is a variant of Klein's Premortem Technique, which uses prospective hindsight to proactively identify failures. This variant targets brainstorming on reasons for losing trust in AI in the context of the sociotechnical system into which it is integrated. That is, the prompts are targeted to specific evidence-based focus areas where trust has been lost in AI. This tool comes with instructions, brainstorming prompts, and additional guidance on how to analyze the outcomes of a TPM session with users, developers, and other stakeholders.</p>
<p><a href="https://www.researchgate.net/publication/389316278_Targeted_PreMortem_TPM_for_Trustworthy_AI">MITRE Targeted PreMortem for Trustworthy AI</a></p>
</div>
<h2 id="introduction-cybsersecurity-references">References<a class="headerlink" href="#introduction-cybsersecurity-references" title="Permanent link">&para;</a></h2>
<h3 id="introduction-cybsersecurity-llms-for-cybersecurity-references">LLMs for CyberSecurity References<a class="headerlink" href="#introduction-cybsersecurity-llms-for-cybersecurity-references" title="Permanent link">&para;</a></h3>
<ol>
<li><a href="https://arxiv.org/pdf/2405.12750">Generative AI and Large Language Models for Cyber Security: All Insights You Need</a>, May 2024</li>
<li><a href="https://www.researchgate.net/publication/384500263_A_Comprehensive_Review_of_Large_Language_Models_in_Cyber_Security">A Comprehensive Review of Large Language Models in Cyber Security</a>, September 2024</li>
<li><a href="https://arxiv.org/pdf/2402.00891">Large Language Models in Cybersecurity: State-of-the-Art</a>, January 2024</li>
<li><a href="https://elie.net/talk/ai-for-cybersecurity-get-started-today">How Large Language Models Are Reshaping the Cybersecurity Landscape</a> | Global AI Symposium talk, September 2024</li>
<li><a href="https://arxiv.org/pdf/2405.04760">Large Language Models for Cyber Security: A Systematic Literature Review</a>, July 2024</li>
<li><a href="https://cloudsecurityalliance.org/artifacts/using-ai-for-offensive-security">Using AI for Offensive Security</a>, June 2024</li>
</ol>
<h3 id="introduction-cybsersecurity-agents-for-cybersecurity-references">Agents for CyberSecurity References<a class="headerlink" href="#introduction-cybsersecurity-agents-for-cybersecurity-references" title="Permanent link">&para;</a></h3>
<ol>
<li><a href="https://www.cybersec-automation.com/p/blueprint-for-ai-agents-in-cybersecurity">Blueprint for AI Agents in Cybersecurity - Leveraging AI Agents to Evolve Cybersecurity Practices</a></li>
<li><a href="https://medium.com/@cpdough/building-ai-agents-lessons-learned-over-the-past-year-41dc4725d8e5">Building AI Agents: Lessons Learned over the past Year</a></li>
</ol>
<h3 id="introduction-cybsersecurity-comparing-llms">Comparing LLMs<a class="headerlink" href="#introduction-cybsersecurity-comparing-llms" title="Permanent link">&para;</a></h3>
<p>There are several sites that allow comparisons of LLMs e.g.</p>
<ol>
<li><a href="https://winston-bosan.github.io/llm-pareto-frontier/">https://winston-bosan.github.io/llm-pareto-frontier/</a><ol>
<li>LLM Arena Pareto Frontier: Performance vs Cost</li>
</ol>
</li>
<li><a href="https://artificialanalysis.ai/">https://artificialanalysis.ai/</a><ol>
<li>Independent analysis of AI models and API providers. Understand the AI landscape to choose the best model and provider for your use-case</li>
</ol>
</li>
<li><a href="https://llmpricecheck.com/">https://llmpricecheck.com/</a><ol>
<li>Compare and calculate the latest prices for LLM (Large Language Models) APIs from leading providers such as OpenAI GPT-4, Anthropic Claude, Google Gemini, Mate Llama 3, and more. Use our streamlined LLM Price Check tool to start optimizing your AI budget efficiently today!</li>
</ol>
</li>
<li><a href="https://openrouter.ai/rankings?view=day">https://openrouter.ai/rankings?view=day</a> <ol>
<li>Compare models used via OpenRouter</li>
</ol>
</li>
<li><a href="https://github.com/vectara/hallucination-leaderboard">https://github.com/vectara/hallucination-leaderboard</a> <ol>
<li>LLM Hallucination Rate leaderboard</li>
</ol>
</li>
<li><a href="https://lmarena.ai/?leaderboard">https://lmarena.ai/?leaderboard</a><ol>
<li>Chatbot Arena is an open platform for crowdsourced AI benchmarking</li>
</ol>
</li>
<li><a href="https://aider.chat/docs/leaderboards/">https://aider.chat/docs/leaderboards/</a><ol>
<li>Benchmark to evaluate an LLMâ€™s ability to follow instructions and edit code successfully without human intervention</li>
</ol>
</li>
<li><a href="https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro">https://huggingface.co/spaces/TIGER-Lab/MMLU-Pro</a><ol>
<li>Benchmark to evaluate language understanding models across broader and more challenging tasks</li>
</ol>
</li>
</ol>
<p>See also <a href="https://medium.com/data-science-collective/economics-of-llms-evaluations-vs-pricing-04802074e095">Economics of LLMs: Evaluations vs Pricing - Looking at which model to use for which task</a></p>
<h3 id="introduction-cybsersecurity-books">Books<a class="headerlink" href="#introduction-cybsersecurity-books" title="Permanent link">&para;</a></h3>
<ol>
<li><a href="https://www.oreilly.com/library/view/build-a-large/9781633437166/">Build a Large Language Model (from Scratch)</a> by Sebastian Raschka, PhD </li>
<li><a href="https://www.oreilly.com/library/view/llm-engineers-handbook/9781836200079/">LLM Engineer's Handbook</a> by Paul Iusztin and Maxime Labonne </li>
<li><a href="https://www.oreilly.com/library/view/ai-engineering/9781098166298/">AI Engineering</a> by Chip Huyen </li>
<li><a href="https://www.amazon.ie/Hands-Large-Language-Models-Understanding/dp/1098150961">Hands-On Large Language Models: Language Understanding and Generation</a>, Oct 2024, Jay Alammar and Maarten Grootendorst</li>
<li><a href="https://www.louisbouchard.ai/book-towards-ai/">Building LLMs for Production: Enhancing LLM Abilities and Reliability with Prompting, Fine-Tuning, and RAG</a>, October 2024, Louis-Francois Bouchard and Louie Peters</li>
<li><a href="https://www.manning.com/books/llms-in-production">LLMs in Production From language models to successful products</a>, December 2024, Christopher Brousseau and Matthew Sharp</li>
<li><a href="https://www.edpb.europa.eu/our-work-tools/our-documents/support-pool-experts-projects/fundamentals-secure-ai-systems-personal_en">Fundamentals of Secure AI Systems with Personal Data</a>, June 2025, Enrico Glerean </li>
</ol></section><h1 class='nav-section-title-end'>Ended: Introduction</h1>
                        <h1 class='nav-section-title' id='section-notebooklm'>
                            NotebookLM <a class='headerlink' href='#section-notebooklm' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="notebooklm-notebooklm"><h1 id="notebooklm-notebooklm-notebooklm">NotebookLM<a class="headerlink" href="#notebooklm-notebooklm-notebooklm" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>LLMs change the information retrieval paradigm. Instead of searching for information where <strong>we go to the information</strong>, we can chat with our documents and ask questions of them, so that <strong>the information comes to us</strong> in the form of an answer. </p>
<p>In this section, we'll use <a href="https://notebooklm.google.com/">NotebookLM</a>, and we just need to import our documents to be able to chat with them. </p>
<p>ChatGPT4o is also used for comparison to highlight where one is better applied than the other depending on the context.</p>
<ul>
<li>Both tools use LLMs, but NoteBookLM uses a "Closed System" (only the document sources you provide), versus ChatGPT4o which bases it answers on the open internet content at the time it was trained, and additionally the documents you provide.</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Your responses from NotebookLM may be different than the examples shown here. LLMs will give different responses to the same question.</p>
</div>
</div>
<h2 id="notebooklm-notebooklm-notebooklm_1"><a href="https://notebooklm.google.com/">NotebookLM</a><a class="headerlink" href="#notebooklm-notebooklm-notebooklm_1" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p><a href="https://notebooklm.google.com/">NotebookLM</a> lets you read, take notes, ask questions, organize your ideas, and much more -- all with the power of Google AI helping you at every step of the way.</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p><a href="https://blog.google/technology/ai/notebooklm-audio-overviews/">Audio Overview</a>, a new way to turn your documents into engaging audio discussions. With one click, two AI hosts start up a lively â€œdeep diveâ€ discussion based on your sources. They summarize your material, make connections between topics, and banter back and forth. You can even download the conversation and take it on the go.</p>
</div>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>It runs on the companyâ€™s Gemini 1.5 Pro model (<a href="https://en.wikipedia.org/wiki/Gemini_(language_model)">released Dec 2023</a>), the same AI that powers the Gemini Advanced chatbot. 
(<a href="https://www.techradar.com/computing/artificial-intelligence/googles-notebooklm-is-now-an-even-smarter-assistant-and-better-fact-checker">ref</a>)</p>
</div>
<h3 id="notebooklm-notebooklm-key-features-and-benefits-of-gemini-15-models">Key Features and Benefits of Gemini 1.5 Models<a class="headerlink" href="#notebooklm-notebooklm-key-features-and-benefits-of-gemini-15-models" title="Permanent link">&para;</a></h3>
<p>Per <a href="https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf">Gemini 1.5 Technical Report</a>, the Key Features and Benefits of Gemini 1.5 Models are</p>
<ol>
<li><strong>Highly Compute-Efficient Multimodal Models</strong><ol>
<li>Capable of recalling and reasoning over fine-grained information from millions of tokens of context, including long documents, videos, and audio.</li>
</ol>
</li>
<li><strong>Benchmark Performance</strong><ol>
<li>Outperforms other models such as Claude 3.0 (200k tokens) and GPT-4 Turbo (128k tokens) in next-token prediction and retrieval up to 10M tokens (approximately 7M words).</li>
</ol>
</li>
<li><strong>Unprecedented Context Handling</strong><ol>
<li>Handles extremely long contexts, up to at least 10M tokens (approximately 7M words).</li>
<li>Capable of processing long-form mixed-modality inputs, including entire document collections, multiple hours of video, and almost five days of audio.</li>
<li>Near-perfect recall on long-context retrieval tasks across various modalities.</li>
</ol>
</li>
<li><strong>Realistic Multimodal Long-Context Benchmarks</strong><ol>
<li>Excels in tasks requiring retrieval and reasoning over multiple parts of the context.</li>
<li>Outperforms all competing models across all modalities, even those augmented with external retrieval methods.</li>
</ol>
</li>
</ol>
<p>These features make Gemini 1.5 models a generational leap over existing models, offering unparalleled performance in processing and understanding extensive and complex multimodal information.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Such systems map document content to vectors (numeric representations of words or tokens in multi-dimensional space).</p>
<p>Queries are based on similarity (proximity in vector space).</p>
</div>
<h3 id="notebooklm-notebooklm-document-loading">Document Loading<a class="headerlink" href="#notebooklm-notebooklm-document-loading" title="Permanent link">&para;</a></h3>
<p>Documents are loaded via GoogleDrive, PDFs, Text files, Copied text, Web page URL.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Any sources can be used e.g. Books in PDF format, websites, text files.</p>
<p>Using a file of site content (if available) e.g.a PDF, is generally more reliable than using a URL to that site; it ensures all the content is ingested.</p>
</div>
<h3 id="notebooklm-notebooklm-closed-system">Closed System<a class="headerlink" href="#notebooklm-notebooklm-closed-system" title="Permanent link">&para;</a></h3>
<p>These documents become the corpus where information is retrieved from, with references to the document(s) the information was retrieved from.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>â€œNotebookLM is a closed system.â€ This means the AI wonâ€™t perform any web searches beyond what you, the user, give it in a prompt. Every response it generates pertains only to the information it has on hand.
(<a href="https://www.techradar.com/computing/artificial-intelligence/googles-notebooklm-is-now-an-even-smarter-assistant-and-better-fact-checker">ref</a>)</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p><strong>â€œsource-grounded AIâ€</strong>: you define a set of documents that are important to your workâ€”called â€œsourcesâ€ in the NotebookLM parlanceâ€”and from that point on, you can have an open-ended conversation with the language model where its answers will be â€œgroundedâ€ in the information youâ€™ve selected. It is as if you are giving the AI instant expertise in whatever domain you happen to be working in. (<a href="https://adjacentpossible.substack.com/p/introducing-notebooklm">ref</a>)</p>
</div>
<h4 id="notebooklm-notebooklm-what-is-a-dog">What is a dog?<a class="headerlink" href="#notebooklm-notebooklm-what-is-a-dog" title="Permanent link">&para;</a></h4>
<p>This is illustrated with a simple example of asking our <a href="#cwe_assignment-cwe_overview">Notebook on CWEs</a> "what is a dog?":</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The sources provided do not contain any information about dogs. Therefore, the query "what is a dog?" cannot be answered from the given sources.</p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/what_is_a_dog.png" /></p>
<figcaption></figcaption>
</figure>
<h3 id="notebooklm-notebooklm-sharing">Sharing<a class="headerlink" href="#notebooklm-notebooklm-sharing" title="Permanent link">&para;</a></h3>
<p>Unlike Google Docs, it is not possible to share a NotebookLM publicly - sharing is done directly via email addresses.</p>
<h3 id="notebooklm-notebooklm-how-to-use-notebooklm">How To Use NotebookLM<a class="headerlink" href="#notebooklm-notebooklm-how-to-use-notebooklm" title="Permanent link">&para;</a></h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/iWPjBwXy_Io?si=0Z0e0u_ni0R4tAM-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<h2 id="notebooklm-notebooklm-references">References<a class="headerlink" href="#notebooklm-notebooklm-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://adjacentpossible.substack.com/p/introducing-notebooklm">Introducing NotebookLM</a>, Oct 19, 2023, Steven Johnson who contributed to NotebookLM</li>
<li><a href="https://medium.com/@stevenbjohnson/getting-the-most-out-of-notes-in-notebooklm-d9d70316b780">Getting The Most Out Of Notes In NotebookLM</a>, Mar 18, 2024, Steven Johnson</li>
<li><a href="https://stevenberlinjohnson.com/how-to-use-notebooklm-as-a-research-tool-6ad5c3a227cc">How To Use NotebookLM As A Research Tool</a>, Feb 19, 2024, Steven Johnson</li>
<li><a href="https://www.techradar.com/computing/artificial-intelligence/googles-notebooklm-is-now-an-even-smarter-assistant-and-better-fact-checker">Google's NotebookLM is now an even smarter assistant and better fact-checker</a>, June 7, 2024 </li>
<li><a href="https://www.kdnuggets.com/using-google-notebooklm-for-data-science-a-comprehensive-guide">Using Googleâ€™s NotebookLM for Data Science: A Comprehensive Guide</a>, Dec 7, 2023 </li>
<li><a href="https://www.computerworld.com/article/1611774/google-notebooklm-generative-ai-notes-app.html">How to use Googleâ€™s genAI-powered note-taking app</a>, Feb 15, 2024 </li>
</ol>
<h2 id="notebooklm-notebooklm-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>NotebookLM is a powerful free solution from Google that allows users to quickly and easily build a source-grounded AI (where users define the set of documents) and then have an open-ended conversation with the language model where its answers will be â€œgroundedâ€ in the information users selected.</li>
<li>The support for large contexts means that large documents can be processed - as demonstrated in the following sections.</li>
<li>I found it a useful tool / companion for the research I was doing on vulnerability management to augment my knowledge and capabilities.</li>
</ol>
</div></section><section class="print-page" id="notebooklm-notebooklm_vulnerabilitystandards"><h1 id="notebooklm-notebooklm_vulnerabilitystandards-notebooklm-vulnerability-standards">NotebookLM Vulnerability Standards<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-notebooklm-vulnerability-standards" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>In this chapter, we'll feed the main vulnerability standards to <a href="https://notebooklm.google.com/">NotebookLM</a>.</p>
</div>
<h2 id="notebooklm-notebooklm_vulnerabilitystandards-data-sources">Data Sources<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-data-sources" title="Permanent link">&para;</a></h2>
<p>These files are available in docs/NotebookLM/InputDocs for convenience.</p>
<table>
<thead>
<tr>
<th><strong>Content</strong></th>
<th><strong>Page with link to content</strong></th>
<th><strong>Direct Link</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr> Based Prioritization Guide</td>
<td><a href="https://riskbasedprioritization.github.io/print_page/">https://riskbasedprioritization.github.io/print_page/</a></td>
<td>Print - Save to PDF</td>
</tr>
<tr>
<td><abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 3.1 User Guide</td>
<td><a href="https://www.first.org/cvss/v3.1/user-guide">https://www.first.org/cvss/v3.1/user-guide</a></td>
<td><a href="https://www.first.org/cvss/v3-1/cvss-v31-user-guide_r1.pdf">https://www.first.org/cvss/v3-1/cvss-v31-user-guide_r1.pdf</a></td>
</tr>
<tr>
<td><abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 3.1 Specification</td>
<td><a href="https://www.first.org/cvss/v3.1/specification-document">https://www.first.org/cvss/v3.1/specification-document</a></td>
<td><a href="https://www.first.org/cvss/v3-1/cvss-v31-specification_r1.pdf">https://www.first.org/cvss/v3-1/cvss-v31-specification_r1.pdf</a></td>
</tr>
<tr>
<td><abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 4.0 User Guide</td>
<td><a href="https://www.first.org/cvss/v4.0/user-guide">https://www.first.org/cvss/v4.0/user-guide</a></td>
<td><a href="https://www.first.org/cvss/v4-0/cvss-v40-user-guide.pdf">https://www.first.org/cvss/v4-0/cvss-v40-user-guide.pdf</a></td>
</tr>
<tr>
<td><abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 4.0 Specification Document</td>
<td><a href="https://www.first.org/cvss/v4.0/specification-document">https://www.first.org/cvss/v4.0/specification-document</a></td>
<td><a href="https://www.first.org/cvss/v4-0/cvss-v40-specification.pdf">https://www.first.org/cvss/v4-0/cvss-v40-specification.pdf</a></td>
</tr>
<tr>
<td>Exploit Prediction Scoring System (<abbr title="Exploit Prediction Scoring System">EPSS</abbr>) FAQ</td>
<td><a href="https://www.first.org/epss/faq">https://www.first.org/epss/faq</a></td>
<td><a href="https://www.first.org/epss/faq">https://www.first.org/epss/faq</a></td>
</tr>
<tr>
<td>Exploit Prediction Scoring System (<abbr title="Exploit Prediction Scoring System">EPSS</abbr>) latest published paper</td>
<td><a href="https://www.first.org/epss/model">https://www.first.org/epss/model</a></td>
<td><a href="https://arxiv.org/pdf/2302.14172">https://arxiv.org/pdf/2302.14172</a></td>
</tr>
<tr>
<td>Stakeholder-Specific Vulnerability Categorization (<abbr title="SSVC Stakeholder-Specific Vulnerability Categorization">SSVC</abbr>) latest published paper</td>
<td><a href="https://github.com/CERTCC/SSVC/tree/main/pdfs">https://github.com/CERTCC/<abbr title="SSVC Stakeholder-Specific Vulnerability Categorization">SSVC</abbr>/tree/main/pdfs</a></td>
<td><a href="https://github.com/CERTCC/SSVC/blob/main/pdfs/ssvc_2_1_draft.pdf">https://github.com/CERTCC/<abbr title="SSVC Stakeholder-Specific Vulnerability Categorization">SSVC</abbr>/blob/main/pdfs/ssvc_2_1_draft.pdf</a></td>
</tr>
<tr>
<td><abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> <abbr title="Known Exploited Vulnerability">KEV</abbr></td>
<td><a href="https://www.cisa.gov/known-exploited-vulnerabilities">https://www.cisa.gov/known-exploited-vulnerabilities</a></td>
<td>copy and paste text to a file cisakev.txt because NotebookLM cannot pull content directly from the page</td>
</tr>
</tbody>
</table>
<div class="admonition experiment">
<p class="admonition-title">Data Sources</p>
<p>The vulnerability standards PDFs are available in
<a href="https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_VulnerabilityStandards">https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_VulnerabilityStandards</a></p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/NotebookLMVulnerabilityManagement1.png" /></p>
<figcaption>The initial screen after the documents are loaded.<br><abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> <abbr title="Known Exploited Vulnerability">KEV</abbr> was then loaded as a text file.</figcaption>
</figure>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>write an introductory article in less than 250 words that gives an overview of all these sources and how they fit together</p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/NotebookLMVulnerabilityManagement2.png" /></p>
<figcaption></figcaption>
</figure>
<p>Each circled-number is a clickable link to the reference text in the original sources.</p>
<h2 id="notebooklm-notebooklm_vulnerabilitystandards-i-want-to-rank-vulnerabilities-by-exploitation">I want to rank vulnerabilities by Exploitation<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-i-want-to-rank-vulnerabilities-by-exploitation" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>I am currently using <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> to rank vulnerabilities. I also want to rank based on exploitation as I heard only a small percentage of CVEs are actually exploited. What standard should I use. How should I use them. Provide an answer with rationale and examples.</p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/notebooklm_vulnerabilities.png" /></p>
<figcaption></figcaption>
</figure>
<h2 id="notebooklm-notebooklm_vulnerabilitystandards-explain-risk-like-im-a-5-year-old">Explain risk like I'm a 5 year old<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-explain-risk-like-im-a-5-year-old" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>I want to prioritize vulnerabilities by risk. But I don't understand risk and the components or factors of risk. Can you explain that to me like I'm a 5 year old. Then explain how I can use that for my risk based prioritization approach. Please provide a rationale</p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/notebooklm_vulnerabilities_risk.png" /></p>
<figcaption></figcaption>
</figure>
<h2 id="notebooklm-notebooklm_vulnerabilitystandards-cvss-base-parameters-for-cvss-v3-and-v4"><abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> Base Parameters for <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> v3 and v4<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-cvss-base-parameters-for-cvss-v3-and-v4" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>what parameters contribute to the <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> base parameter score? How do these parameters differ in <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 3 versus <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr> 4</p>
</div>
<figure>
<p><img alt="Guide" src="../assets/images/notebooklm_cvss_base_parameters.png" /></p>
<figcaption></figcaption>
</figure>
<h3 id="notebooklm-notebooklm_vulnerabilitystandards-chatgpt4o-response">ChatGPT4o Response<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-chatgpt4o-response" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="Guide" src="../assets/images/chatgpt4o_cvss_base_parameters.png" /></p>
<figcaption></figcaption>
</figure>
<div class="admonition failure">
<p class="admonition-title">Failure</p>
<p><strong>Hallucination</strong>
Remediation Level (RL) is NOT part of the Exploitability Metrics</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Remediation Level (RL): New metric considering how available and effective remediation methods are (Not Defined, Official Fix, Temporary Fix, Workaround, Unavailable).</p>
</div>
</div>
<h3 id="notebooklm-notebooklm_vulnerabilitystandards-chatgpt4o-check-response">ChatGPT4o Check Response<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-chatgpt4o-check-response" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="Guide" src="../assets/images/chatgpt4o_remediation_level.png" /></p>
<figcaption></figcaption>
</figure>
<h2 id="notebooklm-notebooklm_vulnerabilitystandards-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm_vulnerabilitystandards-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>NotebookLM does a good job assimilating these verbose standards and was competently able to answer specific factual questions, and broader opinionated questions.</li>
<li>Lots of references to the source material were provided in the answers which help understand and validate the answers.</li>
</ol>
</div></section><section class="print-page" id="notebooklm-notebooklm_capec"><h1 id="notebooklm-notebooklm_capec-notebooklm-capec">NotebookLM CAPEC<a class="headerlink" href="#notebooklm-notebooklm_capec-notebooklm-capec" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>In this chapter, we'll use <a href="https://notebooklm.google.com/">NotebookLM</a> to ingest the <a href="https://capec.mitre.org/">Common Attack Pattern Enumeration and Classification (CAPEC) list</a>. </p>
<ul>
<li>In the current version (CAPEC List Version 3.9 as at June 2024), there are 559 Total Attack Patterns. </li>
<li>It can be unwieldy to navigate or assimilate this information. </li>
</ul>
<p>Using NotebookLM, we can chat with the CAPEC document and ask questions, so that <strong>the information comes to us</strong> in the form of an answer. </p>
<p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p>
<ol>
<li>without uploading any documents to it.</li>
<li>uploading a document to it.</li>
</ol>
<p><strong>Note that CAPEC appears a lot less than <abbr title="CWE Common Weakness Enumeration">CWE</abbr> on the internet so an LLM will have a lot less context for CAPEC.</strong></p>
</div>
<h2 id="notebooklm-notebooklm_capec-data-sources">Data Sources<a class="headerlink" href="#notebooklm-notebooklm_capec-data-sources" title="Permanent link">&para;</a></h2>
<p><a href="https://capec.mitre.org/data/downloads.html">https://capec.mitre.org/data/downloads.html</a> offers various formats (XML, CSV, HTML), and views:</p>
<ul>
<li>Mechanisms of Attack: <a href="https://capec.mitre.org/data/slices/1000.html">https://capec.mitre.org/data/slices/1000.html</a></li>
<li>Domains of Attack: <a href="https://capec.mitre.org/data/slices/3000.html">https://capec.mitre.org/data/slices/3000.html</a><ul>
<li>We'll use this one.</li>
</ul>
</li>
</ul>
<p>NotebookLM - Upload from - Web page URL - Paste website link - <a href="https://capec.mitre.org/data/slices/3000.html">https://capec.mitre.org/data/slices/3000.html</a></p>
<h2 id="notebooklm-notebooklm_capec-what-is-the-capec-id-that-related-to-xss">what is the CAPEC ID that related to xss<a class="headerlink" href="#notebooklm-notebooklm_capec-what-is-the-capec-id-that-related-to-xss" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/capec_xss_1.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_capec-chatgpt4o-answer">ChatGPT4o Answer<a class="headerlink" href="#notebooklm-notebooklm_capec-chatgpt4o-answer" title="Permanent link">&para;</a></h3>
<p>ChatGPT4o did not provide all the CWEs that NotebookLM did.</p>
<figure>
<p><img alt="" src="../assets/images/chatgpt4o.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_capec-chatgpt4o-answer-with-hallucination">ChatGPT4o Answer with Hallucination<a class="headerlink" href="#notebooklm-notebooklm_capec-chatgpt4o-answer-with-hallucination" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/chatgpt4o_retry.png" /></p>
</figure>
<div class="admonition failure">
<p class="admonition-title">Failure</p>
<p><strong>Hallucination</strong></p>
<p>"CAPEC-633: Client-Side XSS using Content-Security-Policy Bypass" is not valid
<a href="https://capec.mitre.org/data/definitions/633.html">https://capec.mitre.org/data/definitions/633.html</a></p>
</div>
<h3 id="notebooklm-notebooklm_capec-chatgpt4o-answer-with-hallucination-with-uploaded-capec-file">ChatGPT4o Answer with Hallucination with Uploaded CAPEC File<a class="headerlink" href="#notebooklm-notebooklm_capec-chatgpt4o-answer-with-hallucination-with-uploaded-capec-file" title="Permanent link">&para;</a></h3>
<p>ChatGPT4o UI did not process the CAPEC HTML file, and the UI does not accept URLs, so the CSV file was uploaded instead.</p>
<figure>
<p><img alt="" src="../assets/images/chatgpt4o_with_file.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_capec-chatgpt4o-validate-the-hallucination">ChatGPT4o Validate the Hallucination<a class="headerlink" href="#notebooklm-notebooklm_capec-chatgpt4o-validate-the-hallucination" title="Permanent link">&para;</a></h3>
<p>In a different ChatGPT4o session (new context to avoid the hallucination), we ask ChatGPT4o to validate the CAPEC. </p>
<figure>
<p><img alt="" src="../assets/images/chatgpt_validate.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_capec-chatgpt4o-review-and-rate-the-responses-from-notebooklm-and-chatgpt4o">ChatGPT4o Review and Rate the Responses from NotebookLM and ChatGPT4o<a class="headerlink" href="#notebooklm-notebooklm_capec-chatgpt4o-review-and-rate-the-responses-from-notebooklm-and-chatgpt4o" title="Permanent link">&para;</a></h3>
<p>ChatGPT4o was used to review and rate both responses (copied directly from the NoteBookLM and ChatGPT4o responses)</p>
<figure>
<p><img alt="" src="../assets/images/chatgpt40_review1.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/chatgpt40_review2.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/chatgpt40_review3.png" /></p>
</figure>
<h2 id="notebooklm-notebooklm_capec-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm_capec-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>For less common or referenced text like CAPEC, ChatGPT4o can hallucinate even when the CAPEC list is uploaded to it.</li>
<li>NotebookLM did not hallucinate (a benefit of the "Closed System" approach).</li>
</ol>
</div></section><section class="print-page" id="notebooklm-notebooklm_attack"><h1 id="notebooklm-notebooklm_attack-notebooklm-attack">NotebookLM ATTACK<a class="headerlink" href="#notebooklm-notebooklm_attack-notebooklm-attack" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>As part of <a href="https://www.linkedin.com/feed/update/urn:li:activity:7189303367423156224/">Proactive Software Supply Chain <abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr> Management (P-SSCRM) Framework that I've been collaborating on</a>, we wanted to apply MITRE ATT&amp;CK. It's a detailed specification, so NotebookLM can help us.</p>
<p>In this chapter, we'll use <a href="https://notebooklm.google.com/">NotebookLM</a> to ingest the <a href="https://attack.mitre.org/tactics/enterprise/">MITRE ATT&amp;CK Enterprise Tactics</a>. </p>
<ul>
<li>In the current version, MITRE ATT&amp;CK Matrix for Enterprise consists of 14 tactics, 559 Total Attack Patterns. </li>
<li>It can be unwieldy to navigate or assimilate this information. </li>
</ul>
<p>Using NotebookLM, we can chat with the MITRE ATT&amp;CK Matrix and ask questions, so that <strong>the information comes to us</strong> in the form of an answer. </p>
<ol>
<li>without uploading any documents to it.</li>
<li>uploading a document to it.</li>
</ol>
</div>
<h2 id="notebooklm-notebooklm_attack-data-sources">Data Sources<a class="headerlink" href="#notebooklm-notebooklm_attack-data-sources" title="Permanent link">&para;</a></h2>
<p>The MITRE ATTACK Tactics and Techniques are available online at <a href="https://attack.mitre.org/tactics/enterprise/">https://attack.mitre.org/tactics/enterprise/</a> as 1 webpage for each of the 14 Tactics.</p>
<ul>
<li>However, loading these webpages (or the "Version Permalink" pages) into NotebookLM did not work.</li>
</ul>
<p>MITRE ATTACK is also available as an Excel file from <a href="https://attack.mitre.org/resources/attack-data-and-tools/">https://attack.mitre.org/resources/attack-data-and-tools/</a></p>
<ul>
<li><a href="https://attack.mitre.org/docs/enterprise-attack-v15.1/enterprise-attack-v15.1.xlsx">https://attack.mitre.org/docs/enterprise-attack-v15.1/enterprise-attack-v15.1.xlsx</a></li>
<li>Note: The data is also available as <a href="https://raw.githubusercontent.com/mitre/cti/master/enterprise-attack/enterprise-attack.json">JSON</a>. </li>
</ul>
<p>So we can convert that to a text file and load those as follows:</p>
<ol>
<li>Open the <a href="https://attack.mitre.org/docs/enterprise-attack-v15.1/enterprise-attack-v15.1.xlsx">Excel file</a></li>
<li>For the tabs we want (e.g. Tactics, Techniques, Mitigations), delete the columns we don't want </li>
<li>Export each tab as a csv file</li>
<li>Transpose the data to a text file</li>
<li>Import the text files</li>
</ol>
<div class="admonition experiment">
<p class="admonition-title">Data Sources</p>
<p>The MITRE ATTACK csv and text files, and script to convert, are available in
<a href="https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/Notebook_Attack">https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/Notebook_Attack</a></p>
</div>
<h3 id="notebooklm-notebooklm_attack-convert-mitre-attack-to-a-text-file-for-import">Convert MITRE ATTACK to a Text File for Import<a class="headerlink" href="#notebooklm-notebooklm_attack-convert-mitre-attack-to-a-text-file-for-import" title="Permanent link">&para;</a></h3>
<p>Claude 3.5 Sonnet Prompt:
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#notebooklm-notebooklm_attack-__codelineno-0-1"></a>i have a csv file with these columns ID    name description    tactics    detection    &quot;data sources&quot;    &quot;is sub-technique&quot;    &quot;sub-technique of&quot;
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#notebooklm-notebooklm_attack-__codelineno-0-2"></a>I want to extract the content into a document to read. 
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#notebooklm-notebooklm_attack-__codelineno-0-3"></a>Each row should be extracted as follows: the name of the first column, then the ccontent for the first column. Then the second column name and content.
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#notebooklm-notebooklm_attack-__codelineno-0-4"></a>And so on for each column.
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#notebooklm-notebooklm_attack-__codelineno-0-5"></a>And do this for all rows
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#notebooklm-notebooklm_attack-__codelineno-0-6"></a>
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#notebooklm-notebooklm_attack-__codelineno-0-7"></a>I want python code to do this
</code></pre></div></p>
<p>The LLM generated generic code that was applied to convert each csv file to a text file.</p>
<h3 id="notebooklm-notebooklm_attack-load-each-text-file">Load each text file<a class="headerlink" href="#notebooklm-notebooklm_attack-load-each-text-file" title="Permanent link">&para;</a></h3>
<p>So we can just load each one to NoteBookLM as a text file:</p>
<ul>
<li>MITRE_ATTACK_mitigations.txt</li>
<li>MITRE_ATTACK_tactics.txt</li>
<li>MITRE_ATTACK_techniques.txt</li>
</ul>
<h2 id="notebooklm-notebooklm_attack-tell-me-about-mitre-techniques-related-to-supply-chain">Tell me about MITRE techniques related to supply chain<a class="headerlink" href="#notebooklm-notebooklm_attack-tell-me-about-mitre-techniques-related-to-supply-chain" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_attack-notebooklm-answer">NotebookLM Answer<a class="headerlink" href="#notebooklm-notebooklm_attack-notebooklm-answer" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/mitre_attack_supply_chain.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_attack-claude-sonnet-35-answer">Claude Sonnet 3.5 Answer<a class="headerlink" href="#notebooklm-notebooklm_attack-claude-sonnet-35-answer" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/mitre_attack_supply_chain_claude.png" /></p>
</figure>
<h2 id="notebooklm-notebooklm_attack-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm_attack-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Any data or document in text format can be converted to a format suitable for import to an LM.</li>
</ol>
</div></section><section class="print-page" id="notebooklm-notebooklm_config"><h1 id="notebooklm-notebooklm_config-notebooklm-config">NotebookLM Config<a class="headerlink" href="#notebooklm-notebooklm_config-notebooklm-config" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>I came across this via <a href="https://tldrsec.com/p/tldr-sec-237">https://tldrsec.com/p/tldr-sec-237</a> (an excellent newsletter) in the "AI + Security" section, and it piqued my interest! </p>
<p>One area of research is using LLMs for infrastructure configuration as detailed in <a href="https://www.coguard.io/post/coguard-uses-openai-cybersecurity-grant-to-automate-infrastructure-security">https://www.coguard.io/post/coguard-uses-openai-cybersecurity-grant-to-automate-infrastructure-security</a> and the associated <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file">repo</a>.</p>
<p>Here we take on the first task [C1]: Extraction of security and uptime-relevant configuration parameters from manuals; for the example provided in the <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file">repo</a>: Apache Spark</p>
</div>
<h2 id="notebooklm-notebooklm_config-details">Details<a class="headerlink" href="#notebooklm-notebooklm_config-details" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_config-task">Task<a class="headerlink" href="#notebooklm-notebooklm_config-task" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>[C1] Extraction of security and uptime-relevant configuration parameters from manuals.
The goal of this component is simple to describe, but hard to accomplish. Given a manual for a software component, extract the configuration parameters and define the security relevant ones from it.</p>
<p>Example: For Apache Spark, the manual is provided on the general <a href="https://spark.apache.org/docs/latest/configuration.html#spark-ui">configuration page</a> online, i.e. in HTML format, and there is also a specific <a href="https://spark.apache.org/docs/latest/security.html">security page</a>. The expectation would be to at least extract the parameters from the security page, as well as some log-related items from the general page. In total, when manually examining the configuration parameters, it totals approximately 80 parameters that are security relevant. You can find these in the <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master##appendix-a">Appendix A</a>.</p>
</div>
<h3 id="notebooklm-notebooklm_config-original-prompt">Original Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-original-prompt" title="Permanent link">&para;</a></h3>
<p>The original prompt used is per <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#extraction-of-security-relevant-parameters-in-c1">https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#extraction-of-security-relevant-parameters-in-c1</a></p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings
Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>
</div>
<h3 id="notebooklm-notebooklm_config-expected-answer">Expected Answer<a class="headerlink" href="#notebooklm-notebooklm_config-expected-answer" title="Permanent link">&para;</a></h3>
<p>The expected answer is per <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#appendix-a">https://github.com/coguardio/coguard_openai_rule_auto_generation_research/tree/master?tab=readme-ov-file#appendix-a</a>. </p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The following parameters were identified by the CoGuard team by hand as relevant from a security point of view.</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#notebooklm-notebooklm_config-__codelineno-0-1"></a>spark.yarn.shuffle.server.recovery.disabled
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#notebooklm-notebooklm_config-__codelineno-0-2"></a>spark.authenticate
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#notebooklm-notebooklm_config-__codelineno-0-3"></a>spark.authenticate.secret
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#notebooklm-notebooklm_config-__codelineno-0-4"></a>spark.authenticate.secret.file
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#notebooklm-notebooklm_config-__codelineno-0-5"></a>spark.authenticate.secret.driver.file
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#notebooklm-notebooklm_config-__codelineno-0-6"></a>spark.authenticate.secret.executor.file
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#notebooklm-notebooklm_config-__codelineno-0-7"></a>spark.network.crypto.enabled
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#notebooklm-notebooklm_config-__codelineno-0-8"></a>spark.network.crypto.config.*
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#notebooklm-notebooklm_config-__codelineno-0-9"></a>spark.network.crypto.saslFallback
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#notebooklm-notebooklm_config-__codelineno-0-10"></a>spark.authenticate.enableSaslEncryption
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#notebooklm-notebooklm_config-__codelineno-0-11"></a>spark.network.sasl.serverAlwaysEncrypt
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#notebooklm-notebooklm_config-__codelineno-0-12"></a>spark.io.encryption.enabled
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#notebooklm-notebooklm_config-__codelineno-0-13"></a>spark.io.encryption.keySizeBits
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#notebooklm-notebooklm_config-__codelineno-0-14"></a>spark.io.encryption.keygen.algorithm
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#notebooklm-notebooklm_config-__codelineno-0-15"></a>spark.io.encryption.commons.config.*
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#notebooklm-notebooklm_config-__codelineno-0-16"></a>spark.ui.allowFramingFrom
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#notebooklm-notebooklm_config-__codelineno-0-17"></a>spark.ui.filters
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#notebooklm-notebooklm_config-__codelineno-0-18"></a>spark.acls.enable
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#notebooklm-notebooklm_config-__codelineno-0-19"></a>spark.admin.acls
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#notebooklm-notebooklm_config-__codelineno-0-20"></a>spark.admin.acls.groups
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#notebooklm-notebooklm_config-__codelineno-0-21"></a>spark.modify.acls
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#notebooklm-notebooklm_config-__codelineno-0-22"></a>spark.modify.acls.groups
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#notebooklm-notebooklm_config-__codelineno-0-23"></a>spark.ui.view.acls
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#notebooklm-notebooklm_config-__codelineno-0-24"></a>spark.ui.view.acls.groups
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#notebooklm-notebooklm_config-__codelineno-0-25"></a>spark.user.groups.mapping
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#notebooklm-notebooklm_config-__codelineno-0-26"></a>spark.history.ui.acls.enable
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#notebooklm-notebooklm_config-__codelineno-0-27"></a>spark.history.ui.admin.acls
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#notebooklm-notebooklm_config-__codelineno-0-28"></a>spark.history.ui.admin.acls.groups
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#notebooklm-notebooklm_config-__codelineno-0-29"></a>spark.ssl.enabled
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#notebooklm-notebooklm_config-__codelineno-0-30"></a>spark.ssl.port
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#notebooklm-notebooklm_config-__codelineno-0-31"></a>spark.ssl.enabledAlgorithms
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#notebooklm-notebooklm_config-__codelineno-0-32"></a>spark.ssl.keyPassword
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#notebooklm-notebooklm_config-__codelineno-0-33"></a>spark.ssl.keyStore
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#notebooklm-notebooklm_config-__codelineno-0-34"></a>spark.ssl.keyStorePassword
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#notebooklm-notebooklm_config-__codelineno-0-35"></a>spark.ssl.keyStoreType
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#notebooklm-notebooklm_config-__codelineno-0-36"></a>spark.ssl.protocol
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#notebooklm-notebooklm_config-__codelineno-0-37"></a>spark.ssl.needClientAuth
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#notebooklm-notebooklm_config-__codelineno-0-38"></a>spark.ssl.trustStore
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#notebooklm-notebooklm_config-__codelineno-0-39"></a>spark.ssl.trustStorePassword
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#notebooklm-notebooklm_config-__codelineno-0-40"></a>spark.ssl.trustStoreType
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#notebooklm-notebooklm_config-__codelineno-0-41"></a>spark.ssl.ui.enabled
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#notebooklm-notebooklm_config-__codelineno-0-42"></a>spark.ssl.ui.port
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#notebooklm-notebooklm_config-__codelineno-0-43"></a>spark.ssl.ui.enabledAlgorithms
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#notebooklm-notebooklm_config-__codelineno-0-44"></a>spark.ssl.ui.keyPassword
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#notebooklm-notebooklm_config-__codelineno-0-45"></a>spark.ssl.ui.keyStore
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#notebooklm-notebooklm_config-__codelineno-0-46"></a>spark.ssl.ui.keyStorePassword
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#notebooklm-notebooklm_config-__codelineno-0-47"></a>spark.ssl.ui.keyStoreType
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#notebooklm-notebooklm_config-__codelineno-0-48"></a>spark.ssl.ui.protocol
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#notebooklm-notebooklm_config-__codelineno-0-49"></a>spark.ssl.ui.needClientAuth
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#notebooklm-notebooklm_config-__codelineno-0-50"></a>spark.ssl.ui.trustStore
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#notebooklm-notebooklm_config-__codelineno-0-51"></a>spark.ssl.ui.trustStorePassword
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#notebooklm-notebooklm_config-__codelineno-0-52"></a>spark.ssl.ui.trustStoreType
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#notebooklm-notebooklm_config-__codelineno-0-53"></a>spark.ssl.standalone.enabled
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#notebooklm-notebooklm_config-__codelineno-0-54"></a>spark.ssl.standalone.port
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#notebooklm-notebooklm_config-__codelineno-0-55"></a>spark.ssl.standalone.enabledAlgorithms
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#notebooklm-notebooklm_config-__codelineno-0-56"></a>spark.ssl.standalone.keyPassword
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#notebooklm-notebooklm_config-__codelineno-0-57"></a>spark.ssl.standalone.keyStore
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#notebooklm-notebooklm_config-__codelineno-0-58"></a>spark.ssl.standalone.keyStorePassword
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#notebooklm-notebooklm_config-__codelineno-0-59"></a>spark.ssl.standalone.keyStoreType
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#notebooklm-notebooklm_config-__codelineno-0-60"></a>spark.ssl.standalone.protocol
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#notebooklm-notebooklm_config-__codelineno-0-61"></a>spark.ssl.standalone.needClientAuth
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#notebooklm-notebooklm_config-__codelineno-0-62"></a>spark.ssl.standalone.trustStore
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#notebooklm-notebooklm_config-__codelineno-0-63"></a>spark.ssl.standalone.trustStorePassword
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#notebooklm-notebooklm_config-__codelineno-0-64"></a>spark.ssl.standalone.trustStoreType
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#notebooklm-notebooklm_config-__codelineno-0-65"></a>spark.ssl.historyServer.enabled
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#notebooklm-notebooklm_config-__codelineno-0-66"></a>spark.ssl.historyServer.port
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#notebooklm-notebooklm_config-__codelineno-0-67"></a>spark.ssl.historyServer.enabledAlgorithms
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#notebooklm-notebooklm_config-__codelineno-0-68"></a>spark.ssl.historyServer.keyPassword
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#notebooklm-notebooklm_config-__codelineno-0-69"></a>spark.ssl.historyServer.keyStore
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#notebooklm-notebooklm_config-__codelineno-0-70"></a>spark.ssl.historyServer.keyStorePassword
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#notebooklm-notebooklm_config-__codelineno-0-71"></a>spark.ssl.historyServer.keyStoreType
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#notebooklm-notebooklm_config-__codelineno-0-72"></a>spark.ssl.historyServer.protocol
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#notebooklm-notebooklm_config-__codelineno-0-73"></a>spark.ssl.historyServer.needClientAuth
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#notebooklm-notebooklm_config-__codelineno-0-74"></a>spark.ssl.historyServer.trustStore
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#notebooklm-notebooklm_config-__codelineno-0-75"></a>spark.ssl.historyServer.trustStorePassword
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#notebooklm-notebooklm_config-__codelineno-0-76"></a>spark.ssl.historyServer.trustStoreType
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#notebooklm-notebooklm_config-__codelineno-0-77"></a>spark.ui.xXssProtection
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#notebooklm-notebooklm_config-__codelineno-0-78"></a>spark.ui.xContentTypeOptions.enabled
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#notebooklm-notebooklm_config-__codelineno-0-79"></a>spark.ui.strictTransportSecurity
</code></pre></div>
</div>
<h2 id="notebooklm-notebooklm_config-data-sources">Data Sources<a class="headerlink" href="#notebooklm-notebooklm_config-data-sources" title="Permanent link">&para;</a></h2>
<p>The data sources are per above:</p>
<ol>
<li><a href="https://spark.apache.org/docs/latest/configuration.html">https://spark.apache.org/docs/latest/configuration.html</a></li>
<li><a href="https://spark.apache.org/docs/latest/security.html">https://spark.apache.org/docs/latest/security.html</a></li>
</ol>
<div class="admonition experiment">
<p class="admonition-title">Data Sources</p>
<p>Copies of the html files are available in
<a href="https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_Config">https://github.com/CyberSecAI/CyberSecAI.github.io/tree/main/data/NotebookLM_Config</a></p>
</div>
<h2 id="notebooklm-notebooklm_config-setup">Setup<a class="headerlink" href="#notebooklm-notebooklm_config-setup" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_config-prepare-validation-file">Prepare Validation File<a class="headerlink" href="#notebooklm-notebooklm_config-prepare-validation-file" title="Permanent link">&para;</a></h3>
<ol>
<li>CopyNPaste the Expected answer to a text file ./data/NotebookLM_Config/security_parameters_manual.txt.</li>
<li>Sort alphabetically to allow diff comparison with answer from NotebookLM.</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#notebooklm-notebooklm_config-__codelineno-1-1"></a>    cat ./data/NotebookLM_Config/security_parameters_manual.txt | sort &gt; ./data/NotebookLM_Config/security_parameters_manual_sorted.txt
</code></pre></div>
<h2 id="notebooklm-notebooklm_config-attempt-1-use-the-provided-prompt">Attempt 1: Use the Provided Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-attempt-1-use-the-provided-prompt" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_config-create-a-new-notebooklm-with-the-2-data-sources-only">Create A New Notebooklm With The 2 Data Sources Only<a class="headerlink" href="#notebooklm-notebooklm_config-create-a-new-notebooklm-with-the-2-data-sources-only" title="Permanent link">&para;</a></h3>
<p>New NotebookLM.
Sources - Upload from - Web page URL for the 2 Data Sources listed above.</p>
<figure>
<p><img alt="" src="../assets/images/notebooklm_config_2.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_config-submit-the-prompt">Submit the prompt<a class="headerlink" href="#notebooklm-notebooklm_config-submit-the-prompt" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/apache_spark_prompt.png" /></p>
</figure>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings
Using the documentation of Apache Spark, which configuration parameters are relevant from a security perspective?.</p>
</div>
<h3 id="notebooklm-notebooklm_config-save-the-result">Save The Result<a class="headerlink" href="#notebooklm-notebooklm_config-save-the-result" title="Permanent link">&para;</a></h3>
<ol>
<li>Click the Copy button.</li>
<li>Create a new file security_parameters.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li>
<li>Sort the answer</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#notebooklm-notebooklm_config-__codelineno-2-1"></a>jq -r &#39;.[]&#39; ./data/NotebookLM_Config/security_parameters.json | sort &gt; ./data/NotebookLM_Config/security_parameters.txt
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer">Compare The Answer With The Expected Answer<a class="headerlink" href="#notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer" title="Permanent link">&para;</a></h3>
<ol>
<li>60 parameters were retrieved</li>
<li>We can see that the main difference relates to "spark.ssl." parameters.</li>
<li>Searching manually in the 2 Data Sources above reveals that these config strings are not actually listed in the documentation e.g. "spark.ssl.ui.needClientAuth" directly - but using placeholders.</li>
<li>The LLM didn't understand that - so we'll let it know - then ask it again.</li>
<li>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt   </li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#notebooklm-notebooklm_config-__codelineno-3-1"></a>diff data/NotebookLM_Config/security_parameters_manual.txt data/NotebookLM_Config/security_parameters.txt                 
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#notebooklm-notebooklm_config-__codelineno-3-2"></a>1c1,4
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#notebooklm-notebooklm_config-__codelineno-3-3"></a>&lt; spark.yarn.shuffle.server.recovery.disabled
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#notebooklm-notebooklm_config-__codelineno-3-4"></a>---
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#notebooklm-notebooklm_config-__codelineno-3-5"></a>&gt; hadoop.security.credential.provider.path
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#notebooklm-notebooklm_config-__codelineno-3-6"></a>&gt; spark.acls.enable
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#notebooklm-notebooklm_config-__codelineno-3-7"></a>&gt; spark.admin.acls
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#notebooklm-notebooklm_config-__codelineno-3-8"></a>&gt; spark.admin.acls.groups
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#notebooklm-notebooklm_config-__codelineno-3-9"></a>2a6
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#notebooklm-notebooklm_config-__codelineno-3-10"></a>&gt; spark.authenticate.enableSaslEncryption
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#notebooklm-notebooklm_config-__codelineno-3-11"></a>4d7
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#notebooklm-notebooklm_config-__codelineno-3-12"></a>&lt; spark.authenticate.secret.file
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#notebooklm-notebooklm_config-__codelineno-3-13"></a>7,11c10,14
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#notebooklm-notebooklm_config-__codelineno-3-14"></a>&lt; spark.network.crypto.enabled
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#notebooklm-notebooklm_config-__codelineno-3-15"></a>&lt; spark.network.crypto.config.*
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#notebooklm-notebooklm_config-__codelineno-3-16"></a>&lt; spark.network.crypto.saslFallback
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#notebooklm-notebooklm_config-__codelineno-3-17"></a>&lt; spark.authenticate.enableSaslEncryption
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#notebooklm-notebooklm_config-__codelineno-3-18"></a>&lt; spark.network.sasl.serverAlwaysEncrypt
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#notebooklm-notebooklm_config-__codelineno-3-19"></a>---
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#notebooklm-notebooklm_config-__codelineno-3-20"></a>&gt; spark.authenticate.secret.file
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#notebooklm-notebooklm_config-__codelineno-3-21"></a>&gt; spark.history.ui.acls.enable
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#notebooklm-notebooklm_config-__codelineno-3-22"></a>&gt; spark.history.ui.admin.acls
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#notebooklm-notebooklm_config-__codelineno-3-23"></a>&gt; spark.history.ui.admin.acls.groups
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#notebooklm-notebooklm_config-__codelineno-3-24"></a>&gt; spark.io.encryption.commons.config.*
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#notebooklm-notebooklm_config-__codelineno-3-25"></a>15,20c18,29
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#notebooklm-notebooklm_config-__codelineno-3-26"></a>&lt; spark.io.encryption.commons.config.*
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#notebooklm-notebooklm_config-__codelineno-3-27"></a>&lt; spark.ui.allowFramingFrom
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#notebooklm-notebooklm_config-__codelineno-3-28"></a>&lt; spark.ui.filters
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#notebooklm-notebooklm_config-__codelineno-3-29"></a>&lt; spark.acls.enable
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#notebooklm-notebooklm_config-__codelineno-3-30"></a>&lt; spark.admin.acls
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#notebooklm-notebooklm_config-__codelineno-3-31"></a>&lt; spark.admin.acls.groups
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#notebooklm-notebooklm_config-__codelineno-3-32"></a>---
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#notebooklm-notebooklm_config-__codelineno-3-33"></a>&gt; spark.kerberos.access.hadoopFileSystems
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#notebooklm-notebooklm_config-__codelineno-3-34"></a>&gt; spark.kerberos.keytab
<a id="__codelineno-3-35" name="__codelineno-3-35" href="#notebooklm-notebooklm_config-__codelineno-3-35"></a>&gt; spark.kerberos.principal
<a id="__codelineno-3-36" name="__codelineno-3-36" href="#notebooklm-notebooklm_config-__codelineno-3-36"></a>&gt; spark.kubernetes.hadoop.configMapName
<a id="__codelineno-3-37" name="__codelineno-3-37" href="#notebooklm-notebooklm_config-__codelineno-3-37"></a>&gt; spark.kubernetes.kerberos.krb5.configMapName
<a id="__codelineno-3-38" name="__codelineno-3-38" href="#notebooklm-notebooklm_config-__codelineno-3-38"></a>&gt; spark.kubernetes.kerberos.krb5.path
<a id="__codelineno-3-39" name="__codelineno-3-39" href="#notebooklm-notebooklm_config-__codelineno-3-39"></a>&gt; spark.kubernetes.kerberos.tokenSecret.itemKey
<a id="__codelineno-3-40" name="__codelineno-3-40" href="#notebooklm-notebooklm_config-__codelineno-3-40"></a>&gt; spark.kubernetes.kerberos.tokenSecret.name
<a id="__codelineno-3-41" name="__codelineno-3-41" href="#notebooklm-notebooklm_config-__codelineno-3-41"></a>&gt; spark.mesos.driver.secret.envkeys
<a id="__codelineno-3-42" name="__codelineno-3-42" href="#notebooklm-notebooklm_config-__codelineno-3-42"></a>&gt; spark.mesos.driver.secret.filenames
<a id="__codelineno-3-43" name="__codelineno-3-43" href="#notebooklm-notebooklm_config-__codelineno-3-43"></a>&gt; spark.mesos.driver.secret.names
<a id="__codelineno-3-44" name="__codelineno-3-44" href="#notebooklm-notebooklm_config-__codelineno-3-44"></a>&gt; spark.mesos.driver.secret.values
<a id="__codelineno-3-45" name="__codelineno-3-45" href="#notebooklm-notebooklm_config-__codelineno-3-45"></a>23,28c32,39
<a id="__codelineno-3-46" name="__codelineno-3-46" href="#notebooklm-notebooklm_config-__codelineno-3-46"></a>&lt; spark.ui.view.acls
<a id="__codelineno-3-47" name="__codelineno-3-47" href="#notebooklm-notebooklm_config-__codelineno-3-47"></a>&lt; spark.ui.view.acls.groups
<a id="__codelineno-3-48" name="__codelineno-3-48" href="#notebooklm-notebooklm_config-__codelineno-3-48"></a>&lt; spark.user.groups.mapping
<a id="__codelineno-3-49" name="__codelineno-3-49" href="#notebooklm-notebooklm_config-__codelineno-3-49"></a>&lt; spark.history.ui.acls.enable
<a id="__codelineno-3-50" name="__codelineno-3-50" href="#notebooklm-notebooklm_config-__codelineno-3-50"></a>&lt; spark.history.ui.admin.acls
<a id="__codelineno-3-51" name="__codelineno-3-51" href="#notebooklm-notebooklm_config-__codelineno-3-51"></a>&lt; spark.history.ui.admin.acls.groups
<a id="__codelineno-3-52" name="__codelineno-3-52" href="#notebooklm-notebooklm_config-__codelineno-3-52"></a>---
<a id="__codelineno-3-53" name="__codelineno-3-53" href="#notebooklm-notebooklm_config-__codelineno-3-53"></a>&gt; spark.network.crypto.config.*
<a id="__codelineno-3-54" name="__codelineno-3-54" href="#notebooklm-notebooklm_config-__codelineno-3-54"></a>&gt; spark.network.crypto.enabled
<a id="__codelineno-3-55" name="__codelineno-3-55" href="#notebooklm-notebooklm_config-__codelineno-3-55"></a>&gt; spark.network.crypto.saslFallback
<a id="__codelineno-3-56" name="__codelineno-3-56" href="#notebooklm-notebooklm_config-__codelineno-3-56"></a>&gt; spark.network.sasl.serverAlwaysEncrypt
<a id="__codelineno-3-57" name="__codelineno-3-57" href="#notebooklm-notebooklm_config-__codelineno-3-57"></a>&gt; spark.redaction.regex
<a id="__codelineno-3-58" name="__codelineno-3-58" href="#notebooklm-notebooklm_config-__codelineno-3-58"></a>&gt; spark.redaction.string.regex
<a id="__codelineno-3-59" name="__codelineno-3-59" href="#notebooklm-notebooklm_config-__codelineno-3-59"></a>&gt; spark.security.credentials.${service}.enabled
<a id="__codelineno-3-60" name="__codelineno-3-60" href="#notebooklm-notebooklm_config-__codelineno-3-60"></a>&gt; spark.sql.redaction.options.regex
<a id="__codelineno-3-61" name="__codelineno-3-61" href="#notebooklm-notebooklm_config-__codelineno-3-61"></a>30d40
<a id="__codelineno-3-62" name="__codelineno-3-62" href="#notebooklm-notebooklm_config-__codelineno-3-62"></a>&lt; spark.ssl.port
<a id="__codelineno-3-63" name="__codelineno-3-63" href="#notebooklm-notebooklm_config-__codelineno-3-63"></a>36d45
<a id="__codelineno-3-64" name="__codelineno-3-64" href="#notebooklm-notebooklm_config-__codelineno-3-64"></a>&lt; spark.ssl.protocol
<a id="__codelineno-3-65" name="__codelineno-3-65" href="#notebooklm-notebooklm_config-__codelineno-3-65"></a>37a47,48
<a id="__codelineno-3-66" name="__codelineno-3-66" href="#notebooklm-notebooklm_config-__codelineno-3-66"></a>&gt; spark.ssl.port
<a id="__codelineno-3-67" name="__codelineno-3-67" href="#notebooklm-notebooklm_config-__codelineno-3-67"></a>&gt; spark.ssl.protocol
<a id="__codelineno-3-68" name="__codelineno-3-68" href="#notebooklm-notebooklm_config-__codelineno-3-68"></a>41,77c52,57
<a id="__codelineno-3-69" name="__codelineno-3-69" href="#notebooklm-notebooklm_config-__codelineno-3-69"></a>&lt; spark.ssl.ui.enabled
<a id="__codelineno-3-70" name="__codelineno-3-70" href="#notebooklm-notebooklm_config-__codelineno-3-70"></a>&lt; spark.ssl.ui.port
<a id="__codelineno-3-71" name="__codelineno-3-71" href="#notebooklm-notebooklm_config-__codelineno-3-71"></a>&lt; spark.ssl.ui.enabledAlgorithms
<a id="__codelineno-3-72" name="__codelineno-3-72" href="#notebooklm-notebooklm_config-__codelineno-3-72"></a>&lt; spark.ssl.ui.keyPassword
<a id="__codelineno-3-73" name="__codelineno-3-73" href="#notebooklm-notebooklm_config-__codelineno-3-73"></a>&lt; spark.ssl.ui.keyStore
<a id="__codelineno-3-74" name="__codelineno-3-74" href="#notebooklm-notebooklm_config-__codelineno-3-74"></a>&lt; spark.ssl.ui.keyStorePassword
<a id="__codelineno-3-75" name="__codelineno-3-75" href="#notebooklm-notebooklm_config-__codelineno-3-75"></a>&lt; spark.ssl.ui.keyStoreType
<a id="__codelineno-3-76" name="__codelineno-3-76" href="#notebooklm-notebooklm_config-__codelineno-3-76"></a>&lt; spark.ssl.ui.protocol
<a id="__codelineno-3-77" name="__codelineno-3-77" href="#notebooklm-notebooklm_config-__codelineno-3-77"></a>&lt; spark.ssl.ui.needClientAuth
<a id="__codelineno-3-78" name="__codelineno-3-78" href="#notebooklm-notebooklm_config-__codelineno-3-78"></a>&lt; spark.ssl.ui.trustStore
<a id="__codelineno-3-79" name="__codelineno-3-79" href="#notebooklm-notebooklm_config-__codelineno-3-79"></a>&lt; spark.ssl.ui.trustStorePassword
<a id="__codelineno-3-80" name="__codelineno-3-80" href="#notebooklm-notebooklm_config-__codelineno-3-80"></a>&lt; spark.ssl.ui.trustStoreType
<a id="__codelineno-3-81" name="__codelineno-3-81" href="#notebooklm-notebooklm_config-__codelineno-3-81"></a>&lt; spark.ssl.standalone.enabled
<a id="__codelineno-3-82" name="__codelineno-3-82" href="#notebooklm-notebooklm_config-__codelineno-3-82"></a>&lt; spark.ssl.standalone.port
<a id="__codelineno-3-83" name="__codelineno-3-83" href="#notebooklm-notebooklm_config-__codelineno-3-83"></a>&lt; spark.ssl.standalone.enabledAlgorithms
<a id="__codelineno-3-84" name="__codelineno-3-84" href="#notebooklm-notebooklm_config-__codelineno-3-84"></a>&lt; spark.ssl.standalone.keyPassword
<a id="__codelineno-3-85" name="__codelineno-3-85" href="#notebooklm-notebooklm_config-__codelineno-3-85"></a>&lt; spark.ssl.standalone.keyStore
<a id="__codelineno-3-86" name="__codelineno-3-86" href="#notebooklm-notebooklm_config-__codelineno-3-86"></a>&lt; spark.ssl.standalone.keyStorePassword
<a id="__codelineno-3-87" name="__codelineno-3-87" href="#notebooklm-notebooklm_config-__codelineno-3-87"></a>&lt; spark.ssl.standalone.keyStoreType
<a id="__codelineno-3-88" name="__codelineno-3-88" href="#notebooklm-notebooklm_config-__codelineno-3-88"></a>&lt; spark.ssl.standalone.protocol
<a id="__codelineno-3-89" name="__codelineno-3-89" href="#notebooklm-notebooklm_config-__codelineno-3-89"></a>&lt; spark.ssl.standalone.needClientAuth
<a id="__codelineno-3-90" name="__codelineno-3-90" href="#notebooklm-notebooklm_config-__codelineno-3-90"></a>&lt; spark.ssl.standalone.trustStore
<a id="__codelineno-3-91" name="__codelineno-3-91" href="#notebooklm-notebooklm_config-__codelineno-3-91"></a>&lt; spark.ssl.standalone.trustStorePassword
<a id="__codelineno-3-92" name="__codelineno-3-92" href="#notebooklm-notebooklm_config-__codelineno-3-92"></a>&lt; spark.ssl.standalone.trustStoreType
<a id="__codelineno-3-93" name="__codelineno-3-93" href="#notebooklm-notebooklm_config-__codelineno-3-93"></a>&lt; spark.ssl.historyServer.enabled
<a id="__codelineno-3-94" name="__codelineno-3-94" href="#notebooklm-notebooklm_config-__codelineno-3-94"></a>&lt; spark.ssl.historyServer.port
<a id="__codelineno-3-95" name="__codelineno-3-95" href="#notebooklm-notebooklm_config-__codelineno-3-95"></a>&lt; spark.ssl.historyServer.enabledAlgorithms
<a id="__codelineno-3-96" name="__codelineno-3-96" href="#notebooklm-notebooklm_config-__codelineno-3-96"></a>&lt; spark.ssl.historyServer.keyPassword
<a id="__codelineno-3-97" name="__codelineno-3-97" href="#notebooklm-notebooklm_config-__codelineno-3-97"></a>&lt; spark.ssl.historyServer.keyStore
<a id="__codelineno-3-98" name="__codelineno-3-98" href="#notebooklm-notebooklm_config-__codelineno-3-98"></a>&lt; spark.ssl.historyServer.keyStorePassword
<a id="__codelineno-3-99" name="__codelineno-3-99" href="#notebooklm-notebooklm_config-__codelineno-3-99"></a>&lt; spark.ssl.historyServer.keyStoreType
<a id="__codelineno-3-100" name="__codelineno-3-100" href="#notebooklm-notebooklm_config-__codelineno-3-100"></a>&lt; spark.ssl.historyServer.protocol
<a id="__codelineno-3-101" name="__codelineno-3-101" href="#notebooklm-notebooklm_config-__codelineno-3-101"></a>&lt; spark.ssl.historyServer.needClientAuth
<a id="__codelineno-3-102" name="__codelineno-3-102" href="#notebooklm-notebooklm_config-__codelineno-3-102"></a>&lt; spark.ssl.historyServer.trustStore
<a id="__codelineno-3-103" name="__codelineno-3-103" href="#notebooklm-notebooklm_config-__codelineno-3-103"></a>&lt; spark.ssl.historyServer.trustStorePassword
<a id="__codelineno-3-104" name="__codelineno-3-104" href="#notebooklm-notebooklm_config-__codelineno-3-104"></a>&lt; spark.ssl.historyServer.trustStoreType
<a id="__codelineno-3-105" name="__codelineno-3-105" href="#notebooklm-notebooklm_config-__codelineno-3-105"></a>&lt; spark.ui.xXssProtection
<a id="__codelineno-3-106" name="__codelineno-3-106" href="#notebooklm-notebooklm_config-__codelineno-3-106"></a>---
<a id="__codelineno-3-107" name="__codelineno-3-107" href="#notebooklm-notebooklm_config-__codelineno-3-107"></a>&gt; spark.ssl.useNodeLocalConf
<a id="__codelineno-3-108" name="__codelineno-3-108" href="#notebooklm-notebooklm_config-__codelineno-3-108"></a>&gt; spark.ui.allowFramingFrom
<a id="__codelineno-3-109" name="__codelineno-3-109" href="#notebooklm-notebooklm_config-__codelineno-3-109"></a>&gt; spark.ui.filters
<a id="__codelineno-3-110" name="__codelineno-3-110" href="#notebooklm-notebooklm_config-__codelineno-3-110"></a>&gt; spark.ui.strictTransportSecurity
<a id="__codelineno-3-111" name="__codelineno-3-111" href="#notebooklm-notebooklm_config-__codelineno-3-111"></a>&gt; spark.ui.view.acls
<a id="__codelineno-3-112" name="__codelineno-3-112" href="#notebooklm-notebooklm_config-__codelineno-3-112"></a>&gt; spark.ui.view.acls.groups
<a id="__codelineno-3-113" name="__codelineno-3-113" href="#notebooklm-notebooklm_config-__codelineno-3-113"></a>79c59,60
<a id="__codelineno-3-114" name="__codelineno-3-114" href="#notebooklm-notebooklm_config-__codelineno-3-114"></a>&lt; spark.ui.strictTransportSecurity
<a id="__codelineno-3-115" name="__codelineno-3-115" href="#notebooklm-notebooklm_config-__codelineno-3-115"></a>\ No newline at end of file
<a id="__codelineno-3-116" name="__codelineno-3-116" href="#notebooklm-notebooklm_config-__codelineno-3-116"></a>---
<a id="__codelineno-3-117" name="__codelineno-3-117" href="#notebooklm-notebooklm_config-__codelineno-3-117"></a>&gt; spark.ui.xXssProtection
<a id="__codelineno-3-118" name="__codelineno-3-118" href="#notebooklm-notebooklm_config-__codelineno-3-118"></a>&gt; spark.user.groups.mapping
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the next section, we'll use an LLM to do the comparison.</p>
<p>Here we used traditional methods i.e. diff.</p>
</div>
<h2 id="notebooklm-notebooklm_config-attempt-2-explain-about-config-namespace-placeholders">Attempt 2: Explain about Config Namespace Placeholders<a class="headerlink" href="#notebooklm-notebooklm_config-attempt-2-explain-about-config-namespace-placeholders" title="Permanent link">&para;</a></h2>
<p>The LLM did not understand from the documents about Config Namespace placeholders:</p>
<figure>
<p><img alt="" src="../assets/images/apache_space_ns.png" /></p>
</figure>
<p>So this time, we explain as part of the prompt about Config Namespace placeholders.</p>
<h3 id="notebooklm-notebooklm_config-submit-the-prompt_1">Submit The Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-submit-the-prompt_1" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/apache_space_ns_prompt.png" /></p>
</figure>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Note that Config Namespace placeholders are used for some security configurations. These are placeholders "<span class="arithmatex" ns="ns">\({ns}" that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: "\)</span>.enabled", "spark.ssl.enabled" and "spark.ssl.historyServer" would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note the duplication in the prompt to emphasize what we want</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>"list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns" in the prompt.</p>
</div>
</div>
<p>security_parameters_ns.json is the resulting file that has 96 config parameters - more than the expected answer config parameters as generated by humans.</p>
<h3 id="notebooklm-notebooklm_config-save-the-result_1">Save The Result<a class="headerlink" href="#notebooklm-notebooklm_config-save-the-result_1" title="Permanent link">&para;</a></h3>
<ol>
<li>Click the Copy button.</li>
<li>Create a new file security_parameters_ns.json and save the result, then remove the ```` part at the beginning and end of the file so the file contains JSON only.</li>
<li>Sort the answer and ensure there's no duplicates.</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#notebooklm-notebooklm_config-__codelineno-4-1"></a>jq -r &#39;.[]&#39; ./data/NotebookLM_Config/security_parameters_ns.json | sort | uniq &gt; ./data/NotebookLM_Config/security_parameters_ns.txt
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_1">Compare The Answer With The Expected Answer<a class="headerlink" href="#notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_1" title="Permanent link">&para;</a></h3>
<p>In this case, we use ChatGPT4o to do the diff, copy and pasting the values from each file:</p>
<ul>
<li>./data/NotebookLM_Config/security_parameters_manual.txt: the expected answers</li>
<li>./data/NotebookLM_Config/security_parameters_ns.txt: the actual answers</li>
</ul>
<h4 id="notebooklm-notebooklm_config-prompt">Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-prompt" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#notebooklm-notebooklm_config-__codelineno-5-1"></a>List the values that are in ===manual===  but not in ===notebooklm===
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#notebooklm-notebooklm_config-__codelineno-5-2"></a>List the values that are in ===notebooklm===  but not in ===manual===
<a id="__codelineno-5-3" name="__codelineno-5-3" href="#notebooklm-notebooklm_config-__codelineno-5-3"></a>
<a id="__codelineno-5-4" name="__codelineno-5-4" href="#notebooklm-notebooklm_config-__codelineno-5-4"></a>===manual=== 
<a id="__codelineno-5-5" name="__codelineno-5-5" href="#notebooklm-notebooklm_config-__codelineno-5-5"></a>spark.yarn.shuffle.server.recovery.disabled
<a id="__codelineno-5-6" name="__codelineno-5-6" href="#notebooklm-notebooklm_config-__codelineno-5-6"></a>spark.authenticate
<a id="__codelineno-5-7" name="__codelineno-5-7" href="#notebooklm-notebooklm_config-__codelineno-5-7"></a>spark.authenticate.secret
<a id="__codelineno-5-8" name="__codelineno-5-8" href="#notebooklm-notebooklm_config-__codelineno-5-8"></a>spark.authenticate.secret.file
<a id="__codelineno-5-9" name="__codelineno-5-9" href="#notebooklm-notebooklm_config-__codelineno-5-9"></a>spark.authenticate.secret.driver.file
<a id="__codelineno-5-10" name="__codelineno-5-10" href="#notebooklm-notebooklm_config-__codelineno-5-10"></a>spark.authenticate.secret.executor.file
<a id="__codelineno-5-11" name="__codelineno-5-11" href="#notebooklm-notebooklm_config-__codelineno-5-11"></a>spark.network.crypto.enabled
<a id="__codelineno-5-12" name="__codelineno-5-12" href="#notebooklm-notebooklm_config-__codelineno-5-12"></a>spark.network.crypto.config.*
<a id="__codelineno-5-13" name="__codelineno-5-13" href="#notebooklm-notebooklm_config-__codelineno-5-13"></a>spark.network.crypto.saslFallback
<a id="__codelineno-5-14" name="__codelineno-5-14" href="#notebooklm-notebooklm_config-__codelineno-5-14"></a>spark.authenticate.enableSaslEncryption
<a id="__codelineno-5-15" name="__codelineno-5-15" href="#notebooklm-notebooklm_config-__codelineno-5-15"></a>spark.network.sasl.serverAlwaysEncrypt
<a id="__codelineno-5-16" name="__codelineno-5-16" href="#notebooklm-notebooklm_config-__codelineno-5-16"></a>spark.io.encryption.enabled
<a id="__codelineno-5-17" name="__codelineno-5-17" href="#notebooklm-notebooklm_config-__codelineno-5-17"></a>spark.io.encryption.keySizeBits
<a id="__codelineno-5-18" name="__codelineno-5-18" href="#notebooklm-notebooklm_config-__codelineno-5-18"></a>spark.io.encryption.keygen.algorithm
<a id="__codelineno-5-19" name="__codelineno-5-19" href="#notebooklm-notebooklm_config-__codelineno-5-19"></a>spark.io.encryption.commons.config.*
<a id="__codelineno-5-20" name="__codelineno-5-20" href="#notebooklm-notebooklm_config-__codelineno-5-20"></a>spark.ui.allowFramingFrom
<a id="__codelineno-5-21" name="__codelineno-5-21" href="#notebooklm-notebooklm_config-__codelineno-5-21"></a>spark.ui.filters
<a id="__codelineno-5-22" name="__codelineno-5-22" href="#notebooklm-notebooklm_config-__codelineno-5-22"></a>spark.acls.enable
<a id="__codelineno-5-23" name="__codelineno-5-23" href="#notebooklm-notebooklm_config-__codelineno-5-23"></a>spark.admin.acls
<a id="__codelineno-5-24" name="__codelineno-5-24" href="#notebooklm-notebooklm_config-__codelineno-5-24"></a>spark.admin.acls.groups
<a id="__codelineno-5-25" name="__codelineno-5-25" href="#notebooklm-notebooklm_config-__codelineno-5-25"></a>spark.modify.acls
<a id="__codelineno-5-26" name="__codelineno-5-26" href="#notebooklm-notebooklm_config-__codelineno-5-26"></a>spark.modify.acls.groups
<a id="__codelineno-5-27" name="__codelineno-5-27" href="#notebooklm-notebooklm_config-__codelineno-5-27"></a>spark.ui.view.acls
<a id="__codelineno-5-28" name="__codelineno-5-28" href="#notebooklm-notebooklm_config-__codelineno-5-28"></a>spark.ui.view.acls.groups
<a id="__codelineno-5-29" name="__codelineno-5-29" href="#notebooklm-notebooklm_config-__codelineno-5-29"></a>spark.user.groups.mapping
<a id="__codelineno-5-30" name="__codelineno-5-30" href="#notebooklm-notebooklm_config-__codelineno-5-30"></a>spark.history.ui.acls.enable
<a id="__codelineno-5-31" name="__codelineno-5-31" href="#notebooklm-notebooklm_config-__codelineno-5-31"></a>spark.history.ui.admin.acls
<a id="__codelineno-5-32" name="__codelineno-5-32" href="#notebooklm-notebooklm_config-__codelineno-5-32"></a>spark.history.ui.admin.acls.groups
<a id="__codelineno-5-33" name="__codelineno-5-33" href="#notebooklm-notebooklm_config-__codelineno-5-33"></a>spark.ssl.enabled
<a id="__codelineno-5-34" name="__codelineno-5-34" href="#notebooklm-notebooklm_config-__codelineno-5-34"></a>spark.ssl.port
<a id="__codelineno-5-35" name="__codelineno-5-35" href="#notebooklm-notebooklm_config-__codelineno-5-35"></a>spark.ssl.enabledAlgorithms
<a id="__codelineno-5-36" name="__codelineno-5-36" href="#notebooklm-notebooklm_config-__codelineno-5-36"></a>spark.ssl.keyPassword
<a id="__codelineno-5-37" name="__codelineno-5-37" href="#notebooklm-notebooklm_config-__codelineno-5-37"></a>spark.ssl.keyStore
<a id="__codelineno-5-38" name="__codelineno-5-38" href="#notebooklm-notebooklm_config-__codelineno-5-38"></a>spark.ssl.keyStorePassword
<a id="__codelineno-5-39" name="__codelineno-5-39" href="#notebooklm-notebooklm_config-__codelineno-5-39"></a>spark.ssl.keyStoreType
<a id="__codelineno-5-40" name="__codelineno-5-40" href="#notebooklm-notebooklm_config-__codelineno-5-40"></a>spark.ssl.protocol
<a id="__codelineno-5-41" name="__codelineno-5-41" href="#notebooklm-notebooklm_config-__codelineno-5-41"></a>spark.ssl.needClientAuth
<a id="__codelineno-5-42" name="__codelineno-5-42" href="#notebooklm-notebooklm_config-__codelineno-5-42"></a>spark.ssl.trustStore
<a id="__codelineno-5-43" name="__codelineno-5-43" href="#notebooklm-notebooklm_config-__codelineno-5-43"></a>spark.ssl.trustStorePassword
<a id="__codelineno-5-44" name="__codelineno-5-44" href="#notebooklm-notebooklm_config-__codelineno-5-44"></a>spark.ssl.trustStoreType
<a id="__codelineno-5-45" name="__codelineno-5-45" href="#notebooklm-notebooklm_config-__codelineno-5-45"></a>spark.ssl.ui.enabled
<a id="__codelineno-5-46" name="__codelineno-5-46" href="#notebooklm-notebooklm_config-__codelineno-5-46"></a>spark.ssl.ui.port
<a id="__codelineno-5-47" name="__codelineno-5-47" href="#notebooklm-notebooklm_config-__codelineno-5-47"></a>spark.ssl.ui.enabledAlgorithms
<a id="__codelineno-5-48" name="__codelineno-5-48" href="#notebooklm-notebooklm_config-__codelineno-5-48"></a>spark.ssl.ui.keyPassword
<a id="__codelineno-5-49" name="__codelineno-5-49" href="#notebooklm-notebooklm_config-__codelineno-5-49"></a>spark.ssl.ui.keyStore
<a id="__codelineno-5-50" name="__codelineno-5-50" href="#notebooklm-notebooklm_config-__codelineno-5-50"></a>spark.ssl.ui.keyStorePassword
<a id="__codelineno-5-51" name="__codelineno-5-51" href="#notebooklm-notebooklm_config-__codelineno-5-51"></a>spark.ssl.ui.keyStoreType
<a id="__codelineno-5-52" name="__codelineno-5-52" href="#notebooklm-notebooklm_config-__codelineno-5-52"></a>spark.ssl.ui.protocol
<a id="__codelineno-5-53" name="__codelineno-5-53" href="#notebooklm-notebooklm_config-__codelineno-5-53"></a>spark.ssl.ui.needClientAuth
<a id="__codelineno-5-54" name="__codelineno-5-54" href="#notebooklm-notebooklm_config-__codelineno-5-54"></a>spark.ssl.ui.trustStore
<a id="__codelineno-5-55" name="__codelineno-5-55" href="#notebooklm-notebooklm_config-__codelineno-5-55"></a>spark.ssl.ui.trustStorePassword
<a id="__codelineno-5-56" name="__codelineno-5-56" href="#notebooklm-notebooklm_config-__codelineno-5-56"></a>spark.ssl.ui.trustStoreType
<a id="__codelineno-5-57" name="__codelineno-5-57" href="#notebooklm-notebooklm_config-__codelineno-5-57"></a>spark.ssl.standalone.enabled
<a id="__codelineno-5-58" name="__codelineno-5-58" href="#notebooklm-notebooklm_config-__codelineno-5-58"></a>spark.ssl.standalone.port
<a id="__codelineno-5-59" name="__codelineno-5-59" href="#notebooklm-notebooklm_config-__codelineno-5-59"></a>spark.ssl.standalone.enabledAlgorithms
<a id="__codelineno-5-60" name="__codelineno-5-60" href="#notebooklm-notebooklm_config-__codelineno-5-60"></a>spark.ssl.standalone.keyPassword
<a id="__codelineno-5-61" name="__codelineno-5-61" href="#notebooklm-notebooklm_config-__codelineno-5-61"></a>spark.ssl.standalone.keyStore
<a id="__codelineno-5-62" name="__codelineno-5-62" href="#notebooklm-notebooklm_config-__codelineno-5-62"></a>spark.ssl.standalone.keyStorePassword
<a id="__codelineno-5-63" name="__codelineno-5-63" href="#notebooklm-notebooklm_config-__codelineno-5-63"></a>spark.ssl.standalone.keyStoreType
<a id="__codelineno-5-64" name="__codelineno-5-64" href="#notebooklm-notebooklm_config-__codelineno-5-64"></a>spark.ssl.standalone.protocol
<a id="__codelineno-5-65" name="__codelineno-5-65" href="#notebooklm-notebooklm_config-__codelineno-5-65"></a>spark.ssl.standalone.needClientAuth
<a id="__codelineno-5-66" name="__codelineno-5-66" href="#notebooklm-notebooklm_config-__codelineno-5-66"></a>spark.ssl.standalone.trustStore
<a id="__codelineno-5-67" name="__codelineno-5-67" href="#notebooklm-notebooklm_config-__codelineno-5-67"></a>spark.ssl.standalone.trustStorePassword
<a id="__codelineno-5-68" name="__codelineno-5-68" href="#notebooklm-notebooklm_config-__codelineno-5-68"></a>spark.ssl.standalone.trustStoreType
<a id="__codelineno-5-69" name="__codelineno-5-69" href="#notebooklm-notebooklm_config-__codelineno-5-69"></a>spark.ssl.historyServer.enabled
<a id="__codelineno-5-70" name="__codelineno-5-70" href="#notebooklm-notebooklm_config-__codelineno-5-70"></a>spark.ssl.historyServer.port
<a id="__codelineno-5-71" name="__codelineno-5-71" href="#notebooklm-notebooklm_config-__codelineno-5-71"></a>spark.ssl.historyServer.enabledAlgorithms
<a id="__codelineno-5-72" name="__codelineno-5-72" href="#notebooklm-notebooklm_config-__codelineno-5-72"></a>spark.ssl.historyServer.keyPassword
<a id="__codelineno-5-73" name="__codelineno-5-73" href="#notebooklm-notebooklm_config-__codelineno-5-73"></a>spark.ssl.historyServer.keyStore
<a id="__codelineno-5-74" name="__codelineno-5-74" href="#notebooklm-notebooklm_config-__codelineno-5-74"></a>spark.ssl.historyServer.keyStorePassword
<a id="__codelineno-5-75" name="__codelineno-5-75" href="#notebooklm-notebooklm_config-__codelineno-5-75"></a>spark.ssl.historyServer.keyStoreType
<a id="__codelineno-5-76" name="__codelineno-5-76" href="#notebooklm-notebooklm_config-__codelineno-5-76"></a>spark.ssl.historyServer.protocol
<a id="__codelineno-5-77" name="__codelineno-5-77" href="#notebooklm-notebooklm_config-__codelineno-5-77"></a>spark.ssl.historyServer.needClientAuth
<a id="__codelineno-5-78" name="__codelineno-5-78" href="#notebooklm-notebooklm_config-__codelineno-5-78"></a>spark.ssl.historyServer.trustStore
<a id="__codelineno-5-79" name="__codelineno-5-79" href="#notebooklm-notebooklm_config-__codelineno-5-79"></a>spark.ssl.historyServer.trustStorePassword
<a id="__codelineno-5-80" name="__codelineno-5-80" href="#notebooklm-notebooklm_config-__codelineno-5-80"></a>spark.ssl.historyServer.trustStoreType
<a id="__codelineno-5-81" name="__codelineno-5-81" href="#notebooklm-notebooklm_config-__codelineno-5-81"></a>spark.ui.xXssProtection
<a id="__codelineno-5-82" name="__codelineno-5-82" href="#notebooklm-notebooklm_config-__codelineno-5-82"></a>spark.ui.xContentTypeOptions.enabled
<a id="__codelineno-5-83" name="__codelineno-5-83" href="#notebooklm-notebooklm_config-__codelineno-5-83"></a>spark.ui.strictTransportSecurity
<a id="__codelineno-5-84" name="__codelineno-5-84" href="#notebooklm-notebooklm_config-__codelineno-5-84"></a>
<a id="__codelineno-5-85" name="__codelineno-5-85" href="#notebooklm-notebooklm_config-__codelineno-5-85"></a>
<a id="__codelineno-5-86" name="__codelineno-5-86" href="#notebooklm-notebooklm_config-__codelineno-5-86"></a>===notebooklm===
<a id="__codelineno-5-87" name="__codelineno-5-87" href="#notebooklm-notebooklm_config-__codelineno-5-87"></a>hadoop.security.credential.provider.path
<a id="__codelineno-5-88" name="__codelineno-5-88" href="#notebooklm-notebooklm_config-__codelineno-5-88"></a>spark.acls.enable
<a id="__codelineno-5-89" name="__codelineno-5-89" href="#notebooklm-notebooklm_config-__codelineno-5-89"></a>spark.admin.acls
<a id="__codelineno-5-90" name="__codelineno-5-90" href="#notebooklm-notebooklm_config-__codelineno-5-90"></a>spark.admin.acls.groups
<a id="__codelineno-5-91" name="__codelineno-5-91" href="#notebooklm-notebooklm_config-__codelineno-5-91"></a>spark.authenticate
<a id="__codelineno-5-92" name="__codelineno-5-92" href="#notebooklm-notebooklm_config-__codelineno-5-92"></a>spark.authenticate.enableSaslEncryption
<a id="__codelineno-5-93" name="__codelineno-5-93" href="#notebooklm-notebooklm_config-__codelineno-5-93"></a>spark.authenticate.secret
<a id="__codelineno-5-94" name="__codelineno-5-94" href="#notebooklm-notebooklm_config-__codelineno-5-94"></a>spark.authenticate.secret.driver.file
<a id="__codelineno-5-95" name="__codelineno-5-95" href="#notebooklm-notebooklm_config-__codelineno-5-95"></a>spark.authenticate.secret.executor.file
<a id="__codelineno-5-96" name="__codelineno-5-96" href="#notebooklm-notebooklm_config-__codelineno-5-96"></a>spark.authenticate.secret.file
<a id="__codelineno-5-97" name="__codelineno-5-97" href="#notebooklm-notebooklm_config-__codelineno-5-97"></a>spark.history.ui.acls.enable
<a id="__codelineno-5-98" name="__codelineno-5-98" href="#notebooklm-notebooklm_config-__codelineno-5-98"></a>spark.history.ui.admin.acls
<a id="__codelineno-5-99" name="__codelineno-5-99" href="#notebooklm-notebooklm_config-__codelineno-5-99"></a>spark.history.ui.admin.acls.groups
<a id="__codelineno-5-100" name="__codelineno-5-100" href="#notebooklm-notebooklm_config-__codelineno-5-100"></a>spark.io.encryption.commons.config.*
<a id="__codelineno-5-101" name="__codelineno-5-101" href="#notebooklm-notebooklm_config-__codelineno-5-101"></a>spark.io.encryption.enabled
<a id="__codelineno-5-102" name="__codelineno-5-102" href="#notebooklm-notebooklm_config-__codelineno-5-102"></a>spark.io.encryption.keySizeBits
<a id="__codelineno-5-103" name="__codelineno-5-103" href="#notebooklm-notebooklm_config-__codelineno-5-103"></a>spark.io.encryption.keygen.algorithm
<a id="__codelineno-5-104" name="__codelineno-5-104" href="#notebooklm-notebooklm_config-__codelineno-5-104"></a>spark.kerberos.access.hadoopFileSystems
<a id="__codelineno-5-105" name="__codelineno-5-105" href="#notebooklm-notebooklm_config-__codelineno-5-105"></a>spark.kerberos.keytab
<a id="__codelineno-5-106" name="__codelineno-5-106" href="#notebooklm-notebooklm_config-__codelineno-5-106"></a>spark.kerberos.principal
<a id="__codelineno-5-107" name="__codelineno-5-107" href="#notebooklm-notebooklm_config-__codelineno-5-107"></a>spark.kubernetes.hadoop.configMapName
<a id="__codelineno-5-108" name="__codelineno-5-108" href="#notebooklm-notebooklm_config-__codelineno-5-108"></a>spark.kubernetes.kerberos.krb5.configMapName
<a id="__codelineno-5-109" name="__codelineno-5-109" href="#notebooklm-notebooklm_config-__codelineno-5-109"></a>spark.kubernetes.kerberos.krb5.path
<a id="__codelineno-5-110" name="__codelineno-5-110" href="#notebooklm-notebooklm_config-__codelineno-5-110"></a>spark.kubernetes.kerberos.tokenSecret.itemKey
<a id="__codelineno-5-111" name="__codelineno-5-111" href="#notebooklm-notebooklm_config-__codelineno-5-111"></a>spark.kubernetes.kerberos.tokenSecret.name
<a id="__codelineno-5-112" name="__codelineno-5-112" href="#notebooklm-notebooklm_config-__codelineno-5-112"></a>spark.mesos.driver.secret.envkeys
<a id="__codelineno-5-113" name="__codelineno-5-113" href="#notebooklm-notebooklm_config-__codelineno-5-113"></a>spark.mesos.driver.secret.filenames
<a id="__codelineno-5-114" name="__codelineno-5-114" href="#notebooklm-notebooklm_config-__codelineno-5-114"></a>spark.mesos.driver.secret.names
<a id="__codelineno-5-115" name="__codelineno-5-115" href="#notebooklm-notebooklm_config-__codelineno-5-115"></a>spark.mesos.driver.secret.values
<a id="__codelineno-5-116" name="__codelineno-5-116" href="#notebooklm-notebooklm_config-__codelineno-5-116"></a>spark.modify.acls
<a id="__codelineno-5-117" name="__codelineno-5-117" href="#notebooklm-notebooklm_config-__codelineno-5-117"></a>spark.modify.acls.groups
<a id="__codelineno-5-118" name="__codelineno-5-118" href="#notebooklm-notebooklm_config-__codelineno-5-118"></a>spark.network.crypto.config.*
<a id="__codelineno-5-119" name="__codelineno-5-119" href="#notebooklm-notebooklm_config-__codelineno-5-119"></a>spark.network.crypto.enabled
<a id="__codelineno-5-120" name="__codelineno-5-120" href="#notebooklm-notebooklm_config-__codelineno-5-120"></a>spark.network.crypto.saslFallback
<a id="__codelineno-5-121" name="__codelineno-5-121" href="#notebooklm-notebooklm_config-__codelineno-5-121"></a>spark.network.sasl.serverAlwaysEncrypt
<a id="__codelineno-5-122" name="__codelineno-5-122" href="#notebooklm-notebooklm_config-__codelineno-5-122"></a>spark.redaction.regex
<a id="__codelineno-5-123" name="__codelineno-5-123" href="#notebooklm-notebooklm_config-__codelineno-5-123"></a>spark.redaction.string.regex
<a id="__codelineno-5-124" name="__codelineno-5-124" href="#notebooklm-notebooklm_config-__codelineno-5-124"></a>spark.security.credentials.${service}.enabled
<a id="__codelineno-5-125" name="__codelineno-5-125" href="#notebooklm-notebooklm_config-__codelineno-5-125"></a>spark.sql.redaction.options.regex
<a id="__codelineno-5-126" name="__codelineno-5-126" href="#notebooklm-notebooklm_config-__codelineno-5-126"></a>spark.ssl.enabled
<a id="__codelineno-5-127" name="__codelineno-5-127" href="#notebooklm-notebooklm_config-__codelineno-5-127"></a>spark.ssl.enabledAlgorithms
<a id="__codelineno-5-128" name="__codelineno-5-128" href="#notebooklm-notebooklm_config-__codelineno-5-128"></a>spark.ssl.historyServer.enabled
<a id="__codelineno-5-129" name="__codelineno-5-129" href="#notebooklm-notebooklm_config-__codelineno-5-129"></a>spark.ssl.historyServer.enabledAlgorithms
<a id="__codelineno-5-130" name="__codelineno-5-130" href="#notebooklm-notebooklm_config-__codelineno-5-130"></a>spark.ssl.historyServer.keyPassword
<a id="__codelineno-5-131" name="__codelineno-5-131" href="#notebooklm-notebooklm_config-__codelineno-5-131"></a>spark.ssl.historyServer.keyStore
<a id="__codelineno-5-132" name="__codelineno-5-132" href="#notebooklm-notebooklm_config-__codelineno-5-132"></a>spark.ssl.historyServer.keyStorePassword
<a id="__codelineno-5-133" name="__codelineno-5-133" href="#notebooklm-notebooklm_config-__codelineno-5-133"></a>spark.ssl.historyServer.keyStoreType
<a id="__codelineno-5-134" name="__codelineno-5-134" href="#notebooklm-notebooklm_config-__codelineno-5-134"></a>spark.ssl.historyServer.needClientAuth
<a id="__codelineno-5-135" name="__codelineno-5-135" href="#notebooklm-notebooklm_config-__codelineno-5-135"></a>spark.ssl.historyServer.port
<a id="__codelineno-5-136" name="__codelineno-5-136" href="#notebooklm-notebooklm_config-__codelineno-5-136"></a>spark.ssl.historyServer.protocol
<a id="__codelineno-5-137" name="__codelineno-5-137" href="#notebooklm-notebooklm_config-__codelineno-5-137"></a>spark.ssl.historyServer.trustStore
<a id="__codelineno-5-138" name="__codelineno-5-138" href="#notebooklm-notebooklm_config-__codelineno-5-138"></a>spark.ssl.historyServer.trustStorePassword
<a id="__codelineno-5-139" name="__codelineno-5-139" href="#notebooklm-notebooklm_config-__codelineno-5-139"></a>spark.ssl.historyServer.trustStoreType
<a id="__codelineno-5-140" name="__codelineno-5-140" href="#notebooklm-notebooklm_config-__codelineno-5-140"></a>spark.ssl.keyPassword
<a id="__codelineno-5-141" name="__codelineno-5-141" href="#notebooklm-notebooklm_config-__codelineno-5-141"></a>spark.ssl.keyStore
<a id="__codelineno-5-142" name="__codelineno-5-142" href="#notebooklm-notebooklm_config-__codelineno-5-142"></a>spark.ssl.keyStorePassword
<a id="__codelineno-5-143" name="__codelineno-5-143" href="#notebooklm-notebooklm_config-__codelineno-5-143"></a>spark.ssl.keyStoreType
<a id="__codelineno-5-144" name="__codelineno-5-144" href="#notebooklm-notebooklm_config-__codelineno-5-144"></a>spark.ssl.needClientAuth
<a id="__codelineno-5-145" name="__codelineno-5-145" href="#notebooklm-notebooklm_config-__codelineno-5-145"></a>spark.ssl.port
<a id="__codelineno-5-146" name="__codelineno-5-146" href="#notebooklm-notebooklm_config-__codelineno-5-146"></a>spark.ssl.protocol
<a id="__codelineno-5-147" name="__codelineno-5-147" href="#notebooklm-notebooklm_config-__codelineno-5-147"></a>spark.ssl.standalone.enabled
<a id="__codelineno-5-148" name="__codelineno-5-148" href="#notebooklm-notebooklm_config-__codelineno-5-148"></a>spark.ssl.standalone.enabledAlgorithms
<a id="__codelineno-5-149" name="__codelineno-5-149" href="#notebooklm-notebooklm_config-__codelineno-5-149"></a>spark.ssl.standalone.keyPassword
<a id="__codelineno-5-150" name="__codelineno-5-150" href="#notebooklm-notebooklm_config-__codelineno-5-150"></a>spark.ssl.standalone.keyStore
<a id="__codelineno-5-151" name="__codelineno-5-151" href="#notebooklm-notebooklm_config-__codelineno-5-151"></a>spark.ssl.standalone.keyStorePassword
<a id="__codelineno-5-152" name="__codelineno-5-152" href="#notebooklm-notebooklm_config-__codelineno-5-152"></a>spark.ssl.standalone.keyStoreType
<a id="__codelineno-5-153" name="__codelineno-5-153" href="#notebooklm-notebooklm_config-__codelineno-5-153"></a>spark.ssl.standalone.needClientAuth
<a id="__codelineno-5-154" name="__codelineno-5-154" href="#notebooklm-notebooklm_config-__codelineno-5-154"></a>spark.ssl.standalone.port
<a id="__codelineno-5-155" name="__codelineno-5-155" href="#notebooklm-notebooklm_config-__codelineno-5-155"></a>spark.ssl.standalone.protocol
<a id="__codelineno-5-156" name="__codelineno-5-156" href="#notebooklm-notebooklm_config-__codelineno-5-156"></a>spark.ssl.standalone.trustStore
<a id="__codelineno-5-157" name="__codelineno-5-157" href="#notebooklm-notebooklm_config-__codelineno-5-157"></a>spark.ssl.standalone.trustStorePassword
<a id="__codelineno-5-158" name="__codelineno-5-158" href="#notebooklm-notebooklm_config-__codelineno-5-158"></a>spark.ssl.standalone.trustStoreType
<a id="__codelineno-5-159" name="__codelineno-5-159" href="#notebooklm-notebooklm_config-__codelineno-5-159"></a>spark.ssl.trustStore
<a id="__codelineno-5-160" name="__codelineno-5-160" href="#notebooklm-notebooklm_config-__codelineno-5-160"></a>spark.ssl.trustStorePassword
<a id="__codelineno-5-161" name="__codelineno-5-161" href="#notebooklm-notebooklm_config-__codelineno-5-161"></a>spark.ssl.trustStoreType
<a id="__codelineno-5-162" name="__codelineno-5-162" href="#notebooklm-notebooklm_config-__codelineno-5-162"></a>spark.ssl.ui.enabled
<a id="__codelineno-5-163" name="__codelineno-5-163" href="#notebooklm-notebooklm_config-__codelineno-5-163"></a>spark.ssl.ui.enabledAlgorithms
<a id="__codelineno-5-164" name="__codelineno-5-164" href="#notebooklm-notebooklm_config-__codelineno-5-164"></a>spark.ssl.ui.keyPassword
<a id="__codelineno-5-165" name="__codelineno-5-165" href="#notebooklm-notebooklm_config-__codelineno-5-165"></a>spark.ssl.ui.keyStore
<a id="__codelineno-5-166" name="__codelineno-5-166" href="#notebooklm-notebooklm_config-__codelineno-5-166"></a>spark.ssl.ui.keyStorePassword
<a id="__codelineno-5-167" name="__codelineno-5-167" href="#notebooklm-notebooklm_config-__codelineno-5-167"></a>spark.ssl.ui.keyStoreType
<a id="__codelineno-5-168" name="__codelineno-5-168" href="#notebooklm-notebooklm_config-__codelineno-5-168"></a>spark.ssl.ui.needClientAuth
<a id="__codelineno-5-169" name="__codelineno-5-169" href="#notebooklm-notebooklm_config-__codelineno-5-169"></a>spark.ssl.ui.port
<a id="__codelineno-5-170" name="__codelineno-5-170" href="#notebooklm-notebooklm_config-__codelineno-5-170"></a>spark.ssl.ui.protocol
<a id="__codelineno-5-171" name="__codelineno-5-171" href="#notebooklm-notebooklm_config-__codelineno-5-171"></a>spark.ssl.ui.trustStore
<a id="__codelineno-5-172" name="__codelineno-5-172" href="#notebooklm-notebooklm_config-__codelineno-5-172"></a>spark.ssl.ui.trustStorePassword
<a id="__codelineno-5-173" name="__codelineno-5-173" href="#notebooklm-notebooklm_config-__codelineno-5-173"></a>spark.ssl.ui.trustStoreType
<a id="__codelineno-5-174" name="__codelineno-5-174" href="#notebooklm-notebooklm_config-__codelineno-5-174"></a>spark.ssl.useNodeLocalConf
<a id="__codelineno-5-175" name="__codelineno-5-175" href="#notebooklm-notebooklm_config-__codelineno-5-175"></a>spark.ui.allowFramingFrom
<a id="__codelineno-5-176" name="__codelineno-5-176" href="#notebooklm-notebooklm_config-__codelineno-5-176"></a>spark.ui.filters
<a id="__codelineno-5-177" name="__codelineno-5-177" href="#notebooklm-notebooklm_config-__codelineno-5-177"></a>spark.ui.strictTransportSecurity
<a id="__codelineno-5-178" name="__codelineno-5-178" href="#notebooklm-notebooklm_config-__codelineno-5-178"></a>spark.ui.view.acls
<a id="__codelineno-5-179" name="__codelineno-5-179" href="#notebooklm-notebooklm_config-__codelineno-5-179"></a>spark.ui.view.acls.groups
<a id="__codelineno-5-180" name="__codelineno-5-180" href="#notebooklm-notebooklm_config-__codelineno-5-180"></a>spark.ui.xContentTypeOptions.enabled
<a id="__codelineno-5-181" name="__codelineno-5-181" href="#notebooklm-notebooklm_config-__codelineno-5-181"></a>spark.ui.xXssProtection
<a id="__codelineno-5-182" name="__codelineno-5-182" href="#notebooklm-notebooklm_config-__codelineno-5-182"></a>spark.user.groups.mapping
</code></pre></div>
<h4 id="notebooklm-notebooklm_config-response">Response<a class="headerlink" href="#notebooklm-notebooklm_config-response" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="" src="../assets/images/apache_spark_chatgpt.png" /></p>
</figure>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#notebooklm-notebooklm_config-__codelineno-6-1"></a>Values in ===manual=== but not in ===notebooklm===
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#notebooklm-notebooklm_config-__codelineno-6-2"></a>spark.yarn.shuffle.server.recovery.disabled
<a id="__codelineno-6-3" name="__codelineno-6-3" href="#notebooklm-notebooklm_config-__codelineno-6-3"></a>Values in ===notebooklm=== but not in ===manual===
<a id="__codelineno-6-4" name="__codelineno-6-4" href="#notebooklm-notebooklm_config-__codelineno-6-4"></a>hadoop.security.credential.provider.path
<a id="__codelineno-6-5" name="__codelineno-6-5" href="#notebooklm-notebooklm_config-__codelineno-6-5"></a>spark.kerberos.access.hadoopFileSystems
<a id="__codelineno-6-6" name="__codelineno-6-6" href="#notebooklm-notebooklm_config-__codelineno-6-6"></a>spark.kerberos.keytab
<a id="__codelineno-6-7" name="__codelineno-6-7" href="#notebooklm-notebooklm_config-__codelineno-6-7"></a>spark.kerberos.principal
<a id="__codelineno-6-8" name="__codelineno-6-8" href="#notebooklm-notebooklm_config-__codelineno-6-8"></a>spark.kubernetes.hadoop.configMapName
<a id="__codelineno-6-9" name="__codelineno-6-9" href="#notebooklm-notebooklm_config-__codelineno-6-9"></a>spark.kubernetes.kerberos.krb5.configMapName
<a id="__codelineno-6-10" name="__codelineno-6-10" href="#notebooklm-notebooklm_config-__codelineno-6-10"></a>spark.kubernetes.kerberos.krb5.path
<a id="__codelineno-6-11" name="__codelineno-6-11" href="#notebooklm-notebooklm_config-__codelineno-6-11"></a>spark.kubernetes.kerberos.tokenSecret.itemKey
<a id="__codelineno-6-12" name="__codelineno-6-12" href="#notebooklm-notebooklm_config-__codelineno-6-12"></a>spark.kubernetes.kerberos.tokenSecret.name
<a id="__codelineno-6-13" name="__codelineno-6-13" href="#notebooklm-notebooklm_config-__codelineno-6-13"></a>spark.mesos.driver.secret.envkeys
<a id="__codelineno-6-14" name="__codelineno-6-14" href="#notebooklm-notebooklm_config-__codelineno-6-14"></a>spark.mesos.driver.secret.filenames
<a id="__codelineno-6-15" name="__codelineno-6-15" href="#notebooklm-notebooklm_config-__codelineno-6-15"></a>spark.mesos.driver.secret.names
<a id="__codelineno-6-16" name="__codelineno-6-16" href="#notebooklm-notebooklm_config-__codelineno-6-16"></a>spark.mesos.driver.secret.values
<a id="__codelineno-6-17" name="__codelineno-6-17" href="#notebooklm-notebooklm_config-__codelineno-6-17"></a>spark.redaction.regex
<a id="__codelineno-6-18" name="__codelineno-6-18" href="#notebooklm-notebooklm_config-__codelineno-6-18"></a>spark.redaction.string.regex
<a id="__codelineno-6-19" name="__codelineno-6-19" href="#notebooklm-notebooklm_config-__codelineno-6-19"></a>spark.security.credentials.${service}.enabled
<a id="__codelineno-6-20" name="__codelineno-6-20" href="#notebooklm-notebooklm_config-__codelineno-6-20"></a>spark.sql.redaction.options.regex
<a id="__codelineno-6-21" name="__codelineno-6-21" href="#notebooklm-notebooklm_config-__codelineno-6-21"></a>spark.ssl.useNodeLocalConf
</code></pre></div>
<div class="admonition observation">
<p class="admonition-title">Observation</p>
<ol>
<li>NotebookLM did not understand the concept of placeholder config parameters from the source documents. Since there are several config parameters per placeholder, it missed many config parameters (Attempt 1).</li>
<li><strong>When the prompt explained about placeholder config parameters, NotebookLM found all but 1 of the 79 configuration parameters related to security (Attempt 2).</strong><ol>
<li><strong>NotebookLM found 18 config parameters related to security that were not found by humans as part of the expected answers</strong> and these appear to be valid configuration parameters related to security based on my review.</li>
</ol>
</li>
<li>1 config parameter was not found by NotebookLM, and it's not obvious why: <code>spark.yarn.shuffle.server.recovery.disabled</code>
    <figure markdown>
    <img alt="" src="../assets/images/apache_spark_chatgpt_miss.png" />
    </figure></li>
</ol>
</div>
<h2 id="notebooklm-notebooklm_config-chatgpt4o">ChatGPT4o<a class="headerlink" href="#notebooklm-notebooklm_config-chatgpt4o" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_config-original-prompt_1">Original Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-original-prompt_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#notebooklm-notebooklm_config-__codelineno-7-1"></a>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings
<a id="__codelineno-7-2" name="__codelineno-7-2" href="#notebooklm-notebooklm_config-__codelineno-7-2"></a>Using only the documentation of Apache Spark from the URLs below (and no other source), which configuration parameters are relevant from a security perspective?
<a id="__codelineno-7-3" name="__codelineno-7-3" href="#notebooklm-notebooklm_config-__codelineno-7-3"></a>
<a id="__codelineno-7-4" name="__codelineno-7-4" href="#notebooklm-notebooklm_config-__codelineno-7-4"></a>The data sources are :
<a id="__codelineno-7-5" name="__codelineno-7-5" href="#notebooklm-notebooklm_config-__codelineno-7-5"></a>1. https://spark.apache.org/docs/latest/configuration.html
<a id="__codelineno-7-6" name="__codelineno-7-6" href="#notebooklm-notebooklm_config-__codelineno-7-6"></a>2. https://spark.apache.org/docs/latest/security.html
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#notebooklm-notebooklm_config-__codelineno-8-1"></a>[
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#notebooklm-notebooklm_config-__codelineno-8-2"></a>    &quot;spark.authenticate&quot;,
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#notebooklm-notebooklm_config-__codelineno-8-3"></a>    &quot;spark.authenticate.secret&quot;,
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#notebooklm-notebooklm_config-__codelineno-8-4"></a>    &quot;spark.authenticate.secret.file&quot;,
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#notebooklm-notebooklm_config-__codelineno-8-5"></a>    &quot;spark.authenticate.secret.driver.file&quot;,
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#notebooklm-notebooklm_config-__codelineno-8-6"></a>    &quot;spark.authenticate.secret.executor.file&quot;,
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#notebooklm-notebooklm_config-__codelineno-8-7"></a>    &quot;spark.network.crypto.enabled&quot;,
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#notebooklm-notebooklm_config-__codelineno-8-8"></a>    &quot;spark.network.crypto.config.*&quot;,
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#notebooklm-notebooklm_config-__codelineno-8-9"></a>    &quot;spark.network.crypto.saslFallback&quot;,
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#notebooklm-notebooklm_config-__codelineno-8-10"></a>    &quot;spark.authenticate.enableSaslEncryption&quot;,
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#notebooklm-notebooklm_config-__codelineno-8-11"></a>    &quot;spark.network.sasl.serverAlwaysEncrypt&quot;,
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#notebooklm-notebooklm_config-__codelineno-8-12"></a>    &quot;spark.io.encryption.enabled&quot;,
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#notebooklm-notebooklm_config-__codelineno-8-13"></a>    &quot;spark.io.encryption.keySizeBits&quot;,
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#notebooklm-notebooklm_config-__codelineno-8-14"></a>    &quot;spark.io.encryption.keygen.algorithm&quot;,
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#notebooklm-notebooklm_config-__codelineno-8-15"></a>    &quot;spark.io.encryption.commons.config.*&quot;,
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#notebooklm-notebooklm_config-__codelineno-8-16"></a>    &quot;spark.ui.allowFramingFrom&quot;,
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#notebooklm-notebooklm_config-__codelineno-8-17"></a>    &quot;spark.ui.filters&quot;,
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#notebooklm-notebooklm_config-__codelineno-8-18"></a>    &quot;spark.acls.enable&quot;,
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#notebooklm-notebooklm_config-__codelineno-8-19"></a>    &quot;spark.admin.acls&quot;,
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#notebooklm-notebooklm_config-__codelineno-8-20"></a>    &quot;spark.admin.acls.groups&quot;,
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#notebooklm-notebooklm_config-__codelineno-8-21"></a>    &quot;spark.modify.acls&quot;,
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#notebooklm-notebooklm_config-__codelineno-8-22"></a>    &quot;spark.modify.acls.groups&quot;,
<a id="__codelineno-8-23" name="__codelineno-8-23" href="#notebooklm-notebooklm_config-__codelineno-8-23"></a>    &quot;spark.ui.view.acls&quot;,
<a id="__codelineno-8-24" name="__codelineno-8-24" href="#notebooklm-notebooklm_config-__codelineno-8-24"></a>    &quot;spark.ui.view.acls.groups&quot;,
<a id="__codelineno-8-25" name="__codelineno-8-25" href="#notebooklm-notebooklm_config-__codelineno-8-25"></a>    &quot;spark.user.groups.mapping&quot;,
<a id="__codelineno-8-26" name="__codelineno-8-26" href="#notebooklm-notebooklm_config-__codelineno-8-26"></a>    &quot;spark.history.ui.acls.enable&quot;,
<a id="__codelineno-8-27" name="__codelineno-8-27" href="#notebooklm-notebooklm_config-__codelineno-8-27"></a>    &quot;spark.history.ui.admin.acls&quot;,
<a id="__codelineno-8-28" name="__codelineno-8-28" href="#notebooklm-notebooklm_config-__codelineno-8-28"></a>    &quot;spark.history.ui.admin.acls.groups&quot;,
<a id="__codelineno-8-29" name="__codelineno-8-29" href="#notebooklm-notebooklm_config-__codelineno-8-29"></a>    &quot;spark.ssl.enabled&quot;,
<a id="__codelineno-8-30" name="__codelineno-8-30" href="#notebooklm-notebooklm_config-__codelineno-8-30"></a>    &quot;spark.ssl.port&quot;,
<a id="__codelineno-8-31" name="__codelineno-8-31" href="#notebooklm-notebooklm_config-__codelineno-8-31"></a>    &quot;spark.ssl.enabledAlgorithms&quot;,
<a id="__codelineno-8-32" name="__codelineno-8-32" href="#notebooklm-notebooklm_config-__codelineno-8-32"></a>    &quot;spark.ssl.keyPassword&quot;,
<a id="__codelineno-8-33" name="__codelineno-8-33" href="#notebooklm-notebooklm_config-__codelineno-8-33"></a>    &quot;spark.ssl.keyStore&quot;,
<a id="__codelineno-8-34" name="__codelineno-8-34" href="#notebooklm-notebooklm_config-__codelineno-8-34"></a>    &quot;spark.ssl.keyStorePassword&quot;,
<a id="__codelineno-8-35" name="__codelineno-8-35" href="#notebooklm-notebooklm_config-__codelineno-8-35"></a>    &quot;spark.ssl.keyStoreType&quot;,
<a id="__codelineno-8-36" name="__codelineno-8-36" href="#notebooklm-notebooklm_config-__codelineno-8-36"></a>    &quot;spark.ssl.protocol&quot;,
<a id="__codelineno-8-37" name="__codelineno-8-37" href="#notebooklm-notebooklm_config-__codelineno-8-37"></a>    &quot;spark.ssl.needClientAuth&quot;,
<a id="__codelineno-8-38" name="__codelineno-8-38" href="#notebooklm-notebooklm_config-__codelineno-8-38"></a>    &quot;spark.ssl.trustStore&quot;,
<a id="__codelineno-8-39" name="__codelineno-8-39" href="#notebooklm-notebooklm_config-__codelineno-8-39"></a>    &quot;spark.ssl.trustStorePassword&quot;,
<a id="__codelineno-8-40" name="__codelineno-8-40" href="#notebooklm-notebooklm_config-__codelineno-8-40"></a>    &quot;spark.ssl.trustStoreType&quot;,
<a id="__codelineno-8-41" name="__codelineno-8-41" href="#notebooklm-notebooklm_config-__codelineno-8-41"></a>    &quot;spark.ui.xXssProtection&quot;,
<a id="__codelineno-8-42" name="__codelineno-8-42" href="#notebooklm-notebooklm_config-__codelineno-8-42"></a>    &quot;spark.ui.xContentTypeOptions.enabled&quot;,
<a id="__codelineno-8-43" name="__codelineno-8-43" href="#notebooklm-notebooklm_config-__codelineno-8-43"></a>    &quot;spark.ui.strictTransportSecurity&quot;,
<a id="__codelineno-8-44" name="__codelineno-8-44" href="#notebooklm-notebooklm_config-__codelineno-8-44"></a>    &quot;spark.kerberos.access.hadoopFileSystems&quot;,
<a id="__codelineno-8-45" name="__codelineno-8-45" href="#notebooklm-notebooklm_config-__codelineno-8-45"></a>    &quot;spark.security.credentials.${service}.enabled&quot;
<a id="__codelineno-8-46" name="__codelineno-8-46" href="#notebooklm-notebooklm_config-__codelineno-8-46"></a>]
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-prompt-explaining-config-namespace-placeholders">Prompt Explaining Config Namespace placeholders<a class="headerlink" href="#notebooklm-notebooklm_config-prompt-explaining-config-namespace-placeholders" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#notebooklm-notebooklm_config-__codelineno-9-1"></a>Note that Config Namespace placeholders are used for some security configurations. These are placeholders &quot;${ns}&quot; that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: &quot;${ns}.enabled&quot;, &quot;spark.ssl.enabled&quot; and &quot;spark.ssl.historyServer&quot; would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#notebooklm-notebooklm_config-__codelineno-10-1"></a>[
<a id="__codelineno-10-2" name="__codelineno-10-2" href="#notebooklm-notebooklm_config-__codelineno-10-2"></a>    &quot;spark.ssl.enabled&quot;,
<a id="__codelineno-10-3" name="__codelineno-10-3" href="#notebooklm-notebooklm_config-__codelineno-10-3"></a>    &quot;spark.ssl.historyServer.enabled&quot;,
<a id="__codelineno-10-4" name="__codelineno-10-4" href="#notebooklm-notebooklm_config-__codelineno-10-4"></a>    &quot;spark.security.credentials.enabled&quot;,
<a id="__codelineno-10-5" name="__codelineno-10-5" href="#notebooklm-notebooklm_config-__codelineno-10-5"></a>    &quot;spark.ssl.port&quot;,
<a id="__codelineno-10-6" name="__codelineno-10-6" href="#notebooklm-notebooklm_config-__codelineno-10-6"></a>    &quot;spark.ssl.historyServer.port&quot;,
<a id="__codelineno-10-7" name="__codelineno-10-7" href="#notebooklm-notebooklm_config-__codelineno-10-7"></a>    &quot;spark.security.credentials.port&quot;,
<a id="__codelineno-10-8" name="__codelineno-10-8" href="#notebooklm-notebooklm_config-__codelineno-10-8"></a>    &quot;spark.ssl.enabledAlgorithms&quot;,
<a id="__codelineno-10-9" name="__codelineno-10-9" href="#notebooklm-notebooklm_config-__codelineno-10-9"></a>    &quot;spark.ssl.historyServer.enabledAlgorithms&quot;,
<a id="__codelineno-10-10" name="__codelineno-10-10" href="#notebooklm-notebooklm_config-__codelineno-10-10"></a>    &quot;spark.security.credentials.enabledAlgorithms&quot;,
<a id="__codelineno-10-11" name="__codelineno-10-11" href="#notebooklm-notebooklm_config-__codelineno-10-11"></a>    &quot;spark.ssl.keyPassword&quot;,
<a id="__codelineno-10-12" name="__codelineno-10-12" href="#notebooklm-notebooklm_config-__codelineno-10-12"></a>    &quot;spark.ssl.historyServer.keyPassword&quot;,
<a id="__codelineno-10-13" name="__codelineno-10-13" href="#notebooklm-notebooklm_config-__codelineno-10-13"></a>    &quot;spark.security.credentials.keyPassword&quot;,
<a id="__codelineno-10-14" name="__codelineno-10-14" href="#notebooklm-notebooklm_config-__codelineno-10-14"></a>    &quot;spark.ssl.keyStore&quot;,
<a id="__codelineno-10-15" name="__codelineno-10-15" href="#notebooklm-notebooklm_config-__codelineno-10-15"></a>    &quot;spark.ssl.historyServer.keyStore&quot;,
<a id="__codelineno-10-16" name="__codelineno-10-16" href="#notebooklm-notebooklm_config-__codelineno-10-16"></a>    &quot;spark.security.credentials.keyStore&quot;,
<a id="__codelineno-10-17" name="__codelineno-10-17" href="#notebooklm-notebooklm_config-__codelineno-10-17"></a>    &quot;spark.ssl.keyStorePassword&quot;,
<a id="__codelineno-10-18" name="__codelineno-10-18" href="#notebooklm-notebooklm_config-__codelineno-10-18"></a>    &quot;spark.ssl.historyServer.keyStorePassword&quot;,
<a id="__codelineno-10-19" name="__codelineno-10-19" href="#notebooklm-notebooklm_config-__codelineno-10-19"></a>    &quot;spark.security.credentials.keyStorePassword&quot;,
<a id="__codelineno-10-20" name="__codelineno-10-20" href="#notebooklm-notebooklm_config-__codelineno-10-20"></a>    &quot;spark.ssl.keyStoreType&quot;,
<a id="__codelineno-10-21" name="__codelineno-10-21" href="#notebooklm-notebooklm_config-__codelineno-10-21"></a>    &quot;spark.ssl.historyServer.keyStoreType&quot;,
<a id="__codelineno-10-22" name="__codelineno-10-22" href="#notebooklm-notebooklm_config-__codelineno-10-22"></a>    &quot;spark.security.credentials.keyStoreType&quot;,
<a id="__codelineno-10-23" name="__codelineno-10-23" href="#notebooklm-notebooklm_config-__codelineno-10-23"></a>    &quot;spark.ssl.protocol&quot;,
<a id="__codelineno-10-24" name="__codelineno-10-24" href="#notebooklm-notebooklm_config-__codelineno-10-24"></a>    &quot;spark.ssl.historyServer.protocol&quot;,
<a id="__codelineno-10-25" name="__codelineno-10-25" href="#notebooklm-notebooklm_config-__codelineno-10-25"></a>    &quot;spark.security.credentials.protocol&quot;,
<a id="__codelineno-10-26" name="__codelineno-10-26" href="#notebooklm-notebooklm_config-__codelineno-10-26"></a>    &quot;spark.ssl.needClientAuth&quot;,
<a id="__codelineno-10-27" name="__codelineno-10-27" href="#notebooklm-notebooklm_config-__codelineno-10-27"></a>    &quot;spark.ssl.historyServer.needClientAuth&quot;,
<a id="__codelineno-10-28" name="__codelineno-10-28" href="#notebooklm-notebooklm_config-__codelineno-10-28"></a>    &quot;spark.security.credentials.needClientAuth&quot;,
<a id="__codelineno-10-29" name="__codelineno-10-29" href="#notebooklm-notebooklm_config-__codelineno-10-29"></a>    &quot;spark.ssl.trustStore&quot;,
<a id="__codelineno-10-30" name="__codelineno-10-30" href="#notebooklm-notebooklm_config-__codelineno-10-30"></a>    &quot;spark.ssl.historyServer.trustStore&quot;,
<a id="__codelineno-10-31" name="__codelineno-10-31" href="#notebooklm-notebooklm_config-__codelineno-10-31"></a>    &quot;spark.security.credentials.trustStore&quot;,
<a id="__codelineno-10-32" name="__codelineno-10-32" href="#notebooklm-notebooklm_config-__codelineno-10-32"></a>    &quot;spark.ssl.trustStorePassword&quot;,
<a id="__codelineno-10-33" name="__codelineno-10-33" href="#notebooklm-notebooklm_config-__codelineno-10-33"></a>    &quot;spark.ssl.historyServer.trustStorePassword&quot;,
<a id="__codelineno-10-34" name="__codelineno-10-34" href="#notebooklm-notebooklm_config-__codelineno-10-34"></a>    &quot;spark.security.credentials.trustStorePassword&quot;,
<a id="__codelineno-10-35" name="__codelineno-10-35" href="#notebooklm-notebooklm_config-__codelineno-10-35"></a>    &quot;spark.ssl.trustStoreType&quot;,
<a id="__codelineno-10-36" name="__codelineno-10-36" href="#notebooklm-notebooklm_config-__codelineno-10-36"></a>    &quot;spark.ssl.historyServer.trustStoreType&quot;,
<a id="__codelineno-10-37" name="__codelineno-10-37" href="#notebooklm-notebooklm_config-__codelineno-10-37"></a>    &quot;spark.security.credentials.trustStoreType&quot;,
<a id="__codelineno-10-38" name="__codelineno-10-38" href="#notebooklm-notebooklm_config-__codelineno-10-38"></a>    &quot;spark.ssl.historyServer&quot;,
<a id="__codelineno-10-39" name="__codelineno-10-39" href="#notebooklm-notebooklm_config-__codelineno-10-39"></a>    &quot;spark.ssl.historyServer.historyServer&quot;,
<a id="__codelineno-10-40" name="__codelineno-10-40" href="#notebooklm-notebooklm_config-__codelineno-10-40"></a>    &quot;spark.security.credentials.historyServer&quot;,
<a id="__codelineno-10-41" name="__codelineno-10-41" href="#notebooklm-notebooklm_config-__codelineno-10-41"></a>    &quot;spark.authenticate&quot;,
<a id="__codelineno-10-42" name="__codelineno-10-42" href="#notebooklm-notebooklm_config-__codelineno-10-42"></a>    &quot;spark.authenticate.secret&quot;,
<a id="__codelineno-10-43" name="__codelineno-10-43" href="#notebooklm-notebooklm_config-__codelineno-10-43"></a>    &quot;spark.authenticate.secret.file&quot;,
<a id="__codelineno-10-44" name="__codelineno-10-44" href="#notebooklm-notebooklm_config-__codelineno-10-44"></a>    &quot;spark.authenticate.secret.driver.file&quot;,
<a id="__codelineno-10-45" name="__codelineno-10-45" href="#notebooklm-notebooklm_config-__codelineno-10-45"></a>    &quot;spark.authenticate.secret.executor.file&quot;,
<a id="__codelineno-10-46" name="__codelineno-10-46" href="#notebooklm-notebooklm_config-__codelineno-10-46"></a>    &quot;spark.network.crypto.enabled&quot;,
<a id="__codelineno-10-47" name="__codelineno-10-47" href="#notebooklm-notebooklm_config-__codelineno-10-47"></a>    &quot;spark.network.crypto.config.*&quot;,
<a id="__codelineno-10-48" name="__codelineno-10-48" href="#notebooklm-notebooklm_config-__codelineno-10-48"></a>    &quot;spark.network.crypto.saslFallback&quot;,
<a id="__codelineno-10-49" name="__codelineno-10-49" href="#notebooklm-notebooklm_config-__codelineno-10-49"></a>    &quot;spark.authenticate.enableSaslEncryption&quot;,
<a id="__codelineno-10-50" name="__codelineno-10-50" href="#notebooklm-notebooklm_config-__codelineno-10-50"></a>    &quot;spark.network.sasl.serverAlwaysEncrypt&quot;,
<a id="__codelineno-10-51" name="__codelineno-10-51" href="#notebooklm-notebooklm_config-__codelineno-10-51"></a>    &quot;spark.io.encryption.enabled&quot;,
<a id="__codelineno-10-52" name="__codelineno-10-52" href="#notebooklm-notebooklm_config-__codelineno-10-52"></a>    &quot;spark.io.encryption.keySizeBits&quot;,
<a id="__codelineno-10-53" name="__codelineno-10-53" href="#notebooklm-notebooklm_config-__codelineno-10-53"></a>    &quot;spark.io.encryption.keygen.algorithm&quot;,
<a id="__codelineno-10-54" name="__codelineno-10-54" href="#notebooklm-notebooklm_config-__codelineno-10-54"></a>    &quot;spark.io.encryption.commons.config.*&quot;,
<a id="__codelineno-10-55" name="__codelineno-10-55" href="#notebooklm-notebooklm_config-__codelineno-10-55"></a>    &quot;spark.ui.allowFramingFrom&quot;,
<a id="__codelineno-10-56" name="__codelineno-10-56" href="#notebooklm-notebooklm_config-__codelineno-10-56"></a>    &quot;spark.ui.filters&quot;,
<a id="__codelineno-10-57" name="__codelineno-10-57" href="#notebooklm-notebooklm_config-__codelineno-10-57"></a>    &quot;spark.acls.enable&quot;,
<a id="__codelineno-10-58" name="__codelineno-10-58" href="#notebooklm-notebooklm_config-__codelineno-10-58"></a>    &quot;spark.admin.acls&quot;,
<a id="__codelineno-10-59" name="__codelineno-10-59" href="#notebooklm-notebooklm_config-__codelineno-10-59"></a>    &quot;spark.admin.acls.groups&quot;,
<a id="__codelineno-10-60" name="__codelineno-10-60" href="#notebooklm-notebooklm_config-__codelineno-10-60"></a>    &quot;spark.modify.acls&quot;,
<a id="__codelineno-10-61" name="__codelineno-10-61" href="#notebooklm-notebooklm_config-__codelineno-10-61"></a>    &quot;spark.modify.acls.groups&quot;,
<a id="__codelineno-10-62" name="__codelineno-10-62" href="#notebooklm-notebooklm_config-__codelineno-10-62"></a>    &quot;spark.ui.view.acls&quot;,
<a id="__codelineno-10-63" name="__codelineno-10-63" href="#notebooklm-notebooklm_config-__codelineno-10-63"></a>    &quot;spark.ui.view.acls.groups&quot;,
<a id="__codelineno-10-64" name="__codelineno-10-64" href="#notebooklm-notebooklm_config-__codelineno-10-64"></a>    &quot;spark.user.groups.mapping&quot;,
<a id="__codelineno-10-65" name="__codelineno-10-65" href="#notebooklm-notebooklm_config-__codelineno-10-65"></a>    &quot;spark.history.ui.acls.enable&quot;,
<a id="__codelineno-10-66" name="__codelineno-10-66" href="#notebooklm-notebooklm_config-__codelineno-10-66"></a>    &quot;spark.history.ui.admin.acls&quot;,
<a id="__codelineno-10-67" name="__codelineno-10-67" href="#notebooklm-notebooklm_config-__codelineno-10-67"></a>    &quot;spark.history.ui.admin.acls.groups&quot;,
<a id="__codelineno-10-68" name="__codelineno-10-68" href="#notebooklm-notebooklm_config-__codelineno-10-68"></a>    &quot;spark.ui.xXssProtection&quot;,
<a id="__codelineno-10-69" name="__codelineno-10-69" href="#notebooklm-notebooklm_config-__codelineno-10-69"></a>    &quot;spark.ui.xContentTypeOptions.enabled&quot;,
<a id="__codelineno-10-70" name="__codelineno-10-70" href="#notebooklm-notebooklm_config-__codelineno-10-70"></a>    &quot;spark.ui.strictTransportSecurity&quot;,
<a id="__codelineno-10-71" name="__codelineno-10-71" href="#notebooklm-notebooklm_config-__codelineno-10-71"></a>    &quot;spark.kerberos.access.hadoopFileSystems&quot;,
<a id="__codelineno-10-72" name="__codelineno-10-72" href="#notebooklm-notebooklm_config-__codelineno-10-72"></a>    &quot;spark.security.credentials.${service}.enabled&quot;
<a id="__codelineno-10-73" name="__codelineno-10-73" href="#notebooklm-notebooklm_config-__codelineno-10-73"></a>]
<a id="__codelineno-10-74" name="__codelineno-10-74" href="#notebooklm-notebooklm_config-__codelineno-10-74"></a>``` &amp;#8203;:citation[oaicite:0]{index=0}&amp;#8203;
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_2">Compare The Answer With The Expected Answer<a class="headerlink" href="#notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_2" title="Permanent link">&para;</a></h3>
<ol>
<li>ChatGPT4o missed these 2 config placeholders (these were not provided in the example in the prompt - only the first and last one were provided)<ol>
<li>spark.ssl.ui</li>
<li>spark.ssl.standalone   </li>
</ol>
</li>
<li>ChatGPT4o wrongly interpreted spark.security.credentials.${service}.enabled as being the same as ${ns} placeholder, and appended the parameters for ${ns} placeholder to spark.security.credentials.</li>
</ol>
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#notebooklm-notebooklm_config-__codelineno-11-1"></a>{
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#notebooklm-notebooklm_config-__codelineno-11-2"></a>    &quot;manual_not_in_chatgpt4o&quot;: [
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#notebooklm-notebooklm_config-__codelineno-11-3"></a>        &quot;spark.yarn.shuffle.server.recovery.disabled&quot;,
<a id="__codelineno-11-4" name="__codelineno-11-4" href="#notebooklm-notebooklm_config-__codelineno-11-4"></a>        &quot;spark.ssl.ui.enabled&quot;,
<a id="__codelineno-11-5" name="__codelineno-11-5" href="#notebooklm-notebooklm_config-__codelineno-11-5"></a>        &quot;spark.ssl.ui.port&quot;,
<a id="__codelineno-11-6" name="__codelineno-11-6" href="#notebooklm-notebooklm_config-__codelineno-11-6"></a>        &quot;spark.ssl.ui.enabledAlgorithms&quot;,
<a id="__codelineno-11-7" name="__codelineno-11-7" href="#notebooklm-notebooklm_config-__codelineno-11-7"></a>        &quot;spark.ssl.ui.keyPassword&quot;,
<a id="__codelineno-11-8" name="__codelineno-11-8" href="#notebooklm-notebooklm_config-__codelineno-11-8"></a>        &quot;spark.ssl.ui.keyStore&quot;,
<a id="__codelineno-11-9" name="__codelineno-11-9" href="#notebooklm-notebooklm_config-__codelineno-11-9"></a>        &quot;spark.ssl.ui.keyStorePassword&quot;,
<a id="__codelineno-11-10" name="__codelineno-11-10" href="#notebooklm-notebooklm_config-__codelineno-11-10"></a>        &quot;spark.ssl.ui.keyStoreType&quot;,
<a id="__codelineno-11-11" name="__codelineno-11-11" href="#notebooklm-notebooklm_config-__codelineno-11-11"></a>        &quot;spark.ssl.ui.protocol&quot;,
<a id="__codelineno-11-12" name="__codelineno-11-12" href="#notebooklm-notebooklm_config-__codelineno-11-12"></a>        &quot;spark.ssl.ui.needClientAuth&quot;,
<a id="__codelineno-11-13" name="__codelineno-11-13" href="#notebooklm-notebooklm_config-__codelineno-11-13"></a>        &quot;spark.ssl.ui.trustStore&quot;,
<a id="__codelineno-11-14" name="__codelineno-11-14" href="#notebooklm-notebooklm_config-__codelineno-11-14"></a>        &quot;spark.ssl.ui.trustStorePassword&quot;,
<a id="__codelineno-11-15" name="__codelineno-11-15" href="#notebooklm-notebooklm_config-__codelineno-11-15"></a>        &quot;spark.ssl.ui.trustStoreType&quot;,
<a id="__codelineno-11-16" name="__codelineno-11-16" href="#notebooklm-notebooklm_config-__codelineno-11-16"></a>        &quot;spark.ssl.standalone.enabled&quot;,
<a id="__codelineno-11-17" name="__codelineno-11-17" href="#notebooklm-notebooklm_config-__codelineno-11-17"></a>        &quot;spark.ssl.standalone.port&quot;,
<a id="__codelineno-11-18" name="__codelineno-11-18" href="#notebooklm-notebooklm_config-__codelineno-11-18"></a>        &quot;spark.ssl.standalone.enabledAlgorithms&quot;,
<a id="__codelineno-11-19" name="__codelineno-11-19" href="#notebooklm-notebooklm_config-__codelineno-11-19"></a>        &quot;spark.ssl.standalone.keyPassword&quot;,
<a id="__codelineno-11-20" name="__codelineno-11-20" href="#notebooklm-notebooklm_config-__codelineno-11-20"></a>        &quot;spark.ssl.standalone.keyStore&quot;,
<a id="__codelineno-11-21" name="__codelineno-11-21" href="#notebooklm-notebooklm_config-__codelineno-11-21"></a>        &quot;spark.ssl.standalone.keyStorePassword&quot;,
<a id="__codelineno-11-22" name="__codelineno-11-22" href="#notebooklm-notebooklm_config-__codelineno-11-22"></a>        &quot;spark.ssl.standalone.keyStoreType&quot;,
<a id="__codelineno-11-23" name="__codelineno-11-23" href="#notebooklm-notebooklm_config-__codelineno-11-23"></a>        &quot;spark.ssl.standalone.protocol&quot;,
<a id="__codelineno-11-24" name="__codelineno-11-24" href="#notebooklm-notebooklm_config-__codelineno-11-24"></a>        &quot;spark.ssl.standalone.needClientAuth&quot;,
<a id="__codelineno-11-25" name="__codelineno-11-25" href="#notebooklm-notebooklm_config-__codelineno-11-25"></a>        &quot;spark.ssl.standalone.trustStore&quot;,
<a id="__codelineno-11-26" name="__codelineno-11-26" href="#notebooklm-notebooklm_config-__codelineno-11-26"></a>        &quot;spark.ssl.standalone.trustStorePassword&quot;,
<a id="__codelineno-11-27" name="__codelineno-11-27" href="#notebooklm-notebooklm_config-__codelineno-11-27"></a>        &quot;spark.ssl.standalone.trustStoreType&quot;
<a id="__codelineno-11-28" name="__codelineno-11-28" href="#notebooklm-notebooklm_config-__codelineno-11-28"></a>    ],
<a id="__codelineno-11-29" name="__codelineno-11-29" href="#notebooklm-notebooklm_config-__codelineno-11-29"></a>    &quot;chatgpt4o_not_in_manual&quot;: [
<a id="__codelineno-11-30" name="__codelineno-11-30" href="#notebooklm-notebooklm_config-__codelineno-11-30"></a>        &quot;spark.security.credentials.enabled&quot;,
<a id="__codelineno-11-31" name="__codelineno-11-31" href="#notebooklm-notebooklm_config-__codelineno-11-31"></a>        &quot;spark.security.credentials.port&quot;,
<a id="__codelineno-11-32" name="__codelineno-11-32" href="#notebooklm-notebooklm_config-__codelineno-11-32"></a>        &quot;spark.security.credentials.enabledAlgorithms&quot;,
<a id="__codelineno-11-33" name="__codelineno-11-33" href="#notebooklm-notebooklm_config-__codelineno-11-33"></a>        &quot;spark.security.credentials.keyPassword&quot;,
<a id="__codelineno-11-34" name="__codelineno-11-34" href="#notebooklm-notebooklm_config-__codelineno-11-34"></a>        &quot;spark.security.credentials.keyStore&quot;,
<a id="__codelineno-11-35" name="__codelineno-11-35" href="#notebooklm-notebooklm_config-__codelineno-11-35"></a>        &quot;spark.security.credentials.keyStorePassword&quot;,
<a id="__codelineno-11-36" name="__codelineno-11-36" href="#notebooklm-notebooklm_config-__codelineno-11-36"></a>        &quot;spark.security.credentials.keyStoreType&quot;,
<a id="__codelineno-11-37" name="__codelineno-11-37" href="#notebooklm-notebooklm_config-__codelineno-11-37"></a>        &quot;spark.security.credentials.protocol&quot;,
<a id="__codelineno-11-38" name="__codelineno-11-38" href="#notebooklm-notebooklm_config-__codelineno-11-38"></a>        &quot;spark.security.credentials.needClientAuth&quot;,
<a id="__codelineno-11-39" name="__codelineno-11-39" href="#notebooklm-notebooklm_config-__codelineno-11-39"></a>        &quot;spark.security.credentials.trustStore&quot;,
<a id="__codelineno-11-40" name="__codelineno-11-40" href="#notebooklm-notebooklm_config-__codelineno-11-40"></a>        &quot;spark.security.credentials.trustStorePassword&quot;,
<a id="__codelineno-11-41" name="__codelineno-11-41" href="#notebooklm-notebooklm_config-__codelineno-11-41"></a>        &quot;spark.security.credentials.trustStoreType&quot;,
<a id="__codelineno-11-42" name="__codelineno-11-42" href="#notebooklm-notebooklm_config-__codelineno-11-42"></a>        &quot;spark.security.credentials.historyServer&quot;,
<a id="__codelineno-11-43" name="__codelineno-11-43" href="#notebooklm-notebooklm_config-__codelineno-11-43"></a>        &quot;spark.security.credentials.${service}.enabled&quot;
<a id="__codelineno-11-44" name="__codelineno-11-44" href="#notebooklm-notebooklm_config-__codelineno-11-44"></a>    ]
<a id="__codelineno-11-45" name="__codelineno-11-45" href="#notebooklm-notebooklm_config-__codelineno-11-45"></a>}
</code></pre></div>
<div class="admonition observation">
<p class="admonition-title">Observation</p>
<ol>
<li><code>spark.yarn.shuffle.server.recovery.disabled</code> was not found by ChatGPT4o (or NotebookLM).     </li>
<li>ChatGPT4o found 44 parameters in the first prompt.</li>
<li>When the concept of placeholder config parameters was explained in the second prompt, ChatGPT made 2 mistakes and thereby got many config parameters wrong<ol>
<li>it did not extend the example to all the placeholder config parameters</li>
<li>it appended the {ns} placeholder parameters to a different placeholder {service}</li>
</ol>
</li>
</ol>
</div>
<h2 id="notebooklm-notebooklm_config-claude-sonnet-35">Claude Sonnet 3.5<a class="headerlink" href="#notebooklm-notebooklm_config-claude-sonnet-35" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Claude Sonnet 3.5 Pro was used as both documents were too large for the free version.</p>
</div>
<h3 id="notebooklm-notebooklm_config-original-prompt_2">Original Prompt<a class="headerlink" href="#notebooklm-notebooklm_config-original-prompt_2" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#notebooklm-notebooklm_config-__codelineno-12-1"></a>You are an assistant that is a cybersecurity expert and knows their configuration files. Your response here should be a JSON list of strings
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#notebooklm-notebooklm_config-__codelineno-12-2"></a>Using only the documentation of Apache Spark from the URLs below (and no other source), which configuration parameters are relevant from a security perspective?
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#notebooklm-notebooklm_config-__codelineno-12-3"></a>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#notebooklm-notebooklm_config-__codelineno-12-4"></a>The data sources are :
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#notebooklm-notebooklm_config-__codelineno-12-5"></a>1. https://spark.apache.org/docs/latest/configuration.html
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#notebooklm-notebooklm_config-__codelineno-12-6"></a>2. https://spark.apache.org/docs/latest/security.html
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1" href="#notebooklm-notebooklm_config-__codelineno-13-1"></a>Based on my analysis of the Apache Spark documentation, here is a JSON list of configuration parameters that are relevant from a security perspective:
<a id="__codelineno-13-2" name="__codelineno-13-2" href="#notebooklm-notebooklm_config-__codelineno-13-2"></a>[
<a id="__codelineno-13-3" name="__codelineno-13-3" href="#notebooklm-notebooklm_config-__codelineno-13-3"></a>&quot;spark.authenticate&quot;,
<a id="__codelineno-13-4" name="__codelineno-13-4" href="#notebooklm-notebooklm_config-__codelineno-13-4"></a>&quot;spark.authenticate.secret&quot;,
<a id="__codelineno-13-5" name="__codelineno-13-5" href="#notebooklm-notebooklm_config-__codelineno-13-5"></a>&quot;spark.network.crypto.enabled&quot;,
<a id="__codelineno-13-6" name="__codelineno-13-6" href="#notebooklm-notebooklm_config-__codelineno-13-6"></a>&quot;spark.network.crypto.saslFallback&quot;,
<a id="__codelineno-13-7" name="__codelineno-13-7" href="#notebooklm-notebooklm_config-__codelineno-13-7"></a>&quot;spark.authenticate.enableSaslEncryption&quot;,
<a id="__codelineno-13-8" name="__codelineno-13-8" href="#notebooklm-notebooklm_config-__codelineno-13-8"></a>&quot;spark.network.sasl.serverAlwaysEncrypt&quot;,
<a id="__codelineno-13-9" name="__codelineno-13-9" href="#notebooklm-notebooklm_config-__codelineno-13-9"></a>&quot;spark.io.encryption.enabled&quot;,
<a id="__codelineno-13-10" name="__codelineno-13-10" href="#notebooklm-notebooklm_config-__codelineno-13-10"></a>&quot;spark.io.encryption.keySizeBits&quot;,
<a id="__codelineno-13-11" name="__codelineno-13-11" href="#notebooklm-notebooklm_config-__codelineno-13-11"></a>&quot;spark.io.encryption.keygen.algorithm&quot;,
<a id="__codelineno-13-12" name="__codelineno-13-12" href="#notebooklm-notebooklm_config-__codelineno-13-12"></a>&quot;spark.ssl.enabled&quot;,
<a id="__codelineno-13-13" name="__codelineno-13-13" href="#notebooklm-notebooklm_config-__codelineno-13-13"></a>&quot;spark.ssl.keyStore&quot;,
<a id="__codelineno-13-14" name="__codelineno-13-14" href="#notebooklm-notebooklm_config-__codelineno-13-14"></a>&quot;spark.ssl.keyStorePassword&quot;,
<a id="__codelineno-13-15" name="__codelineno-13-15" href="#notebooklm-notebooklm_config-__codelineno-13-15"></a>&quot;spark.ssl.keyPassword&quot;,
<a id="__codelineno-13-16" name="__codelineno-13-16" href="#notebooklm-notebooklm_config-__codelineno-13-16"></a>&quot;spark.ssl.trustStore&quot;,
<a id="__codelineno-13-17" name="__codelineno-13-17" href="#notebooklm-notebooklm_config-__codelineno-13-17"></a>&quot;spark.ssl.trustStorePassword&quot;,
<a id="__codelineno-13-18" name="__codelineno-13-18" href="#notebooklm-notebooklm_config-__codelineno-13-18"></a>&quot;spark.ssl.protocol&quot;,
<a id="__codelineno-13-19" name="__codelineno-13-19" href="#notebooklm-notebooklm_config-__codelineno-13-19"></a>&quot;spark.ssl.enabledAlgorithms&quot;,
<a id="__codelineno-13-20" name="__codelineno-13-20" href="#notebooklm-notebooklm_config-__codelineno-13-20"></a>&quot;spark.ui.filters&quot;,
<a id="__codelineno-13-21" name="__codelineno-13-21" href="#notebooklm-notebooklm_config-__codelineno-13-21"></a>&quot;spark.acls.enable&quot;,
<a id="__codelineno-13-22" name="__codelineno-13-22" href="#notebooklm-notebooklm_config-__codelineno-13-22"></a>&quot;spark.admin.acls&quot;,
<a id="__codelineno-13-23" name="__codelineno-13-23" href="#notebooklm-notebooklm_config-__codelineno-13-23"></a>&quot;spark.admin.acls.groups&quot;,
<a id="__codelineno-13-24" name="__codelineno-13-24" href="#notebooklm-notebooklm_config-__codelineno-13-24"></a>&quot;spark.modify.acls&quot;,
<a id="__codelineno-13-25" name="__codelineno-13-25" href="#notebooklm-notebooklm_config-__codelineno-13-25"></a>&quot;spark.modify.acls.groups&quot;,
<a id="__codelineno-13-26" name="__codelineno-13-26" href="#notebooklm-notebooklm_config-__codelineno-13-26"></a>&quot;spark.ui.view.acls&quot;,
<a id="__codelineno-13-27" name="__codelineno-13-27" href="#notebooklm-notebooklm_config-__codelineno-13-27"></a>&quot;spark.ui.view.acls.groups&quot;,
<a id="__codelineno-13-28" name="__codelineno-13-28" href="#notebooklm-notebooklm_config-__codelineno-13-28"></a>&quot;spark.eventLog.enabled&quot;,
<a id="__codelineno-13-29" name="__codelineno-13-29" href="#notebooklm-notebooklm_config-__codelineno-13-29"></a>&quot;spark.eventLog.dir&quot;,
<a id="__codelineno-13-30" name="__codelineno-13-30" href="#notebooklm-notebooklm_config-__codelineno-13-30"></a>&quot;spark.history.kerberos.enabled&quot;,
<a id="__codelineno-13-31" name="__codelineno-13-31" href="#notebooklm-notebooklm_config-__codelineno-13-31"></a>&quot;spark.history.kerberos.principal&quot;,
<a id="__codelineno-13-32" name="__codelineno-13-32" href="#notebooklm-notebooklm_config-__codelineno-13-32"></a>&quot;spark.history.kerberos.keytab&quot;,
<a id="__codelineno-13-33" name="__codelineno-13-33" href="#notebooklm-notebooklm_config-__codelineno-13-33"></a>&quot;spark.kerberos.principal&quot;,
<a id="__codelineno-13-34" name="__codelineno-13-34" href="#notebooklm-notebooklm_config-__codelineno-13-34"></a>&quot;spark.kerberos.keytab&quot;,
<a id="__codelineno-13-35" name="__codelineno-13-35" href="#notebooklm-notebooklm_config-__codelineno-13-35"></a>&quot;spark.hadoop.security.authentication&quot;,
<a id="__codelineno-13-36" name="__codelineno-13-36" href="#notebooklm-notebooklm_config-__codelineno-13-36"></a>&quot;spark.yarn.security.tokens.hbase.enabled&quot;,
<a id="__codelineno-13-37" name="__codelineno-13-37" href="#notebooklm-notebooklm_config-__codelineno-13-37"></a>&quot;spark.yarn.security.tokens.hive.enabled&quot;,
<a id="__codelineno-13-38" name="__codelineno-13-38" href="#notebooklm-notebooklm_config-__codelineno-13-38"></a>&quot;spark.yarn.security.credentials.hadoop.enabled&quot;,
<a id="__codelineno-13-39" name="__codelineno-13-39" href="#notebooklm-notebooklm_config-__codelineno-13-39"></a>&quot;spark.redaction.regex&quot;,
<a id="__codelineno-13-40" name="__codelineno-13-40" href="#notebooklm-notebooklm_config-__codelineno-13-40"></a>&quot;spark.ui.proxyRedirectUri&quot;,
<a id="__codelineno-13-41" name="__codelineno-13-41" href="#notebooklm-notebooklm_config-__codelineno-13-41"></a>&quot;spark.driver.log.dfsDir&quot;
<a id="__codelineno-13-42" name="__codelineno-13-42" href="#notebooklm-notebooklm_config-__codelineno-13-42"></a>]
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-prompt-explaining-config-namespace-placeholders_1">Prompt Explaining Config Namespace placeholders<a class="headerlink" href="#notebooklm-notebooklm_config-prompt-explaining-config-namespace-placeholders_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#notebooklm-notebooklm_config-__codelineno-14-1"></a>Note that Config Namespace placeholders are used for some security configurations. These are placeholders &quot;${ns}&quot; that can take values listed under Config Namespace. For these security configurations placeholders list all possible security configurations for each Config Namespace e.g. For Property Name: &quot;${ns}.enabled&quot;, &quot;spark.ssl.enabled&quot; and &quot;spark.ssl.historyServer&quot; would be some possible configurations now that you understand namespace placeholders, list all the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values. Your response here should be a JSON list of strings only. list the configuration parameters that are relevant from a security perspective replacing all placeholders with possible config namespace values and repeated patterns
</code></pre></div>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#notebooklm-notebooklm_config-__codelineno-15-1"></a>I understand. Here&#39;s a revised JSON list of configuration parameters relevant from a security perspective, with namespace placeholders expanded and repeated patterns included:
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#notebooklm-notebooklm_config-__codelineno-15-2"></a>[
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#notebooklm-notebooklm_config-__codelineno-15-3"></a>&quot;spark.authenticate&quot;,
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#notebooklm-notebooklm_config-__codelineno-15-4"></a>&quot;spark.authenticate.secret&quot;,
<a id="__codelineno-15-5" name="__codelineno-15-5" href="#notebooklm-notebooklm_config-__codelineno-15-5"></a>&quot;spark.network.crypto.enabled&quot;,
<a id="__codelineno-15-6" name="__codelineno-15-6" href="#notebooklm-notebooklm_config-__codelineno-15-6"></a>&quot;spark.network.crypto.saslFallback&quot;,
<a id="__codelineno-15-7" name="__codelineno-15-7" href="#notebooklm-notebooklm_config-__codelineno-15-7"></a>&quot;spark.authenticate.enableSaslEncryption&quot;,
<a id="__codelineno-15-8" name="__codelineno-15-8" href="#notebooklm-notebooklm_config-__codelineno-15-8"></a>&quot;spark.network.sasl.serverAlwaysEncrypt&quot;,
<a id="__codelineno-15-9" name="__codelineno-15-9" href="#notebooklm-notebooklm_config-__codelineno-15-9"></a>&quot;spark.io.encryption.enabled&quot;,
<a id="__codelineno-15-10" name="__codelineno-15-10" href="#notebooklm-notebooklm_config-__codelineno-15-10"></a>&quot;spark.io.encryption.keySizeBits&quot;,
<a id="__codelineno-15-11" name="__codelineno-15-11" href="#notebooklm-notebooklm_config-__codelineno-15-11"></a>&quot;spark.io.encryption.keygen.algorithm&quot;,
<a id="__codelineno-15-12" name="__codelineno-15-12" href="#notebooklm-notebooklm_config-__codelineno-15-12"></a>&quot;spark.ssl.enabled&quot;,
<a id="__codelineno-15-13" name="__codelineno-15-13" href="#notebooklm-notebooklm_config-__codelineno-15-13"></a>&quot;spark.ssl.ui.enabled&quot;,
<a id="__codelineno-15-14" name="__codelineno-15-14" href="#notebooklm-notebooklm_config-__codelineno-15-14"></a>&quot;spark.ssl.standalone.enabled&quot;,
<a id="__codelineno-15-15" name="__codelineno-15-15" href="#notebooklm-notebooklm_config-__codelineno-15-15"></a>&quot;spark.ssl.historyServer.enabled&quot;,
<a id="__codelineno-15-16" name="__codelineno-15-16" href="#notebooklm-notebooklm_config-__codelineno-15-16"></a>&quot;spark.ssl.keyStore&quot;,
<a id="__codelineno-15-17" name="__codelineno-15-17" href="#notebooklm-notebooklm_config-__codelineno-15-17"></a>&quot;spark.ssl.ui.keyStore&quot;,
<a id="__codelineno-15-18" name="__codelineno-15-18" href="#notebooklm-notebooklm_config-__codelineno-15-18"></a>&quot;spark.ssl.standalone.keyStore&quot;,
<a id="__codelineno-15-19" name="__codelineno-15-19" href="#notebooklm-notebooklm_config-__codelineno-15-19"></a>&quot;spark.ssl.historyServer.keyStore&quot;,
<a id="__codelineno-15-20" name="__codelineno-15-20" href="#notebooklm-notebooklm_config-__codelineno-15-20"></a>&quot;spark.ssl.keyStorePassword&quot;,
<a id="__codelineno-15-21" name="__codelineno-15-21" href="#notebooklm-notebooklm_config-__codelineno-15-21"></a>&quot;spark.ssl.ui.keyStorePassword&quot;,
<a id="__codelineno-15-22" name="__codelineno-15-22" href="#notebooklm-notebooklm_config-__codelineno-15-22"></a>&quot;spark.ssl.standalone.keyStorePassword&quot;,
<a id="__codelineno-15-23" name="__codelineno-15-23" href="#notebooklm-notebooklm_config-__codelineno-15-23"></a>&quot;spark.ssl.historyServer.keyStorePassword&quot;,
<a id="__codelineno-15-24" name="__codelineno-15-24" href="#notebooklm-notebooklm_config-__codelineno-15-24"></a>&quot;spark.ssl.keyPassword&quot;,
<a id="__codelineno-15-25" name="__codelineno-15-25" href="#notebooklm-notebooklm_config-__codelineno-15-25"></a>&quot;spark.ssl.ui.keyPassword&quot;,
<a id="__codelineno-15-26" name="__codelineno-15-26" href="#notebooklm-notebooklm_config-__codelineno-15-26"></a>&quot;spark.ssl.standalone.keyPassword&quot;,
<a id="__codelineno-15-27" name="__codelineno-15-27" href="#notebooklm-notebooklm_config-__codelineno-15-27"></a>&quot;spark.ssl.historyServer.keyPassword&quot;,
<a id="__codelineno-15-28" name="__codelineno-15-28" href="#notebooklm-notebooklm_config-__codelineno-15-28"></a>&quot;spark.ssl.trustStore&quot;,
<a id="__codelineno-15-29" name="__codelineno-15-29" href="#notebooklm-notebooklm_config-__codelineno-15-29"></a>&quot;spark.ssl.ui.trustStore&quot;,
<a id="__codelineno-15-30" name="__codelineno-15-30" href="#notebooklm-notebooklm_config-__codelineno-15-30"></a>&quot;spark.ssl.standalone.trustStore&quot;,
<a id="__codelineno-15-31" name="__codelineno-15-31" href="#notebooklm-notebooklm_config-__codelineno-15-31"></a>&quot;spark.ssl.historyServer.trustStore&quot;,
<a id="__codelineno-15-32" name="__codelineno-15-32" href="#notebooklm-notebooklm_config-__codelineno-15-32"></a>&quot;spark.ssl.trustStorePassword&quot;,
<a id="__codelineno-15-33" name="__codelineno-15-33" href="#notebooklm-notebooklm_config-__codelineno-15-33"></a>&quot;spark.ssl.ui.trustStorePassword&quot;,
<a id="__codelineno-15-34" name="__codelineno-15-34" href="#notebooklm-notebooklm_config-__codelineno-15-34"></a>&quot;spark.ssl.standalone.trustStorePassword&quot;,
<a id="__codelineno-15-35" name="__codelineno-15-35" href="#notebooklm-notebooklm_config-__codelineno-15-35"></a>&quot;spark.ssl.historyServer.trustStorePassword&quot;,
<a id="__codelineno-15-36" name="__codelineno-15-36" href="#notebooklm-notebooklm_config-__codelineno-15-36"></a>&quot;spark.ssl.protocol&quot;,
<a id="__codelineno-15-37" name="__codelineno-15-37" href="#notebooklm-notebooklm_config-__codelineno-15-37"></a>&quot;spark.ssl.ui.protocol&quot;,
<a id="__codelineno-15-38" name="__codelineno-15-38" href="#notebooklm-notebooklm_config-__codelineno-15-38"></a>&quot;spark.ssl.standalone.protocol&quot;,
<a id="__codelineno-15-39" name="__codelineno-15-39" href="#notebooklm-notebooklm_config-__codelineno-15-39"></a>&quot;spark.ssl.historyServer.protocol&quot;,
<a id="__codelineno-15-40" name="__codelineno-15-40" href="#notebooklm-notebooklm_config-__codelineno-15-40"></a>&quot;spark.ssl.enabledAlgorithms&quot;,
<a id="__codelineno-15-41" name="__codelineno-15-41" href="#notebooklm-notebooklm_config-__codelineno-15-41"></a>&quot;spark.ssl.ui.enabledAlgorithms&quot;,
<a id="__codelineno-15-42" name="__codelineno-15-42" href="#notebooklm-notebooklm_config-__codelineno-15-42"></a>&quot;spark.ssl.standalone.enabledAlgorithms&quot;,
<a id="__codelineno-15-43" name="__codelineno-15-43" href="#notebooklm-notebooklm_config-__codelineno-15-43"></a>&quot;spark.ssl.historyServer.enabledAlgorithms&quot;,
<a id="__codelineno-15-44" name="__codelineno-15-44" href="#notebooklm-notebooklm_config-__codelineno-15-44"></a>&quot;spark.ui.filters&quot;,
<a id="__codelineno-15-45" name="__codelineno-15-45" href="#notebooklm-notebooklm_config-__codelineno-15-45"></a>&quot;spark.acls.enable&quot;,
<a id="__codelineno-15-46" name="__codelineno-15-46" href="#notebooklm-notebooklm_config-__codelineno-15-46"></a>&quot;spark.admin.acls&quot;,
<a id="__codelineno-15-47" name="__codelineno-15-47" href="#notebooklm-notebooklm_config-__codelineno-15-47"></a>&quot;spark.admin.acls.groups&quot;,
<a id="__codelineno-15-48" name="__codelineno-15-48" href="#notebooklm-notebooklm_config-__codelineno-15-48"></a>&quot;spark.modify.acls&quot;,
<a id="__codelineno-15-49" name="__codelineno-15-49" href="#notebooklm-notebooklm_config-__codelineno-15-49"></a>&quot;spark.modify.acls.groups&quot;,
<a id="__codelineno-15-50" name="__codelineno-15-50" href="#notebooklm-notebooklm_config-__codelineno-15-50"></a>&quot;spark.ui.view.acls&quot;,
<a id="__codelineno-15-51" name="__codelineno-15-51" href="#notebooklm-notebooklm_config-__codelineno-15-51"></a>&quot;spark.ui.view.acls.groups&quot;,
<a id="__codelineno-15-52" name="__codelineno-15-52" href="#notebooklm-notebooklm_config-__codelineno-15-52"></a>&quot;spark.eventLog.enabled&quot;,
<a id="__codelineno-15-53" name="__codelineno-15-53" href="#notebooklm-notebooklm_config-__codelineno-15-53"></a>&quot;spark.eventLog.dir&quot;,
<a id="__codelineno-15-54" name="__codelineno-15-54" href="#notebooklm-notebooklm_config-__codelineno-15-54"></a>&quot;spark.history.kerberos.enabled&quot;,
<a id="__codelineno-15-55" name="__codelineno-15-55" href="#notebooklm-notebooklm_config-__codelineno-15-55"></a>&quot;spark.history.kerberos.principal&quot;,
<a id="__codelineno-15-56" name="__codelineno-15-56" href="#notebooklm-notebooklm_config-__codelineno-15-56"></a>&quot;spark.history.kerberos.keytab&quot;,
<a id="__codelineno-15-57" name="__codelineno-15-57" href="#notebooklm-notebooklm_config-__codelineno-15-57"></a>&quot;spark.kerberos.principal&quot;,
<a id="__codelineno-15-58" name="__codelineno-15-58" href="#notebooklm-notebooklm_config-__codelineno-15-58"></a>&quot;spark.kerberos.keytab&quot;,
<a id="__codelineno-15-59" name="__codelineno-15-59" href="#notebooklm-notebooklm_config-__codelineno-15-59"></a>&quot;spark.hadoop.security.authentication&quot;,
<a id="__codelineno-15-60" name="__codelineno-15-60" href="#notebooklm-notebooklm_config-__codelineno-15-60"></a>&quot;spark.yarn.security.tokens.hbase.enabled&quot;,
<a id="__codelineno-15-61" name="__codelineno-15-61" href="#notebooklm-notebooklm_config-__codelineno-15-61"></a>&quot;spark.yarn.security.tokens.hive.enabled&quot;,
<a id="__codelineno-15-62" name="__codelineno-15-62" href="#notebooklm-notebooklm_config-__codelineno-15-62"></a>&quot;spark.yarn.security.credentials.hadoop.enabled&quot;,
<a id="__codelineno-15-63" name="__codelineno-15-63" href="#notebooklm-notebooklm_config-__codelineno-15-63"></a>&quot;spark.redaction.regex&quot;,
<a id="__codelineno-15-64" name="__codelineno-15-64" href="#notebooklm-notebooklm_config-__codelineno-15-64"></a>&quot;spark.ui.proxyRedirectUri&quot;,
<a id="__codelineno-15-65" name="__codelineno-15-65" href="#notebooklm-notebooklm_config-__codelineno-15-65"></a>&quot;spark.driver.log.dfsDir&quot;,
<a id="__codelineno-15-66" name="__codelineno-15-66" href="#notebooklm-notebooklm_config-__codelineno-15-66"></a>&quot;spark.ssl.keyStoreType&quot;,
<a id="__codelineno-15-67" name="__codelineno-15-67" href="#notebooklm-notebooklm_config-__codelineno-15-67"></a>&quot;spark.ssl.ui.keyStoreType&quot;,
<a id="__codelineno-15-68" name="__codelineno-15-68" href="#notebooklm-notebooklm_config-__codelineno-15-68"></a>&quot;spark.ssl.standalone.keyStoreType&quot;,
<a id="__codelineno-15-69" name="__codelineno-15-69" href="#notebooklm-notebooklm_config-__codelineno-15-69"></a>&quot;spark.ssl.historyServer.keyStoreType&quot;,
<a id="__codelineno-15-70" name="__codelineno-15-70" href="#notebooklm-notebooklm_config-__codelineno-15-70"></a>&quot;spark.ssl.trustStoreType&quot;,
<a id="__codelineno-15-71" name="__codelineno-15-71" href="#notebooklm-notebooklm_config-__codelineno-15-71"></a>&quot;spark.ssl.ui.trustStoreType&quot;,
<a id="__codelineno-15-72" name="__codelineno-15-72" href="#notebooklm-notebooklm_config-__codelineno-15-72"></a>&quot;spark.ssl.standalone.trustStoreType&quot;,
<a id="__codelineno-15-73" name="__codelineno-15-73" href="#notebooklm-notebooklm_config-__codelineno-15-73"></a>&quot;spark.ssl.historyServer.trustStoreType&quot;,
<a id="__codelineno-15-74" name="__codelineno-15-74" href="#notebooklm-notebooklm_config-__codelineno-15-74"></a>&quot;spark.ssl.needClientAuth&quot;,
<a id="__codelineno-15-75" name="__codelineno-15-75" href="#notebooklm-notebooklm_config-__codelineno-15-75"></a>&quot;spark.ssl.ui.needClientAuth&quot;,
<a id="__codelineno-15-76" name="__codelineno-15-76" href="#notebooklm-notebooklm_config-__codelineno-15-76"></a>&quot;spark.ssl.standalone.needClientAuth&quot;,
<a id="__codelineno-15-77" name="__codelineno-15-77" href="#notebooklm-notebooklm_config-__codelineno-15-77"></a>&quot;spark.ssl.historyServer.needClientAuth&quot;,
<a id="__codelineno-15-78" name="__codelineno-15-78" href="#notebooklm-notebooklm_config-__codelineno-15-78"></a>&quot;spark.ui.allowFramingFrom&quot;,
<a id="__codelineno-15-79" name="__codelineno-15-79" href="#notebooklm-notebooklm_config-__codelineno-15-79"></a>&quot;spark.ui.xXssProtection&quot;,
<a id="__codelineno-15-80" name="__codelineno-15-80" href="#notebooklm-notebooklm_config-__codelineno-15-80"></a>&quot;spark.ui.xContentTypeOptions.enabled&quot;,
<a id="__codelineno-15-81" name="__codelineno-15-81" href="#notebooklm-notebooklm_config-__codelineno-15-81"></a>&quot;spark.ui.strictTransportSecurity&quot;
<a id="__codelineno-15-82" name="__codelineno-15-82" href="#notebooklm-notebooklm_config-__codelineno-15-82"></a>]
</code></pre></div>
<h3 id="notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_3">Compare The Answer With The Expected Answer<a class="headerlink" href="#notebooklm-notebooklm_config-compare-the-answer-with-the-expected-answer_3" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#notebooklm-notebooklm_config-__codelineno-16-1"></a>Values in ===manual=== but not in ===claude35===:
<a id="__codelineno-16-2" name="__codelineno-16-2" href="#notebooklm-notebooklm_config-__codelineno-16-2"></a>
<a id="__codelineno-16-3" name="__codelineno-16-3" href="#notebooklm-notebooklm_config-__codelineno-16-3"></a>spark.yarn.shuffle.server.recovery.disabled
<a id="__codelineno-16-4" name="__codelineno-16-4" href="#notebooklm-notebooklm_config-__codelineno-16-4"></a>spark.authenticate.secret.file
<a id="__codelineno-16-5" name="__codelineno-16-5" href="#notebooklm-notebooklm_config-__codelineno-16-5"></a>spark.authenticate.secret.driver.file
<a id="__codelineno-16-6" name="__codelineno-16-6" href="#notebooklm-notebooklm_config-__codelineno-16-6"></a>spark.authenticate.secret.executor.file
<a id="__codelineno-16-7" name="__codelineno-16-7" href="#notebooklm-notebooklm_config-__codelineno-16-7"></a>spark.network.crypto.config.*
<a id="__codelineno-16-8" name="__codelineno-16-8" href="#notebooklm-notebooklm_config-__codelineno-16-8"></a>spark.io.encryption.commons.config.*
<a id="__codelineno-16-9" name="__codelineno-16-9" href="#notebooklm-notebooklm_config-__codelineno-16-9"></a>spark.user.groups.mapping
<a id="__codelineno-16-10" name="__codelineno-16-10" href="#notebooklm-notebooklm_config-__codelineno-16-10"></a>spark.history.ui.acls.enable
<a id="__codelineno-16-11" name="__codelineno-16-11" href="#notebooklm-notebooklm_config-__codelineno-16-11"></a>spark.history.ui.admin.acls
<a id="__codelineno-16-12" name="__codelineno-16-12" href="#notebooklm-notebooklm_config-__codelineno-16-12"></a>spark.history.ui.admin.acls.groups
<a id="__codelineno-16-13" name="__codelineno-16-13" href="#notebooklm-notebooklm_config-__codelineno-16-13"></a>spark.ssl.port
<a id="__codelineno-16-14" name="__codelineno-16-14" href="#notebooklm-notebooklm_config-__codelineno-16-14"></a>spark.ssl.ui.port
<a id="__codelineno-16-15" name="__codelineno-16-15" href="#notebooklm-notebooklm_config-__codelineno-16-15"></a>spark.ssl.standalone.port
<a id="__codelineno-16-16" name="__codelineno-16-16" href="#notebooklm-notebooklm_config-__codelineno-16-16"></a>spark.ssl.historyServer.port
<a id="__codelineno-16-17" name="__codelineno-16-17" href="#notebooklm-notebooklm_config-__codelineno-16-17"></a>
<a id="__codelineno-16-18" name="__codelineno-16-18" href="#notebooklm-notebooklm_config-__codelineno-16-18"></a>Values in ===claude35=== but not in ===manual===:
<a id="__codelineno-16-19" name="__codelineno-16-19" href="#notebooklm-notebooklm_config-__codelineno-16-19"></a>
<a id="__codelineno-16-20" name="__codelineno-16-20" href="#notebooklm-notebooklm_config-__codelineno-16-20"></a>spark.eventLog.enabled
<a id="__codelineno-16-21" name="__codelineno-16-21" href="#notebooklm-notebooklm_config-__codelineno-16-21"></a>spark.eventLog.dir
<a id="__codelineno-16-22" name="__codelineno-16-22" href="#notebooklm-notebooklm_config-__codelineno-16-22"></a>spark.history.kerberos.enabled
<a id="__codelineno-16-23" name="__codelineno-16-23" href="#notebooklm-notebooklm_config-__codelineno-16-23"></a>spark.history.kerberos.principal
<a id="__codelineno-16-24" name="__codelineno-16-24" href="#notebooklm-notebooklm_config-__codelineno-16-24"></a>spark.history.kerberos.keytab
<a id="__codelineno-16-25" name="__codelineno-16-25" href="#notebooklm-notebooklm_config-__codelineno-16-25"></a>spark.kerberos.principal
<a id="__codelineno-16-26" name="__codelineno-16-26" href="#notebooklm-notebooklm_config-__codelineno-16-26"></a>spark.kerberos.keytab
<a id="__codelineno-16-27" name="__codelineno-16-27" href="#notebooklm-notebooklm_config-__codelineno-16-27"></a>spark.hadoop.security.authentication
<a id="__codelineno-16-28" name="__codelineno-16-28" href="#notebooklm-notebooklm_config-__codelineno-16-28"></a>spark.yarn.security.tokens.hbase.enabled
<a id="__codelineno-16-29" name="__codelineno-16-29" href="#notebooklm-notebooklm_config-__codelineno-16-29"></a>spark.yarn.security.tokens.hive.enabled
<a id="__codelineno-16-30" name="__codelineno-16-30" href="#notebooklm-notebooklm_config-__codelineno-16-30"></a>spark.yarn.security.credentials.hadoop.enabled
<a id="__codelineno-16-31" name="__codelineno-16-31" href="#notebooklm-notebooklm_config-__codelineno-16-31"></a>spark.redaction.regex
<a id="__codelineno-16-32" name="__codelineno-16-32" href="#notebooklm-notebooklm_config-__codelineno-16-32"></a>spark.ui.proxyRedirectUri
<a id="__codelineno-16-33" name="__codelineno-16-33" href="#notebooklm-notebooklm_config-__codelineno-16-33"></a>spark.driver.log.dfsDir
</code></pre></div>
<div class="admonition observation">
<p class="admonition-title">Observation</p>
<ol>
<li><code>spark.yarn.shuffle.server.recovery.disabled</code> was not found by Claude3.5 (or ChatGPT4o or NotebookLM).     </li>
<li>Claude3.5 found 39 parameters in the first prompt.</li>
<li>When the concept of placeholder config parameters was explained in the second prompt, Claude3.5 understood it.</li>
<li>Claude3.5 found 14 parameters more than the human-generated answer, including several parameters that the other LLMs did not find.</li>
</ol>
</div>
<h2 id="notebooklm-notebooklm_config-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm_config-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>NotebookLM, ChatGPT4o and Claude3.5 Pro did reasonably well at extracting the config parameters related to security</li>
<li>NotebookLM performed best, missing just 1, and finding 18 more than the human-generated answer.</li>
<li>Claude3.5 found 79 parameters, missed 14, and found 14 more than the human-generated answer.</li>
<li>ChatGPT 4o found 71 parameters.</li>
<li>Overall, with everything-as-code (infrastructure, policy, LLM answers, ....), and LLMs being able to process code, there's a lot of benefit and promise in applying LLMs.</li>
<li>The feedback to CoGuard is via <a href="https://github.com/coguardio/coguard_openai_rule_auto_generation_research/issues/2">https://github.com/coguardio/coguard_openai_rule_auto_generation_research/issues/2</a> </li>
</ol>
</div></section><section class="print-page" id="notebooklm-notebooklm_secure_code"><h1 id="notebooklm-notebooklm_secure_code-notebooklm-secure-code">NotebookLM Secure Code<a class="headerlink" href="#notebooklm-notebooklm_secure_code-notebooklm-secure-code" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>In two separate conversations recently, the topic of using LLMs for secure coding came up.
One of the concerns that is often raised is that GenAI Code is not secure because GenAI is trained on arbitrary code on the internet.</p>
<p>I was curious how NotebookLM would work for generating or reviewing secure code i.e. a closed system that has been provided a lot of guidance on secure code (and not arbitrary examples).</p>
<p>Claude Sonnet 3.5 was also used for comparison.</p>
</div>
<h2 id="notebooklm-notebooklm_secure_code-vulnerability-types">Vulnerability Types<a class="headerlink" href="#notebooklm-notebooklm_secure_code-vulnerability-types" title="Permanent link">&para;</a></h2>
<p><a href="http://www.amazon.com/Secure-Programming-Static-Analysis-Brian/dp/0321424778/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1345459967&amp;sr=1-1&amp;keywords=Secure+Programming+with+Static+Analysis">Secure Programming with Static Analysis</a> classifies vulnerability types as follows:</p>
<figure>
<p><img alt="" src="../assets/images/Secure_programming_with_Static_Analysis.png" /></p>
</figure>
<p>LLMs go beyond understanding syntax to understanding semantics and may be effective in the 3 quadrants that traditional static analysis isn't.</p>
<p>But in this simple test case below, the focus is on Generic defects visible in the code, as an initial proof of concept.</p>
<h2 id="notebooklm-notebooklm_secure_code-data-sources">Data Sources<a class="headerlink" href="#notebooklm-notebooklm_secure_code-data-sources" title="Permanent link">&para;</a></h2>
<p>Two books I had on Java were loaded to NotebookLM:</p>
<ol>
<li><a href="https://www.informit.com/store/cert-oracle-secure-coding-standard-for-java-9780321803955">The CERT Oracle Secure Coding Standard for Java</a><ol>
<li>The same material is available on <a href="https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java">https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java</a></li>
</ol>
</li>
<li><a href="https://www.informit.com/store/java-coding-guidelines-75-recommendations-for-reliable-9780133439519">Java Coding Guidelines: 75 Recommendations for Reliable and Secure Programs</a></li>
</ol>
<h3 id="notebooklm-notebooklm_secure_code-test-data">Test Data<a class="headerlink" href="#notebooklm-notebooklm_secure_code-test-data" title="Permanent link">&para;</a></h3>
<p>NIST <a href="https://samate.nist.gov/SARD/">Software Assurance Reference Dataset (SARD)</a> was used as the test dataset.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The <a href="https://samate.nist.gov/SARD/">Software Assurance Reference Dataset (SARD)</a> is a growing collection of test programs with documented weaknesses. Test cases vary from small synthetic programs to large applications. The programs are in C, C++, Java, PHP, and C#, and cover over 150 classes of weaknesses.</p>
</div>
<p>e.g. <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: 191 Integer Underflow <a href="https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4">https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4</a></p>
<h2 id="notebooklm-notebooklm_secure_code-setup">Setup<a class="headerlink" href="#notebooklm-notebooklm_secure_code-setup" title="Permanent link">&para;</a></h2>
<ol>
<li>Import both PDFs into a new NotebookLM.</li>
</ol>
<h2 id="notebooklm-notebooklm_secure_code-test">Test<a class="headerlink" href="#notebooklm-notebooklm_secure_code-test" title="Permanent link">&para;</a></h2>
<h3 id="notebooklm-notebooklm_secure_code-test-code-cwe-191-integer-underflow">Test Code <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: 191 Integer Underflow<a class="headerlink" href="#notebooklm-notebooklm_secure_code-test-code-cwe-191-integer-underflow" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/sard_cwe-191.png" />
<a href="https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4">https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4</a></p>
</figure>
<h3 id="notebooklm-notebooklm_secure_code-review-test-code">Review Test Code<a class="headerlink" href="#notebooklm-notebooklm_secure_code-review-test-code" title="Permanent link">&para;</a></h3>
<p>Comments are removed from <a href="https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4">https://samate.nist.gov/SARD/test-cases/252126/versions/1.0.0#4</a> so the code fits in the prompt window.</p>
<figure>
<p><img alt="" src="../assets/images/java_review.png" /></p>
</figure>
<h4 id="notebooklm-notebooklm_secure_code-claude-35">Claude 3.5<a class="headerlink" href="#notebooklm-notebooklm_secure_code-claude-35" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="" src="../assets/images/java_review_claude.png" /></p>
</figure>
<h3 id="notebooklm-notebooklm_secure_code-generate-code-write-secure-code-to-multiply-2-numbers">Generate Code: Write Secure Code to Multiply 2 numbers<a class="headerlink" href="#notebooklm-notebooklm_secure_code-generate-code-write-secure-code-to-multiply-2-numbers" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/java_mult.png" /></p>
</figure>
<h4 id="notebooklm-notebooklm_secure_code-use-biginteger-instead">Use BigInteger Instead<a class="headerlink" href="#notebooklm-notebooklm_secure_code-use-biginteger-instead" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="" src="../assets/images/java_bigint.png" /></p>
</figure>
<h4 id="notebooklm-notebooklm_secure_code-claude-35_1">Claude 3.5<a class="headerlink" href="#notebooklm-notebooklm_secure_code-claude-35_1" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="" src="../assets/images/java_claude.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/java_claude_bigint.png" /></p>
</figure>
<h2 id="notebooklm-notebooklm_secure_code-llama-31-405b-code-training">Llama 3.1 405B Code Training<a class="headerlink" href="#notebooklm-notebooklm_secure_code-llama-31-405b-code-training" title="Permanent link">&para;</a></h2>
<p>Llama 3.1 405B was released July 2024.</p>
<p>The training process to generate good code is described in <a href="https://www.deeplearning.ai/the-batch/issue-260/">https://www.deeplearning.ai/the-batch/issue-260/</a>.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The pretrained model was fine-tuned to perform seven tasks, including <strong>coding</strong> and reasoning, via supervised learning and direct preference optimization (DPO). <strong>Most of the fine-tuning data was generated by the model itself and curated using a variety of methods including agentic workflows</strong>. For instance,</p>
<p>To <strong>generate good code to learn from</strong>, the team: </p>
<ol>
<li>Generated programming problems from random code snippets. </li>
<li>Generated a solution to each problem, prompting the model to follow good programming practices and explain its thought process in comments. </li>
<li>Ran the generated code through a parser and linter to check for issues like syntax errors, style issues, and uninitialized variables. </li>
<li>Generated unit tests. </li>
<li>Tested the code on the unit tests. </li>
<li>If there were any issues, regenerated the code, giving the model the original question, code, and feedback. </li>
<li>If the code passed all tests, added it to the dataset. </li>
<li>Fine-tuned the model. </li>
<li>Repeated this process several times.</li>
</ol>
<p><a href="https://www.deeplearning.ai/the-batch/issue-260/">https://www.deeplearning.ai/the-batch/issue-260/</a></p>
</div>
<h2 id="notebooklm-notebooklm_secure_code-takeaways">Takeaways<a class="headerlink" href="#notebooklm-notebooklm_secure_code-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>NotebookLM with 2 Secure Code Java references performed well in these simple test cases.</li>
<li>LLMs in conjunction with traditional code assurance tools can be used to "generate good code".</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: NotebookLM</h1>
                        <h1 class='nav-section-title' id='section-grounded-closed-system'>
                            Grounded Closed System <a class='headerlink' href='#section-grounded-closed-system' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="grounded-grounding"><h1 id="grounded-grounding-grounding">Grounding<a class="headerlink" href="#grounded-grounding-grounding" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>The accurate answers from <a href="#notebooklm-notebooklm">NotebookLM</a> highlight the benefits of a grounded closed system.</p>
<p>NotebookLM also provides links to the content it references in the data sources.</p>
<p>There are many tools that can be used to build such a system.</p>
</div>
<h2 id="grounded-grounding-grounding-overview">Grounding Overview<a class="headerlink" href="#grounded-grounding-grounding-overview" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>What is Grounding?</p>
<p>Grounding is the process of using large language models (LLMs) with information that is use-case specific, relevant, and not available as part of the LLM's trained knowledge. It is crucial for ensuring the quality, accuracy, and relevance of the generated output. While LLMs come with a vast amount of knowledge already, this knowledge is limited and not tailored to specific use-cases. To obtain accurate and relevant output, we must provide LLMs with the necessary information. In other words, we need to "ground" the models in the context of our specific use-case.</p>
<p>Motivation for Grounding</p>
<p>The primary motivation for grounding is that LLMs are not databases, even if they possess a wealth of knowledge. They are designed to be used as general reasoning and text engines. LLMs have been trained on an extensive corpus of information, some of which has been retained, giving them a broad understanding of language, the world, reasoning, and text manipulation. However, we should use them as engines rather than stores of knowledge.</p>
<p><a href="https://techcommunity.microsoft.com/t5/fasttrack-for-azure/grounding-llms/ba-p/3843857">https://techcommunity.microsoft.com/t5/fasttrack-for-azure/grounding-llms/ba-p/3843857</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>In generative AI, grounding is the ability to connect model output to verifiable sources of information. If you provide models with access to specific data sources, then grounding tethers their output to these data and reduces the chances of inventing content. This is particularly important in situations where accuracy and reliability are significant.</p>
<p>Grounding provides the following benefits:</p>
<ul>
<li>Reduces model hallucinations, which are instances where the model generates content that isn't factual.</li>
<li>Anchors model responses to specific information.</li>
<li>Enhances the trustworthiness and applicability of the generated content.</li>
</ul>
<p><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview">https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview</a></p>
</div>
<h3 id="grounded-grounding-retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)<a class="headerlink" href="#grounded-grounding-retrieval-augmented-generation-rag" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/simple_rag.png" />
<a href="https://techcommunity.microsoft.com/t5/fasttrack-for-azure/grounding-llms/ba-p/3843857">https://techcommunity.microsoft.com/t5/fasttrack-for-azure/grounding-llms/ba-p/3843857</a></p>
</figure>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Retrieval Augmented Generation (RAG) is the primary technique for grounding and the only one I will discuss in detail. <strong>RAG is a process for retrieving information relevant to a task, providing it to the language model along with a prompt, and relying on the model to use this specific information when responding. While sometimes used interchangeably with grounding, RAG is a distinct technique, albeit with some overlap.</strong> It is a powerful and easy-to-use method, applicable to many use-cases.</p>
<p><strong>Fine-tuning</strong>, on the other hand, is an "honourable mention" when it comes to grounding. It involves orchestrating additional training steps to create a new version of the model that builds on the general training and infuses the model with task-relevant information. In the past, when we had less capable models, fine-tuning was more prevalent. However, it has become less relevant as time-consuming, expensive, and not offering a significant advantage in many scenarios.</p>
<p>The general consensus among experts in the field is that fine-tuning typically results in only a 1-2% improvement in accuracy (depending on how accuracy is defined). While there may be specific scenarios where fine-tuning offers more significant gains, it should be considered a last-resort option for optimisation, rather than the starting go-to technique.</p>
</div>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>Unlike RAG, fine tuning changes some of the model weights. In some cases, it can lead to reduced performance via catastrophic forgetting. </p>
</div>
<h2 id="grounded-grounding-vertex-ai-grounding">Vertex AI Grounding<a class="headerlink" href="#grounded-grounding-vertex-ai-grounding" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/google_grounding.png" />
<a href="https://youtu.be/RjuKEMVe_Q4?t=303">https://youtu.be/RjuKEMVe_Q4?t=303</a></p>
</figure>
<p>Google <a href="https://youtu.be/vax4Nl7frAo?t=1648">announced Grounding in April 2024</a>.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>You can ground language models to your own text data using Vertex AI Search as a datastore. With Vertex AI Search you integrate your own data, regardless of format, to refine the model output. Supported data types include:</p>
<ul>
<li>Website data: Directly use content from your website.</li>
<li>Unstructured data: Utilize raw, unformatted data.</li>
</ul>
<p>When you ground to your specific data the model can perform beyond its training data. By linking to designated data stores within Vertex AI Search, the grounded model can produce more accurate and relevant responses, and responses directly related to your use case.</p>
<p><a href="https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview#ground-private">https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview#ground-private</a></p>
</div>
<h2 id="grounded-grounding-rag-architectures">RAG Architectures<a class="headerlink" href="#grounded-grounding-rag-architectures" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/rag_types.jpeg" />
<a href="https://www.linkedin.com/posts/weaviate-io_struggling-to-keep-up-with-new-rag-variants-activity-7272294342122192896-iMs1">https://www.linkedin.com/posts/weaviate-io_struggling-to-keep-up-with-new-rag-variants-activity-7272294342122192896-iMs1</a> is the image source, and it contains other useful articles on RAG.</p>
</figure>
<h2 id="grounded-grounding-takeaways">Takeaways<a class="headerlink" href="#grounded-grounding-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Where a lot of the information needed is captured in documentation e.g. MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification, Grounding is an effective efficient easy option to improve the quality of responses.</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: Grounded Closed System</h1>
                        <h1 class='nav-section-title' id='section-cwe-assignment'>
                            CWE Assignment <a class='headerlink' href='#section-cwe-assignment' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="cwe_assignment-cwe_overview"><h1 id="cwe_assignment-cwe_overview-overview">Overview<a class="headerlink" href="#cwe_assignment-cwe_overview-overview" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>There are several options to consider when building an LM solution for <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment as described here.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a href="https://www.first.org/conference/vulncon2025/program#pVulnerability-Root-Cause-Mapping-with-CWE-Challenges-Solutions-and-Insights-from-Grounded-LLM-based-Analysis">Vulnerability Root Cause Mapping with <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: Challenges, Solutions, and Insights from Grounded LLM-based Analysis</a> details a more comprehensive production solution using LLMs for <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Mapping.</p>
</div>
<h2 id="cwe_assignment-cwe_overview-approach-to-using-language-models">Approach to using Language Models<a class="headerlink" href="#cwe_assignment-cwe_overview-approach-to-using-language-models" title="Permanent link">&para;</a></h2>
<h3 id="cwe_assignment-cwe_overview-dont-train-a-model-on-bad-data">Don't Train A Model On Bad Data!<a class="headerlink" href="#cwe_assignment-cwe_overview-dont-train-a-model-on-bad-data" title="Permanent link">&para;</a></h3>
<p>It is possible to train a Language Model as a Classifier to assign CWEs to a <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description - and there are several research papers that took that approach e.g.</p>
<ul>
<li><a href="https://arxiv.org/pdf/2102.11498v1.pdf">V2W-BERT: A Framework for Effective Hierarchical Multiclass Classification of Software Vulnerabilities</a> </li>
<li><a href="https://arxiv.org/pdf/2304.11130.pdf">Automated Mapping of <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Vulnerability Records to MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Weaknesses</a></li>
</ul>
<p>The problems with this approach:</p>
<ol>
<li>
<p>It's delusional based on my research and experience of incorrect assigned CWEs in general - Garbage In Garbage Out</p>
<ol>
<li>Per <a href="https://www.linkedin.com/feed/update/urn:li:activity:7186373368344920064?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7186373368344920064%2C7186417379470385153%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287186417379470385153%2Curn%3Ali%3Aactivity%3A7186373368344920064%29">Steve Christey Coley, <abbr title="CWE Common Weakness Enumeration">CWE</abbr> tech lead</a>: </li>
</ol>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>There has been significant interest in using AI/ML in various applications to use and/or map to <abbr title="CWE Common Weakness Enumeration">CWE</abbr>, but in my opinion there are a number of significant hurdles, e.g. you can't train on "bad mappings" to learn how to do good mappings.</p>
</div>
</li>
<li>
<p>It removes a lot of the context that could be available to an LM by reducing the reference target down to a set of values or classes (for the given input <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Descriptions)</p>
</li>
</ol>
<h3 id="cwe_assignment-cwe_overview-train-on-good-data-and-the-full-standard">Train on Good Data and the Full Standard<a class="headerlink" href="#cwe_assignment-cwe_overview-train-on-good-data-and-the-full-standard" title="Permanent link">&para;</a></h3>
<p>We can "train" on "good mappings".</p>
<ol>
<li>The <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard includes known "good mappings" e.g. <a href="https://riskbasedprioritization.github.io/risk/Log4Shell/#mitre-cwe-917"><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-917 Observed Examples</a> includes <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-44228 and its Description.<ol>
<li>The count of these <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Observed Examples varies significantly per <abbr title="CWE Common Weakness Enumeration">CWE</abbr>. </li>
<li>There's ~3K <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Observed Examples in the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard.</li>
</ol>
</li>
<li>The <a href="https://github.com/CyberSecAI/cwe_top25">Top25 Dataset</a> of known-good mappings contains ~6K CVEs with known-good <a href="https://www.youtube.com/watch?v=AtBZIAikdL0&amp;list=PLBAUUhONOrO_aB01lOv6XNRTHD4ueFVTp&amp;t=1142s"><abbr title="CWE Common Weakness Enumeration">CWE</abbr> mappings by MITRE</a>.</li>
<li>We can use the full <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard and associated known good <abbr title="CWE Common Weakness Enumeration">CWE</abbr> mappings as the target, allowing an LLM to compare the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description (and other data) to this.<ol>
<li>And moreover, prompt the LLM to provide similar CVEs to support its rationale for the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment</li>
</ol>
</li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Rather than train a model on bad data, we can ask a model to assign / validate a <abbr title="CWE Common Weakness Enumeration">CWE</abbr> based on its understanding of the CWEs available (and its understanding of CWEs assigned to similar CVEs based on the Observed and Top25 Examples for each <abbr title="CWE Common Weakness Enumeration">CWE</abbr> in the standard).</p>
<p>We can ask the model to follow the <a href="https://cwe.mitre.org/documents/cwe_usage/guidance.html">MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Guidance</a> when assigning a <abbr title="CWE Common Weakness Enumeration">CWE</abbr>.</p>
</div>
<h2 id="cwe_assignment-cwe_overview-closed-or-open-model">Closed or Open Model<a class="headerlink" href="#cwe_assignment-cwe_overview-closed-or-open-model" title="Permanent link">&para;</a></h2>
<p>We can use a Closed or Open Model:</p>
<ol>
<li>a closed-model with access to the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification only (and no other data) e.g. NotebookLM</li>
<li>an open-model with access to the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification and other data</li>
</ol>
<h2 id="cwe_assignment-cwe_overview-rag-corpus">RAG Corpus<a class="headerlink" href="#cwe_assignment-cwe_overview-rag-corpus" title="Permanent link">&para;</a></h2>
<p>Representations of the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification:</p>
<ol>
<li>PDF version of the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification <ol>
<li><a href="https://cwe.mitre.org/data/downloads.html">https://cwe.mitre.org/data/downloads.html</a> </li>
</ol>
</li>
<li>JSON version of the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification <ol>
<li><a href="https://github.com/CWE-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json">https://github.com/<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json</a></li>
</ol>
</li>
<li>
<p>JSON version of the modified MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification to add and remove parts to make it more relevant to <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment for an LLM as described <a href="https://github.com/CyberSecAI/cwe_top25/tree/main?tab=readme-ov-file#add-cve-descriptions-to-top-25-and-remove-rationale-and-cwe-entries-that-are-not-a-cwe">here</a></p>
<ol>
<li><a href="https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl">https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl</a> </li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>JSON is preferred over PDF as PDF is generally more lossy because it is less structured.</p>
</div>
</li>
</ol>
<h2 id="cwe_assignment-cwe_overview-gpt-setups">GPT setups<a class="headerlink" href="#cwe_assignment-cwe_overview-gpt-setups" title="Permanent link">&para;</a></h2>
<p>Different GPT setups e.g.</p>
<ol>
<li><a href="#cwe_assignment-cwe_gpt">ChatGPT GPT</a><ol>
<li>Requires you and users to have a paid ChatGPT subscription</li>
</ol>
</li>
<li><a href="#cwe_assignment-notebooklm_cwe">NoteBookLM</a><ol>
<li>Anyone with a Google account can get up and running in 5 minutes for free.</li>
</ol>
</li>
<li><a href="#cwe_assignment-vertex_ai">VertexAI</a><ol>
<li>This allows the most customization - but there's more effort to set it up and it is not free.</li>
</ol>
</li>
</ol>
<h2 id="cwe_assignment-cwe_overview-prompts">Prompts<a class="headerlink" href="#cwe_assignment-cwe_overview-prompts" title="Permanent link">&para;</a></h2>
<ol>
<li>Various Prompts, and <a href="#prompt_engineering-prompt_engineering">Prompt Engineering Techniques</a>, can be used depending on what you want.</li>
</ol>
<h2 id="cwe_assignment-cwe_overview-model-and-environment">Model and Environment<a class="headerlink" href="#cwe_assignment-cwe_overview-model-and-environment" title="Permanent link">&para;</a></h2>
<p>For processing 250K+ <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Descriptions, speed, latency and cost are important considerations, in addition to accuracy.</p>
<p>Based on <a href="#introduction-cybsersecurity-comparing-llms">comparing LLMs</a> as at September 2024, Gemini 1.5 Flash was chosen.</p>
<p>There are different Google AI Environments:
   - <a href="https://aistudio.google.com/prompts/new_chat">Google AI Studio</a>
     - lower learning curve and cost and capability
   - <a href="https://console.cloud.google.com/vertex-ai/studio">Vertex AI Studio</a> or VertexAI in general</p></section><section class="print-page" id="cwe_assignment-cwe_gpt"><h1 id="cwe_assignment-cwe_gpt-chatgpt-cwe-gpt">ChatGPT <abbr title="CWE Common Weakness Enumeration">CWE</abbr> GPT<a class="headerlink" href="#cwe_assignment-cwe_gpt-chatgpt-cwe-gpt" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>Here we'll use ChatGPT with the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification to aid mapping CWEs to vulnerability descriptions.</p>
<p>This is a no-code option.</p>
<p>We'll attempt to implement a closed grounded system to ensure the accuracy of the data (and mitigate hallucinations)</p>
<ol>
<li><strong>Grounded</strong>: content is provided to inform the ansers</li>
<li><strong>Closed system</strong>: answers come from only the documents you provide</li>
</ol>
</div>
<div class="admonition warning">
<p class="admonition-title">Result</p>
<p>The result is a Grounded Open-System i.e. we can ground - but can't create a closed system - and we still get hallucinations in some cases.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a href="https://www.first.org/conference/vulncon2025/program#pVulnerability-Root-Cause-Mapping-with-CWE-Challenges-Solutions-and-Insights-from-Grounded-LLM-based-Analysis">Vulnerability Root Cause Mapping with <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: Challenges, Solutions, and Insights from Grounded LLM-based Analysis</a> details a more comprehensive production solution using LLMs for <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Mapping.</p>
</div>
<h2 id="cwe_assignment-cwe_gpt-recipe">Recipe<a class="headerlink" href="#cwe_assignment-cwe_gpt-recipe" title="Permanent link">&para;</a></h2>
<ol>
<li>Use ChatGPT GPTs which are <a href="https://chatgpt.com/gpts">"custom versions of ChatGPT that combine instructions, extra knowledge, and any combination of skills."</a> </li>
<li><strong>Grounded</strong>: Provide the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification as the "extra knowledge" in JSON format (not PDF).</li>
<li><strong>Closed system</strong>: Limit the GPT to that knowledge only i.e. disable web search <ol>
<li>but we see that the GPT still has knowledge from its training data </li>
</ol>
</li>
</ol>
<h2 id="cwe_assignment-cwe_gpt-mitre-cwe-specification">MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification<a class="headerlink" href="#cwe_assignment-cwe_gpt-mitre-cwe-specification" title="Permanent link">&para;</a></h2>
<ol>
<li>Use a JSON text version instead of PDF <ol>
<li>ensures all the relevant text we want is fed to the model (e.g. text extraction from PDFs can be lossy for tables)</li>
<li>allows us to remove content that is not relevant e.g. "ContentHistory" can contain a lot of text that is not relevant to <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment</li>
</ol>
</li>
<li>Get the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification as JSON from <a href="https://github.com/CWE-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json">https://github.com/<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json</a></li>
<li>Remove the "ContentHistory" entries as this is not useful to assign CWEs and is a lot of content<ol>
<li>use Claude 3.5 to generate the python code to do this</li>
</ol>
</li>
<li>Split it into smaller files<ol>
<li>because the single file is too large to import</li>
<li>use Claude 3.5 to generate the python code to do this</li>
</ol>
</li>
</ol>
<h2 id="cwe_assignment-cwe_gpt-configure-chatgpt-cwe-gpt">Configure ChatGPT <abbr title="CWE Common Weakness Enumeration">CWE</abbr> GPT<a class="headerlink" href="#cwe_assignment-cwe_gpt-configure-chatgpt-cwe-gpt" title="Permanent link">&para;</a></h2>
<ol>
<li>Import the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification as split JSON files</li>
<li>Disable all capabilities:<ol>
<li>Web browsing is disabled so the answers come from the imported MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification</li>
</ol>
</li>
<li>Provide example starter prompts:<ol>
<li>what is the best <abbr title="CWE Common Weakness Enumeration">CWE</abbr> to describe the root cause weakness in <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "an issue in the Pickle Python library of some product allows attackers to execute arbitrary commands". Provide CVEs with the most similar root cause to support your answer.</li>
<li>what is the best <abbr title="CWE Common Weakness Enumeration">CWE</abbr> to describe the root cause weakness in <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "ProductX contains a default SSH public key in the authorized_keys file. A remote attacker could use this key to gain root privileges.". Provide CVEs with the most similar.  root cause to support your answer.</li>
<li>what cwe ids are associated with xss. list them all</li>
<li>what cwe ids are associated with path or directory traversal. list them all</li>
</ol>
</li>
<li>Publish it so others can use it: <a href="https://chatgpt.com/g/g-d8guurMPs-cwe-map">https://chatgpt.com/g/g-d8guurMPs-cwe-map</a> </li>
</ol>
<figure>
<p><img alt="" src="../assets/images/chatgpt_cwe_gpt.png" /></p>
</figure>
<h2 id="cwe_assignment-cwe_gpt-check-if-the-system-is-closed">Check if the System is Closed<a class="headerlink" href="#cwe_assignment-cwe_gpt-check-if-the-system-is-closed" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>What is a dog?</p>
</div>
<div class="admonition failure">
<p class="admonition-title">Failure</p>
<p><figure markdown>
  <img alt="" src="../assets/images/chatgpt_what_is_a_dog.png" />
  </figure></p>
</div>
<div class="admonition observations">
<p class="admonition-title">Observations</p>
<p>The system is not closed because the GPT can answer the question even though there is no information about dogs in the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification.</p>
</div>
<h2 id="cwe_assignment-cwe_gpt-example-usage-cwe-502">Example Usage: <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-502<a class="headerlink" href="#cwe_assignment-cwe_gpt-example-usage-cwe-502" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>what is the best <abbr title="CWE Common Weakness Enumeration">CWE</abbr> to describe the root cause weakness in <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "an issue in the Pickle Python library of some product allows attackers to execute arbitrary commands". </p>
<p>let's think this out step by step. Before you answer, validate your answer by checking that at least one of ObservedExamples for that <abbr title="CWE Common Weakness Enumeration">CWE</abbr> is similar to the description I provided.</p>
</div>
<figure>
<p><img alt="" src="../assets/images/chatgpt_cwe_gpt_example2.png" /></p>
</figure>
<p><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-502 includes this as part of the ObservedExamples
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#cwe_assignment-cwe_gpt-__codelineno-0-1"></a>        {
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#cwe_assignment-cwe_gpt-__codelineno-0-2"></a>          &quot;Reference&quot;: &quot;CVE-2011-2520&quot;,
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#cwe_assignment-cwe_gpt-__codelineno-0-3"></a>          &quot;Description&quot;: &quot;Python script allows local users to execute code via pickled data.&quot;,
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#cwe_assignment-cwe_gpt-__codelineno-0-4"></a>          &quot;Link&quot;: &quot;https://www.cve.org/CVERecord?id=CVE-2011-2520&quot;
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#cwe_assignment-cwe_gpt-__codelineno-0-5"></a>        },
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#cwe_assignment-cwe_gpt-__codelineno-0-6"></a>        {
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#cwe_assignment-cwe_gpt-__codelineno-0-7"></a>          &quot;Reference&quot;: &quot;CVE-2012-4406&quot;,
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#cwe_assignment-cwe_gpt-__codelineno-0-8"></a>          &quot;Description&quot;: &quot;Unsafe deserialization using pickle in a Python script.&quot;,
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#cwe_assignment-cwe_gpt-__codelineno-0-9"></a>          &quot;Link&quot;: &quot;https://www.cve.org/CVERecord?id=CVE-2012-4406&quot;
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#cwe_assignment-cwe_gpt-__codelineno-0-10"></a>        },
</code></pre></div></p>
<h2 id="cwe_assignment-cwe_gpt-example-usage-cwe-1394">Example Usage: <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-1394<a class="headerlink" href="#cwe_assignment-cwe_gpt-example-usage-cwe-1394" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>what is the best <abbr title="CWE Common Weakness Enumeration">CWE</abbr> to describe the root cause weakness in <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "ProductX contains a default SSH public key in the authorized_keys file. A remote attacker could use this key to gain root privileges."</p>
<p>let's think this out step by step. Before you answer, validate your answer by checking that at least one of ObservedExamples for that <abbr title="CWE Common Weakness Enumeration">CWE</abbr> is similar to the description I provided.</p>
</div>
<figure>
<p><img alt="" src="../assets/images/chatgpt_cwe_gpt_example1.png" /></p>
</figure>
<p><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-1394 includes this as part of the ObservedExamples
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#cwe_assignment-cwe_gpt-__codelineno-1-1"></a>        {
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#cwe_assignment-cwe_gpt-__codelineno-1-2"></a>          &quot;Reference&quot;: &quot;CVE-2016-1561&quot;,
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#cwe_assignment-cwe_gpt-__codelineno-1-3"></a>          &quot;Description&quot;: &quot;backup storage product has a default SSH public key in the authorized_keys file, allowing root access&quot;,
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#cwe_assignment-cwe_gpt-__codelineno-1-4"></a>          &quot;Link&quot;: &quot;https://www.cve.org/CVERecord?id=CVE-2016-1561&quot;
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#cwe_assignment-cwe_gpt-__codelineno-1-5"></a>        },
</code></pre></div></p>
<h2 id="cwe_assignment-cwe_gpt-example-usage-cwe-1394-with-example-cves">Example Usage: <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-1394 with Example CVEs<a class="headerlink" href="#cwe_assignment-cwe_gpt-example-usage-cwe-1394-with-example-cves" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/chatgpt_gpt_hallucination2.png" /></p>
</figure>
<div class="admonition failure">
<p class="admonition-title">Failure</p>
<p>"<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2013-0138: Network device with a default SSH key that can be exploited to gain unauthorized access."</p>
<p>This is not the description for <a href="https://nvd.nist.gov/vuln/detail/CVE-2013-0138">https://nvd.nist.gov/vuln/detail/<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2013-0138</a>.</p>
<p><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2013-0138 is not listed in the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification.</p>
<p>Note: <a href="https://nvd.nist.gov/vuln/detail/CVE-2013-0137">https://nvd.nist.gov/vuln/detail/<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2013-0137</a> relates to a known SSH key.</p>
</div>
<div class="admonition observations">
<p class="admonition-title">Observations</p>
<p>Hallucinations happened for the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> IDs that the GPT gave as supporting examples whether the "Web Browsing" Capability was enabled or not.</p>
</div>
<h2 id="cwe_assignment-cwe_gpt-takeaways">Takeaways<a class="headerlink" href="#cwe_assignment-cwe_gpt-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Grounding ChatGPT with the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification helps reduce hallucinations but does not eliminate them.</li>
<li>Hallucinations happened for the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> IDs that the GPT gave as supporting examples whether the "Web Browsing" Capability was enabled or not.</li>
<li>It is not possible to make ChatGPT GPT a closed system because it has knowledge outside the provided content and will answer from that.</li>
</ol>
</div></section><section class="print-page" id="cwe_assignment-notebooklm_cwe"><h1 id="cwe_assignment-notebooklm_cwe-notebooklm-cwe">NotebookLM <abbr title="CWE Common Weakness Enumeration">CWE</abbr><a class="headerlink" href="#cwe_assignment-notebooklm_cwe-notebooklm-cwe" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>In this chapter, we'll use <a href="https://notebooklm.google.com/">NotebookLM</a> to ingest the <a href="https://cwe.mitre.org/">Common Weakness Enumeration (<abbr title="CWE Common Weakness Enumeration">CWE</abbr>)</a> list. </p>
<ul>
<li>In the current version (<abbr title="CWE Common Weakness Enumeration">CWE</abbr> Version 4.14 2024-02-29 as at June 2024), there are over 1400 CWEs, and 2789 pages in the PDF version of the list. </li>
<li>It can be unwieldy to navigate or assimilate this information. </li>
</ul>
<p>Using NotebookLM, we can chat with the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> document and ask questions, so that <strong>the information comes to us</strong> in the form of an answer. </p>
<p>For comparison, we will also ask some of the same questions of ChatGPT4o covering 2 cases:</p>
<ol>
<li>without uploading any documents to it.</li>
<li>uploading a document to it.</li>
</ol>
</div>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>This content and approach was presented to the <a href="https://github.com/Root-Cause-Mapping-Working-Group/RCM-WG"><abbr title="CWE Common Weakness Enumeration">CWE</abbr> Root Cause Mapping Working Group</a> mid July.</p>
<p>The feedback was very positive!</p>
</div>
<h2 id="cwe_assignment-notebooklm_cwe-data-sources">Data Sources<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-data-sources" title="Permanent link">&para;</a></h2>
<h2 id="cwe_assignment-notebooklm_cwe-mitre-cwe-specification-preparation">MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification Preparation<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-mitre-cwe-specification-preparation" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a href="https://cwe.mitre.org/data/published/cwe_latest.pdf">cwe_latest.pdf </a> from <a href="https://cwe.mitre.org/data/downloads.html">https://cwe.mitre.org/data/downloads.html</a> has 2789 pages (version <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Version 4.14 2024-02-29).</p>
<ul>
<li>This is too big for NotebookLM to ingest.</li>
<li>Use a JSON text version instead of PDF:<ul>
<li>ensures all the relevant text we want is fed to the model (e.g. text extraction from PDFs can be lossy for tables)</li>
<li>allows us to remove content that is not relevant e.g. "ContentHistory" can contain a lot of text that is not relevant to <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment</li>
</ul>
</li>
</ul>
</div>
<div class="admonition experiment">
<p class="admonition-title">Data Sources</p>
<p><strong>The files in <a href="https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl">https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl</a> are imported into NoteBookLM.</strong>. They are generated as follows: </p>
<ol>
<li>Get the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification as JSON from <a href="https://github.com/CWE-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json">https://github.com/<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-CAPEC/REST-API-wg/blob/main/json_repo/cwe.json</a></li>
<li>Remove the "ContentHistory" entries as this is not useful to assign CWEs and is a lot of content<ol>
<li>use Claude 3.5 to generate the python code to do this</li>
</ol>
</li>
<li>Split it into smaller files<ol>
<li>because the single file is too large to import</li>
<li>use Claude 3.5 to generate the python code to do this</li>
</ol>
</li>
<li>The output files are JSONL with a txt extension so NoteBookLM recognizes them: <a href="https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl">https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl</a></li>
</ol>
</div>
<h2 id="cwe_assignment-notebooklm_cwe-import-mitre-cwe-specification-to-notebooklm">Import MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification to NoteBookLM<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-import-mitre-cwe-specification-to-notebooklm" title="Permanent link">&para;</a></h2>
<ol>
<li>Download all jsonl.txt files from <a href="https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl">https://github.com/CyberSecAI/cwe_top25/tree/main/data_out/output_jsonl</a></li>
<li>Open <a href="https://notebooklm.google.com/">https://notebooklm.google.com/</a> in a browser</li>
<li>Add sources</li>
</ol>
<figure>
<p><img alt="" src="../assets/images/notebooklm_jsonl_txt.png" /></p>
</figure>
<h2 id="cwe_assignment-notebooklm_cwe-what-cwe-ids-are-associated-with-buffer-overflow">what cwe ids are associated with buffer overflow?<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-what-cwe-ids-are-associated-with-buffer-overflow" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/bufferoverflow.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/bufferoverflow_examples.png" /></p>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a href="https://cwe.mitre.org/data/definitions/121.html">https://cwe.mitre.org/data/definitions/121.html</a> contains only 1 Observed Example: </p>
<ul>
<li><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-35395. This is listed under <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-121: Stack-based Buffer Overflow</li>
</ul>
<p>The other <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> examples are from the Top25 Mapping Examples included in the JSONL files</p>
<ul>
<li><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-20046, <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-20048: Stack-based buffer overflows in SonicOS HTTP response headers allow for Denial of Service and potentially remote code execution.</li>
<li><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-21887: A stack-based buffer overflow in Lantronix PremierWave 2050 8.9.0.0R4 allows remote code execution via a crafted HTTP request.</li>
<li><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-35395: A stack-based buffer overflow vulnerability exists in the DHCP client of Lantronix PremierWave 2050 8.9.0.0R4.</li>
</ul>
</div>
<h2 id="cwe_assignment-notebooklm_cwe-cwe-assignment-prompt"><abbr title="CWE Common Weakness Enumeration">CWE</abbr> Assignment Prompt<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-cwe-assignment-prompt" title="Permanent link">&para;</a></h2>
<p>The notebook can be used to assign CWEs to a given <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description using a specific prompt:
<a href="https://github.com/CyberSecAI/CWEMap/blob/main/prompts/assign_cwes/system.md">https://github.com/CyberSecAI/CWEMap/blob/main/prompts/assign_cwes/system.md</a></p>
<p>NoteBookLM does not allow the full prompt to be copied into the chat as is - it needs to be copied in 3 smaller parts.</p>
<h3 id="cwe_assignment-notebooklm_cwe-example-cve-2024-5158">Example <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2024-5158<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-example-cve-2024-5158" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title"><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2024-5158</p>
<p>Type Confusion in V8 in Google Chrome prior to 125.0.6422.76 allowed a remote attacker to potentially perform arbitrary read/write via a crafted HTML page. (Chromium security severity: High)
<a href="https://nvd.nist.gov/vuln/detail/CVE-2024-5158">https://nvd.nist.gov/vuln/detail/<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2024-5158</a></p>
</div>
<figure>
<p><img alt="" src="../assets/images/type_confusion2.png" /></p>
</figure>
<h3 id="cwe_assignment-notebooklm_cwe-example-cve-2022-30271">Example <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2022-30271<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-example-cve-2022-30271" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title"><abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2022-30271</p>
<p>The Motorola ACE1000 RTU through 2022-05-02 ships with a hardcoded SSH private key and initialization scripts (such as /etc/init.d/sshd_service) only generate a new key if no private-key file exists. Thus, this hardcoded key is likely to be used by default.
<a href="https://nvd.nist.gov/vuln/detail/CVE-2022-30271">https://nvd.nist.gov/vuln/detail/<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2022-30271</a></p>
</div>
<figure>
<p><img alt="" src="../assets/images/hardcoded_ssh_key.png" /></p>
</figure>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Some of the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Abstraction Level values are incorrect; weâ€™re asking for too much here in one prompt with this simple setup.</p>
<p>We need to either simplify or decompose into separate prompts.</p>
</div>
<h2 id="cwe_assignment-notebooklm_cwe-sharing-notebooks">Sharing Notebooks<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-sharing-notebooks" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The notebook can be shared with other users via email (using the share button top right) to allow them to use the notebook. See <a href="https://support.google.com/notebooklm/answer/14276471?hl=en">https://support.google.com/notebooklm/answer/14276471?hl=en</a>.</p>
<p>Sharing is via a user's email.</p>
</div>
<h2 id="cwe_assignment-notebooklm_cwe-takeaways">Takeaways<a class="headerlink" href="#cwe_assignment-notebooklm_cwe-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>I found it useful, quick, and convenient to be able to ask questions of the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> list, as a compliment to the traditional search method I've used in the past.</li>
<li>It is also useful to suggest CWEs (and associated info) for a given Vulnerability Description.</li>
<li>The <a href="#cwe_assignment-vulnrichment">Vulnrichment</a> chapter covers a much more detailed use case - and NoteBookLM performed better than other LLMs.</li>
</ol>
</div></section><section class="print-page" id="cwe_assignment-vertex_ai"><h1 id="cwe_assignment-vertex_ai-google-vertex-ai-agent-builder">Google Vertex AI Agent Builder<a class="headerlink" href="#cwe_assignment-vertex_ai-google-vertex-ai-agent-builder" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>Here we'll use Vertex AI Agent Builder with the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification to aid mapping CWEs to vulnerability descriptions.</p>
<p>This is a no-code option.</p>
<p>We'll implement a closed grounded system to ensure the accuracy of the data (and mitigate hallucinations)</p>
<ol>
<li><strong>Grounded</strong>: content is provided to inform the answers</li>
<li><strong>Closed system</strong>: answers come from only the documents you provide</li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>In other words, we'll build <a href="#notebooklm-notebooklm">NotebookLM</a>.</p>
<ul>
<li>where NotebookLM is basically a combination of Vertex AI Search for Unstructured (PDFs, HTML, etc.), <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview">Vertex AI Grounding</a>, and a custom UX/UI.</li>
<li>But we'll take advantage of the structured data (JSON) that we have for MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> list, instead of using the unstructured data from the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> list PDF.</li>
</ul>
</div>
</div>
<div class="admonition success">
<p class="admonition-title">Result</p>
<p>The result is that we have a grounded closed system (that compares in performance and accuracy to <a href="#notebooklm-notebooklm">NotebookLM</a>.</p>
<p>But we don't have reference links to the source content in the response i.e. I didn't add that part yet but it's standard functionality that is easy in Vertex AI.</p>
</div>
<h2 id="cwe_assignment-vertex_ai-grounding-confidence">Grounding Confidence<a class="headerlink" href="#cwe_assignment-vertex_ai-grounding-confidence" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>For each response generated from the content of your connected data stores, the agent evaluates a confidence level, which gauges the confidence that all information in the response is supported by information in the data stores. You can customize which responses to allow by selecting the lowest confidence level you are comfortable with. Only responses at or above that confidence level will be shown.</p>
<p>There are 5 confidence levels to choose from: VERY_LOW, LOW, MEDIUM, HIGH, and VERY_HIGH.</p>
<p><a href="https://cloud.google.com/dialogflow/vertex/docs/concept/tools">https://cloud.google.com/dialogflow/vertex/docs/concept/tools</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>To create a data store and connect it to your app, you can use the Tools link in the left navigation of the console. Follow the instructions to create a data store.
  <a href="https://cloud.google.com/dialogflow/vertex/docs/concept/tools">https://cloud.google.com/dialogflow/vertex/docs/concept/tools</a></p>
</div>
<h2 id="cwe_assignment-vertex_ai-recipe">Recipe<a class="headerlink" href="#cwe_assignment-vertex_ai-recipe" title="Permanent link">&para;</a></h2>
<p>Same recipe as <a href="#cwe_assignment-cwe_gpt-recipe">before</a> but we'll use <a href="https://cloud.google.com/products/agent-builder">Google Vertex AI Agent Builder</a></p>
<h2 id="cwe_assignment-vertex_ai-mitre-cwe-specification">MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification<a class="headerlink" href="#cwe_assignment-vertex_ai-mitre-cwe-specification" title="Permanent link">&para;</a></h2>
<p>Same <a href="#cwe_assignment-cwe_gpt-mitre-cwe-specification">MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Specification</a> as the data source.</p>
<h2 id="cwe_assignment-vertex_ai-build-vertex-ai-agent">Build Vertex AI Agent<a class="headerlink" href="#cwe_assignment-vertex_ai-build-vertex-ai-agent" title="Permanent link">&para;</a></h2>
<p>This <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#private-ground-gemini">link</a> gives the steps with links to the details, summarized here:</p>
<ol>
<li><a href="https://cloud.google.com/products/agent-builder?hl=en">Vertex AI Agent Builder</a> </li>
<li>Create App </li>
<li>Select app type<ol>
<li>Agent (preview) "Built using natural language, agents can answer questions from data, connect with business systems through tools and more"</li>
</ol>
</li>
<li>Create Data Store<ol>
<li>The MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> JSON data is converted to jsonl format for import</li>
<li>It takes ~5 minutes to ingest (create embeddings for) the jsonl file</li>
</ol>
</li>
<li>There are lots of other Settings available like Logging, Git integration to push/pull agents from a Github repo, or just download the JSON file that represents the agent.</li>
<li>The built agent supports <a href="https://cloud.google.com/dialogflow/vertex/docs/quick/api">Interactions with the API </a>.</li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>To create an Grounded <strong>Open</strong> system, select "search" app type.</p>
<p>The agent will retrieve information from the local documents you provide and via web search.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Alternatively these steps can be implemented with code e.g. 
  <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#generative-ai-gemini-grounding-python_vertex_ai_sdk">https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini#generative-ai-gemini-grounding-python_vertex_ai_sdk</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Note: Conversation history is used as context during tool invocation. Learn more</p>
</div>
<h2 id="cwe_assignment-vertex_ai-data-preprocessing">Data Preprocessing<a class="headerlink" href="#cwe_assignment-vertex_ai-data-preprocessing" title="Permanent link">&para;</a></h2>
<p>Remove unneeded sections from the json</p>
<ul>
<li>content_history</li>
<li>views</li>
<li>categories</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#cwe_assignment-vertex_ai-__codelineno-0-1"></a>python3 ./trim_json.py # cwe.json -&gt; cwe_trimmed.json
</code></pre></div>
<p>Convert to jsonl for import
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#cwe_assignment-vertex_ai-__codelineno-1-1"></a>python3 ./json_to_jsonl.py # cwe_trimmed.json -&gt; cwe_trimmed.jsonl
</code></pre></div></p>
<h2 id="cwe_assignment-vertex_ai-data-import">Data Import<a class="headerlink" href="#cwe_assignment-vertex_ai-data-import" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/vertexai_datastore.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_agent1.png" /></p>
</figure>
<figure>
<p><img alt="" src="../assets/images/vertexai_jsonl.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-check-if-the-system-is-closed">Check if the System is Closed<a class="headerlink" href="#cwe_assignment-vertex_ai-check-if-the-system-is-closed" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>What is a dog?</p>
<p><figure markdown>
  <img alt="" src="../assets/images/vertex_ai_what_is_a_dog.png" />
  </figure></p>
</div>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>The system is closed because the GPT can't answer the question because there is no information about dogs in the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> specification.</p>
</div>
<h2 id="cwe_assignment-vertex_ai-what-are-the-different-types-of-xss">What are the different types of XSS?<a class="headerlink" href="#cwe_assignment-vertex_ai-what-are-the-different-types-of-xss" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_xss_types.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-what-cwe-ids-relate-to-xss">What <abbr title="CWE Common Weakness Enumeration">CWE</abbr> IDs Relate To XSS?<a class="headerlink" href="#cwe_assignment-vertex_ai-what-cwe-ids-relate-to-xss" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_xss.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-what-is-the-parent-weakness-or-cwe-for-xss-and-csrf">What Is The Parent Weakness Or <abbr title="CWE Common Weakness Enumeration">CWE</abbr> For XSS And CSRF?<a class="headerlink" href="#cwe_assignment-vertex_ai-what-is-the-parent-weakness-or-cwe-for-xss-and-csrf" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_parent.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-what-cwe-ids-relate-to-path-or-directory-traversal-list-all-cwe-ids-and-their-description-in-a-table">What <abbr title="CWE Common Weakness Enumeration">CWE</abbr> IDs Relate To Path Or Directory Traversal?  List All <abbr title="CWE Common Weakness Enumeration">CWE</abbr> IDs And Their Description In A Table<a class="headerlink" href="#cwe_assignment-vertex_ai-what-cwe-ids-relate-to-path-or-directory-traversal-list-all-cwe-ids-and-their-description-in-a-table" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_path_traversal.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-what-is-the-cwe-associated-with-cve">What is the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Associated With <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr><a class="headerlink" href="#cwe_assignment-vertex_ai-what-is-the-cwe-associated-with-cve" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>What is the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> associated with <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2021-27104 "Accellion FTA OS Command Injection Vulnerability"</p>
<p>What is the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> associated with "Cisco Small Business RV320 and RV325 Routers Information Disclosure Vulnerability"</p>
</div>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_cves.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-example-usage-cwe-1394">Example Usage: <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-1394<a class="headerlink" href="#cwe_assignment-vertex_ai-example-usage-cwe-1394" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>what is the best <abbr title="CWE Common Weakness Enumeration">CWE</abbr> to describe the root cause weakness in <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "ProductX contains a default SSH public key in the authorized_keys file. A remote attacker could use this key to gain root privileges.". </p>
</div>
<figure>
<p><img alt="" src="../assets/images/vertex_ai_ssh.png" /></p>
</figure>
<h2 id="cwe_assignment-vertex_ai-other-app-builder-docs">Other App Builder Docs<a class="headerlink" href="#cwe_assignment-vertex_ai-other-app-builder-docs" title="Permanent link">&para;</a></h2>
<p>These were not used or required but listing here as I found them informative.</p>
<ol>
<li><a href="https://codelabs.developers.google.com/codelabs/vertex-ai-conversation#0">https://codelabs.developers.google.com/codelabs/vertex-ai-conversation#0</a></li>
<li><a href="https://codelabs.developers.google.com/build-google-quality-rag#0">https://codelabs.developers.google.com/build-google-quality-rag#0</a></li>
<li><a href="https://github.com/GoogleCloudPlatform/generative-ai/tree/main">https://github.com/GoogleCloudPlatform/generative-ai/tree/main</a></li>
<li><a href="https://github.com/GoogleCloudPlatform/generative-ai/tree/main/conversation/chat-app">https://github.com/GoogleCloudPlatform/generative-ai/tree/main/conversation/chat-app</a></li>
<li><a href="https://cloud.google.com/generative-ai-app-builder/docs/samples?language=python">https://cloud.google.com/generative-ai-app-builder/docs/samples?language=python</a></li>
<li><a href="https://cloud.google.com/generative-ai-app-builder/docs/samples/genappbuilder-multi-turn-search?hl=en">https://cloud.google.com/generative-ai-app-builder/docs/samples/genappbuilder-multi-turn-search?hl=en</a></li>
<li><a href="https://cloud.google.com/generative-ai-app-builder/docs/samples/genappbuilder-import-documents?hl=en">https://cloud.google.com/generative-ai-app-builder/docs/samples/genappbuilder-import-documents?hl=en</a></li>
<li><a href="https://www.googlecloudcommunity.com/gc/Community-Blogs/Building-and-Deploying-AI-Agents-with-LangChain-on-Vertex-AI/bc-p/750793#M415">https://www.googlecloudcommunity.com/gc/Community-Blogs/Building-and-Deploying-AI-Agents-with-LangChain-on-Vertex-AI/bc-p/750793#M415</a></li>
<li><a href="https://medium.com/google-cloud/gen-ai-grounding-with-vertex-ai-llm-3cb1cbe9f9d2">https://medium.com/google-cloud/gen-ai-grounding-with-vertex-ai-llm-3cb1cbe9f9d2</a></li>
<li><a href="https://medium.com/google-cloud/designing-data-store-hybrid-agents-with-dialogflow-cx-vertex-ai-agents-070082f07cb4">https://medium.com/google-cloud/designing-data-store-hybrid-agents-with-dialogflow-cx-vertex-ai-agents-070082f07cb4</a></li>
<li><a href="https://www.cloudskillsboost.google/paths/236/course_templates/978/labs/488165">https://www.cloudskillsboost.google/paths/236/course_templates/978/labs/488165</a></li>
<li><a href="https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/2d22382cf72840dcde313db2f2feb2115f9fbd70/gemini/grounding/intro-grounding-gemini.ipynb?hl=es-419">https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/2d22382cf72840dcde313db2f2feb2115f9fbd70/gemini/grounding/intro-grounding-gemini.ipynb?hl=es-419</a></li>
<li><a href="https://docs.llamaindex.ai/en/stable/examples/agent/agentic_rag_using_vertex_ai/">https://docs.llamaindex.ai/en/stable/examples/agent/agentic_rag_using_vertex_ai/</a></li>
<li><a href="https://saschaheyer.medium.com/vertex-ai-grounding-large-language-models-8335f838990f">https://saschaheyer.medium.com/vertex-ai-grounding-large-language-models-8335f838990f</a></li>
</ol>
<h2 id="cwe_assignment-vertex_ai-takeaways">Takeaways<a class="headerlink" href="#cwe_assignment-vertex_ai-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Google Vertex AI Agent Builder allows/requires more control over the agent than the <a href="#cwe_assignment-cwe_gpt">ChatGPT GPTs</a> currently. </li>
<li>Google Vertex AI Agent Builder supports a Closed (or Open) System with Grounding and <a href="#cwe_assignment-vertex_ai-grounding-confidence">Grounding Confidence threshold</a> unlike <a href="#cwe_assignment-cwe_gpt">ChatGPT GPTs</a> currently.</li>
<li>This comes close to <a href="#notebooklm-notebooklm">NotebookLM</a> but <ol>
<li>does not provide references from the original documents from which the answer was determined.</li>
</ol>
</li>
</ol>
</div></section><section class="print-page" id="cwe_assignment-vulnrichment"><h1 id="cwe_assignment-vulnrichment-cisa-vulnrichment"><abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment<a class="headerlink" href="#cwe_assignment-vulnrichment-cisa-vulnrichment" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p><strong>An incorrect <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment caught my eye while reading a post</strong></p>
<p>I was reading a <a href="https://www.linkedin.com/feed/update/urn:li:activity:7214295735440187393?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7214295735440187393%2C7214365350828613632%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287214365350828613632%2Curn%3Ali%3Aactivity%3A7214295735440187393%29">post on LinkedIn</a> and the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assigned by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP looked wrong so...</p>
<ul>
<li>I used my <a href="#notebooklm-notebooklm">NotebookLM <abbr title="CWE Common Weakness Enumeration">CWE</abbr> notebook</a>, and other LLMs, to determine the appropriate <abbr title="CWE Common Weakness Enumeration">CWE</abbr>.</li>
<li>I then raised an issue: <a href="https://github.com/cisagov/vulnrichment/issues/84">https://github.com/cisagov/vulnrichment/issues/84</a>.</li>
<li>I then decided to dig a bit more into this... specifically the CWEs assigned by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP.</li>
</ul>
<p><strong>Using LLMs to find incorrect <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignments at scale</strong></p>
<p>I used <a href="https://www.langchain.com/">langchain</a> to create a consensus of LLMs to review all CWEs assigned by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP to find issues:</p>
<ul>
<li>These issues were found automatically by a consensus of 3 LLMs: (current state-of-the-art) ChatGPT4o, Gemini 1.5 Pro, Claude 3.5 Sonnet who were asked to review CWEs assigned to CVEs by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP.</li>
<li>
<p>The consensus output was then reviewed by a human (me).</p>
</li>
<li>
<p>I created <a href="https://github.com/cisagov/vulnrichment/issues?q=is%3Aissue+author%3ACrashedmind+is%3Aclosed">3 Vulnrichment Github Issues initially</a> and these were accepted by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment and resolved promptly!</p>
</li>
<li>
<p>I then provided a report to <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment for all CWEs that were incorrect based on the consensus.</p>
</li>
</ul>
<p><strong>Using LLMs to assign correct CWEs</strong></p>
<p>Finally, I showed how NotebookLM can be used for <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment</p>
<ul>
<li>It avoids the problem of<ul>
<li>training language models on bad data (existing <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignments)</li>
<li>training humans on the detailed <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard (though a basic understanding is still required)</li>
</ul>
</li>
<li><strong>NotebookLM did well in recommending a <abbr title="CWE Common Weakness Enumeration">CWE</abbr> given a <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description.... and providing a supporting <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> from the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Observed Examples in the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard</strong>.<ul>
<li>NotebookLM has a large context window which allows it to digest the large <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard, and it is source-grounded as described in the <a href="#notebooklm-notebooklm">NotebookLM chapter</a>.</li>
<li><a href="#cwe_assignment-cwe_overview">Notebook on CWEs</a> describes how to create this NotebookLM for CWEs</li>
</ul>
</li>
</ul>
<p>The different approaches used (and the subscription plan used):</p>
<ol>
<li>code: <ol>
<li>ChatGPT4o <a href="https://platform.openai.com/docs/guides/batch/overview">OpenAI Batch API</a> (Plus Plan)</li>
<li>langchain calling 2 LLMs via APIs: Gemini 1.5 Pro, Claude 3.5 Sonnet (ChatGPT4 or ChatGPT4o is also supported in the code (but commented out) if your plan supports that)</li>
</ol>
</li>
<li>no-code using the browser chat interface is not shown here but it is useful for initial evaluation<ol>
<li>Gemini 1.5 Pro (subscription)</li>
<li>Claude 3.5 Sonnet (prepay)</li>
</ol>
</li>
</ol>
</div>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>The approach described here resulted in successfully identifying incorrectly assigned CWEs, and identifying the correct CWEs, and a report to <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment.</p>
</div>
<h2 id="cwe_assignment-vulnrichment-consensus-of-3-llms">Consensus of 3 LLMs<a class="headerlink" href="#cwe_assignment-vulnrichment-consensus-of-3-llms" title="Permanent link">&para;</a></h2>
<p><img alt="Consensus of 3 LLMs" src="https://github.com/CyberSecAI/CWEMap/blob/5a63ab52480d7686d308341de263ec3896f9caaf/images/ai_agreement_parcat.png?raw=true" /></p>
<div class="admonition example">
<p class="admonition-title">Source Code</p>
<p><a href="https://github.com/CyberSecAI/CWEMap">https://github.com/CyberSecAI/CWEMap</a></p>
</div>
<h2 id="cwe_assignment-vulnrichment-cisa-vulnrichment_1"><abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment<a class="headerlink" href="#cwe_assignment-vulnrichment-cisa-vulnrichment_1" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment project is the public repository of <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr>'s enrichment of public <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> records through <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr>'s ADP (Authorized Data Publisher) container. In this phase of the project, <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> is assessing new and recent CVEs and adding key <abbr title="SSVC Stakeholder-Specific Vulnerability Categorization">SSVC</abbr> decision points. Once scored, some higher-risk CVEs will also receive enrichment of <abbr title="CWE Common Weakness Enumeration">CWE</abbr>, <abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr>, and CPE data points, where possible.</p>
<p><a href="https://github.com/cisagov/vulnrichment">https://github.com/cisagov/vulnrichment</a></p>
</div>
<p>I have great admiration for <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> and their pragmatic initiatives like <a href="https://riskbasedprioritization.github.io/cisa_kev/cisa_kev/"><abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> <abbr title="Known Exploited Vulnerability">KEV</abbr></a> and <a href="https://riskbasedprioritization.github.io/ssvc/SSVC/"><abbr title="SSVC Stakeholder-Specific Vulnerability Categorization">SSVC</abbr></a> and have <a href="https://riskbasedprioritization.github.io/talks/talks/">spoken about them</a> and applied them in production.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>One of the many benefits of this Vulnrichment project is that feedback can be provided as GitHub issues and <strong>the team is VERY responsive</strong> âœ… <img alt="ðŸ‘" class="twemoji" src="https://cdn.jsdelivr.net/gh/jdecked/twemoji@15.0.3/assets/svg/1f44f.svg" title=":clap:" /> ðŸ™Œ</p>
<ul>
<li>The 'Bug' label was assigned the same day to the 3 issues I submitted: <a href="https://github.com/cisagov/vulnrichment/issues?q=is%3Aissue+author%3ACrashedmind+is%3Aclosed">https://github.com/cisagov/vulnrichment/issues?q=is%3Aissue+author%3ACrashedmind+is%3Aclosed</a>.</li>
<li>The changes were accepted and applied the next working day and a comment was added to the ticket which was then closed.</li>
</ul>
<p>My overall goal here was to </p>
<ul>
<li>Show that LLMs could augment human analysts where vulnerability enrichment today is largely done manually.</li>
<li>Show how to use them for this purpose.</li>
<li>Get people to use LLMs to improve the quality of the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> data in general, and in this specific example case, the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> data.</li>
<li>Maximize the value of the <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP data and enrichment by improving <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-assignment quality.</li>
</ul>
</div>
<h2 id="cwe_assignment-vulnrichment-get-cves-enriched-by-cisa-adp">Get CVEs Enriched by <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP<a class="headerlink" href="#cwe_assignment-vulnrichment-get-cves-enriched-by-cisa-adp" title="Permanent link">&para;</a></h2>
<h3 id="cwe_assignment-vulnrichment-what-to-ask-the-llms">What to ask the LLMs?<a class="headerlink" href="#cwe_assignment-vulnrichment-what-to-ask-the-llms" title="Permanent link">&para;</a></h3>
<p>Different approaches are possible when providing the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description to the LLM:</p>
<ol>
<li>provide the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assigned as part of the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>, and ask the LLM if it agrees or not, and only if not, why<ol>
<li>This reduces the output token count/cost by only outputting the verbose rationale in case of disagreement</li>
</ol>
</li>
<li>ask the LLM to assign one or more CWEs, with rationale</li>
</ol>
<p>The first approach is easier and simpler and cheaper (in terms of token use i.e. shorter response output), and better as a first pass option to get the low hanging fruit.</p>
<p>The second approach could be used at the time of <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment to get a second opinion.</p>
<h3 id="cwe_assignment-vulnrichment-consensus">Consensus<a class="headerlink" href="#cwe_assignment-vulnrichment-consensus" title="Permanent link">&para;</a></h3>
<p>To minimize human effort, 3 LLMs are used and the consensus is reviewed</p>
<ul>
<li>The LLMs are state-of-the-art models from different providers i.e. the best available and reasonably independent.</li>
<li>The results are sorted by consensus i.e. 3 models in agreement, then 2 models in agreement,.... and by the LLM's confidence in their responses</li>
<li>A Human (me) then reviewed (sorted by consensus and confidence) and made the final decision.</li>
</ul>
<h3 id="cwe_assignment-vulnrichment-recipe">Recipe<a class="headerlink" href="#cwe_assignment-vulnrichment-recipe" title="Permanent link">&para;</a></h3>
<ol>
<li>Get the Vulnrichment subset of CVEs where <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP assigned a <abbr title="CWE Common Weakness Enumeration">CWE</abbr> (regardless of whether the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> was the same or different than that assigned by the CNA) into a sheet/CSV file.<ol>
<li>~1.8K (<abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> ADP Assigned CWEs) of ~~10K CVEs (in Vulnrichment)</li>
</ol>
</li>
<li>As a dry-run submit e.g. 50 <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Descriptions, CWEs to each of the 3 LLMs to review via the chat UI in one prompt</li>
<li>Ask ChatGPT4o (via Batch API) to Agree (Yes/No) with the assigned <abbr title="CWE Common Weakness Enumeration">CWE</abbr> (and provide a Confidence score, and rationale if not)<ol>
<li>Sort these by Confidence score i.e. start with the highest Confidence ones.</li>
</ol>
</li>
<li>Assign the same task to Gemini and Claude via APIs driven by langchain</li>
</ol>
<h3 id="cwe_assignment-vulnrichment-create-a-prompt">Create a Prompt<a class="headerlink" href="#cwe_assignment-vulnrichment-create-a-prompt" title="Permanent link">&para;</a></h3>
<h4 id="cwe_assignment-vulnrichment-chat-interface-table-output">Chat Interface - Table Output<a class="headerlink" href="#cwe_assignment-vulnrichment-chat-interface-table-output" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#cwe_assignment-vulnrichment-__codelineno-0-1"></a>caption_system_prompt =
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#cwe_assignment-vulnrichment-__codelineno-0-2"></a>You are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#cwe_assignment-vulnrichment-__codelineno-0-3"></a>Your goal is is to say if you Agree with the assigned CWE ID or not.
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#cwe_assignment-vulnrichment-__codelineno-0-4"></a>You will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#cwe_assignment-vulnrichment-__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#cwe_assignment-vulnrichment-__codelineno-0-6"></a>Please provide the response in a table &#39;cve_id&#39;, &#39;CWE_ID&#39;, &#39;Agree&#39;. &quot;Rationale&quot;, Confidence&#39; where
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#cwe_assignment-vulnrichment-__codelineno-0-7"></a>1. Agree: string // Yes or No
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#cwe_assignment-vulnrichment-__codelineno-0-8"></a>2. Rationale: string // Only if you do not Agree, provide a rationale why not
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#cwe_assignment-vulnrichment-__codelineno-0-9"></a>3. Confidence: string // a confidence score between 0 and 1
</code></pre></div>
<p>The table output allows copy-and-pasting by a human into a sheet.</p>
<p>The prompt consists of these parts:</p>
<ol>
<li>Role + Task: which is the same for the Chat and API interface</li>
<li>Output format: which is different for the Chat and API interface</li>
<li>A binary value Agree is requested</li>
<li>The rationale only if there is disagreement. This saves on output tokens.</li>
<li>A Confidence score to limit impacts of hallucinations, and as a way to assess and prioritize responses by confidence.</li>
<li>No (Few-shot) examples are provided. Based on the results, these were not necessary.<ol>
<li>If Few-shot examples were required, I'd submit multiple CVEs in a single batch request (because putting the examples in each single <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> request would add a LOT of input tokens)</li>
</ol>
</li>
</ol>
<h4 id="cwe_assignment-vulnrichment-batch-api-interface-json-output">Batch API Interface - JSON Output<a class="headerlink" href="#cwe_assignment-vulnrichment-batch-api-interface-json-output" title="Permanent link">&para;</a></h4>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#cwe_assignment-vulnrichment-__codelineno-1-1"></a>caption_system_prompt =
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#cwe_assignment-vulnrichment-__codelineno-1-2"></a>You are a cybersecurity expert specializing in identifying Common Weakness Enumeration (CWE) IDs from CVE descriptions.
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#cwe_assignment-vulnrichment-__codelineno-1-3"></a>Your goal is is to say if you Agree with the assigned CWE ID or not.
<a id="__codelineno-1-4" name="__codelineno-1-4" href="#cwe_assignment-vulnrichment-__codelineno-1-4"></a>You will be provided with a CVE ID and description amd a CWE ID that has been assigned to that CVE description.
<a id="__codelineno-1-5" name="__codelineno-1-5" href="#cwe_assignment-vulnrichment-__codelineno-1-5"></a>
<a id="__codelineno-1-6" name="__codelineno-1-6" href="#cwe_assignment-vulnrichment-__codelineno-1-6"></a>You will output a json object containing the following information:
<a id="__codelineno-1-7" name="__codelineno-1-7" href="#cwe_assignment-vulnrichment-__codelineno-1-7"></a>{
<a id="__codelineno-1-8" name="__codelineno-1-8" href="#cwe_assignment-vulnrichment-__codelineno-1-8"></a>    Agree: string // Yes or No
<a id="__codelineno-1-9" name="__codelineno-1-9" href="#cwe_assignment-vulnrichment-__codelineno-1-9"></a>    Rationale: string // Only if you do not Agree, provide a rationale why not
<a id="__codelineno-1-10" name="__codelineno-1-10" href="#cwe_assignment-vulnrichment-__codelineno-1-10"></a>    Confidence: string // a confidence score between 0 and 1
<a id="__codelineno-1-11" name="__codelineno-1-11" href="#cwe_assignment-vulnrichment-__codelineno-1-11"></a>}
</code></pre></div>
The JSON output allows processing by machines.</p>
<div class="admonition tip">
<p class="admonition-title">Use JSON Mode</p>
<p><a href="https://platform.openai.com/docs/guides/text-generation/json-mode">ChatGPT</a> and <a href="https://ai.google.dev/gemini-api/docs/json-mode?lang=python">Gemini 1.5</a> support JSON mode that always outputs valid JSON. Use it!</p>
<ul>
<li>See <a href="https://medium.com/google-cloud/latest-gemini-features-support-in-langchain4j-0-32-0-732791e4c34c">details of Latest Gemini features support in LangChain4j 0.32.0</a>.</li>
</ul>
<p>While you can prompt an LLM to output JSON, it may not always output valid JSON and you're left with a cleanup exercise (a friend of mine had that experience when they first tried this ðŸ˜‰)</p>
<p><a href="https://github.com/anthropics/anthropic-cookbook/blob/main/misc/how_to_enable_json_mode.ipynb">Claude doesn't have a formal "JSON Mode"</a> though, in my usage, it always produced valid JSON.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>It is possible to submit multiple CVEs in one prompt for each batch entry i.e. similar to what is done when using the Chat interface.</p>
<ul>
<li>This is what is done here. 10 <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignments are sent per batch (though the <a href="https://platform.openai.com/docs/guides/batch/overview">OpenAI Batch API</a> example contains 1 entry only)</li>
</ul>
</div>
<h3 id="cwe_assignment-vulnrichment-llms">LLMs<a class="headerlink" href="#cwe_assignment-vulnrichment-llms" title="Permanent link">&para;</a></h3>
<h4 id="cwe_assignment-vulnrichment-gemini-15-pro-api-via-langchain">Gemini 1.5 Pro API via Langchain<a class="headerlink" href="#cwe_assignment-vulnrichment-gemini-15-pro-api-via-langchain" title="Permanent link">&para;</a></h4>
<p>The API interface (via Langchain) was used in this example submitting multiple CVEs in one prompt.</p>
<h4 id="cwe_assignment-vulnrichment-claude-35-sonnet-api-via-langchain">Claude 3.5 Sonnet API via Langchain<a class="headerlink" href="#cwe_assignment-vulnrichment-claude-35-sonnet-api-via-langchain" title="Permanent link">&para;</a></h4>
<h5 id="cwe_assignment-vulnrichment-model">Model<a class="headerlink" href="#cwe_assignment-vulnrichment-model" title="Permanent link">&para;</a></h5>
<p>Currently: Claude 3.5 Sonnet was used as it has the best performance vs cost for Claude models.</p>
<figure>
<p><img alt="" src="../assets/images/claude.png" />
<a href="https://docs.anthropic.com/en/docs/welcome">https://docs.anthropic.com/en/docs/welcome</a> </p>
</figure>
<h5 id="cwe_assignment-vulnrichment-interface">Interface<a class="headerlink" href="#cwe_assignment-vulnrichment-interface" title="Permanent link">&para;</a></h5>
<p>Currently: Claude does not support a native <a href="https://www.anthropic.com/pricing#anthropic-api">Batch API interface</a> - though 
<a href="https://aws.amazon.com/bedrock/pricing/">Amazon Bedrock</a> supports batching of prompts to models including Claude.</p>
<p>The API interface (via Langchain) was used in this example submitting multiple CVEs in one prompt.</p>
<h4 id="cwe_assignment-vulnrichment-chatgpt4o-batch-api"><a href="https://platform.openai.com/docs/guides/batch/overview">ChatGPT4o Batch API</a><a class="headerlink" href="#cwe_assignment-vulnrichment-chatgpt4o-batch-api" title="Permanent link">&para;</a></h4>
<h5 id="cwe_assignment-vulnrichment-model_1">Model<a class="headerlink" href="#cwe_assignment-vulnrichment-model_1" title="Permanent link">&para;</a></h5>
<p>gpt-4o</p>
<h5 id="cwe_assignment-vulnrichment-plan">Plan<a class="headerlink" href="#cwe_assignment-vulnrichment-plan" title="Permanent link">&para;</a></h5>
<p>The Plus plan subscription was used.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>There are some restrictions:</p>
<ul>
<li>The file can contain up to 50,000 requests.</li>
<li>The file cannot be more than 100 MB in size.</li>
</ul>
<p>Enqueued token limit reached for gpt-4o in organization XYZ. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.'</p>
</div>
<h5 id="cwe_assignment-vulnrichment-interface_1">Interface<a class="headerlink" href="#cwe_assignment-vulnrichment-interface_1" title="Permanent link">&para;</a></h5>
<p>Batch Interface API.</p>
<p>The ~1800 ADP <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-<abbr title="CWE Common Weakness Enumeration">CWE</abbr> pairs were split into 15 files of 100 <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-<abbr title="CWE Common Weakness Enumeration">CWE</abbr> pair prompts to comfortably fit under this token limit.</p>
<ul>
<li>very little effort was spent to optimize the file size (number of prompts per batch), or the prompt size.</li>
<li>The cost to process the ~1800 ADP <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-<abbr title="CWE Common Weakness Enumeration">CWE</abbr> pairs: ~$2.</li>
</ul>
<h2 id="cwe_assignment-vulnrichment-observations">Observations<a class="headerlink" href="#cwe_assignment-vulnrichment-observations" title="Permanent link">&para;</a></h2>
<h3 id="cwe_assignment-vulnrichment-leak">Leak<a class="headerlink" href="#cwe_assignment-vulnrichment-leak" title="Permanent link">&para;</a></h3>
<p>Several <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Descriptions that include "leak" were incorrectly assigned "<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-200 Exposure of Sensitive Information to an Unauthorized Actor".</p>
<p>These were actually resource leaks (memory, program objects like handles etc...), not leakage of sensitive data.</p>
<h3 id="cwe_assignment-vulnrichment-gemini-15-pro-hallucinations">Gemini 1.5 Pro Hallucinations<a class="headerlink" href="#cwe_assignment-vulnrichment-gemini-15-pro-hallucinations" title="Permanent link">&para;</a></h3>
<div class="admonition failure">
<p class="admonition-title">Failure</p>
<p>From a sample of 30 assigned CWEs, Gemini 1.5 Pro had 3 hallucinations when asked to provide a rationale for its response (response text shown below, with hallucination in <strong>bold</strong>).</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<ol>
<li>While <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-400 (Uncontrolled Resource Consumption) could be a potential consequence, the core issue described in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> is about improper handling of the Python crash handler within a chroot environment. This misconfiguration could allow an attacker to potentially escape the chroot and execute code in the context of the Apport process.  A more appropriate <abbr title="CWE Common Weakness Enumeration">CWE</abbr> might be <strong><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-247 (Improper Handling of Chroot Environments)</strong> or <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-22 (Improper Limitation of a Pathname to a Restricted Directory ('Path Traversal')).<ol>
<li><a href="https://cwe.mitre.org/data/definitions/247.html"><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-247: DEPRECATED: Reliance on DNS Lookups in a Security Decision</a></li>
<li><a href="https://cwe.mitre.org/data/definitions/243.html"><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-243: Creation of chroot Jail Without Changing Working Directory</a> is the closest to "Improper Handling of Chroot Environments"</li>
</ol>
</li>
<li>The assigned <strong><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-436 (Unspecified Encoding or Escaping of Output)</strong> doesn't fit well. The description argues that the plugin itself doesn't handle file uploads, making it a matter of what WordPress allows to be uploaded. If the core WordPress installation doesn't prevent polyglot files, it's not directly the plugin's fault. A more suitable <abbr title="CWE Common Weakness Enumeration">CWE</abbr> might be <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-284 (Improper Access Control) if the plugin fails to restrict access to already uploaded polyglot files, allowing unauthorized viewing or download.<ol>
<li><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-116 is the correct <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: <a href="https://cwe.mitre.org/data/definitions/116.html"><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-116: Improper Encoding or Escaping of Output</a></li>
</ol>
</li>
<li>While <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-57 (Relative Path Traversal) could be a factor in exploiting this vulnerability, the description more directly aligns with <strong><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-664: Improper Control of File Deletion or Renaming Operations</strong>. The vulnerability allows attackers to delete arbitrary files, which is the core characteristic of <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-664. Relative path traversal might be a means to reach different files, but the primary issue is the improper control over file deletion.<ol>
<li><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-664 correct title is <a href="https://cwe.mitre.org/data/definitions/664.html"><abbr title="CWE Common Weakness Enumeration">CWE</abbr>-664: Improper Control of a Resource Through its Lifetime</a></li>
</ol>
</li>
</ol>
</div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>While Gemini 1.5 Pro is the backend for NotebookLM, no hallucinations were detected in NotebookLM (the benefit of a source-grounded closed system).</p>
</div>
<h2 id="cwe_assignment-vulnrichment-notebooklm">NotebookLM<a class="headerlink" href="#cwe_assignment-vulnrichment-notebooklm" title="Permanent link">&para;</a></h2>
<p>NotebookLM works very well for suggesting a relevant <abbr title="CWE Common Weakness Enumeration">CWE</abbr> for a given <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description (or reviewing an assigned <abbr title="CWE Common Weakness Enumeration">CWE</abbr>)</p>
<ul>
<li>It suggests related CVEs to support the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> it suggests (sometimes prompting is required). These CVEs are part of the "Observed Examples" CVEs that are listed under a <abbr title="CWE Common Weakness Enumeration">CWE</abbr> in the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard.</li>
<li>The numbered grey circles in the diagram below are links to references from the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard.</li>
</ul>
<figure>
<p><img alt="" src="../assets/images/notebooklm_pickle.png" />
<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2024-35059</p>
</figure>
<figure>
<p><img alt="" src="../assets/images/vulnrichment_notebooklm.png" />
<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-2023-49224</p>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The NotebookLM prompts above are deliberately not applying <a href="#prompt_engineering-prompt_engineering">prompt engineering principles</a> to show that NotebookLM still provides a useful response.</p>
</div>
<h2 id="cwe_assignment-vulnrichment-refinements">Refinements<a class="headerlink" href="#cwe_assignment-vulnrichment-refinements" title="Permanent link">&para;</a></h2>
<div class="admonition notes">
<p class="admonition-title">Note: Some refinements are possible, but were not implemented in this first pass to minimize Time-To-Value</p>
<ol>
<li>The full <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard was used here for illustration purposes (and to take on the harder problem of a large specification)<ol>
<li>A subset of CWEs could be used if that is desired. </li>
<li>In practice, several hundred CWEs are assigned to CVEs.</li>
<li>Remove the 25 "DEPRECATED:" entries</li>
</ol>
</li>
<li>The text from the references in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> "References to Advisories, Solutions, and Tools" was not retrieved and fed to the LLM as part of the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description for <abbr title="CWE Common Weakness Enumeration">CWE</abbr> review or assignment.<ol>
<li>These references were reviewed manually (for the consensus of incorrect <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignments)</li>
<li>In some cases, this has additional text available that can inform the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment beyond the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description alone</li>
<li>It is relatively easy to retrieve this content automatically but this content varies significantly by type (text, image, pdf), quality, structure.</li>
<li>Separately, it is common that these links break because the original website or post is removed, or it's not in the latest version in Github,... - so it would be useful to have the extracted text at the time of <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment.  </li>
</ol>
</li>
<li>Additional known good <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> descriptions and <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignments could be incorporated into the corpus, to augment the limited <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> observed examples that are part of the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard.</li>
<li>Reducing the set of CWEs to the desired population, or providing guidance in the prompt on what CWEs to use (e.g. "don't use <abbr title="CWE Common Weakness Enumeration">CWE</abbr>'s marked as Discouraged")</li>
<li>As I was interested in comparing LLM responses, I did not optimize the LLM usage (all LLMs were fed all <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-CWEs)<ol>
<li>This can be done in several ways e.g. <ol>
<li>Ask each LLM in turn to review the previous assessments by LLMs</li>
<li>Sampling</li>
</ol>
</li>
</ol>
</li>
</ol>
</div>
<h2 id="cwe_assignment-vulnrichment-takeaways">Takeaways<a class="headerlink" href="#cwe_assignment-vulnrichment-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>
<p>The value of <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> data depends on its quality. </p>
<ol>
<li>For all published CVEs to date, <a href="https://www.linkedin.com/feed/update/urn:li:activity:7186373368344920064?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7186373368344920064%2C7186417379470385153%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287186417379470385153%2Curn%3Ali%3Aactivity%3A7186373368344920064%29">the quality of CWEs assigned is questionable</a>.</li>
<li>A large part of that is that humans can't grok ~~1000 CWEs. LLMs can.</li>
</ol>
</li>
<li>
<p>Using LLMs to suggest or validate CWEs can reduce the manual effort and error in <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment.</p>
</li>
<li>LLMs can validate CWEs at scale e.g. using Batch mode, or multiple CVEs per prompt, or both.</li>
<li>LLMs perform well at this task and, given they can be automated, can augment the human manual effort, and improve the quality of assigned CWEs.</li>
<li>Langchain makes it easier to have generic code that works across multiple LLMs.</li>
<li>LLM JSON Mode should be used where possible to reduce bad JSON output and subsequent cleanup.</li>
<li>Based on a manual review of the subset where all 3 LLMs disagreed with the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment, &gt; 75% of these CWEs were incorrect (and a report with these was submitted to <abbr title="Cybersecurity &amp; Infrastructure Security Agency">CISA</abbr> Vulnrichment)<ol>
<li>I did not dig into the subset where 2 of 3 LLMs disagreed.</li>
</ol>
</li>
<li>Using LLMs to suggest or validate CWEs can reduce the manual effort and error in <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assignment.</li>
<li>A closed-system that is grounded on the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> standard only e.g. NotebookLM, performs very well for assigning CWEs, or reviewing assigned CWEs (though it does not have an API so can't do this at scale), and no hallucinations were observed.</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: CWE Assignment</h1>
                        <h1 class='nav-section-title' id='section-context-engineering'>
                            Context Engineering <a class='headerlink' href='#section-context-engineering' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="context_engineering-context"><h1 id="context_engineering-context-overview">Overview<a class="headerlink" href="#context_engineering-context-overview" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Abstract</p>
<p>This section looks at Context Engineering, and gives Prioritized Context Engineering Steps for Agentic AI.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>"Context engineering is the delicate art and science of filling the context window with just the right information for the next step." Andrej Karpathy,
<a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">https://www.youtube.com/watch?v=LCEmiRjPEtQ</a></p>
</div>
<p><figure markdown>
<img alt="" src="../assets/images/context12.png" />
Source: <a href="https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md">https://github.com/humanlayer/12-factor-agents/blob/main/content/factor-03-own-your-context-window.md</a>
</figure></p>
</div>
<h2 id="context_engineering-context-intent-engineering-over-context-engineering-over-prompt-engineering">Intent Engineering over Context Engineering over Prompt Engineering<a class="headerlink" href="#context_engineering-context-intent-engineering-over-context-engineering-over-prompt-engineering" title="Permanent link">&para;</a></h2>
<h3 id="context_engineering-context-context-engineering">Context Engineering<a class="headerlink" href="#context_engineering-context-context-engineering" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>+1 for "context engineering" over "prompt engineering".</p>
<p>People associate prompts with short task descriptions you'd give an LLM in your day-to-day use. When in every industrial-strength LLM app, context engineering is the delicate art and science of filling the context window with just the right information for the next step. Science because doing this right involves task descriptions and explanations, few shot examples, RAG, related (possibly multimodal) data, tools, state and history, compacting... Too little or of the wrong form and the LLM doesn't have the right context for optimal performance. Too much or too irrelevant and the LLM costs might go up and performance might come down. Doing this well is highly non-trivial. And art because of the guiding intuition around LLM psychology of people spirits.</p>
<p>On top of context engineering itself, an LLM app has to:</p>
<ul>
<li>break up problems just right into control flows</li>
<li>pack the context windows just right</li>
<li>dispatch calls to LLMs of the right kind and capability</li>
<li>handle generation-verification UIUX flows</li>
<li>a lot more - guardrails, security, evals, parallelism, prefetching, ...</li>
</ul>
<p><strong>So context engineering is just one small piece of an emerging thick layer of non-trivial software that coordinates individual LLM calls (and a lot more) into full LLM apps.</strong> The term "ChatGPT wrapper" is tired and really, really wrong.</p>
<p><a href="https://x.com/karpathy/status/1937902205765607626">https://x.com/karpathy/status/1937902205765607626</a> @karpathy Jun 25</p>
</div>
<h3 id="context_engineering-context-intent-engineering">Intent Engineering<a class="headerlink" href="#context_engineering-context-intent-engineering" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>I really like it! But itâ€™s still one level too deep. </p>
<p>I think the actual skill is more like <strong>Intent engineering. Articulating what you want extremely clearly.</strong></p>
<p>As critical as it is, the context is still just support. </p>
<p>The more important part is the clear thinking.</p>
<p><a href="https://x.com/DanielMiessler/status/1937937649005957260">https://x.com/DanielMiessler/status/1937937649005957260</a> @DanielMiessler Jun 25</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See also <a href="https://muness.com/posts/intent-engineering/">https://muness.com/posts/intent-engineering/</a>.</p>
<p><a href="#software-swe_redux">Breakthrough Method for Agile AI-Driven Development (BMAD</a> is an example framework where intent is expressed and checked.</p>
</div>
<h2 id="context_engineering-context-guides-from-anthropic-and-openai">Guides from Anthropic and OpenAI<a class="headerlink" href="#context_engineering-context-guides-from-anthropic-and-openai" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">Guides from Anthropic and OpenAI</p>
<p><a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">Anthropic's Guide</a>:</p>
<ul>
<li>Introduces the concept of "<strong>context rot</strong>," where model performance degrades as the context window fills.</li>
<li>Stresses the importance of providing the smallest possible set of high-signal tokens.</li>
<li>Recommends dynamic, "just-in-time" context retrieval.</li>
<li>For long-horizon tasks, it suggests compaction, structured note-taking, and multi-agent architectures.</li>
<li>They beta released a <a href="https://docs.claude.com/en/docs/agents-and-tools/tool-use/memory-tool">Memory Tool</a> "to store and retrieve information across conversations through a memory file directory"</li>
</ul>
<p><a href="https://cookbook.openai.com/examples/agents_sdk/session_memory">OpenAI Cookbook (on Session Memory)</a>:</p>
<ul>
<li>Provides a concrete implementation of short-term memory management through "session memory."</li>
<li>Details specific techniques like "<strong>context trimming</strong>" (keeping the last N turns) and "context summarization."</li>
<li>Offers practical parameters for implementation, such as context_limit and keep_last_n_turns.</li>
</ul>
</div>
<h2 id="context_engineering-context-essential-knowledge">Essential Knowledge<a class="headerlink" href="#context_engineering-context-essential-knowledge" title="Permanent link">&para;</a></h2>
<div class="admonition tip">
<p class="admonition-title">The best references covering the Problem and Solution space</p>
<ul>
<li>
<p>Reunig, D. (2025, June 22). <a href="https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html"><em>How long contexts fail (and how to fix them).</em></a><br />
  Analyzes failure modes of excessively long context windows.<br />
<strong>Failure modes:</strong>  </p>
<ul>
<li><strong>Context poisoning</strong>: When a hallucination makes it into the context  </li>
<li><strong>Context distraction</strong>: When the context overwhelms the training  </li>
<li><strong>Context confusion</strong>: When superfluous context influences the response  </li>
<li><strong>Context clash</strong>: When parts of the context disagree  </li>
</ul>
</li>
<li>
<p>Reunig, D. (2025, June 26). <a href="https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html"><em>How to fix your context.</em></a><br />
  Follow-up article offering tactics to avoid context failure: RAG, tool loadout, context pruning, summarization, and offloading.</p>
</li>
<li>
<p>Martin, R. L. (2025, June 23). <a href="https://rlancemartin.github.io/2025/06/23/context_engineering/"><em>Context engineering.</em></a><br />
  Overview of practical strategies for structuring and optimizing context for LLMs.<br />
<strong>Key practices: write, select, compress, isolate</strong></p>
</li>
<li>
<p>IndyDevDan. (2025, July). <a href="https://www.youtube.com/watch?v=Kf5-HWJPTIE"><em>Elite context engineering with Claude Code</em></a><br />
  Demonstrates advanced context engineering techniques using Claude Code.
  <strong>Core mantra:</strong> <strong>R&amp;D = Reduce + Delegate.</strong><br />
  Reduce what the primary agent sees; delegate everything else to sub-agents or background primaries, with crisp contracts and logs  </p>
</li>
</ul>
</div>
<h2 id="context_engineering-context-prioritized-context-engineering-steps-for-agentic-ai">Prioritized Context Engineering Steps for Agentic AI<a class="headerlink" href="#context_engineering-context-prioritized-context-engineering-steps-for-agentic-ai" title="Permanent link">&para;</a></h2>
<h3 id="context_engineering-context-1-minimize-the-primary-context-treat-it-like-a-cache">1) Minimize the Primary Context (treat it like a cache)<a class="headerlink" href="#context_engineering-context-1-minimize-the-primary-context-treat-it-like-a-cache" title="Permanent link">&para;</a></h3>
<ul>
<li>Keep only: <strong>goal</strong>, <strong>immediate instructions</strong>, <strong>tiny retrieved slice</strong>, <strong>output schema</strong>.</li>
<li>Keep ephemeral scratchpads for step-by-step reasoning; purge after use.</li>
<li>Offload history, rules, and big docs to external memory or files.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Faster, cheaper, less distracted agent; fewer long-context failure modes.</li>
</ul>
<hr />
<h3 id="context_engineering-context-2-write-context-intentionally-dont-just-append-everything">2) Write Context Intentionally (donâ€™t just append everything)<a class="headerlink" href="#context_engineering-context-2-write-context-intentionally-dont-just-append-everything" title="Permanent link">&para;</a></h3>
<ul>
<li>Clear <strong>system message</strong> for goals, rules, constraints, evaluation criteria.</li>
<li>Define <strong>output schemas</strong> (JSON/table) and acceptance checks.</li>
<li>Put canonical facts/API contracts in stable references, not the live window.</li>
<li>Log key decisions so context can be rebuilt if needed.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Prevents bloated prompts; establishes reliable â€œground truthâ€.</li>
</ul>
<hr />
<h3 id="context_engineering-context-3-select-context-dynamically-quality-quantity">3) Select Context Dynamically (quality &gt; quantity)<a class="headerlink" href="#context_engineering-context-3-select-context-dynamically-quality-quantity" title="Permanent link">&para;</a></h3>
<ul>
<li>Retrieve only whatâ€™s relevant <strong>now</strong> via embeddings/filters.</li>
<li>Cap retrieval: few high-signal snippets; drop duplicates/stale text.</li>
<li>Prefer structured facts (tables/JSON) over long prose.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Model focuses on the right information; fewer hallucinations.</li>
</ul>
<hr />
<h3 id="context_engineering-context-4-use-context-priming-instead-of-big-always-on-memory-files">4) Use Context Priming (instead of big always-on memory files)<a class="headerlink" href="#context_engineering-context-4-use-context-priming-instead-of-big-always-on-memory-files" title="Permanent link">&para;</a></h3>
<ul>
<li>Create reusable <strong>prime commands</strong> per task (Purpose â†’ Read/Fetch â†’ Steps â†’ Report).</li>
<li>Keep a <strong>tiny universal core</strong> (guardrails + IO schema) always loaded.</li>
<li>Prime on demand for bugfix, feature, research, etc.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Minimal startup tokens with task-specific readiness.</li>
</ul>
<hr />
<h3 id="context_engineering-context-5-kill-always-on-baggage-toolsmcp-autoloading">5) Kill Always-On Baggage (tools/MCP autoloading)<a class="headerlink" href="#context_engineering-context-5-kill-always-on-baggage-toolsmcp-autoloading" title="Permanent link">&para;</a></h3>
<ul>
<li>Donâ€™t preload tool packs/MCP servers by default; load <strong>lazily</strong> per task.</li>
<li>Unload after use; explicitly justify any autoload.</li>
<li>Audit startup context and remove dead weight.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Frees large chunks of window; cuts token waste and latency.</li>
</ul>
<hr />
<h3 id="context_engineering-context-6-delegate-heavy-work-to-sub-agents-properly">6) Delegate Heavy Work to <strong>Sub-Agents</strong> (properly)<a class="headerlink" href="#context_engineering-context-6-delegate-heavy-work-to-sub-agents-properly" title="Permanent link">&para;</a></h3>
<ul>
<li>One sub-agent = <strong>one job</strong> with a tight <strong>system prompt</strong>.</li>
<li>Let sub-agents consume <strong>their</strong> windows; return <strong>distilled reports</strong> + artifacts.</li>
<li>Standard report contract: <code>{summary, key_facts, risks, artifacts[]}</code>.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Keeps the primary window small while scaling capability.</li>
</ul>
<hr />
<h3 id="context_engineering-context-7-delegate-longexpensive-tasks-to-background-primary-agents">7) Delegate Long/Expensive Tasks to <strong>Background Primary Agents</strong><a class="headerlink" href="#context_engineering-context-7-delegate-longexpensive-tasks-to-background-primary-agents" title="Permanent link">&para;</a></h3>
<ul>
<li>Kick off separate agents for crawls, planning, batch edits, evals.</li>
<li>They write <strong>report files + artifacts</strong>; foreground ingests concise summaries.</li>
<li>Use this to â€œget out of the loopâ€ while work continues.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Parallelizes work; maintains a lean, responsive main loop.</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><a href="#software-claude_code-claude-code-cli-god-mode">Claude Code CLI God Mode</a> is an example of this, delegating to a different Primary model (that is the best tool for the job.)</p>
</div>
<hr />
<h3 id="context_engineering-context-8-compress-context-mostly-outside-the-window">8) Compress Context (mostly outside the window)<a class="headerlink" href="#context_engineering-context-8-compress-context-mostly-outside-the-window" title="Permanent link">&para;</a></h3>
<ul>
<li>Rolling conversation summaries; hierarchical notes (facts â†’ decisions â†’ actions).</li>
<li>Store raw data externally; insert only <strong>pointers + summaries</strong>.</li>
<li>Heuristic trimming rules (dedupe, last-N, relevance thresholds).</li>
<li>ðŸ”‘ <strong>Impact:</strong> Extends effective history without clogging the window.</li>
</ul>
<hr />
<h3 id="context_engineering-context-9-isolate-contexts-sandboxing-pipelines">9) Isolate Contexts (sandboxing &amp; pipelines)<a class="headerlink" href="#context_engineering-context-9-isolate-contexts-sandboxing-pipelines" title="Permanent link">&para;</a></h3>
<ul>
<li>Keep runtime state objects and scratchpads <strong>per agent</strong>.</li>
<li>Avoid leaking sub-agent history into the primary prompt.</li>
<li>Build multi-agent pipelines with explicit handoffs.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Reduces poisoning, distraction, and cross-task conflicts.</li>
</ul>
<hr />
<h3 id="context_engineering-context-10-log-context-bundles-for-replayhandoff">10) Log <strong>Context Bundles</strong> for replay/handoff<a class="headerlink" href="#context_engineering-context-10-log-context-bundles-for-replayhandoff" title="Permanent link">&para;</a></h3>
<ul>
<li>Save <code>{run_id, primes, reads, tool_calls, key_findings, decisions, outputs, next_steps}</code>.</li>
<li>Use bundles to reprime new agents after window blow-ups or for continuity.</li>
<li>Keep bundles conciseâ€”no verbatim dumps of huge content.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Reproducibility and seamless continuation across sessions.</li>
</ul>
<hr />
<h3 id="context_engineering-context-11-defend-against-context-failure-modes">11) Defend Against Context Failure Modes<a class="headerlink" href="#context_engineering-context-11-defend-against-context-failure-modes" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Poisoning:</strong> verify tool outputs; tag trust levels; gate propagation.</li>
<li><strong>Confusion:</strong> filter irrelevant turns; dedupe aggressively.</li>
<li><strong>Conflict:</strong> detect/resolve contradictions before composing answers.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Higher reliability and fewer cascading errors.</li>
</ul>
<hr />
<h3 id="context_engineering-context-12-standardize-schemas-measure-what-matters">12) Standardize Schemas &amp; Measure What Matters<a class="headerlink" href="#context_engineering-context-12-standardize-schemas-measure-what-matters" title="Permanent link">&para;</a></h3>
<ul>
<li>Standard prompt skeletons, report JSON, artifact layout, retrieval policies.</li>
<li>Track <code>startup_tokens</code>, <code>peak_tokens</code>, <code>#agents_spawned</code>, <code>attempts_to_success</code>, <code>retrieval_hits</code>.</li>
<li>Set SLOs (e.g., startup â‰¤10% window, attempts â‰¤3) and alert on drift.</li>
<li>ðŸ”‘ <strong>Impact:</strong> Consistency at scale; makes optimization and debugging straightforward.</li>
</ul>
<hr />
<h2 id="context_engineering-context-context-engineering-101-cheat-sheet">Context Engineering 101 cheat sheet<a class="headerlink" href="#context_engineering-context-context-engineering-101-cheat-sheet" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/context_cheatsheet.jpeg" /></p>
<p>Context Engineering 101 cheat sheet by Lena Hall <a href="https://x.com/lenadroid/status/1943685060785524824">https://x.com/lenadroid/status/1943685060785524824</a></p>
</figure>
<h2 id="context_engineering-context-references">References<a class="headerlink" href="#context_engineering-context-references" title="Permanent link">&para;</a></h2>
<h3 id="context_engineering-context-academic-papers">Academic Papers<a class="headerlink" href="#context_engineering-context-academic-papers" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>Zhang, W., Gupta, R., MÃ¼ller, F., et al. (2025, July). <em>A Survey of Context Engineering for Large Language Models</em>. <em>arXiv preprint</em>.</p>
</li>
<li>
<p><strong>Comprehensive academic survey reviewing context engineering techniques, challenges, and future research directions.</strong>
     <a href="https://arxiv.org/pdf/2507.13334">https://arxiv.org/pdf/2507.13334</a></p>
</li>
<li>
<p>Haseeb, M., et al. (2025, August). <em>Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code</em>. <em>arXiv preprint</em>.</p>
</li>
<li>
<p><strong>Proposes a multi-agent workflow combining intent translation, semantic retrieval, document synthesis, and Claude Code to improve code generation and validation in large codebases.</strong>
     <a href="https://arxiv.org/html/2508.08322v1">https://arxiv.org/html/2508.08322v1</a></p>
</li>
<li>
<p>Hua, Q., Ye, L., Fu, D., Xiao, Y., Cai, X., Wu, Y., Lin, J., Wang, J., &amp; Liu, P. (2025, October). <em>Context Engineering 2.0: The Context of Context Engineering</em>. <em>arXiv preprint</em>.</p>
</li>
<li>
<p><strong>Foundational position paper that situates context engineering historically, defines it as entropy reduction between human intentions and machine-readable representations, and introduces a four-era framework with design considerations for context collection, management, and usage.</strong>
     <a href="https://arxiv.org/abs/2510.26493">https://arxiv.org/abs/2510.26493</a></p>
</li>
</ol>
<hr />
<h3 id="context_engineering-context-blogs-articles">Blogs &amp; Articles<a class="headerlink" href="#context_engineering-context-blogs-articles" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>Martin, R. L. (2025, June). <em>Context Engineering</em>.</p>
</li>
<li>
<p><strong>Blog post introducing principles of context engineering for AI systems, including prompt design, retrieval, and orchestration strategies.</strong>
     <a href="https://rlancemartin.github.io/2025/06/23/context_engineering/">https://rlancemartin.github.io/2025/06/23/context_engineering/</a></p>
</li>
<li>
<p>Schmid, P. (2025, June). <em>Context Engineering: Optimizing Prompts and Retrieval for LLMs</em>.</p>
</li>
<li>
<p><strong>Detailed exploration of context engineering patterns and their practical application in LLM development.</strong>
     <a href="https://www.philschmid.de/context-engineering">https://www.philschmid.de/context-engineering</a></p>
</li>
<li>
<p>LlamaIndex (2025, June). <em>Context Engineering â€“ What it is, and techniques to consider</em>.</p>
</li>
<li>
<p><strong>Official blog post from LlamaIndex outlining core techniques in context engineering for enterprise AI assistants.</strong>
     <a href="https://www.llamaindex.ai/blog/context-engineering-what-it-is-and-techniques-to-consider">https://www.llamaindex.ai/blog/context-engineering-what-it-is-and-techniques-to-consider</a></p>
</li>
<li>
<p>Datacamp (2025, June). <em>Context Engineering: The Next Frontier of AI Development</em>.</p>
</li>
<li>
<p><strong>Educational article explaining how context engineering enhances AI reliability, accuracy, and enterprise integration.</strong>
     <a href="https://www.datacamp.com/blog/context-engineering">https://www.datacamp.com/blog/context-engineering</a></p>
</li>
<li>
<p>Landgraf, T. (2025, August). <em>Context Engineering for Claude Code: Mastering Deep Technical Knowledge</em>.</p>
</li>
<li>
<p><strong>Medium article introducing advanced context engineering workflows for Claude Code, including knowledge-file creation, project architecture awareness, and technical validation.</strong>
     <a href="https://medium.com/%40tl_99311/context-engineering-for-claude-code-mastering-deep-technical-knowledge-bae14f158289">https://medium.com/%40tl_99311/context-engineering-for-claude-code-mastering-deep-technical-knowledge-bae14f158289</a></p>
</li>
<li>
<p>Breunig, D. (2025, June). <em>How to Fix Your Context</em>.</p>
</li>
<li>
<p><strong>Practical guide to diagnosing long-context failures and applying tactics like RAG, tool loadouts, quarantine, pruning, summarization, and offloading to stabilize agent behavior.</strong>
     <a href="https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html">https://www.dbreunig.com/2025/06/26/how-to-fix-your-context.html</a></p>
</li>
<li>
<p>LangChain. (n.d.). <em>Context engineering in agents</em>.</p>
<ul>
<li><strong>Official LangChain documentation page explaining context engineering as the core of reliable agents, with middleware patterns for managing model, tool, and life-cycle context.</strong>
  <a href="https://docs.langchain.com/oss/python/langchain/context-engineering">https://docs.langchain.com/oss/python/langchain/context-engineering</a></li>
</ul>
</li>
<li>
<p>LangChain. (2025, July). <em>Context Engineering</em>.</p>
<ul>
<li><strong>LangChain blog post (â€œContext Engineering for Agentsâ€) organizing context engineering strategies into write, select, compress, and isolate patterns, with concrete examples from real agents.</strong>
  <a href="https://blog.langchain.com/context-engineering-for-agents/">https://blog.langchain.com/context-engineering-for-agents/</a></li>
</ul>
</li>
<li>
<p>Osmani, A. (2024, July). <em>Context Engineering: Bringing Engineering Discipline to Prompts</em>.</p>
<ul>
<li><strong>Substack essay framing context engineering as bringing software-engineering discipline and information architecture to prompt and context design for production AI systems.</strong>
  <a href="https://addyo.substack.com/p/context-engineering-bringing-engineering">https://addyo.substack.com/p/context-engineering-bringing-engineering</a></li>
</ul>
</li>
</ol>
<hr />
<h3 id="context_engineering-context-open-source-repositories-tools">Open Source Repositories &amp; Tools<a class="headerlink" href="#context_engineering-context-open-source-repositories-tools" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>Kimai, D. (2025, July). <em>Context-Engineering (GitHub Repository)</em>.</p>
<ul>
<li><strong>Open-source repository providing frameworks and examples for implementing context engineering strategies in real-world projects.</strong>
  <a href="https://github.com/davidkimai/Context-Engineering">https://github.com/davidkimai/Context-Engineering</a></li>
</ul>
</li>
<li>
<p><em>Context Engineering Template</em> (2025, August). <em>Context-Engineering-Intro (GitHub Repository)</em>.</p>
<ul>
<li><strong>Template repository by coleam00 for setting up Claude Code-based context engineering projects, including examples, global rules, and workflows.</strong>
  <a href="https://github.com/coleam00/context-engineering-intro">https://github.com/coleam00/context-engineering-intro</a></li>
</ul>
</li>
</ol>
<hr />
<h3 id="context_engineering-context-media-visualizations">Media &amp; Visualizations<a class="headerlink" href="#context_engineering-context-media-visualizations" title="Permanent link">&para;</a></h3>
<ol>
<li>
<p>Youtube (2025, September). <em>Elite Context Engineering with Claude Code</em> â€” IndyDevDan [Video].</p>
<ul>
<li><strong>Advanced context engineering techniques using Claude Code, as presented by IndyDevDan.</strong>
  <a href="https://www.youtube.com/watch?v=Kf5-HWJPTIE">https://www.youtube.com/watch?v=Kf5-HWJPTIE</a> ([YouTube][1])</li>
</ul>
</li>
<li>
<p>Youtube (2025, September). <em>Context Engineering for Agents â€” Lance Martin, LangChain</em> [Video].</p>
<ul>
<li><strong>Discussion on context engineering specifically for agent frameworks, by Lance Martin from LangChain.</strong>
  <a href="https://www.youtube.com/watch?v=_IlTcWciEC4">https://www.youtube.com/watch?v=_IlTcWciEC4</a> ([YouTube][2])</li>
</ul>
</li>
<li>
<p>Droid, L. (2025, July). <em>Context Engineering Visualization</em>.</p>
<ul>
<li><strong>Illustrative summary of context engineering techniques, shared via social media.</strong>
  <a href="https://x.com/lenadroid/status/1943685060785524824/photo/1">https://x.com/lenadroid/status/1943685060785524824/photo/1</a></li>
</ul>
</li>
<li>
<p>Youtube (2025, September). <em>Advanced Context Engineering for Agents â€” Dexter Horthy</em> [Video].</p>
<ul>
<li><strong>Walks through why naive back-and-forth prompting fails, how spec-first development keeps teams aligned, and why â€œeverything is context engineering.â€ From compaction strategies to subagents and planning workflows, he shows how intentional context management turns AI coding from prototypes into production.</strong>
  <a href="https://www.youtube.com/watch?v=IS_y40zY-hc">https://www.youtube.com/watch?v=IS_y40zY-hc</a> ([YouTube][3])</li>
</ul>
</li>
</ol>
<hr />
<h2 id="context_engineering-context-takeaways">Takeaways<a class="headerlink" href="#context_engineering-context-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Key Takeaways</p>
<ul>
<li><strong>Treat the Context Window Like a CPU Cache, Not a Hard Drive:</strong> The core principle is to keep the primary agent's context minimal and focusedâ€”containing only the immediate goal, instructions, and a small slice of relevant data. Offload history, large documents, and non-essential tools to external memory to improve speed, reduce cost, and avoid distraction.</li>
<li><strong>Reduce and Delegate, Don't Accumulate:</strong> Instead of bloating a single agent's context, delegate heavy or specialized tasks to sub-agents or background agents. These agents work in their own isolated contexts and return only concise, distilled reports, enabling complex work without overwhelming the primary agent.</li>
<li><strong>Context Must Be Actively Managed, Not Passively Appended:</strong> Implement dynamic strategies like just-in-time retrieval (RAG), summarization, and context isolation to ensure the model always has high-quality, relevant information. Actively defend against common failure modes like poisoning and confusion by verifying inputs and filtering irrelevant data.</li>
</ul>
</div></section>
                        <h2 class='nav-section-title' id='section-prompt-engineering'>
                            Prompt Engineering <a class='headerlink' href='#section-prompt-engineering' title='Permanent link'>â†µ</a>
                        </h2>
                        <section class="print-page" id="prompt_engineering-prompt_engineering"><h1 id="prompt_engineering-prompt_engineering-prompt-engineering">Prompt Engineering<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-engineering" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>A large part of working LLMs is knowing how to prompt them to get the information you want.</p>
<p>ChatGPTo will be used here but the techniques apply in general to any LLM.</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>With newer Reasoning models, there is less of a need for extensive prompts.</p>
<p>But this Prompt Guidance is still applicable.</p>
</div>
<h2 id="prompt_engineering-prompt_engineering-prompt-guides">Prompt Guides<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-guides" title="Permanent link">&para;</a></h2>
<p>There are many books, guides, and articles on Prompt Engineering. Some of the better ones are listed here:</p>
<ol>
<li><a href="https://www.promptingguide.ai/">Prompt Engineering Guide</a> </li>
<li><a href="https://platform.openai.com/docs/guides/prompt-engineering">OpenAI Prompt Engineering Guide</a> </li>
<li><a href="https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api">Best practices for prompt Engineering with the OpenAI API</a></li>
<li><a href="https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf">Google Gemini Prompting guide 101 - A quick-start handbook for effective prompts, April 2024 edition</a></li>
<li><a href="https://towardsdatascience.com/how-i-won-singapores-gpt-4-prompt-engineering-competition-34c195a93d41">How I Won Singaporeâ€™s GPT-4 Prompt Engineering Competition</a>, Dec 2023</li>
<li><a href="https://www.oreilly.com/library/view/prompt-engineering-for/9781098153427/">Prompt Engineering for Generative AI Book</a>, May 2024</li>
<li><a href="https://ai.google.dev/gemini-api/docs/prompting-strategies">Google Prompt design strategies</a> </li>
<li><a href="https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview">Anthropic Prompt Engineering overview</a> </li>
<li><a href="https://medium.com/the-modern-scientist/best-prompt-techniques-for-best-llm-responses-24d2ff4f6bca">Best Prompt Techniques for Best LLM Responses</a>, Feb 2024</li>
</ol>
<h2 id="prompt_engineering-prompt_engineering-prompt-taxonomy">Prompt Taxonomy<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-taxonomy" title="Permanent link">&para;</a></h2>
<h3 id="prompt_engineering-prompt_engineering-prompt-taxonomy-turn-expression-level-of-details-role">Prompt Taxonomy Turn, Expression, Level of Details, Role<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-taxonomy-turn-expression-level-of-details-role" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="Guide" src="../assets/images/promptTaxonomy.png" /></p>
</figure>
<p>The above proposed Prompt Taxonomy is TELeR: Turn, Expression, Level of Details, Role from  <a href="https://arxiv.org/pdf/2305.11430">TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks</a></p>
<h3 id="prompt_engineering-prompt_engineering-prompt-taxonomy-26-guiding-principles">Prompt Taxonomy 26 Guiding Principles<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-taxonomy-26-guiding-principles" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="Guide" src="../assets/images/prompt_principles_cat.png" /> </p>
</figure>
<p>The above "26 guiding principles designed to streamline the process of querying and prompting large language models" is from <a href="https://arxiv.org/pdf/2312.16171">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a></p>
<h2 id="prompt_engineering-prompt_engineering-prompt-tactics">Prompt Tactics<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompt-tactics" title="Permanent link">&para;</a></h2>
<p>Some tactics I find particularly useful:</p>
<ol>
<li>Ask the LLM to generate the prompt.<ol>
<li>Do this in 2 parts (task decomposition)<ol>
<li>Ask the LLM what techniques are best to use for effective prompt engineering</li>
<li>Ask the LLM to create a prompt using these techniques for the objective and example you specify</li>
</ol>
</li>
</ol>
</li>
<li>Ask the LLM to provide a confidence score for their answer. <ol>
<li>People can be fooled by the fluency of LLMs aka hallucinations </li>
<li>LLMs know how confident they are in their answer.</li>
<li>So asking an LLM to rate their confidence in the answer can reduce blind trust.</li>
</ol>
</li>
<li>Ask the LLM (or a different LLM) to review the answer and provide improvements.</li>
</ol>
<h3 id="prompt_engineering-prompt_engineering-ask-the-llm-to-generate-the-prompt">Ask the LLM to generate the prompt<a class="headerlink" href="#prompt_engineering-prompt_engineering-ask-the-llm-to-generate-the-prompt" title="Permanent link">&para;</a></h3>
<h4 id="prompt_engineering-prompt_engineering-ask-the-llm-what-techniques-are-best-to-use-for-effective-prompt-engineering">Ask the LLM what techniques are best to use for effective prompt engineering?<a class="headerlink" href="#prompt_engineering-prompt_engineering-ask-the-llm-what-techniques-are-best-to-use-for-effective-prompt-engineering" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="Guide" src="../assets/images/prompting1.png" />
<img alt="Guide" src="../assets/images/prompting1_2.png" /></p>
</figure>
<h4 id="prompt_engineering-prompt_engineering-ask-the-llm-to-create-a-prompt-using-these-techniques-for-the-objective-and-example-you-specify">Ask the LLM to create a prompt using these techniques for the objective and example you specify<a class="headerlink" href="#prompt_engineering-prompt_engineering-ask-the-llm-to-create-a-prompt-using-these-techniques-for-the-objective-and-example-you-specify" title="Permanent link">&para;</a></h4>
<figure>
<p><img alt="Guide" src="../assets/images/prompting3.png" /></p>
</figure>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#prompt_engineering-prompt_engineering-__codelineno-0-1"></a>_functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#prompt_engineering-prompt_engineering-__codelineno-0-2"></a>
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#prompt_engineering-prompt_engineering-__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#prompt_engineering-prompt_engineering-__codelineno-0-4"></a>#CVE# _functions.php in cpCommerce 1.2.x, possibly including 1.2.9, sends a redirect but does not exit when it is called directly, which allows remote attackers to bypass a protection mechanism to conduct remote file inclusion and directory traversal attacks, execute arbitrary PHP code, or read arbitrary files via the GLOBALS[prefix] parameter, a different vector than CVE-2003-1500.
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#prompt_engineering-prompt_engineering-__codelineno-0-5"></a>#IMPACT# Remote Code Execution, Information Disclosure, Security Bypass
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#prompt_engineering-prompt_engineering-__codelineno-0-6"></a>#RATIONALE# The description specifies multiple potential impacts:
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#prompt_engineering-prompt_engineering-__codelineno-0-7"></a>1. **Remote Code Execution**: The ability to &quot;execute arbitrary PHP code&quot; directly implies a high severity impact where an attacker can run malicious code on the affected system.
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#prompt_engineering-prompt_engineering-__codelineno-0-8"></a>2. **Information Disclosure**: The mention of &quot;read arbitrary files&quot; suggests that attackers can access sensitive information stored in files.
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#prompt_engineering-prompt_engineering-__codelineno-0-9"></a>3. **Security Bypass**: The bypass of a protection mechanism to conduct remote file inclusion and directory traversal attacks implies that security controls are being circumvented.
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#prompt_engineering-prompt_engineering-__codelineno-0-10"></a>#CONFIDENCE# 95
</code></pre></div>
<figure>
<p><img alt="Guide" src="../assets/images/prompting_classification1.png" /></p>
</figure>
<h3 id="prompt_engineering-prompt_engineering-ask-the-llm-to-review-the-answer-and-provide-improvements">Ask the LLM to review the answer and provide improvements.<a class="headerlink" href="#prompt_engineering-prompt_engineering-ask-the-llm-to-review-the-answer-and-provide-improvements" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="Guide" src="../assets/images/prompting_classification2.png" /></p>
</figure>
<h3 id="prompt_engineering-prompt_engineering-llm-tools-to-improve-prompts">LLM Tools to Improve Prompts<a class="headerlink" href="#prompt_engineering-prompt_engineering-llm-tools-to-improve-prompts" title="Permanent link">&para;</a></h3>
<p>In addition to using LLMs to generate prompts (aka Meta Prompts), and review prompts in an adhoc manner via the chat interface, there are various tools that use LLMs to improve prompts:</p>
<ol>
<li><a href="#prompt_engineering-fabric-fabric-prompt-to-improve-prompts">Fabric Prompt to Improve Prompts</a></li>
<li><a href="https://www.anthropic.com/news/evaluate-prompts">Anthropic Console supports testing and improving prompts</a> (for Anthropic - but likely the resulting prompt would be portable to other LLMs)<ol>
<li>Claude can generate prompts, create test variables, and show you the outputs of prompts side by side.</li>
<li><a href="https://x.com/AnthropicAI/status/1810747792807342395">https://x.com/AnthropicAI/status/1810747792807342395</a></li>
</ol>
</li>
<li><a href="https://aistudio.google.com/app/gallery">Google Prompt Gallery</a> </li>
</ol>
<h3 id="prompt_engineering-prompt_engineering-prompts-used-in-various-code-generation-tools">Prompts used in various Code Generation Tools<a class="headerlink" href="#prompt_engineering-prompt_engineering-prompts-used-in-various-code-generation-tools" title="Permanent link">&para;</a></h3>
<p><a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools">https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools</a></p>
<p>FULL v0, Cursor, Manus, Same.dev, Lovable, Devin, Replit Agent, Windsurf Agent &amp; VSCode Agent (And other Open Sourced) System Prompts, Tools &amp; AI Models.</p>
<p>These are useful as reference examples.</p>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Getting the right prompt to get what you want out of an LLM can sometimes feel like art or interrogation. There are several options covered here:<ol>
<li>Prompt Templates</li>
<li>Prompt Frameworks</li>
<li>Ask an LLM to generate a prompt</li>
<li>LLM-based tools for prompt refinement</li>
</ol>
</li>
</ol>
</div></section><section class="print-page" id="prompt_engineering-fabric"><h1 id="prompt_engineering-fabric-fabric">Fabric<a class="headerlink" href="#prompt_engineering-fabric-fabric" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>One of Fabric's primary features is helping people collect and integrate prompts</p>
</div>
<h2 id="prompt_engineering-fabric-fabric-prompt-collection-and-framework">Fabric Prompt Collection and Framework<a class="headerlink" href="#prompt_engineering-fabric-fabric-prompt-collection-and-framework" title="Permanent link">&para;</a></h2>
<p><a href="https://github.com/danielmiessler/fabric/tree/main">https://github.com/danielmiessler/fabric/tree/main</a> </p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Since the start of 2023 and GenAI we've seen a massive number of AI applications for accomplishing tasks. It's powerful, but it's not easy to integrate this functionality into our lives.</p>
<p>In other words, AI doesn't have a capabilities problemâ€”it has an integration problem.
Fabric was created to address this by enabling everyone to granularly apply AI to everyday challenges.</p>
<p>One of fabric's primary features is helping people collect and integrate prompts, which we call Patterns, into various parts of their lives.</p>
</div>
<p>The prompts (aka Patterns) are available at <a href="https://github.com/danielmiessler/fabric/tree/main/patterns">https://github.com/danielmiessler/fabric/tree/main/patterns</a></p>
<h3 id="prompt_engineering-fabric-fabric-prompts-for-cybersecurity">Fabric Prompts for CyberSecurity<a class="headerlink" href="#prompt_engineering-fabric-fabric-prompts-for-cybersecurity" title="Permanent link">&para;</a></h3>
<p>Fabric has Prompts that are specific to CyberSecurity e.g.</p>
<ul>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/create_threat_model/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/create_threat_model/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_logs/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_logs/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_malware/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_malware/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report_trends/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/analyze_threat_report_trends/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/write_hackerone_report/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/write_hackerone_report/system.md</a></li>
<li><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/write_semgrep_rule/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/write_semgrep_rule/system.md</a> </li>
</ul>
<h3 id="prompt_engineering-fabric-fabric-prompt-to-improve-prompts">Fabric Prompt to Improve Prompts<a class="headerlink" href="#prompt_engineering-fabric-fabric-prompt-to-improve-prompts" title="Permanent link">&para;</a></h3>
<p><a href="https://github.com/danielmiessler/fabric/blob/main/patterns/improve_prompt/system.md">https://github.com/danielmiessler/fabric/blob/main/patterns/improve_prompt/system.md</a></p>
<h3 id="prompt_engineering-fabric-fabric-extract-wisdom">Fabric Extract Wisdom<a class="headerlink" href="#prompt_engineering-fabric-fabric-extract-wisdom" title="Permanent link">&para;</a></h3>
<p>We'll take <a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf">Goldman Sachs, Top of Mind, Gen AI: Too Much Spend, Too Little Benefit?</a>, June 2024 as the example content to extract wisdom from. It's a 30 page report that is dense and varied.</p>
<p>Below the summary by Claude 3.5 Sonnet using the <a href="https://github.com/danielmiessler/fabric/blob/main/patterns/extract_article_wisdom/system.md">extract_article_wisdom prompt</a>.   </p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#prompt_engineering-fabric-__codelineno-0-1"></a>SUMMARY
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#prompt_engineering-fabric-__codelineno-0-2"></a>Goldman Sachs analyzes AI&#39;s economic impact, discussing potential benefits, challenges, and investment implications in their &quot;Top of Mind&quot; report.
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#prompt_engineering-fabric-__codelineno-0-3"></a>
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#prompt_engineering-fabric-__codelineno-0-4"></a>IDEAS
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#prompt_engineering-fabric-__codelineno-0-5"></a>
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#prompt_engineering-fabric-__codelineno-0-6"></a>AI could increase US productivity by 9% and GDP growth by 6.1% over the next decade.
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#prompt_engineering-fabric-__codelineno-0-7"></a>The current AI investment boom may be unsustainable, with potential for a market correction.
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#prompt_engineering-fabric-__codelineno-0-8"></a>Power demand from AI data centers could lead to a significant energy crunch in the coming years.
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#prompt_engineering-fabric-__codelineno-0-9"></a>AI&#39;s economic impact may be more limited than many expect, with only 4.6% of tasks potentially automated within a decade.
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#prompt_engineering-fabric-__codelineno-0-10"></a>The semiconductor industry faces supply constraints that could limit AI growth in the near term.
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#prompt_engineering-fabric-__codelineno-0-11"></a>Utilities companies are emerging as unexpected beneficiaries of the AI boom due to increased power demand.
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#prompt_engineering-fabric-__codelineno-0-12"></a>AI technology may struggle to replicate human cognitive abilities, limiting its transformative potential.
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#prompt_engineering-fabric-__codelineno-0-13"></a>The cost of AI infrastructure is currently high, raising questions about return on investment.
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#prompt_engineering-fabric-__codelineno-0-14"></a>AI&#39;s impact on corporate profitability will be crucial for long-term equity returns.
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#prompt_engineering-fabric-__codelineno-0-15"></a>The AI theme in the stock market may have room to run despite recent gains.
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#prompt_engineering-fabric-__codelineno-0-16"></a>Data centers could consume up to 8% of total US power demand by 2030.
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#prompt_engineering-fabric-__codelineno-0-17"></a>AI development is outpacing the ability of power infrastructure to support it.
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#prompt_engineering-fabric-__codelineno-0-18"></a>The US may struggle to build the necessary infrastructure to support AI growth.
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#prompt_engineering-fabric-__codelineno-0-19"></a>AI spending by tech giants is not seen as irrational exuberance by some analysts.
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#prompt_engineering-fabric-__codelineno-0-20"></a>The AI investment cycle is still in the infrastructure buildout phase, with applications yet to emerge.
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#prompt_engineering-fabric-__codelineno-0-21"></a>European power demand could increase by 40-50% over the next decade due to AI and electrification.
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#prompt_engineering-fabric-__codelineno-0-22"></a>AI data centers can consume up to 10 times more energy than traditional data centers.
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#prompt_engineering-fabric-__codelineno-0-23"></a>The US utility industry has not experienced significant load growth in almost two decades.
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#prompt_engineering-fabric-__codelineno-0-24"></a>AI chip demand is outstripping supply, particularly for High-Bandwidth Memory technology.
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#prompt_engineering-fabric-__codelineno-0-25"></a>The pace of AI model improvements may be slower than many anticipate.
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#prompt_engineering-fabric-__codelineno-0-26"></a>
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#prompt_engineering-fabric-__codelineno-0-27"></a>QUOTES
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#prompt_engineering-fabric-__codelineno-0-28"></a>
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#prompt_engineering-fabric-__codelineno-0-29"></a>&quot;Given the focus and architecture of generative AI technology today... truly transformative changes won&#39;t happen quickly and fewâ€”if anyâ€”will likely occur within the next 10 years.&quot; - Daron Acemoglu
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#prompt_engineering-fabric-__codelineno-0-30"></a>&quot;AI technology is exceptionally expensive, and to justify those costs, the technology must be able to solve complex problems, which it isn&#39;t designed to do.&quot; - Jim Covello
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#prompt_engineering-fabric-__codelineno-0-31"></a>&quot;Spending is certainly high today in absolute dollar terms. But this capex cycle seems more promising than even previous capex cycles.&quot; - Kash Rangan
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#prompt_engineering-fabric-__codelineno-0-32"></a>&quot;The devil is ultimately in the details. So, I don&#39;t have a strong prior as to how much of the current investment boom will be wasted vs. productive. But I expect both will happen.&quot; - Daron Acemoglu
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#prompt_engineering-fabric-__codelineno-0-33"></a>&quot;Until we reach a level of saturation in terms of human capacity to consume data, any amount of efficiency gains will undoubtedly be gobbled up by even more demand.&quot; - Brian Janous
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#prompt_engineering-fabric-__codelineno-0-34"></a>&quot;The risk that our children or grandchildren in 2074 accuse us of moving too slowly in 2024 at the expense of growth seems far lower than the risk that we end up moving too quickly and destroy institutions, democracy, and beyond in the process.&quot; - Daron Acemoglu
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#prompt_engineering-fabric-__codelineno-0-35"></a>&quot;I&#39;m loathe to use the word &#39;bubble&#39; because I don&#39;t believe that AI is a bubble, but most bubbles in history ended either because the cost of capital changed dramatically or end-demand deteriorated and affected companies&#39; ability to deploy capital, not because companies retreated from investing in a technology where the payoff was taking longer than expected.&quot; - Eric Sheridan
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#prompt_engineering-fabric-__codelineno-0-36"></a>&quot;Utilities have not experienced a period of load growth in almost two decades and are not prepared forâ€”or even capable of matchingâ€”the speed at which AI technology is developing.&quot; - Brian Janous
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#prompt_engineering-fabric-__codelineno-0-37"></a>&quot;The US has unfortunately lost the ability to build large infrastructure projectsâ€”this is a task better suited for 1930s America, not 2030s America.&quot; - Brian Janous
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#prompt_engineering-fabric-__codelineno-0-38"></a>&quot;Every human invention should be celebrated, and generative AI is a true human invention. But too much optimism and hype may lead to the premature use of technologies that are not yet ready for prime time.&quot; - Daron Acemoglu
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#prompt_engineering-fabric-__codelineno-0-39"></a>
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#prompt_engineering-fabric-__codelineno-0-40"></a>FACTS
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#prompt_engineering-fabric-__codelineno-0-41"></a>
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#prompt_engineering-fabric-__codelineno-0-42"></a>Data centers currently account for only about 1% of global power demand.
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#prompt_engineering-fabric-__codelineno-0-43"></a>The US utility industry has not experienced significant load growth in almost two decades.
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#prompt_engineering-fabric-__codelineno-0-44"></a>60% of workers today are employed in occupations that did not exist in 1940.
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#prompt_engineering-fabric-__codelineno-0-45"></a>The US corporate profit share of GDP is near its highest levels since World War II.
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#prompt_engineering-fabric-__codelineno-0-46"></a>Northern Virginia is home to the most data centers in the US.
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#prompt_engineering-fabric-__codelineno-0-47"></a>Commercial power consumption in Virginia rose 37% from 2016 to 2023.
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#prompt_engineering-fabric-__codelineno-0-48"></a>AI data centers can consume up to 10 times more energy than traditional data centers.
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#prompt_engineering-fabric-__codelineno-0-49"></a>The average power usage effectiveness (PUE) of cloud data centers declined by only 0.2 over the course of a decade.
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#prompt_engineering-fabric-__codelineno-0-50"></a>Wait times for power projects to connect to the grid currently range from 40-70 months.
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#prompt_engineering-fabric-__codelineno-0-51"></a>The High-Bandwidth Memory market is expected to grow at a ~100% compound annual growth rate over the next few years.
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#prompt_engineering-fabric-__codelineno-0-52"></a>The S&amp;P 500 Shiller P/E ratio is currently in the 97th percentile since 1900.
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#prompt_engineering-fabric-__codelineno-0-53"></a>Utilities returned 16% between March and May, making them the best-performing sector in the S&amp;P 500.
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#prompt_engineering-fabric-__codelineno-0-54"></a>European electricity consumption has declined by around 10% from its 2008 peak.
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#prompt_engineering-fabric-__codelineno-0-55"></a>TSMC&#39;s Chip-on-Wafer-on-Substrate packaging capacity is expected to more than double in 2024.
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#prompt_engineering-fabric-__codelineno-0-56"></a>The US is expected to add nearly 800 gigawatts of wind and solar over the coming 10-15 years.
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#prompt_engineering-fabric-__codelineno-0-57"></a>
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#prompt_engineering-fabric-__codelineno-0-58"></a>REFERENCES
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#prompt_engineering-fabric-__codelineno-0-59"></a>
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#prompt_engineering-fabric-__codelineno-0-60"></a>ChatGPT
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#prompt_engineering-fabric-__codelineno-0-61"></a>Global Macro Research by Goldman Sachs
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#prompt_engineering-fabric-__codelineno-0-62"></a>MIT&#39;s Daron Acemoglu&#39;s research
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#prompt_engineering-fabric-__codelineno-0-63"></a>Jim Covello&#39;s analysis
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#prompt_engineering-fabric-__codelineno-0-64"></a>Joseph Briggs&#39; economic forecasts
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#prompt_engineering-fabric-__codelineno-0-65"></a>Kash Rangan and Eric Sheridan&#39;s market analysis
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#prompt_engineering-fabric-__codelineno-0-66"></a>Brian Janous&#39; insights on power infrastructure
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#prompt_engineering-fabric-__codelineno-0-67"></a>Carly Davenport&#39;s utility sector analysis
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#prompt_engineering-fabric-__codelineno-0-68"></a>Toshiya Hari, Anmol Makkar, and David Balaban&#39;s semiconductor industry research
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#prompt_engineering-fabric-__codelineno-0-69"></a>Ryan Hammond&#39;s equity market analysis
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#prompt_engineering-fabric-__codelineno-0-70"></a>Christian Mueller-Glissmann&#39;s long-term return forecasting framework
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#prompt_engineering-fabric-__codelineno-0-71"></a>Alberto Gandolfi&#39;s European utilities analysis
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#prompt_engineering-fabric-__codelineno-0-72"></a>Hongcen Wei&#39;s power consumption analysis
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#prompt_engineering-fabric-__codelineno-0-73"></a>David Autor&#39;s research on technological innovation and employment
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#prompt_engineering-fabric-__codelineno-0-74"></a>Robert Shiller&#39;s P/E ratio data
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#prompt_engineering-fabric-__codelineno-0-75"></a>EIA (Energy Information Administration) data
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#prompt_engineering-fabric-__codelineno-0-76"></a>Census Bureau data
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#prompt_engineering-fabric-__codelineno-0-77"></a>FactSet financial data
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#prompt_engineering-fabric-__codelineno-0-78"></a>TSMC&#39;s capacity projections
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#prompt_engineering-fabric-__codelineno-0-79"></a>REPowerEU Plan
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#prompt_engineering-fabric-__codelineno-0-80"></a>
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#prompt_engineering-fabric-__codelineno-0-81"></a>RECOMMENDATIONS
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#prompt_engineering-fabric-__codelineno-0-82"></a>
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#prompt_engineering-fabric-__codelineno-0-83"></a>Investors should remain invested in AI infrastructure providers despite high valuations.
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#prompt_engineering-fabric-__codelineno-0-84"></a>Utilities companies should find ways to extract more efficiencies from the current power system.
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#prompt_engineering-fabric-__codelineno-0-85"></a>Policymakers should focus on investing in America&#39;s transmission infrastructure.
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#prompt_engineering-fabric-__codelineno-0-86"></a>Companies should tie AI spending to visible revenue growth to maintain investor confidence.
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#prompt_engineering-fabric-__codelineno-0-87"></a>Investors should consider &quot;Electrification Compounders&quot; in the utilities sector as potential beneficiaries of AI growth.
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#prompt_engineering-fabric-__codelineno-0-88"></a>The US should prioritize expanding long-duration energy storage to meet growing power demand.
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#prompt_engineering-fabric-__codelineno-0-89"></a>Tech companies should prepare for potential power constraints when planning AI infrastructure.
<a id="__codelineno-0-90" name="__codelineno-0-90" href="#prompt_engineering-fabric-__codelineno-0-90"></a>Investors should monitor the emergence of AI&#39;s &quot;killer application&quot; as a sign of the technology&#39;s maturity.
<a id="__codelineno-0-91" name="__codelineno-0-91" href="#prompt_engineering-fabric-__codelineno-0-91"></a>Policymakers should address regulatory lags and interconnection constraints in the power sector.
<a id="__codelineno-0-92" name="__codelineno-0-92" href="#prompt_engineering-fabric-__codelineno-0-92"></a>Companies should be cautious about premature use of AI technologies that are not yet fully developed.
<a id="__codelineno-0-93" name="__codelineno-0-93" href="#prompt_engineering-fabric-__codelineno-0-93"></a>Investors should watch for signs of corporate profitability decline as a potential trigger for reduced AI spending.
<a id="__codelineno-0-94" name="__codelineno-0-94" href="#prompt_engineering-fabric-__codelineno-0-94"></a>The semiconductor industry should focus on expanding High-Bandwidth Memory and advanced packaging capacity.
<a id="__codelineno-0-95" name="__codelineno-0-95" href="#prompt_engineering-fabric-__codelineno-0-95"></a>Utilities should prepare for a potential doubling of grid capacity in some regions over the next decade.
<a id="__codelineno-0-96" name="__codelineno-0-96" href="#prompt_engineering-fabric-__codelineno-0-96"></a>Investors should consider the impact of AI on corporate profitability when assessing long-term equity returns.
<a id="__codelineno-0-97" name="__codelineno-0-97" href="#prompt_engineering-fabric-__codelineno-0-97"></a>Policymakers should balance the need for AI innovation with potential risks to institutions and democracy.
</code></pre></div>
<h3 id="prompt_engineering-fabric-process-youtube-transcripts">Process Youtube Transcripts<a class="headerlink" href="#prompt_engineering-fabric-process-youtube-transcripts" title="Permanent link">&para;</a></h3>
<p>Fabric, and LLMs in general, can process Youtube Transcripts (which are text).</p>
<p>The Youtube Transcript for a video can be retrieved in different ways e.g. <a href="https://www.youtube.com/watch?v=oMZN810xfck">https://www.youtube.com/watch?v=oMZN810xfck</a>:</p>
<ul>
<li>Click the Transcript button under a video and copy and paste, or download, to a text file</li>
<li>Use Fabric helper function: <a href="https://github.com/danielmiessler/fabric/blob/main/installer/client/cli/yt.py">installer/client/cli/yt.py</a> (or other tool)</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#prompt_engineering-fabric-__codelineno-1-1"></a>yt --transcript https://www.youtube.com/watch?v=oMZN810xfck
</code></pre></div>
The text can then be processed with an LLM.</p>
<p>This download and processing can be done in one command with Fabric
<div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#prompt_engineering-fabric-__codelineno-2-1"></a>yt --transcript https://www.youtube.com/watch?v=oMZN810xfck | fabric -sp extract_wisdom
</code></pre></div>
where</p>
<ul>
<li>-s is for streaming</li>
<li>-p is for pattern</li>
<li><a href="https://github.com/danielmiessler/fabric/tree/main/patterns/extract_wisdom">extract_wisdom</a> is the Fabric prompt that extracts wisdom from any text. It addresses the problem of too much content and too little time.</li>
</ul>
<h2 id="prompt_engineering-fabric-takeaways">Takeaways<a class="headerlink" href="#prompt_engineering-fabric-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Fabric is a good resource for prompts with many being related to CyberSecurity.</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: Prompt Engineering</h1><h1 class='nav-section-title-end'>Ended: Context Engineering</h1>
                        <h1 class='nav-section-title' id='section-software-engineering'>
                            Software Engineering <a class='headerlink' href='#section-software-engineering' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="software-overview"><h1 id="software-overview-overview">Overview<a class="headerlink" href="#software-overview-overview" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Abstract</p>
<p>This Software Engineering section explores how AI is fundamentally transforming software engineering, from changing development paradigms to redefining the role of traditional artifacts. </p>
<p>It covers immutable principles that remain constant regardless of who or what creates the software, and examines the evolving landscape of AI-powered development tools.</p>
</div>
<h2 id="software-overview-1-how-ai-is-changing-software-engineering">1. <a href="#software-introduction">How AI is Changing Software Engineering</a><a class="headerlink" href="#software-overview-1-how-ai-is-changing-software-engineering" title="Permanent link">&para;</a></h2>
<p>An examination of software engineering's evolution through three distinct eras: traditional Waterfall methodologies, Agile development with its emphasis on communication over documentation, and the current AI-driven transformation.</p>
<p>The analysis traces two parallel developments: </p>
<ol>
<li><strong>Software 2.0</strong> where "AI is eating software" by replacing traditional algorithms with neural networks, </li>
<li><strong>Software 1.0 Redux</strong> where "AI is feeding software" through generative tools that accelerate traditional development (introducing the concept of "Vibe Coding").</li>
</ol>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li><strong>Accelerated Innovation</strong>: AI compresses idea-to-prototype cycles from weeks to minutes, fundamentally changing development velocity</li>
<li><strong>Inverted Priorities</strong>: Upstream artifacts (requirements, architecture, contracts) become primary deliverables, while code becomes a generated byproduct</li>
<li><strong>Evolved Skill Sets</strong>: Success now requires mastering requirements engineering, system architecture, and human-AI collaboration alongside traditional coding skills</li>
<li><strong>New Paradigms</strong>: We're witnessing both Software 2.0 (AI eating software) and Software 1.0 Redux (AI feeding traditional development), each suited to different problem domains</li>
</ul>
<h2 id="software-overview-2-software-assurance">2. <a href="#software-software_assurance">Software Assurance</a><a class="headerlink" href="#software-overview-2-software-assurance" title="Permanent link">&para;</a></h2>
<p>A comprehensive overview of Software Assurance fundamentals that remain constant across all Software Development Life Cycle (SDLC) methodologies and development entities. This section covers the immutable principles that govern quality software development.</p>
<ul>
<li><strong>verification</strong> ("Are you building it right?") versus <strong>validation</strong> ("Are you building the right thing?")</li>
<li>fundamental architectural principles including the Laws of Software Architecture and how quality attributes drive design decisions.</li>
</ul>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>The software requirements specification is the key artifact that distinguishes verification activities from validation activities</li>
<li>Understanding the <strong>what</strong> (requirements) independent of the <strong>how</strong> (design) is crucial</li>
<li>The <strong>why</strong> for the <strong>how</strong> (captured in Architecture Decision Records) is paramount: "Why is more important than how"</li>
<li>Everything in software architecture involves trade-offs</li>
<li>Quality attributes are the primary drivers of architectural design</li>
</ul>
<h2 id="software-overview-3-software-artifacts">3. <a href="#software-software_artifacts">Software Artifacts</a><a class="headerlink" href="#software-overview-3-software-artifacts" title="Permanent link">&para;</a></h2>
<p>Building on the foundational concepts from the previous sections, this explores how software engineering artifacts are evolving from passive documentation into <strong>active contracts</strong> that guide AI-driven code generation and system behavior.</p>
<p>As AI transforms development workflows, these artifacts become the core deliverables that specify system requirements, architecture, and behavior in machine-readable formats that AI tools can directly consume and act upon.</p>
<p><strong>Key Takeaways:</strong></p>
<ol>
<li><strong>Precision Over Brevity</strong> - AI needs explicit, unambiguous specifications</li>
<li><strong>Machine-Readable Formats</strong> - Use structured data (JSON, YAML, Markdown with frontmatter)</li>
<li><strong>Version Everything</strong> - Track changes to specifications alongside generated code</li>
<li><strong>Automate Validation</strong> - Ensure AI outputs meet specification requirements</li>
<li><strong>Maintain Traceability</strong> - Link generated code back to originating specifications</li>
</ol>
<h2 id="software-overview-4-ai-coding-tools">4. <a href="#software-code-code_assistant_agents">AI Coding Tools</a><a class="headerlink" href="#software-overview-4-ai-coding-tools" title="Permanent link">&para;</a></h2>
<p>A comprehensive analysis of AI-powered development tools, categorized by autonomy levels from basic code completion to autonomous feature development. This classification helps developers understand the capabilities and limitations of different tools.</p>
<p>The comparison spans from Level 1 (basic autocomplete) through Level 4 (autonomous agents), with Level 5 remaining theoretical. The analysis shows how AI tools are progressively taking on more of the coding burden, allowing developers to focus on higher-level concerns.</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>Tools range from simple code completion to autonomous feature development</li>
<li>Developers can mix and match tools based on autonomy levels and specific needs</li>
<li>Understanding each tool's autonomy level is crucial for effective adoption</li>
<li>The field evolves rapidly, with tools advancing between autonomy levels frequently</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See also <a href="../assets/docs/IDEs_Feature_Comparison.pdf">Feature Comparison and Analysis of Leading AI IDEs: Cursor, Windsurf, Roo Code, and GitHub Copilot, May 27, 2025</a>.</p>
</div>
<h2 id="software-overview-5-leaderboards">5. <a href="#software-code-leaderboards">Leaderboards</a><a class="headerlink" href="#software-overview-5-leaderboards" title="Permanent link">&para;</a></h2>
<p>A curated collection of benchmarks and evaluation metrics for Large Language Models (LLMs) specifically focused on coding capabilities. These leaderboards provide objective measures for comparing the performance of different AI models in software development tasks.</p>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li>Leaderboards are a good way to quantitatively and objectively compare solutions.</li>
<li>Comparison across multiple metrics and leaderboards avoids solutions that overfit to a benchmark.</li>
</ul>
<hr />
<h2 id="software-overview-takeaways">Takeaways<a class="headerlink" href="#software-overview-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Key Takeaways</p>
<p>This Software Engineering section demonstrates how AI is not merely automating existing processes but fundamentally reshaping software engineering. While core principles like verification, validation, and architectural trade-offs remain constant, the methods of implementation are evolving rapidly. The shift toward AI-driven development emphasizes the critical importance of well-defined specifications and requirements as the new primary deliverables, with generated code becoming a secondary artifact.</p>
<p>Success in this new paradigm requires mastering both traditional software engineering principles and emerging AI collaboration skills, understanding when to apply different levels of AI autonomy, and maintaining quality through robust specification and validation processes.</p>
</div></section><section class="print-page" id="software-introduction"><h1 id="software-introduction-how-ai-is-changing-software-engineering">How AI is Changing Software Engineering<a class="headerlink" href="#software-introduction-how-ai-is-changing-software-engineering" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section gives an overview of Software Engineering and how it has evolved with AI and Generative AI.</p>
<p>It looks at the early days of Software Engineering and the transition from Waterfall to Agile - and the emphasis on communication over code and documentation. </p>
<p>Then it looks at how AI gave us Software 2.0 where "AI is <strong>eating</strong> software", and how Generative AI gave us Software 1.0 <strong>Redux</strong> where "AI is <strong>feeding</strong> software" (and Vibe Coding).</p>
<p><a href="https://en.wikipedia.org/wiki/Andrej_Karpathy">Andrej Karpathy</a> quotes are used throughout as a consistent commentary from someone who has been formative in this space.</p>
</div>
<p>Software engineering </p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Software engineering is a branch of both computer science and engineering focused on <strong>designing, developing, testing, and maintaining software applications</strong>. It involves applying engineering principles and computer programming expertise to develop software systems that meet user needs.</p>
<p><a href="https://en.wikipedia.org/wiki/Software_engineering">https://en.wikipedia.org/wiki/Software_engineering</a></p>
</div>
<h2 id="software-introduction-evolution-of-software-engineering-as-communication-over-code">Evolution of Software Engineering as Communication over Code<a class="headerlink" href="#software-introduction-evolution-of-software-engineering-as-communication-over-code" title="Permanent link">&para;</a></h2>
<p>Effective software development depends fundamentally on clear communication between all stakeholdersâ€”from business experts to developers to end users. The evolution from rigid, document-heavy approaches to collaborative, feedback-driven methodologies illustrates how the industry has learned to prioritize human communication over process documentation.</p>
<h3 id="software-introduction-the-waterfall-challenge">The Waterfall Challenge<a class="headerlink" href="#software-introduction-the-waterfall-challenge" title="Permanent link">&para;</a></h3>
<p>The <a href="https://en.wikipedia.org/wiki/Waterfall_model">Waterfall model</a> dominated software development for decades through its linear, sequential approach. However, this methodology created significant communication barriers. Requirements, design documents, and other pre-coding artifacts quickly became outdated as projects progressed. The code itself became the only reliable source of truth, but most stakeholders couldn't understand it.</p>
<p>This disconnect between documentation and reality often led teams to solve the wrong problems. The fundamental issue was the lack of continuous feedback loops between those who understood the business needs and those building the software.</p>
<h3 id="software-introduction-the-agile-response">The Agile Response<a class="headerlink" href="#software-introduction-the-agile-response" title="Permanent link">&para;</a></h3>
<p>During the 1990s, <a href="https://en.wikipedia.org/wiki/Agile_software_development">lightweight development methodologies emerged</a> in response to these heavyweight, document-centric approaches. <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile software development</a> became the most influential of these approaches, emphasizing iterative development, continuous feedback, and direct collaboration between business stakeholders and development teams.</p>
<p>Rather than relying on comprehensive documentation, Agile methodologies prioritize working software and frequent communication. This shift recognized that software development is fundamentally a collaborative, creative process that benefits from ongoing dialogue rather than upfront specification.</p>
<h3 id="software-introduction-the-language-of-collaboration">The Language of Collaboration<a class="headerlink" href="#software-introduction-the-language-of-collaboration" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/doublediamondprocess.png" /></p>
</figure>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See the Design Council's <a href="https://medium.com/design-council/developing-our-new-systemic-design-framework-e0f74fe118f7">Systemic Design Framework</a> for an evolution of the Double Diamond that recognizes the importance of the 'invisible activities' that sit around the design process: orientation and value setting, continuing the journey, collaboration and connection, and leadership and storytelling.</p>
</div>
<p>Software engineering thought leaders have consistently emphasized how critical shared understanding becomes in successful projects.</p>
<ul>
<li>
<p><a href="https://agilemodeling.com/essays/communication.htm">Alistair Cockburn's research</a> demonstrated that face-to-face communication, particularly when enhanced by shared modeling tools like whiteboards, represents the most effective form of team communication. His work on <a href="https://alistaircockburn.com/">communication effectiveness</a> showed that physical proximity and multiple communication modalities dramatically improve information transfer and reduce misunderstandings.</p>
</li>
<li>
<p>Eric Evans, in his foundational work on <a href="https://www.domainlanguage.com/">Domain-Driven Design</a>, introduced the concept of <a href="https://martinfowler.com/bliki/UbiquitousLanguage.html">"ubiquitous language"</a>â€”a shared vocabulary that bridges the gap between business experts and technical teams. This common language emerges from ongoing collaboration and becomes embedded in both conversations and code, ensuring that business terminology permeates throughout the software system.</p>
</li>
<li>
<p><a href="https://dannorth.net/">Dan North</a> extended these ideas when developing <a href="https://dannorth.net/introducing-bdd/">Behavior-Driven Development (BDD)</a>, creating frameworks that use natural language constructs to describe software behavior in terms that all stakeholders can understand. BDD treats the specification of desired behavior as a ubiquitous language for the entire project team, helping prevent communication breakdowns between developers and business stakeholders.</p>
</li>
</ul>
<p>These approaches share a common insight: <strong>successful software development requires more than technical expertiseâ€”it demands ongoing communication, shared vocabulary, and collaborative understanding of both the problem domain and the solution being built.</strong></p>
<h2 id="software-introduction-software-20">Software 2.0<a class="headerlink" href="#software-introduction-software-20" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/andrey.jpeg" /></p>
</figure>
<p>The emergence of artificial intelligence is fundamentally changing how we think about software development.</p>
<p>In 2017, Andrej Karpathy introduced the concept of "Software 2.0" to describe this transformation, where traditional human-written code gives way to AI-generated solutions.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Software (1.0) is eating the world, and now AI (Software 2.0) is eating software.</p>
<p>The "classical stack" of Software 1.0 is what we're all familiar with â€” it is written in languages such as Python, C++, etc. It consists of explicit instructions to the computer written by a programmer. By writing each line of code, the programmer identifies a specific point in program space with some desirable behavior.</p>
<p>In contrast, Software 2.0 is written in much more abstract, human unfriendly language, such as the weights of a neural network. No human is involved in writing this code because there are a lot of weights (typical networks might have millions), and coding directly in weights is kind of hard.</p>
<p>In Software 1.0, human-engineered source code (e.g. some .cpp files) is compiled into a binary that does useful work. </p>
<p>In Software 2.0 most often the source code comprises </p>
<ol>
<li>the dataset that defines the desirable behavior and </li>
<li>the neural net architecture that gives the rough skeleton of the code, but with many details (the weights) to be filled in.</li>
</ol>
<p>It is likely that any setting where the program is not obvious but one can repeatedly evaluate the performance of it (e.g. â€” did you classify some images correctly? do you win games of Go?) will be subject to this transition, because the optimization can find much better code than what a human can write.</p>
<p>Andrej Karpathy, Nov 11, 2017 <a href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>"Software (1.0) is eating the world" is a reference to "Why Software Is Eating the World", Marc Andreessen, 2011.</p>
<p><a href="https://a16z.com/why-software-is-eating-the-world/">https://a16z.com/why-software-is-eating-the-world/</a> where a16z is "<strong>A</strong>ndreessenHorowit<strong>z</strong>."</p>
</div>
<h3 id="software-introduction-software-20-example-tesla-autopilot-transition-from-c-code-to-ai">Software 2.0 Example: Tesla Autopilot transition from C++ code to AI<a class="headerlink" href="#software-introduction-software-20-example-tesla-autopilot-transition-from-c-code-to-ai" title="Permanent link">&para;</a></h3>
<p>Tesla's Autopilot system demonstrates this transition in practice. As Karpathy explained:</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Neural network can eat through the [programming] stackâ€¦ When I joined Tesla, there was a ton of C++ code, and now there's much, much less C++ code in the code that runs in the car. </p>
<p>Neural network initially was just doing a detection on the image level, then it went for multiple images, it gives you prediction, then multiple images over time give you a prediction, and you're discarding C++ code. And eventually you're just giving steering commands.</p>
<p>â€¦ I do suspect that the end-to-end systems for Tesla in, say, 10 years, it is just a neural net. I mean, the videos stream into a neural net and commands come out.</p>
<p><a href="https://www.linkedin.com/pulse/andrej-karpathy-8-big-ideas-mikael-alemu-gorsky-eckuf/">https://www.linkedin.com/pulse/andrej-karpathy-8-big-ideas-mikael-alemu-gorsky-eckuf/</a></p>
</div>
<p>This evolution illustrates how AI systems can progressively replace traditional programmatic logic, moving toward end-to-end neural networks that process inputs and generate outputs directly.</p>
<h3 id="software-introduction-data-as-the-new-source-code">Data as the New Source Code<a class="headerlink" href="#software-introduction-data-as-the-new-source-code" title="Permanent link">&para;</a></h3>
<p>In this Software 2.0 world, datasets become the primary artifact of development.</p>
<p><a href="https://huggingface.co/">Hugging Face</a> has emerged as "Software 2.0's GitHub," hosting over <a href="https://huggingface.co/datasets">400K+ datasets</a> alongside <a href="https://huggingface.co/models">1.7M+ models,</a> where repositories contain datasets and commits represent additions and edits of labels rather than code changes.</p>
<p>This shift fundamentally changes how we think about version control, collaboration, and the artifacts that define our systems. The focus moves from managing code repositories to curating and versioning the data that trains our AI systems.</p>
<p>As Karpathy noted:</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Github is a very successful home for Software 1.0 code. Is there space for a Software 2.0 Github? In this case repositories are datasets and commits are made up of additions and edits of the labels.</p>
<p><a href="https://karpathy.medium.com/software-2-0-a64152b37c35">https://karpathy.medium.com/software-2-0-a64152b37c35</a></p>
</div>
<h2 id="software-introduction-software-30">Software 3.0<a class="headerlink" href="#software-introduction-software-30" title="Permanent link">&para;</a></h2>
<p>Software 3.0 is using English to program LLMs. </p>
<p>The LLM can be programmed to </p>
<ul>
<li>carry out the end action e.g. sentiment classification.</li>
<li>write code to carry out the end action e.g. a web or mobile app.</li>
</ul>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Software 1.0 is code, 2.0 was weights of tightly scoped ML models, 3.0 is using English to program LLMs.
Just like how in certain use cases software 2.0 would â€œeat awayâ€ at software 1.0 code, software 3.0 will now eat away at a lot of places where we would previously have used 1.0/2.0
<a href="https://x.com/ethanniser/status/1935056628350599473">https://x.com/ethanniser/status/1935056628350599473</a> </p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>We are witnessing the rise of a new paradigm: Software 3.0.
If traditional coding was Software 1.0, and neural networks trained on data represented Software 2.0, Software 3.0 is where your prompts directly program LLMs
<a href="https://x.com/huwng_tran/status/1935052873769042115">https://x.com/huwng_tran/status/1935052873769042115</a> </p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>There is new category of consumer/manipulator of digital information:</p>
<ul>
<li>Humans (GUIs)</li>
<li>Computers (APIs)</li>
<li>NEW: Agents &lt;- computers... but human-like</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">Andrej Karpathy: Software Is Changing (Again)</a></p>
</div>
<p>This new category of consumer/manipulator is in line with "From People to Machines as Consumers/Customers/Creators" per <a href="#software-introduction-thoughts-on-the-future-from-the-past">thoughts-on-the-future-from-the-past</a>.</p>
<h2 id="software-introduction-software-10-redux">Software 1.0 Redux<a class="headerlink" href="#software-introduction-software-10-redux" title="Permanent link">&para;</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>"Software 1.0 <strong>Redux</strong>" refers to how fundamental software engineering principles remain unchanged, but the development process itself has been transformed by Generative AI and LLMs. All traditional artifacts become even more relevant as AI-generated code depends on high-quality specifications.</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>"The hottest new programming language is English."  </p>
<p>â€”<a href="https://x.com/karpathy/status/1617979122625712128">Andrej Karpathy on X/Twitter, 2023</a> </p>
</div>
<p>Not all problems are suited to the Software 2.0 paradigm of neural networks replacing traditional code.</p>
<p>For such problems, Large Language Models (LLMs) are transforming how we write traditional software, creating what we might call "Software 1.0 <strong>Redux</strong>", where AI feeds and enhances traditional software, rather than eating it Ã  la Software 2.0.</p>
<ul>
<li>While AI handles low-level implementation details, human developers are elevated to higher levels of abstraction, using natural language to specify intent and behavior.</li>
<li>The skill shifts from syntax mastery to effective requirements management, architecture, and system design, and clean coding principles.</li>
</ul>
<h3 id="software-introduction-thoughts-on-the-future-from-the-past">Thoughts on the Future from the Past<a class="headerlink" href="#software-introduction-thoughts-on-the-future-from-the-past" title="Permanent link">&para;</a></h3>
<p>In the past, I captured some thoughts publicly on how I thought the future of software would play out.</p>
<p>These predictions have materialized through today's Generative AI tools, though at the time the Generative AI that we take for granted today did not exist.</p>
<h4 id="software-introduction-more-continuity-between-requirements-documentation-test-sw">More Continuity between Requirements â€“ Documentation â€“ Test â€“ SW<a class="headerlink" href="#software-introduction-more-continuity-between-requirements-documentation-test-sw" title="Permanent link">&para;</a></h4>
<p>Six years ago (March 2019), as part of a presentation on <a href="../assets/docs/DevSecOps_v0201.pdf">DevSecOps - Thoughts from the Trenches</a>, I concluded with my view of the next 10 years:</p>
<figure>
<p><img alt="" src="../assets/images/devsecops_10yrs.png" /></p>
</figure>
<p>For "More Continuity between Requirements â€“ Documentation â€“ Test â€“ SW", these points were already playing out at that time:</p>
<ul>
<li>Less heavy lifting required by people to build software</li>
<li>The breadth and depth and rate of change of new technologies means that developers can't keep pace</li>
<li>Value moves further up the stack â€“ the lower layers become commodities</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The "More Continuity between Requirements â€“ Documentation â€“ Test â€“ SW" is now playing out as "Software 1.0 Redux" where the non-code artifacts (requirements, architecture and design documentation, tests, user documentation) become the contracts from which code is generated by LLMsâ€”and the code becomes more of a byproduct. These contracts are maintained and versioned alongside the code.</p>
<p>Natural language prompts have become first-class citizens in development workflows, allowing developers to specify intent at higher levels of abstraction while AI handles implementation details. Prompt engineering is an important skill currently, though the need for prompt engineering diminishes with more capable models (e.g. Reasoning, Research).</p>
</div>
<h4 id="software-introduction-diagrams-as-code">Diagrams as Code<a class="headerlink" href="#software-introduction-diagrams-as-code" title="Permanent link">&para;</a></h4>
<p>Five years ago (May 2020), as part of a "<a href="https://crashedmind.github.io/PlantUMLHitchhikersGuide/about/future.html?highlight=machine#machine-processing-of-text-files">Thoughts For The Future</a>" chapter for <a href="https://crashedmind.github.io/PlantUMLHitchhikersGuide/">The Hitchhiker's Guide to PlantUML!</a> (linked from <a href="https://www.plantuml.com">plantuml.com</a>), I wrote:</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>1.3. Machine Processing Of Text Files</p>
<p>Having a diagram source as a text file is powerful because it allows for machine processing e.g.</p>
<ol>
<li>
<p>If standard building blocks are used, it allows automated analysis and recognition of the diagram text source, and recommendations to the user e.g. if an arrow text includes "TLS" to indicate the link is secured, then an external program can provide recommendations on TLS protocol version, cipher-suites etcâ€¦</p>
</li>
<li>
<p>As companies move towards standard architecture icon sets (AWS, MS/Azure, Google,â€¦), it is possible to process an existing architecture diagram image with optical recognition (and machine learning) and create the text (plantuml) equivalent.</p>
</li>
</ol>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Having diagrams as code that can live beside the system code, that the stakeholders are equally comfortable editing and viewing, reduces the gap i.e. "Where system diagrams meet system reality"</p>
<p><a href="https://crashedmind.github.io/PlantUMLHitchhikersGuide/about/AboutPlantUML.html#diagrams-as-code">https://crashedmind.github.io/PlantUMLHitchhikersGuide/about/AboutPlantUML.html#diagrams-as-code</a></p>
</div>
<p>I felt strongly enough about this that I wrote a guide on PlantUML, a diagram-as-code tool.</p>
<div class="admonition experiment">
<p class="admonition-title">Experiment</p>
<p>One of my first experiments with an LLM (text-only) was to ask it to do a security review of a diagram-as-code architecture.</p>
<p>And when multi-modal LLMs became available, with a diagram-as-image architecture.</p>
</div>
<h3 id="software-introduction-validation-through-current-ai-tools">Validation Through Current AI Tools<a class="headerlink" href="#software-introduction-validation-through-current-ai-tools" title="Permanent link">&para;</a></h3>
<p>These predictions have materialized through today's generative AI tools:</p>
<ul>
<li>e.g. <a href="https://support.anthropic.com/en/articles/9487310-what-are-artifacts-and-how-do-i-use-them">Claude's Artifacts feature</a> exemplifies the upstream artifacts concept, allowing users to generate substantial, standalone content like code snippets, documents, or website designs that appear in a dedicated window for iterative refinement. Meanwhile, <a href="https://www.anthropic.com/claude-code">Claude Code</a> takes this further by operating directly in the terminal, understanding entire codebases and helping developers code faster by executing routine tasks, explaining complex code, and handling git workflows through natural language commands.</li>
<li>The "diagrams as code" vision has also been realizedâ€”modern AI can now generate Mermaid diagrams, SVG graphics, and complete architecture visualizations from natural language descriptions, then provide contextual analysis including security recommendations and threat modeling based on those diagrams. It can also generate the code given an image.</li>
<li>I've used <a href="#agents-build_agents-architecture">LLMs to create architecture diagrams, and then generate code from those diagrams</a>.</li>
</ul>
<p>But <a href="https://github.com/aws-samples/sample-devgenius-aws-solution-builder/tree/main">AWS DevGenius</a> is a more recent complete example application that exemplifies this.</p>
<h4 id="software-introduction-example-devgenius-aws-solution-generator">Example DevGenius - AWS Solution Generator<a class="headerlink" href="#software-introduction-example-devgenius-aws-solution-generator" title="Permanent link">&para;</a></h4>
<p><a href="https://github.com/aws-samples/sample-devgenius-aws-solution-builder/tree/main">AWS DevGenius</a> (April 2025) is an example of this.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>DevGenius is an AI-powered application that transforms project ideas into complete, ready-to-deploy AWS solutions. It leverages Amazon Bedrock and Claude AI models to provide architecture diagrams, cost estimates, infrastructure as code, and comprehensive technical documentation.</p>
<p><strong>Conversational Solution Architecture Building</strong>: DevGenius enables customers to design solution architectures in a conversational manner. Users can create architecture diagrams (in draw.io format) and refine them interactively. Once the design is finalized, they can generate end-to-end code automation using CDK or CloudFormation templates, and deploy it in their AWS account with a single click. Additionally, customers can receive cost estimates for running the architecture in production, along with detailed documentation for the solution.</p>
<p><strong>Build Solution Architecture from Whiteboard Drawings</strong>: For customers who already have their architecture in image form (e.g., whiteboard drawings), DevGenius allows them to upload the image. Once uploaded, DevGenius analyzes the architecture and provides a detailed explanation. Customers can then refine the design conversationally and, once finalized, generate end-to-end code automation using CDK or CloudFormation. Cost estimates and comprehensive documentation are also available.</p>
</div>
<h3 id="software-introduction-from-code-centric-to-contract-centric-development">From Code-Centric to Contract-Centric Development<a class="headerlink" href="#software-introduction-from-code-centric-to-contract-centric-development" title="Permanent link">&para;</a></h3>
<p>This transformation reflects a broader trend toward what <a href="https://a16z.com/nine-emerging-developer-patterns-for-the-ai-era/">a16z calls</a> "upstream artifacts" becoming the primary deliverables:</p>
<blockquote>
<p>In agent-driven workflows, code becomes a byproductâ€”like a compiled artifactâ€”while high-level inputs become the core deliverable. Code becomes the byproduct of those inputs, more like a compiled artifact than a manually authored source.</p>
</blockquote>
<h4 id="software-introduction-the-new-development-hierarchy">The New Development Hierarchy<a class="headerlink" href="#software-introduction-the-new-development-hierarchy" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Traditional (Software 1.0)</th>
<th>AI-Enhanced (Software 1.0 Redux)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Primary Artifact</strong></td>
<td>Code</td>
<td>Requirements, contracts, specifications</td>
</tr>
<tr>
<td><strong>Developer Role</strong></td>
<td>Implementation focused</td>
<td>Architecture and validation focused</td>
</tr>
<tr>
<td><strong>Skill Emphasis</strong></td>
<td>Syntax, algorithms, debugging</td>
<td>Requirements engineering, system design</td>
</tr>
<tr>
<td><strong>Version Control</strong></td>
<td>Code changes</td>
<td>Contract changes + generated artifacts</td>
</tr>
</tbody>
</table>
<h4 id="software-introduction-critical-upstream-artifacts">Critical Upstream Artifacts<a class="headerlink" href="#software-introduction-critical-upstream-artifacts" title="Permanent link">&para;</a></h4>
<p>The most valuable artifacts in AI-driven development become the specifications that guide code generation:</p>
<table>
<thead>
<tr>
<th>Artifact Category</th>
<th>Examples</th>
<th>AI-Centric Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Requirements</strong></td>
<td>User stories, acceptance criteria, functional specs</td>
<td>Clear evaluation targets for AI validation</td>
</tr>
<tr>
<td><strong>Architecture &amp; Design</strong></td>
<td>ADRs, system diagrams, API contracts</td>
<td>Unambiguous constraints for code generation</td>
</tr>
<tr>
<td><strong>Data &amp; Schemas</strong></td>
<td>JSON schemas, database models, API specifications</td>
<td>Structured templates for consistent output</td>
</tr>
<tr>
<td><strong>Security &amp; Compliance</strong></td>
<td>Threat models, security policies, audit requirements</td>
<td>Automated guardrails and validation rules</td>
</tr>
</tbody>
</table>
<h3 id="software-introduction-everything-as-code-the-infrastructure-precedent">Everything-as-Code: The Infrastructure Precedent<a class="headerlink" href="#software-introduction-everything-as-code-the-infrastructure-precedent" title="Permanent link">&para;</a></h3>
<p>This shift toward specification-driven development builds on existing "everything-as-code" movements:</p>
<ul>
<li><strong>Infrastructure as Code</strong> (Terraform, CloudFormation)</li>
<li><strong>Policy as Code</strong> (Open Policy Agent)</li>
<li><strong>Diagrams as Code</strong> (Mermaid, PlantUML)</li>
<li><strong>Configuration as Code</strong> (Kubernetes manifests)</li>
</ul>
<p>These approaches already demonstrated the value of maintaining human-readable specifications that generate operational artifacts. AI extends this pattern to application code itself.</p>
<h3 id="software-introduction-blurred-boundaries-developer-roles-evolve">Blurred Boundaries: Developer Roles Evolve<a class="headerlink" href="#software-introduction-blurred-boundaries-developer-roles-evolve" title="Permanent link">&para;</a></h3>
<p>The lines between traditional software engineering roles are blurring:</p>
<p><strong>Developer + Requirements Analyst:</strong> Developers must now excel at translating business needs into precise specifications that AI can implement reliably.</p>
<p><strong>Human + Machine Collaboration:</strong> Success requires understanding both what AI can do well (pattern matching, code generation) and what humans do better (creative problem-solving, architectural judgment).</p>
<p>This evolution suggests developers will spend less time on implementation minutiae and more time on:</p>
<ul>
<li><strong>System design</strong> and architectural decision-making</li>
<li><strong>Requirements engineering</strong> and specification writing  </li>
<li><strong>Quality validation</strong> of AI-generated outputs</li>
<li><strong>Integration orchestration</strong> across AI and human-created components</li>
</ul>
<h3 id="software-introduction-coding-for-ai-agents-vs-humans">Coding for AI Agents vs. Humans<a class="headerlink" href="#software-introduction-coding-for-ai-agents-vs-humans" title="Permanent link">&para;</a></h3>
<p><a href="https://www.ikangai.com/coding-for-ai-agents-vs-coding-for-human-developers/">Coding for AI Agents vs. Humans, May 2025, Martin Treiber</a></p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>As AI coding assistants and autonomous agents (often powered by large language models) become more involved in software development, best practices in coding must account for a new "audience." Traditionally, code is written by and for human developers, emphasizing readability and maintainability for people. In contrast, code intended to be generated or maintained by AI agents may prioritize different qualities to align with an AI's interpretive capabilities.</p>
<table>
<thead>
<tr>
<th>ASPECT</th>
<th>CODE OPTIMIZED FOR HUMAN DEVS</th>
<th>CODE OPTIMIZED FOR AI AGENTS</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Design &amp; Patterns</strong></td>
<td>Uses established design patterns and abstractions for maintainability; architecture planned with human intuition in mind. <em>E.g.</em> heavily employs DRY and common patterns to avoid duplication.</td>
<td>Prefers straightforward implementations unless instructed otherwise; may duplicate logic or use simpler patterns by default. Requires explicit guidance to enforce complex patterns or project-specific architectures.</td>
</tr>
<tr>
<td><strong>Readability &amp; Naming</strong></td>
<td>Emphasizes self-explanatory code: clear but concise names, standard formatting, and comments only where needed. Relies on code being self-documenting and consistent by convention.</td>
<td>Emphasizes explicit clarity: very descriptive names (the AI doesn't mind length), extremely consistent naming and styling. Heavy inline documentation and docstrings are included to provide context (since AI can update).</td>
</tr>
<tr>
<td><strong>Performance Trade-offs</strong></td>
<td>Prioritizes readability and maintainability; avoids premature optimizations. Optimizes hotspots after profiling, using complex techniques only with justification (and documenting them for colleagues).</td>
<td>Prioritizes correctness and completeness on first pass; optimizations are applied via iteration or prompts. Tends toward robust, error-checked code even if slightly slower. Can leverage known optimizations or libraries.</td>
</tr>
</tbody>
</table>
<p>Ultimately, good code is good code â€“ many best practices overlap whether the consumer is human or AI. Clean architecture, readable style, and efficient execution benefit both. The key differences lie in emphasis: AI agents "read" code differently than humans, so code meant for them leans into consistency, explicit context, and simplicity of structure.</p>
</div>
<h3 id="software-introduction-from-professional-development-to-rapid-prototyping-via-vibe-coding">From Professional Development to Rapid Prototyping via Vibe Coding<a class="headerlink" href="#software-introduction-from-professional-development-to-rapid-prototyping-via-vibe-coding" title="Permanent link">&para;</a></h3>
<p>While professional software engineering requires rigorous practices, AI has also enabled what <a href="https://en.wikipedia.org/wiki/Vibe_coding">Andrej Karpathy terms "vibe coding"</a>â€” a more experimental approach where developers "see things, say things, run things, and copy-paste things, and it mostly works."</p>
<p>Though Karpathy notes this isn't traditional software engineering and has limitations, vibe coding serves an important role in enabling rapid prototyping and proof-of-concepts for both experienced developers and newcomers to programming.</p>
<h2 id="software-introduction-ai-across-the-development-lifecycle">AI Across the Development Lifecycle<a class="headerlink" href="#software-introduction-ai-across-the-development-lifecycle" title="Permanent link">&para;</a></h2>
<p>Tracy Bannon's excellent talk <a href="https://www.infoq.com/presentations/ai-sdlc/">Applying AI to the SDLC: New Ideas and Gotchas! - Leveraging AI to Improve Software Engineering</a> includes a model for where AI can be used with DevSecOps.</p>
<figure>
<p><img alt="" src="../assets/images/ai_devsecops.png" /></p>
</figure>
<p>It demonstrates how AI can enhance every phase of software development:</p>
<table>
<thead>
<tr>
<th>Phase</th>
<th>AI Applications</th>
<th>Current Tools</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Plan &amp; Design</strong></td>
<td>Generate design alternatives, review architectural decisions</td>
<td>Claude Artifacts, GitHub Copilot Chat</td>
</tr>
<tr>
<td><strong>Code</strong></td>
<td>Auto-complete, generate from natural language specs</td>
<td>GitHub Copilot, Claude Code, Cursor</td>
</tr>
<tr>
<td><strong>Test &amp; QA</strong></td>
<td>Auto-generate test cases, intelligent fuzzing</td>
<td>GitHub Copilot, automated testing tools</td>
</tr>
<tr>
<td><strong>Deploy &amp; Ops</strong></td>
<td>Predictive scaling, infrastructure optimization</td>
<td>AI-powered DevOps platforms</td>
</tr>
<tr>
<td><strong>Monitor</strong></td>
<td>Automated root-cause analysis, performance insights</td>
<td>AI monitoring and observability tools</td>
</tr>
</tbody>
</table>
<p>This comprehensive integration shows AI's potential to transform every aspect of the software development lifecycle.</p>
<h2 id="software-introduction-takeaways">Takeaways<a class="headerlink" href="#software-introduction-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Key Takeaways</p>
<ol>
<li>
<p><strong>Accelerated Innovation</strong>: AI compresses idea-to-prototype cycles from weeks to minutes, fundamentally changing development velocity.</p>
</li>
<li>
<p><strong>Inverted Priorities</strong>: Upstream artifacts (requirements, architecture, contracts) become primary deliverables, while code becomes a generated byproduct.</p>
</li>
<li>
<p><strong>Evolved Skill Sets</strong>: Success now requires mastering requirements engineering, system architecture, and human-AI collaboration alongside traditional coding skills.</p>
</li>
<li>
<p><strong>New Paradigms</strong>: We're witnessing both Software 2.0 (AI eating software) and Software 1.0 Redux (AI feeding traditional development), each suited to different problem domains.</p>
</li>
</ol>
</div></section><section class="print-page" id="software-software_assurance"><h1 id="software-software_assurance-software-assurance">Software Assurance<a class="headerlink" href="#software-software_assurance-software-assurance" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section provides a brief overview of Software Assurance fundamentals that are independent of the Software Development Life Cycle (SDLC) <a href="https://en.wikipedia.org/wiki/Software_development_process#Methodologies">Methodology</a> or what entity is creating the software:</p>
<ol>
<li>Software Assurance</li>
<li>Verification and Validation</li>
<li>Architecture<ol>
<li>Laws of Software Architecture</li>
<li>Quality Attributes Drive the Architecture Design</li>
</ol>
</li>
</ol>
<p>It also covers the what, how, and why for the how, of Software Engineering.</p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>"Don't worry about that specification paperwork. We'd better hurry up and start coding, because we're going to have a whole lot of debugging to do."</p>
<p>Verifying And Validating Software Requirements And Design Specifications, Barry Boehm, 1984</p>
</div>
<h2 id="software-software_assurance-software-assurance_1">Software Assurance<a class="headerlink" href="#software-software_assurance-software-assurance_1" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Software assurance aims to ensure the reliability, safety, and security of software products.</p>
<p>Software assurance (SwA) is a critical process in software development that ensures the reliability, safety, and security of software products.</p>
<p>There are several types of software assurance initiatives, including:</p>
<ul>
<li><strong>Certification and accreditation</strong>: These programs establish standards and guidelines for software development, and verify that software products meet these standards. Certification and accreditation can help to ensure that software products are reliable, secure, and compliant with regulations and industry standards.[6]</li>
<li><strong>Training and education</strong>: These initiatives provide software developers with the knowledge and skills they need to create high-quality, secure software. Training and education can include courses on software testing, secure coding practices, and industry standards and best practices.[7]</li>
<li><strong>Code analysis and testing</strong>: These initiatives use tools and techniques to analyze software code and identify defects or vulnerabilities. Code analysis and testing can include static analysis, dynamic analysis, and fuzz testing, among other techniques.[8]</li>
<li><strong>Threat modeling and risk assessment</strong>: These initiatives assess the potential risks and threats to a software system, and identify strategies for mitigating these risks. Threat modeling and risk assessment can help to ensure that software systems are designed to be resilient to attacks and other threats.[21]</li>
</ul>
<p>Software assurance is executed through a series of activities that aim to ensure the reliability, safety, and security of software products. These activities include requirements analysis, design reviews, code inspections, testing, and formal verification.</p>
<p><a href="https://en.wikipedia.org/wiki/Software_assurance">https://en.wikipedia.org/wiki/Software_assurance</a></p>
</div>
<h2 id="software-software_assurance-validation-vs-verification">Validation vs. Verification<a class="headerlink" href="#software-software_assurance-validation-vs-verification" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">verification and validation to resolve issues early in the software life cycle</p>
<p><strong>The basic objectives in verification and validation (V&amp;V) of software requirements and design specifications are to identify and resolve software problems and high-risk issues early in the software life cycle.</strong></p>
<p><strong>Verification</strong> - to establish the truth of the correspondence between a software product and its specification. </p>
<ul>
<li>"Are you building it right?" </li>
</ul>
<p><strong>Validation</strong> - to establish the fitness or worth of a software product for its operational mission.</p>
<ul>
<li>"Are you building the right thing?"</li>
</ul>
<p><strong>Verification</strong> activities begin in the Product Design phase and conclude with the acceptance test. They do not lead to changes in the requirements baseline; only to changes in the refinements descending from it.</p>
<p>On the other hand, <strong>validation</strong> identifies problems which must be resolved by a change of the requirements specification. Thus, there are validation activities which occur throughout the software life cycle, including the development phase. </p>
<ul>
<li>For example, a simulation of the product design may establish not only that the design cannot meet the baseline performance requirements (verification), but also that the performance requirements are too stringent for any cost-effective product designs, and therefore need to be changed (validation).</li>
</ul>
<p>Basic V&amp;V criteria for software requirements and design specifications: </p>
<ul>
<li>completeness</li>
<li>consistency</li>
<li>feasibility</li>
<li>testability</li>
</ul>
<p>Guidelines For Verifying And Validating Software Requirements And Design Specifications, Barry W. Boehm</p>
</div>
<h3 id="software-software_assurance-continuous-validation-and-verification-process">Continuous Validation And Verification Process<a class="headerlink" href="#software-software_assurance-continuous-validation-and-verification-process" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/fig1big.webp.png" />
A continuous validation and verification process. Validation ensures the requirements correctly capture the users' and stakeholders' expectations and should be performed whenever a translation of requirements from one domain to another occurs. <a href="https://www.infoq.com/articles/ieee-verification-and-validation-for-software-systems/">https://www.infoq.com/articles/ieee-verification-and-validation-for-software-systems/</a></p>
</figure>
<p>The <strong>key artifact that distinguishes verification activities from validation activities is the software requirements</strong> specification.</p>
<ul>
<li>This covers <strong>what</strong> the software product will do (but not <strong>how</strong> it will do it; this is to be done in the design specification).</li>
</ul>
<figure>
<p><img alt="" src="../assets/images/VandV.png" />
"Incremental Architecture-centric Validation &amp; Verification Improves Qualification Confidence"
Continuous Verification &amp; Validation of Critical Software via DevSecOps, <a href="https://apps.dtic.mil/sti/pdfs/AD1187382.pdf">https://apps.dtic.mil/sti/pdfs/AD1187382.pdf</a></p>
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>These assurance steps apply independent of the Software Development Life Cycle (SDLC) <a href="https://en.wikipedia.org/wiki/Software_development_process#Methodologies">Methodology</a>. </p>
</div>
<h2 id="software-software_assurance-architecture">Architecture<a class="headerlink" href="#software-software_assurance-architecture" title="Permanent link">&para;</a></h2>
<h3 id="software-software_assurance-laws-of-software-architecture">Laws of Software Architecture<a class="headerlink" href="#software-software_assurance-laws-of-software-architecture" title="Permanent link">&para;</a></h3>
<p><a href="https://www.oreilly.com/library/view/fundamentals-of-software/9781492043447/">Fundamentals of Software Architecture</a>, Mark Richards &amp; Neal Ford, defines some fundamental Laws of Software Architecture.</p>
<h4 id="software-software_assurance-first-law-of-software-architecture">First Law of Software Architecture<a class="headerlink" href="#software-software_assurance-first-law-of-software-architecture" title="Permanent link">&para;</a></h4>
<p><strong>"Everything in software architecture is a trade-off."</strong></p>
<ul>
<li>Corollary 1: If an architect thinks they have discovered something that isn't a trade-off, more likely they just haven't identified the trade-off yet.</li>
</ul>
<h4 id="software-software_assurance-second-law-of-software-architecture">Second Law of Software Architecture<a class="headerlink" href="#software-software_assurance-second-law-of-software-architecture" title="Permanent link">&para;</a></h4>
<p><strong>"Why is more important than how."</strong></p>
<h3 id="software-software_assurance-quality-attributes-drive-the-architecture-design">Quality Attributes Drive The Architecture Design<a class="headerlink" href="#software-software_assurance-quality-attributes-drive-the-architecture-design" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quality Attributes drive the architecture design</p>
<p>Requirements for a software system fall into the following two categories: </p>
<ol>
<li>
<p>Functional requirements: These requirements describe the business capabilities that the system must provide, as well as its behavior at run-time. </p>
</li>
<li>
<p>Non-functional requirements: These requirements describe the "<a href="https://en.wikipedia.org/wiki/ISO/IEC_9126">Quality Attributes</a>" that the system must meet in delivering functional requirements.</p>
</li>
</ol>
<p><strong>Quality Attributes drive the architecture design.</strong></p>
<p><a href="https://www.oreilly.com/library/view/continuous-architecture/9780128032855/">Continuous Architecture: Sustainable Architecture in an Agile and Cloud-Centric World</a></p>
</div>
<h3 id="software-software_assurance-architecture-decision-records-adr">Architecture Decision Records (ADR)<a class="headerlink" href="#software-software_assurance-architecture-decision-records-adr" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">ADRs as a Decision Log</p>
<p>An ADR can help you understand the reasons for a chosen architectural decision, along with its trade-offs and consequences. The collection of ADRs created and maintained in a project constitute its decision log.
<a href="https://adr.github.io/">https://adr.github.io/</a></p>
</div>
<p>ADRs are common e.g.</p>
<ul>
<li><a href="https://learn.microsoft.com/en-us/azure/well-architected/architect-role/architecture-decision-record">Azure Well-Architected Framework ADRs</a></li>
<li><a href="https://docs.aws.amazon.com/prescriptive-guidance/latest/architectural-decision-records/adr-process.html">Amazon AWS ADR Prescriptive Guidance</a></li>
<li><a href="https://cloud.google.com/architecture/architecture-decision-records">Google GCP Architecture</a></li>
</ul>
<div class="admonition quote">
<p class="admonition-title">ADRs as Documentation</p>
<p>Architecture Decision Records can be used as an effective means to document a software architecture. </p>
<ul>
<li>The Context section of an ADR provides an excellent opportunity to describe the specific area of the system that requires an architecture decision to be made. This section also provides an opportunity to describe the alternatives. </li>
<li>Perhaps more important is that the Decision section describes the reasons why a particular decision is made, which is by far the best form of architecture documentation. </li>
<li>The Consequences section adds the final piece to the architecture documentation by describing additional aspects of a particular decision, such as the trade-off analysis of choosing performance over scalability.</li>
</ul>
<p>Chapter 19: Architecture Decisions, <a href="https://www.oreilly.com/library/view/fundamentals-of-software/9781492043447/">Fundamentals of Software Architecture</a>, Mark Richards &amp; Neal Ford</p>
</div>
<h2 id="software-software_assurance-the-what-how-why-of-software-engineering">The What How Why Of Software Engineering<a class="headerlink" href="#software-software_assurance-the-what-how-why-of-software-engineering" title="Permanent link">&para;</a></h2>
<div class="admonition observation">
<p class="admonition-title">People often struggle with what vs how</p>
<p>As a software architect for most of my career, I've seen people (customers and technical people) struggle with the <strong>what vs how</strong>. </p>
<p>They will often specify the implementation details (the <strong>how</strong>), but not <strong>what</strong> they want and why.</p>
<ul>
<li>Or they will specify what they know exists - not what they actually want.</li>
</ul>
<p>I've seen this also in a security context e.g. </p>
<ul>
<li>how: "I want to share a secret key with a trusted 3rd party"<ul>
<li>The wrong thing to do is start by describing secure ways to share keys (which some technical people will do regardless of their seniority)</li>
<li>The right thing to do is ask "why, what are you trying to do? Can you give an example?", but often people don't ask.</li>
</ul>
</li>
<li>what: "I want to give read access to a trusted 3rd party to data on <em>somewhere</em> so they can do <em>something</em>"<ul>
<li>This may not require sharing keys depending on the context. But even if it does require sharing keys, you can give advice appropriate to the use case and context.</li>
</ul>
</li>
</ul>
<div class="admonition quote">
<p class="admonition-title">Framing the "what"</p>
<p>Think of me as a good plumber:</p>
<ol>
<li>Ask for what you want, not what you think you can get. In other words, assume you can have anything you want, now what do you want?</li>
<li>You tell me what features you want. I'll take care of the plumbing details.</li>
</ol>
</div>
</div>
<h3 id="software-software_assurance-what-how-why">What How Why<a class="headerlink" href="#software-software_assurance-what-how-why" title="Permanent link">&para;</a></h3>
<ul>
<li>The <strong>what</strong> is captured in the <strong>Software Requirements</strong>.</li>
<li>The <strong>how</strong> is captured in the <strong>System Design</strong>.</li>
<li>The <strong>why</strong> for the <strong>how</strong> is captured in Decision Records covering the reasons and tradeoffs associated with the decisions. These decisions can be at an Architecture or Design level.</li>
</ul>
<h2 id="software-software_assurance-takeaways">Takeaways<a class="headerlink" href="#software-software_assurance-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<p>The key artifact that distinguishes verification activities from validation activities is the software requirements.</p>
<p>It is important to understand the <strong>what</strong> independent of the <strong>how</strong> (requirements vs design).</p>
<p>It is important to understand the <strong>why</strong> for the <strong>how</strong> (e.g. ADRs) aka </p>
<p>"Why is more important than how."</p>
<p>Everything in software architecture is a trade-off.</p>
<p>Quality Attributes drive the architecture design.</p>
</div></section><section class="print-page" id="software-software_artifacts"><h1 id="software-software_artifacts-software-engineering-artifacts-in-the-ai-era">Software Engineering Artifacts in the AI Era<a class="headerlink" href="#software-software_artifacts-software-engineering-artifacts-in-the-ai-era" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section builds on <a href="#software-introduction">How AI is Changing Software Engineering</a> and <a href="#software-software_assurance">Software Assurance</a> to focus on the Software Engineering artifacts, which are becoming the core deliverable, the <strong>active contracts</strong> that guide code generation and system behavior. </p>
</div>
<h2 id="software-software_artifacts-artifacts">Artifacts<a class="headerlink" href="#software-software_artifacts-artifacts" title="Permanent link">&para;</a></h2>
<h3 id="software-software_artifacts-1-research-discovery">1. Research &amp; Discovery<a class="headerlink" href="#software-software_artifacts-1-research-discovery" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Technical Research Documentation</strong> - Market analysis, technology evaluations, feasibility studies</li>
<li><strong>AI Model Research</strong> - Model selection criteria, capability assessments, performance benchmarks</li>
<li><strong>Competitive Analysis</strong> - Feature comparisons, architectural patterns, industry standards</li>
</ul>
<h3 id="software-software_artifacts-2-requirements-specifications">2. Requirements &amp; Specifications â­<a class="headerlink" href="#software-software_artifacts-2-requirements-specifications" title="Permanent link">&para;</a></h3>
<p><em>These become </em><em>critical contracts</em><em> for AI code generation</em></p>
<ul>
<li><strong>User Stories</strong> with clear acceptance criteria for AI validation</li>
<li><strong>Functional &amp; Non-functional Requirements</strong> - Precise, unambiguous specifications</li>
<li><strong>Use-case Diagrams and Scenarios</strong> - Visual specifications for complex workflows</li>
<li><strong>Feature Backlog</strong> with AI-friendly descriptions and constraints</li>
<li><strong>Prompt Libraries</strong> - Reusable natural language specifications for common patterns</li>
<li><strong>Prompt Engineering Specifications</strong> - Detailed instructions optimized for AI performance and reliability</li>
</ul>
<h3 id="software-software_artifacts-3-architecture-design">3. Architecture &amp; Design â­<a class="headerlink" href="#software-software_artifacts-3-architecture-design" title="Permanent link">&para;</a></h3>
<p><em>Primary artifacts that guide AI implementation</em></p>
<ul>
<li><strong>Architecture Diagrams</strong> (UML, component diagrams, system context)</li>
<li><strong>Architectural Decision Records (ADRs)</strong> - Critical for maintaining AI-generated code consistency</li>
<li><strong>System Design Documents</strong> - High-level constraints and patterns</li>
<li><strong>API Contracts &amp; Specifications</strong> (OpenAPI/Swagger) - Precise interfaces for AI code generation</li>
<li><strong>Data Schemas</strong> (JSON Schema, database models) - Structured templates for consistent output</li>
<li><strong>Diagrams-as-Code</strong> (Mermaid, PlantUML) - Machine-readable architectural specifications</li>
<li><strong>Diagrams-as-Images</strong> (any) - Multi-Modal-LLM-readable architectural specifications</li>
</ul>
<h3 id="software-software_artifacts-4-implementation">4. Implementation<a class="headerlink" href="#software-software_artifacts-4-implementation" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Generated Source Code</strong> - Now a byproduct of upstream specifications</li>
<li><strong>Code Repositories</strong> with enhanced metadata tracking (human vs. AI contributions)</li>
<li><strong>AI Generation Prompts</strong> - Versioned natural language instructions</li>
<li><strong>Code Review Guidelines</strong> for AI-generated code</li>
<li><strong>Refactoring Documentation</strong> - Plans and histories for AI-assisted refactoring</li>
<li><strong>Legacy Migration Plans</strong> - Strategies for AI-assisted modernization</li>
<li><strong>Dataset Management</strong> - Versioning, curation, and labeling of training data as code artifacts</li>
<li><strong>Traceability Matrices</strong> - Automated linkage between specifications, generated code, and test artifacts</li>
<li><strong>Metadata Standards</strong> - Explicit schema for documenting AI contributions vs. human edits, linked to audit trails</li>
</ul>
<h3 id="software-software_artifacts-5-testing-quality-assurance">5. Testing &amp; Quality Assurance<a class="headerlink" href="#software-software_artifacts-5-testing-quality-assurance" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Test Plans</strong> with AI-generated test case specifications</li>
<li><strong>Automated Test Suites</strong> (unit, integration, end-to-end)</li>
<li><strong>AI-Generated Test Cases</strong> - Coverage for edge cases and scenarios</li>
<li><strong>Quality Gates</strong> - Automated validation rules for AI-generated code</li>
<li><strong>Performance Benchmarks</strong> - Baseline metrics for AI optimization</li>
<li><strong>Bug Tracking</strong> with AI-assistance classification and resolution suggestions</li>
</ul>
<h3 id="software-software_artifacts-6-security-compliance">6. Security &amp; Compliance â­<a class="headerlink" href="#software-software_artifacts-6-security-compliance" title="Permanent link">&para;</a></h3>
<p><em>Critical guardrails for AI-generated code</em></p>
<ul>
<li><strong>Threat Models</strong> - Security constraints for AI code generation</li>
<li><strong>Security Policies as Code</strong> - Automated security validation rules</li>
<li><strong>Vulnerability Scans</strong> of AI-generated code</li>
<li><strong>Compliance Checklists</strong> - Regulatory requirements embedded in AI workflows</li>
<li><strong>Audit Trails</strong> - Enhanced tracking of AI-generated changes</li>
<li><strong>Code Reviews</strong> - Code Reviews by AI</li>
</ul>
<h3 id="software-software_artifacts-7-deployment-operations">7. Deployment &amp; Operations<a class="headerlink" href="#software-software_artifacts-7-deployment-operations" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Infrastructure as Code</strong> (IaC) - Terraform, CloudFormation specifications</li>
<li><strong>CI/CD Pipeline Configurations</strong> - Automated deployment workflows</li>
<li><strong>Release Notes</strong> - Generated from commit messages and change logs</li>
<li><strong>Monitoring &amp; Observability</strong> - AI-powered dashboards and alerting</li>
<li><strong>Runbooks</strong> - Operational procedures with AI-assisted troubleshooting</li>
</ul>
<h3 id="software-software_artifacts-8-maintenance-evolution">8. Maintenance &amp; Evolution<a class="headerlink" href="#software-software_artifacts-8-maintenance-evolution" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Change Logs</strong> - Automated tracking of modifications</li>
<li><strong>Incident Response</strong> - AI-assisted root cause analysis</li>
<li><strong>Post-mortem Reports</strong> - Learning from failures with AI insights</li>
<li><strong>Dependency Management</strong> - Automated updates and security patches</li>
<li><strong>Technical Debt Tracking</strong> - AI-identified improvement opportunities</li>
<li><strong>Continuous Improvement Plans</strong> - Strategies integrating feedback loops from operational AI performance to refine specifications and AI model performance over time</li>
</ul>
<h3 id="software-software_artifacts-9-communication-collaboration">9. Communication &amp; Collaboration<a class="headerlink" href="#software-software_artifacts-9-communication-collaboration" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Project Documentation</strong> - Living documents that evolve with the codebase</li>
<li><strong>Team Knowledge Base</strong> - Searchable, AI-enhanced documentation</li>
<li><strong>Decision Logs</strong> - Context for architectural and design choices</li>
<li><strong>User Documentation</strong> - Generated from code and specifications</li>
<li><strong>Training Materials</strong> - AI-assisted onboarding and skill development</li>
<li><strong>Role Definitions for Human-AI Interaction</strong> - Clear delineation of responsibilities, authority, and interaction protocols for AI vs. human developers</li>
<li><strong>Ubiquitous Language Glossaries</strong> - Domain-driven language consistently used across requirements, code, prompts, and AI interactions</li>
</ul>
<hr />
<h2 id="software-software_artifacts-artifact-formats-for-ai-integration">Artifact Formats for AI Integration<a class="headerlink" href="#software-software_artifacts-artifact-formats-for-ai-integration" title="Permanent link">&para;</a></h2>
<p>Multi-modal LLMs can process diverse document formats, but strategic format selection enhances AI comprehension and workflow efficiency.</p>
<h3 id="software-software_artifacts-recommended-primary-formats">Recommended Primary Formats<a class="headerlink" href="#software-software_artifacts-recommended-primary-formats" title="Permanent link">&para;</a></h3>
<p><strong>Markdown (.md)</strong> - <em>Optimal for AI processing</em></p>
<ul>
<li>Semi-structured, lightweight format ideal for LLMs</li>
<li>Human-readable with machine-parseable structure</li>
<li>Supports frontmatter for metadata</li>
<li>Version control friendly</li>
</ul>
<p><strong>Structured Data</strong></p>
<ul>
<li><strong>JSON/YAML</strong> - Configuration files, schemas, API definitions</li>
<li><strong>TOML</strong> - Configuration with human-friendly syntax</li>
<li><strong>CSV</strong> - Tabular data, test cases, requirements matrices</li>
</ul>
<p><strong>Dataset Management Formats</strong> - CSV, Parquet, JSONL for structured training data versioning and curation</p>
<p><strong>Diagrams-as-Code</strong></p>
<ul>
<li><strong>Mermaid</strong> - Flowcharts, sequence diagrams, system architecture</li>
<li><strong>PlantUML</strong> - UML diagrams, component relationships</li>
<li><strong>DOT/Graphviz</strong> - Network diagrams, dependency graphs</li>
</ul>
<h3 id="software-software_artifacts-document-conversion-pipeline">Document Conversion Pipeline<a class="headerlink" href="#software-software_artifacts-document-conversion-pipeline" title="Permanent link">&para;</a></h3>
<p>Modern tools enable seamless format conversion for AI consumption:</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>Input Formats</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/microsoft/markitdown">MarkItDown</a></td>
<td>PDF, DOCX, PPTX, XLSX, Images</td>
<td>Legacy document conversion</td>
</tr>
<tr>
<td><a href="https://github.com/docling-project/docling">Docling</a></td>
<td>PDF, DOCX, HTML, Images</td>
<td>Enterprise document processing</td>
</tr>
<tr>
<td><a href="https://pandoc.org/">Pandoc</a></td>
<td>40+ formats</td>
<td>Universal document conversion</td>
</tr>
</tbody>
</table>
<p><strong>Best Practices:</strong></p>
<ul>
<li>Start with Markdown for new artifacts</li>
<li>Convert legacy documents using automated tools</li>
<li>Use frontmatter for metadata (tags, version, AI instructions)</li>
<li>Maintain original formats alongside Markdown for compliance</li>
</ul>
<p>This approach ensures artifacts remain both human-readable and AI-processable throughout the development lifecycle.</p>
<hr />
<h2 id="software-software_artifacts-ai-enhanced-artifact-workflow">AI-Enhanced Artifact Workflow<a class="headerlink" href="#software-software_artifacts-ai-enhanced-artifact-workflow" title="Permanent link">&para;</a></h2>
<h3 id="software-software_artifacts-traditional-vs-ai-driven-development">Traditional vs. AI-Driven Development<a class="headerlink" href="#software-software_artifacts-traditional-vs-ai-driven-development" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Aspect</th>
<th>Traditional Approach</th>
<th>AI-Enhanced Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Primary Focus</strong></td>
<td>Code implementation</td>
<td>Specification quality</td>
</tr>
<tr>
<td><strong>Artifact Role</strong></td>
<td>Documentation</td>
<td>Active contracts</td>
</tr>
<tr>
<td><strong>Maintenance</strong></td>
<td>Manual updates</td>
<td>Automated synchronization</td>
</tr>
<tr>
<td><strong>Quality Assurance</strong></td>
<td>Post-development review</td>
<td>Continuous validation</td>
</tr>
<tr>
<td><strong>Knowledge Transfer</strong></td>
<td>Human documentation</td>
<td>AI-searchable knowledge base</td>
</tr>
</tbody>
</table>
<h3 id="software-software_artifacts-repository-structure-for-ai-first-development">Repository Structure for AI-First Development<a class="headerlink" href="#software-software_artifacts-repository-structure-for-ai-first-development" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#software-software_artifacts-__codelineno-0-1"></a>project-root/
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#software-software_artifacts-__codelineno-0-2"></a>â”œâ”€â”€ README.md
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#software-software_artifacts-__codelineno-0-3"></a>â”œâ”€â”€ CONTRIBUTING.md
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#software-software_artifacts-__codelineno-0-4"></a>â”œâ”€â”€ .ai/                                    # AI-specific configurations
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#software-software_artifacts-__codelineno-0-5"></a>â”‚   â”œâ”€â”€ prompts/                           # Reusable prompt templates
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#software-software_artifacts-__codelineno-0-6"></a>â”‚   â”œâ”€â”€ models/                            # Model configurations
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#software-software_artifacts-__codelineno-0-7"></a>â”‚   â””â”€â”€ validation/                        # AI output validation rules
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#software-software_artifacts-__codelineno-0-8"></a>â”‚
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#software-software_artifacts-__codelineno-0-9"></a>â”œâ”€â”€ docs/
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#software-software_artifacts-__codelineno-0-10"></a>â”‚   â”œâ”€â”€ system-docs/                       # System-focused documentation
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#software-software_artifacts-__codelineno-0-11"></a>â”‚   â”‚   â”œâ”€â”€ 01-research/
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#software-software_artifacts-__codelineno-0-12"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ technical-research.md
<a id="__codelineno-0-13" name="__codelineno-0-13" href="#software-software_artifacts-__codelineno-0-13"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ ai-model-research.md
<a id="__codelineno-0-14" name="__codelineno-0-14" href="#software-software_artifacts-__codelineno-0-14"></a>â”‚   â”‚   â”‚   â””â”€â”€ competitive-analysis.md
<a id="__codelineno-0-15" name="__codelineno-0-15" href="#software-software_artifacts-__codelineno-0-15"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-16" name="__codelineno-0-16" href="#software-software_artifacts-__codelineno-0-16"></a>â”‚   â”‚   â”œâ”€â”€ 02-requirements/               # â­ CRITICAL for AI generation
<a id="__codelineno-0-17" name="__codelineno-0-17" href="#software-software_artifacts-__codelineno-0-17"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ user-stories.md
<a id="__codelineno-0-18" name="__codelineno-0-18" href="#software-software_artifacts-__codelineno-0-18"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ functional-requirements.md
<a id="__codelineno-0-19" name="__codelineno-0-19" href="#software-software_artifacts-__codelineno-0-19"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ use-case-scenarios.md
<a id="__codelineno-0-20" name="__codelineno-0-20" href="#software-software_artifacts-__codelineno-0-20"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ feature-backlog.md
<a id="__codelineno-0-21" name="__codelineno-0-21" href="#software-software_artifacts-__codelineno-0-21"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ prompt-libraries.md
<a id="__codelineno-0-22" name="__codelineno-0-22" href="#software-software_artifacts-__codelineno-0-22"></a>â”‚   â”‚   â”‚   â””â”€â”€ prompt-engineering-specifications.md
<a id="__codelineno-0-23" name="__codelineno-0-23" href="#software-software_artifacts-__codelineno-0-23"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-24" name="__codelineno-0-24" href="#software-software_artifacts-__codelineno-0-24"></a>â”‚   â”‚   â”œâ”€â”€ 03-architecture/               # â­ PRIMARY contracts
<a id="__codelineno-0-25" name="__codelineno-0-25" href="#software-software_artifacts-__codelineno-0-25"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ architecture-diagrams/
<a id="__codelineno-0-26" name="__codelineno-0-26" href="#software-software_artifacts-__codelineno-0-26"></a>â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ diagrams-as-code/
<a id="__codelineno-0-27" name="__codelineno-0-27" href="#software-software_artifacts-__codelineno-0-27"></a>â”‚   â”‚   â”‚   â”‚   â””â”€â”€ diagrams-as-images/
<a id="__codelineno-0-28" name="__codelineno-0-28" href="#software-software_artifacts-__codelineno-0-28"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ ADR/
<a id="__codelineno-0-29" name="__codelineno-0-29" href="#software-software_artifacts-__codelineno-0-29"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ system-design-documents.md
<a id="__codelineno-0-30" name="__codelineno-0-30" href="#software-software_artifacts-__codelineno-0-30"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ api-contracts/
<a id="__codelineno-0-31" name="__codelineno-0-31" href="#software-software_artifacts-__codelineno-0-31"></a>â”‚   â”‚   â”‚   â””â”€â”€ data-schemas/
<a id="__codelineno-0-32" name="__codelineno-0-32" href="#software-software_artifacts-__codelineno-0-32"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-33" name="__codelineno-0-33" href="#software-software_artifacts-__codelineno-0-33"></a>â”‚   â”‚   â”œâ”€â”€ 04-implementation/
<a id="__codelineno-0-34" name="__codelineno-0-34" href="#software-software_artifacts-__codelineno-0-34"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ generated-source-code/
<a id="__codelineno-0-35" name="__codelineno-0-35" href="#software-software_artifacts-__codelineno-0-35"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ code-repositories-metadata.md
<a id="__codelineno-0-36" name="__codelineno-0-36" href="#software-software_artifacts-__codelineno-0-36"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ ai-generation-prompts.md
<a id="__codelineno-0-37" name="__codelineno-0-37" href="#software-software_artifacts-__codelineno-0-37"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ code-review-guidelines.md
<a id="__codelineno-0-38" name="__codelineno-0-38" href="#software-software_artifacts-__codelineno-0-38"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ refactoring-documentation.md
<a id="__codelineno-0-39" name="__codelineno-0-39" href="#software-software_artifacts-__codelineno-0-39"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ legacy-migration-plans.md
<a id="__codelineno-0-40" name="__codelineno-0-40" href="#software-software_artifacts-__codelineno-0-40"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ dataset-management.md
<a id="__codelineno-0-41" name="__codelineno-0-41" href="#software-software_artifacts-__codelineno-0-41"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ traceability-matrices.md
<a id="__codelineno-0-42" name="__codelineno-0-42" href="#software-software_artifacts-__codelineno-0-42"></a>â”‚   â”‚   â”‚   â””â”€â”€ metadata-standards.md
<a id="__codelineno-0-43" name="__codelineno-0-43" href="#software-software_artifacts-__codelineno-0-43"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-44" name="__codelineno-0-44" href="#software-software_artifacts-__codelineno-0-44"></a>â”‚   â”‚   â”œâ”€â”€ 05-testing/
<a id="__codelineno-0-45" name="__codelineno-0-45" href="#software-software_artifacts-__codelineno-0-45"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ test-plans.md
<a id="__codelineno-0-46" name="__codelineno-0-46" href="#software-software_artifacts-__codelineno-0-46"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ automated-test-suites.md
<a id="__codelineno-0-47" name="__codelineno-0-47" href="#software-software_artifacts-__codelineno-0-47"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ ai-generated-test-cases.md
<a id="__codelineno-0-48" name="__codelineno-0-48" href="#software-software_artifacts-__codelineno-0-48"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ quality-gates.md
<a id="__codelineno-0-49" name="__codelineno-0-49" href="#software-software_artifacts-__codelineno-0-49"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ performance-benchmarks.md
<a id="__codelineno-0-50" name="__codelineno-0-50" href="#software-software_artifacts-__codelineno-0-50"></a>â”‚   â”‚   â”‚   â””â”€â”€ bug-tracking.md
<a id="__codelineno-0-51" name="__codelineno-0-51" href="#software-software_artifacts-__codelineno-0-51"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-52" name="__codelineno-0-52" href="#software-software_artifacts-__codelineno-0-52"></a>â”‚   â”‚   â”œâ”€â”€ 06-security/                   # â­ AI guardrails
<a id="__codelineno-0-53" name="__codelineno-0-53" href="#software-software_artifacts-__codelineno-0-53"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ threat-models.md
<a id="__codelineno-0-54" name="__codelineno-0-54" href="#software-software_artifacts-__codelineno-0-54"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ security-policies-as-code.md
<a id="__codelineno-0-55" name="__codelineno-0-55" href="#software-software_artifacts-__codelineno-0-55"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ vulnerability-scans.md
<a id="__codelineno-0-56" name="__codelineno-0-56" href="#software-software_artifacts-__codelineno-0-56"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ compliance-checklists.md
<a id="__codelineno-0-57" name="__codelineno-0-57" href="#software-software_artifacts-__codelineno-0-57"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ audit-trails.md
<a id="__codelineno-0-58" name="__codelineno-0-58" href="#software-software_artifacts-__codelineno-0-58"></a>â”‚   â”‚   â”‚   â””â”€â”€ ai-code-reviews.md
<a id="__codelineno-0-59" name="__codelineno-0-59" href="#software-software_artifacts-__codelineno-0-59"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-60" name="__codelineno-0-60" href="#software-software_artifacts-__codelineno-0-60"></a>â”‚   â”‚   â”œâ”€â”€ 07-deployment-operations/
<a id="__codelineno-0-61" name="__codelineno-0-61" href="#software-software_artifacts-__codelineno-0-61"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ infrastructure-as-code/
<a id="__codelineno-0-62" name="__codelineno-0-62" href="#software-software_artifacts-__codelineno-0-62"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ ci-cd-pipeline-configurations.md
<a id="__codelineno-0-63" name="__codelineno-0-63" href="#software-software_artifacts-__codelineno-0-63"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ release-notes.md
<a id="__codelineno-0-64" name="__codelineno-0-64" href="#software-software_artifacts-__codelineno-0-64"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring-observability.md
<a id="__codelineno-0-65" name="__codelineno-0-65" href="#software-software_artifacts-__codelineno-0-65"></a>â”‚   â”‚   â”‚   â””â”€â”€ runbooks.md
<a id="__codelineno-0-66" name="__codelineno-0-66" href="#software-software_artifacts-__codelineno-0-66"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-67" name="__codelineno-0-67" href="#software-software_artifacts-__codelineno-0-67"></a>â”‚   â”‚   â”œâ”€â”€ 08-maintenance-evolution/
<a id="__codelineno-0-68" name="__codelineno-0-68" href="#software-software_artifacts-__codelineno-0-68"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ change-logs.md
<a id="__codelineno-0-69" name="__codelineno-0-69" href="#software-software_artifacts-__codelineno-0-69"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ incident-response.md
<a id="__codelineno-0-70" name="__codelineno-0-70" href="#software-software_artifacts-__codelineno-0-70"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ post-mortem-reports.md
<a id="__codelineno-0-71" name="__codelineno-0-71" href="#software-software_artifacts-__codelineno-0-71"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ dependency-management.md
<a id="__codelineno-0-72" name="__codelineno-0-72" href="#software-software_artifacts-__codelineno-0-72"></a>â”‚   â”‚   â”‚   â”œâ”€â”€ technical-debt-tracking.md
<a id="__codelineno-0-73" name="__codelineno-0-73" href="#software-software_artifacts-__codelineno-0-73"></a>â”‚   â”‚   â”‚   â””â”€â”€ continuous-improvement-plans.md
<a id="__codelineno-0-74" name="__codelineno-0-74" href="#software-software_artifacts-__codelineno-0-74"></a>â”‚   â”‚   â”‚
<a id="__codelineno-0-75" name="__codelineno-0-75" href="#software-software_artifacts-__codelineno-0-75"></a>â”‚   â”‚   â””â”€â”€ 09-communication-collaboration/
<a id="__codelineno-0-76" name="__codelineno-0-76" href="#software-software_artifacts-__codelineno-0-76"></a>â”‚   â”‚       â”œâ”€â”€ project-documentation.md
<a id="__codelineno-0-77" name="__codelineno-0-77" href="#software-software_artifacts-__codelineno-0-77"></a>â”‚   â”‚       â”œâ”€â”€ team-knowledge-base.md
<a id="__codelineno-0-78" name="__codelineno-0-78" href="#software-software_artifacts-__codelineno-0-78"></a>â”‚   â”‚       â”œâ”€â”€ decision-logs.md
<a id="__codelineno-0-79" name="__codelineno-0-79" href="#software-software_artifacts-__codelineno-0-79"></a>â”‚   â”‚       â”œâ”€â”€ role-definitions-human-ai.md
<a id="__codelineno-0-80" name="__codelineno-0-80" href="#software-software_artifacts-__codelineno-0-80"></a>â”‚   â”‚       â””â”€â”€ ubiquitous-language-glossaries.md
<a id="__codelineno-0-81" name="__codelineno-0-81" href="#software-software_artifacts-__codelineno-0-81"></a>â”‚   â”‚
<a id="__codelineno-0-82" name="__codelineno-0-82" href="#software-software_artifacts-__codelineno-0-82"></a>â”‚   â””â”€â”€ user-docs/                         # User-facing documentation
<a id="__codelineno-0-83" name="__codelineno-0-83" href="#software-software_artifacts-__codelineno-0-83"></a>â”‚       â”œâ”€â”€ user-documentation.md
<a id="__codelineno-0-84" name="__codelineno-0-84" href="#software-software_artifacts-__codelineno-0-84"></a>â”‚       â””â”€â”€ training-materials.md
<a id="__codelineno-0-85" name="__codelineno-0-85" href="#software-software_artifacts-__codelineno-0-85"></a>â”‚
<a id="__codelineno-0-86" name="__codelineno-0-86" href="#software-software_artifacts-__codelineno-0-86"></a>â”œâ”€â”€ src/                                   # Generated and human code
<a id="__codelineno-0-87" name="__codelineno-0-87" href="#software-software_artifacts-__codelineno-0-87"></a>â”œâ”€â”€ infra/                                 # IaC specifications
<a id="__codelineno-0-88" name="__codelineno-0-88" href="#software-software_artifacts-__codelineno-0-88"></a>â”œâ”€â”€ .github/workflows/                     # AI-enhanced CI/CD
<a id="__codelineno-0-89" name="__codelineno-0-89" href="#software-software_artifacts-__codelineno-0-89"></a>â””â”€â”€ scripts/ai/                            # AI automation scripts
</code></pre></div>
<hr />
<h2 id="software-software_artifacts-key-principles-for-ai-era-artifacts">Key Principles for AI-Era Artifacts<a class="headerlink" href="#software-software_artifacts-key-principles-for-ai-era-artifacts" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Best Practices</p>
<ol>
<li><strong>Precision Over Brevity</strong> - AI needs explicit, unambiguous specifications</li>
<li><strong>Machine-Readable Formats</strong> - Use structured data (JSON, YAML, Markdown with frontmatter)</li>
<li><strong>Version Everything</strong> - Track changes to specifications alongside generated code</li>
<li><strong>Automate Validation</strong> - Ensure AI outputs meet specification requirements</li>
<li><strong>Maintain Traceability</strong> - Link generated code back to originating specifications</li>
</ol>
</div>
<p>These artifacts serve as the foundation for AI-driven development, transforming from passive documentation into active contracts that guide intelligent code generation and system evolution.</p></section>
                        <h2 class='nav-section-title' id='section-software-engineering-agents'>
                            Software Engineering Agents <a class='headerlink' href='#section-software-engineering-agents' title='Permanent link'>â†µ</a>
                        </h2>
                        <section class="print-page" id="software-code-code_assistant_agents"><h1 id="software-code-code_assistant_agents-ai-coding-tools">AI Coding Tools<a class="headerlink" href="#software-code-code_assistant_agents-ai-coding-tools" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This page gives a comparison of AI Coding Tools by Autonomy Levels.</p>
<p>It starts by defining Autonomy Levels for AI Coding Tools.</p>
<p>Then it categorizes and compares these AI Coding Tools based on these Autonomy Levels</p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>See also <a href="../assets/docs/IDEs_Feature_Comparison.pdf">Feature Comparison and Analysis of Leading AI IDEs: Cursor,
Windsurf, Roo Code, and GitHub Copilot, May 27, 2025</a>.</p>
</div>
<div class="admonition observation">
<p class="admonition-title">Observation</p>
<p>Current <a href="https://en.wikipedia.org/wiki/Integrated_development_environment">integrated development environments (IDEs)</a> are optimized for human programmers.</p>
<p>They are not optimal  </p>
<ul>
<li>For <a href="#software-software_artifacts">Software Engineering Artifacts in the AI Era</a></li>
<li>For shared understanding among stakeholders</li>
<li>As we move <a href="#software-introduction-from-code-centric-to-contract-centric-development">From Code-Centric to Contract-Centric Development</a></li>
</ul>
</div>
<p>Since I made this observation, there have been some relevant updates:</p>
<ul>
<li>Amazon Kiro introduces <a href="https://garysvenson09.medium.com/kiro-by-amazon-rethinking-the-ai-coding-ide-landscape-ed357628b71e">a â€œspec-driven developmentâ€ philosophy</a></li>
<li>Sean Grove, OpenAI, July 2025 discuuses <a href="https://youtu.be/8rABwKRsec4?si=bVyUlwN6XsRnvzkp">The New Code</a> where specifications, not traditional code, are the primary valuable artifact for aligning human and AI intent.<ul>
<li>Future IDEs might function as "integrated thought clarifiers," helping to surface and resolve ambiguities in specifications.</li>
<li>Moving from disparate machine encodings to a unified human encoding (specifications) will simplify how we solve problems.</li>
</ul>
</li>
<li>"There's a good chance that, by the end of the year, people aren't using IDEs anymore", <a href="https://youtu.be/6eBSHbLKuN0?t=1586">Mastering Claude Code in 30 minutes</a>, Anthropic, 22 May 2025</li>
</ul>
<h2 id="software-code-code_assistant_agents-autonomy-levels-for-ai-coding-tools"><strong>Autonomy Levels for AI Coding Tools</strong><a class="headerlink" href="#software-code-code_assistant_agents-autonomy-levels-for-ai-coding-tools" title="Permanent link">&para;</a></h2>
<p>We define autonomy levels similar to <a href="https://sourcegraph.com/blog/levels-of-code-ai">how autonomous driving is categorized</a>:</p>
<ul>
<li><strong>Level 1 â€“ Basic Code Completion:</strong> AI offers <em>single-line or small code suggestions</em> based on context. The developer is fully in control, and the AI assists with micro-tasks (comparable to basic cruise control in cars). Tools at this level accelerate typing but <strong>do not generate complex code blocks or make decisions</strong>.</li>
<li><strong>Level 2 â€“ Advanced Code Generation (AI Pair Programmer):</strong> AI can produce <em>larger code snippets or entire functions</em> from natural language prompts or broader context. The AI behaves like a junior pair programmer â€“ it writes significant blocks of code or fixes simple bugs on request, but <strong>each AI output is a single-step operation reviewed by the human</strong>. Developers still guide the overall structure and verify the results.</li>
<li><strong>Level 3 â€“ Context-Aware Agents (Supervised Automation):</strong> AI acts more <em>agentically</em>, performing <strong>multi-step coding tasks</strong> in an iterative loop to fulfill a high-level goal. The developer provides a goal (e.g. â€œAdd a profile featureâ€ or â€œFix this bugâ€) and the AI <strong>plans steps, writes or edits multiple files, runs code or tests, debugs, and iterates</strong> with minimal prompting. The human oversees the process and may intervene or review final changes, but does not micromanage each step. This is akin to an intern or junior dev autonomously coding under supervision.</li>
<li><strong>Level 4 â€“ Highly Autonomous Coding:</strong> The AI can handle <strong>complex projects end-to-end</strong>, needing only minimal human input (like a prompt or spec) and <em>no required oversight on each change</em>. It can design solutions, write code across the entire codebase, test, debug, and even proactively improve code without awaiting human review. At this level, you might trust the AI as you would a strong senior engineer: provide requirements and let it deliver a solution to review. (In practice, developers may still do a final review, but the AIâ€™s output is intended to be production-ready.)</li>
<li><strong>Level 5 â€“ Full Autonomy (Experimental/Future):</strong> At this theoretical stage, an AI coding agent <strong>sets its own goals and continuously improves software</strong> without explicit human-defined tasks. It could analyze user needs or system metrics and autonomously decide to implement features or optimizations. This remains speculative â€“ current tools do <strong>not</strong> reach Level 5, but research projects hint at this direction (e.g. AutoGPT agents that take an open-ended goal and break it into sub-tasks to achieve it). No mainstream coding tool today operates at full Level 5 autonomy.</li>
</ul>
<p><strong>Comparison Table of Developer AI Tools by Autonomy and Capabilities</strong></p>
<p>The following table provides a summarized comparison of the developer AI tools discussed in this report, categorized by their primary autonomy level and highlighting their key characteristics, interaction styles, strengths, and limitations. This table serves as a quick reference to differentiate the capabilities and intended use cases of various tools in the rapidly evolving landscape of AI-assisted software development. Understanding these distinctions is crucial for developers and engineering leaders seeking to effectively integrate AI into their workflows.</p>
<table>
<thead>
<tr>
<th style="text-align: left;">Tool Name</th>
<th style="text-align: left;">Autonomy Level</th>
<th style="text-align: left;">Interaction Style</th>
<th style="text-align: left;">Key Strengths</th>
<th style="text-align: left;">Notable Limitations</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>VS Code IntelliSense</strong></td>
<td style="text-align: left;">1 (Basic Assist)</td>
<td style="text-align: left;">Inline IDE suggestions as you type</td>
<td style="text-align: left;">Fast, context-aware completions for syntax &amp; names based on language semantics and source analysis <a href="https://code.visualstudio.com/docs/editing/intellisense">7</a>; works offline; reliable for known code patterns; extensible.</td>
<td style="text-align: left;">No true "AI" generation of novel logic; limited to current file/project context; cannot understand higher-level intent [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Tabnine</strong></td>
<td style="text-align: left;">1 (with L3 agent features)</td>
<td style="text-align: left;">IDE plugin, ML-based autocomplete; AI chat; AI agents for specific tasks <a href="https://www.tabnine.com/">8</a></td>
<td style="text-align: left;">ML-driven suggestions for full lines/functions; supports many languages; local models for privacy <a href="https://www.tabnine.com/">8</a>; team-trained models <a href="https://spacelift.io/blog/ai-coding-assistant-tools">10</a>; agents for docs, review, Jira tasks.<a href="https://www.tabnine.com/">8</a></td>
<td style="text-align: left;">Core completion reactive; agent features newer; quality varies with context; large local models can be resource-intensive.<a href="https://spacelift.io/blog/ai-coding-assistant-tools">10</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>GitHub Copilot (Standard Mode)</strong></td>
<td style="text-align: left;">2 (Pair Programmer)</td>
<td style="text-align: left;">IDE plugin (inline suggestions); Copilot Chat interface <a href="https://spacelift.io/blog/ai-coding-assistant-tools">10</a></td>
<td style="text-align: left;">Generates larger code blocks/functions from comments/context <a href="https://spacelift.io/blog/ai-coding-assistant-tools">10</a>; broad framework knowledge; seamless IDE integration; chat for Q\&amp;A/explanations.<a href="https://spacelift.io/blog/ai-coding-assistant-tools">10</a></td>
<td style="text-align: left;">Can produce incorrect/insecure code requiring review <a href="https://www.peerspot.com/products/github-copilot-pros-and-cons">6</a>; limited full-project context; cloud-dependent; privacy/licensing concerns [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Amazon CodeWhisperer</strong></td>
<td style="text-align: left;">2 (Pair Programmer)</td>
<td style="text-align: left;">IDE plugin (inline suggestions) <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html">11</a></td>
<td style="text-align: left;">Optimized for AWS services and APIs <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html">11</a>; generates multi-line completions from comments; security scans <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html">11</a>; free for individuals.<a href="https://www.revoyant.com/blog/best-ai-code-assistants-2025-top-tools">47</a> (Becoming part of Amazon Q Developer <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html">11</a>)</td>
<td style="text-align: left;">Strong AWS bias, less effective for non-AWS work <a href="https://www.revoyant.com/blog/best-ai-code-assistants-2025-top-tools">47</a>; suggestions can be basic; output needs review; requires AWS account [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>OpenAI Codex (API) / GPT Models</strong></td>
<td style="text-align: left;">2 (Pair Programmer)</td>
<td style="text-align: left;">API/Playground; via ChatGPT (prompt-response); new "Codex" agent in ChatGPT <a href="https://emelia.io/hub/codex-open-ai">12</a></td>
<td style="text-align: left;">Powerful natural language to code generation (esp. GPT-4.1 <a href="https://openai.com/index/gpt-4-1/">13</a>); many languages; new "Codex" agent can edit files, run commands.<a href="https://openai.com/index/introducing-codex/">48</a></td>
<td style="text-align: left;">Original Codex API deprecated <a href="https://emelia.io/hub/codex-open-ai">12</a>; API use requires prompt engineering, output needs validation; context limits; advanced access often paid [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Replit Ghostwriter</strong></td>
<td style="text-align: left;">2 (Pair Programmer)</td>
<td style="text-align: left;">Replit IDE integration (inline autocomplete &amp; Ghostwriter Chat) <a href="https://apidog.com/blog/how-to-use-replit-ai-for-free/">49</a></td>
<td style="text-align: left;">Tight Replit integration for instant execution/testing; multi-line/function completion, refactoring, explanation, proactive debugger <a href="https://www.codestringers.com/insights/replit-ghostwriter-vs-copilot/">50</a>; good for learning/prototyping.</td>
<td style="text-align: left;">Primarily Replit-locked <a href="https://goldenowl.asia/blog/best-ai-for-coding">51</a>; quality similar to other LLM tools (needs review); advanced AI features are paid <a href="https://apidog.com/blog/how-to-use-replit-ai-for-free/">49</a>; internet-dependent.<a href="https://goldenowl.asia/blog/best-ai-for-coding">51</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>GitHub Copilot (Agent Mode)</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">IDE chat/command (VS Code); GitHub issue assignment <a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">14</a></td>
<td style="text-align: left;">Plans &amp; executes multi-file edits, runs tests, iterates on errors autonomously based on high-level goals/issues <a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">14</a>; creates PRs <a href="https://docs.github.com/en/copilot/about-github-copilot/github-copilot-features">44</a>; developer kept in loop.</td>
<td style="text-align: left;">Newer feature (stable in VS Code <a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">14</a>); can misinterpret complex requests, output needs review; performance varies with repo complexity.<a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">14</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Cursor (AI Editor)</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">Full AI-based code editor (VS Code fork) with chat &amp; agent modes <a href="https://docs.cursor.com/chat/agent">15</a></td>
<td style="text-align: left;">Deep codebase indexing for global context <a href="https://docs.cursor.com/chat/agent">15</a>; multi-file ops, refactoring; Agent Mode explores, plans, executes with tools <a href="https://docs.cursor.com/chat/agent">15</a>; "YOLO mode" for auto-execution (user term for auto-run) <a href="https://www.software.com/ai-index/tools/cursor">57</a>; checkpoints for safety.<a href="https://docs.cursor.com/chat/agent">15</a></td>
<td style="text-align: left;">Standalone editor (though high VS Code compatibility <a href="https://www.enginelabs.ai/blog/cursor-ai-an-in-depth-review-may-2025-update">56</a>); auto-run/YOLO mode is risky <a href="https://www.software.com/ai-index/tools/cursor">57</a>; performance/cost depends on chosen LLM API keys.<a href="https://www.fahimai.com/cursor-ai">55</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Windsurf (Cascade Agent)</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">AI-driven IDE (VS Code-based) with "Cascade" agent (Write/Chat modes) <a href="https://windsurf.com/">63</a></td>
<td style="text-align: left;">Cascade agent modifies code, runs it, debugs, iterates until success (Write Mode) <a href="https://www.datacamp.com/tutorial/windsurf-ai-agentic-code-editor">16</a>; uses tools (search, terminal, web); auto-fixes lint errors <a href="https://windsurf.com/">63</a>; "Turbo mode" for auto-execution.<a href="https://windsurf.com/">63</a></td>
<td style="text-align: left;">Newer tool; auto-execution ("Turbo mode") risky; must use its IDE; can make errors requiring human fix <a href="https://www.g2.com/products/codeium/reviews">68</a>; some features paid/enterprise.<a href="https://docs.windsurf.com/windsurf/cascade/cascade">65</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>ChatGPT (with Plugins &amp; Advanced Data Analysis)</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">Conversational AI (web UI or API) with Code Interpreter &amp; plugins (tool use) <a href="https://devdynamics.ai/blog/how-to-use-chatgpts-new-code-interpreter/">75</a></td>
<td style="text-align: left;">Highly flexible multi-tool agent: can fetch docs, run/debug Python code iteratively, use Git (via plugins) <a href="https://devdynamics.ai/blog/how-to-use-chatgpts-new-code-interpreter/">75</a>; strong natural language understanding (GPT-4).<a href="https://help.openai.com/en/articles/6825453-chatgpt-release-notes">74</a></td>
<td style="text-align: left;">Not an IDE tool by default (copy-paste workflow unless plugins bridge gap) [User Query]; plugin reliability varies; context limits; requires paid subscription for advanced features.<a href="https://sonary.com/b/open-ai/chatgpt-writing-tool+ai-tools/">82</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>Aider (CLI + Git assistant)</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">CLI chat tool working on local Git repo <a href="https://aider.chat/">17</a></td>
<td style="text-align: left;">Excellent Git integration (auto-commits, diffs); auto-runs linters/tests &amp; attempts fixes <a href="https://aider.chat/">17</a>; supports various LLMs (cloud/local) <a href="https://aider.chat/">17</a>; open-source.<a href="https://uibakery.io/blog/aider-vs-windsurf">18</a></td>
<td style="text-align: left;">CLI-based (less visual, steeper curve) <a href="https://uibakery.io/blog/aider-vs-windsurf">18</a>; requires API key setup; auto-fix quality depends on tests/linters; model errors possible [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Amazon Q Developer CLI</strong></td>
<td style="text-align: left;">3 (Agentic â€“ supervised)</td>
<td style="text-align: left;">Interactive CLI agent (natural language to CLI commands &amp; code edits) <a href="https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-developer-cli-agent-command-line/">85</a></td>
<td style="text-align: left;">AI orchestrates local CLI tools (compilers, package managers, AWS CLI) <a href="https://aws.amazon.com/blogs/devops/introducing-the-enhanced-command-line-interface-in-amazon-q-developer/">86</a>; strong for AWS/cloud tasks; uses powerful models (Claude via Bedrock) <a href="https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-developer-cli-agent-command-line/">85</a>; iterative adjustments based on feedback.<a href="https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-developer-cli-agent-command-line/">85</a></td>
<td style="text-align: left;">Newer tool; executing commands automatically has inherent risks [User Query]; primarily benefits AWS users; requires AWS setup [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Anthropic Claude Code</strong></td>
<td style="text-align: left;">4 (High Autonomy)</td>
<td style="text-align: left;">Terminal-based chat agent; IDE integrations (VS Code, JetBrains) <a href="https://docs.anthropic.com/en/docs/agents/claude-code/introduction">19</a></td>
<td style="text-align: left;">Handles full-codebase context (million-token); edits files with diffs; runs tests, debugs, iterates; performs Git ops (branch, commit, PR, merge); designs modular solutions from prompts; proactively refactors and optimizes code; SDK for custom agents <a href="https://docs.anthropic.com/en/docs/agents/claude-code/introduction">19</a>, <a href="https://www.anthropic.com/news/claude-4">69</a></td>
<td style="text-align: left;">Output is production-ready with minimal review; CLI interface may deter some users; currently in beta <a href="https://docs.anthropic.com/en/docs/agents/claude-code/introduction">19</a>; API costs can add up for large use cases <a href="https://anthropic.com/news/claude-4">71</a>; very large monorepos may still need human guidance</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Google Jules</strong></td>
<td style="text-align: left;">4 (High Autonomy)</td>
<td style="text-align: left;">Asynchronous cloud-based agent; GitHub integration (task assignment &amp; PRs) <a href="https://blog.google/technology/google-labs/jules/">20</a></td>
<td style="text-align: left;"><em>Autonomous coding agent:</em> takes high-level goals (features, bugs), works independently in cloud VM, presents PRs <a href="https://blog.google/technology/google-labs/jules/">20</a>; uses Gemini 2.5 Pro; provides plan/reasoning; audio changelogs.<a href="https://blog.google/technology/google-labs/jules/">20</a></td>
<td style="text-align: left;">Very new (public beta May 2025) <a href="https://blog.google/technology/google-labs/jules/">20</a>; cloud-only (code sent to Google VM); asynchronous (no real-time interaction); high autonomy needs careful review of results [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Cognition Devin</strong></td>
<td style="text-align: left;">4 (High Autonomy)</td>
<td style="text-align: left;">Cloud AI service (task assignment via dashboard/Slack/CLI) <a href="https://research.contrary.com/company/cognition">22</a></td>
<td style="text-align: left;"><em>AI Software Engineer:</em> plans &amp; executes complex end-to-end tasks using own shell, editor, browser <a href="https://devin.ai/">21</a>; strong SWE-bench (13.86%) <a href="https://cognition.ai/blog/swe-bench-technical-report">23</a>; Devin 2.0 has interactive planning, search, wiki.<a href="https://research.contrary.com/company/cognition">22</a></td>
<td style="text-align: left;">Expensive enterprise tool [User Query]; success on very complex/novel tasks still limited <a href="https://cognition.ai/blog/swe-bench-technical-report">23</a>; requires codebase access by third-party; some demo authenticity concerns raised.<a href="https://research.contrary.com/company/cognition">22</a></td>
</tr>
<tr>
<td style="text-align: left;"><strong>GPT-Engineer (open-source)</strong></td>
<td style="text-align: left;">4 (High Autonomy, experimental)</td>
<td style="text-align: left;">CLI tool: single prompt -&gt; clarification dialogue -&gt; codebase generation <a href="https://logicballs.com/ai-tools/gpt-engineer">24</a></td>
<td style="text-align: left;">Can bootstrap entire (simple) projects from one prompt; automates initial spec-to-code process <a href="https://logicballs.com/ai-tools/gpt-engineer">24</a>; open-source and customizable.<a href="https://logicballs.com/ai-tools/gpt-engineer">24</a></td>
<td style="text-align: left;">Highly prompt-dependent; generated code needs significant review/debugging for complex apps <a href="https://logicballs.com/ai-tools/gpt-engineer">24</a>; primarily for initial generation, not iterative work on existing code [User Query].</td>
</tr>
<tr>
<td style="text-align: left;"><strong>AutoGPT (for coding tasks)</strong></td>
<td style="text-align: left;">4 (High Autonomy, experimental)</td>
<td style="text-align: left;">Self-directed AI agent framework (user sets high-level goal, agent plans &amp; executes with tools) <a href="https://aiagentsdirectory.com/agent/autogpt">98</a></td>
<td style="text-align: left;">Fully automated workflow: breaks goal into sub-tasks, uses tools (web search, file I/O, code execution) iteratively without human prompts.<a href="https://aiagentsdirectory.com/agent/autogpt">98</a></td>
<td style="text-align: left;">Often inefficient, prone to loops or incorrect paths without precise goals/human feedback <a href="https://www.geeksforgeeks.org/what-is-autogpt-and-how-to-use-it/">100</a>; not specialized for coding; high API costs; mainly experimental for dev tasks.<a href="https://codoid.com/ai/autogpt-examples-expert-tips-for-success/">99</a></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Tools at <strong>Level 5</strong> are omitted from the table as no productized examples currently exist; this level remains theoretical and experimental.)*</p>
<p>This comparison underscores that as we progress from LevelÂ 1 to LevelÂ 4, AI tools take on more of the coding burden â€” from merely completing the next line of code to handling whole features. Developers today can mix and match these tools to suit their needs, but itâ€™s crucial to understand each toolâ€™s autonomy and limits to use them effectively. The field is evolving rapidly, and what is LevelÂ 3 today may become LevelÂ 4 tomorrow. Keeping an eye on these autonomy levels helps set expectations and guides us in adopting AI tools that truly enhance productivity while maintaining quality and control in software development.</p>
</div>
<h4 id="software-code-code_assistant_agents-works-cited"><strong>Works cited</strong><a class="headerlink" href="#software-code-code_assistant_agents-works-cited" title="Permanent link">&para;</a></h4>
<ol>
<li>The 2025 AI Index Report | Stanford HAI, accessed May 26, 2025, <a href="https://hai.stanford.edu/ai-index/2025-ai-index-report">https://hai.stanford.edu/ai-index/2025-ai-index-report</a>  </li>
<li>AI: A Declaration of Autonomy - Accenture, accessed May 26, 2025, <a href="https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-Tech-Vision-2025.pdf">https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-Tech-Vision-2025.pdf</a>  </li>
<li>What are AI Agents?- Agents in Artificial Intelligence Explained - AWS, accessed May 26, 2025, <a href="https://aws.amazon.com/what-is/ai-agents/">https://aws.amazon.com/what-is/ai-agents/</a>  </li>
<li>A More Practical Future for Autonomous Vehicles | S\&amp;P Global, accessed May 26, 2025, <a href="https://www.spglobal.com/automotive-insights/en/blogs/fuel-for-thought-a-more-practical-future-for-autonomous-vehicles">https://www.spglobal.com/automotive-insights/en/blogs/fuel-for-thought-a-more-practical-future-for-autonomous-vehicles</a>  </li>
<li>Levels of intelligence: Navigating the future of AI, from robotic arms to autonomous cars, accessed May 26, 2025, <a href="https://roboticsandautomationnews.com/2025/05/17/levels-of-intelligence-navigating-the-future-of-ai-from-robotic-arms-to-autonomous-cars/90943/">https://roboticsandautomationnews.com/2025/05/17/levels-of-intelligence-navigating-the-future-of-ai-from-robotic-arms-to-autonomous-cars/90943/</a>  </li>
<li>GitHub CoPilot: Pros and Cons 2025 - PeerSpot, accessed May 26, 2025, <a href="https://www.peerspot.com/products/github-copilot-pros-and-cons">https://www.peerspot.com/products/github-copilot-pros-and-cons</a>  </li>
<li>IntelliSense - Visual Studio Code, accessed May 26, 2025, <a href="https://code.visualstudio.com/docs/editing/intellisense">https://code.visualstudio.com/docs/editing/intellisense</a>  </li>
<li>Tabnine AI Code Assistant | private, personalized, protected, accessed May 26, 2025, <a href="https://www.tabnine.com/">https://www.tabnine.com/</a>  </li>
<li>Plans &amp; Pricing | Tabnine: The AI code assistant that you control, accessed May 26, 2025, <a href="https://www.tabnine.com/pricing/">https://www.tabnine.com/pricing/</a>  </li>
<li>20 Best AI-Powered Coding Assistant Tools in 2025 - Spacelift, accessed May 26, 2025, <a href="https://spacelift.io/blog/ai-coding-assistant-tools">https://spacelift.io/blog/ai-coding-assistant-tools</a>  </li>
<li>What is CodeWhisperer? - CodeWhisperer - AWS Documentation, accessed May 26, 2025, <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html">https://docs.aws.amazon.com/codewhisperer/latest/userguide/what-is-cwspr.html</a>  </li>
<li>Codex Open AI: The Ultimate Guide to AI-Powered Coding in 2025 - Emelia.io, accessed May 26, 2025, <a href="https://emelia.io/hub/codex-open-ai">https://emelia.io/hub/codex-open-ai</a>  </li>
<li>Introducing GPT-4.1 in the API - OpenAI, accessed May 26, 2025, <a href="https://openai.com/index/gpt-4-1/">https://openai.com/index/gpt-4-1/</a>  </li>
<li>Introducing GitHub Copilot agent mode (preview) - Visual Studio Code, accessed May 26, 2025, <a href="https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode">https://code.visualstudio.com/blogs/2025/02/24/introducing-copilot-agent-mode</a>  </li>
<li>Agent Mode - Cursor, accessed May 26, 2025, <a href="https://docs.cursor.com/chat/agent">https://docs.cursor.com/chat/agent</a>  </li>
<li>Windsurf AI Agentic Code Editor: Features, Setup, and Use Cases | DataCamp, accessed May 26, 2025, <a href="https://www.datacamp.com/tutorial/windsurf-ai-agentic-code-editor">https://www.datacamp.com/tutorial/windsurf-ai-agentic-code-editor</a>  </li>
<li>Aider - AI Pair Programming in Your Terminal, accessed May 26, 2025, <a href="https://aider.chat/">https://aider.chat/</a>  </li>
<li>Aider vs Windsurf: Which AI Coding Assistant Should You Choose? | UI Bakery Blog, accessed May 26, 2025, <a href="https://uibakery.io/blog/aider-vs-windsurf">https://uibakery.io/blog/aider-vs-windsurf</a>  </li>
<li>Claude Code overview - Anthropic API, accessed May 26, 2025, <a href="https://docs.anthropic.com/en/docs/agents/claude-code/introduction">https://docs.anthropic.com/en/docs/agents/claude-code/introduction</a>  </li>
<li>Jules: Google's autonomous AI coding agent - Google Blog, accessed May 26, 2025, <a href="https://blog.google/technology/google-labs/jules/">https://blog.google/technology/google-labs/jules/</a>  </li>
<li>Devin | The AI Software Engineer, accessed May 26, 2025, <a href="https://devin.ai/">https://devin.ai/</a>  </li>
<li>Report: Cognition Business Breakdown &amp; Founding Story | Contrary ..., accessed May 26, 2025, <a href="https://research.contrary.com/company/cognition">https://research.contrary.com/company/cognition</a>  </li>
<li>SWE-bench technical report - Cognition, accessed May 26, 2025, <a href="https://cognition.ai/blog/swe-bench-technical-report">https://cognition.ai/blog/swe-bench-technical-report</a>  </li>
<li>GPT Engineer | AI Low-Code/No-Code Tool Review 2025 - LogicBalls, accessed May 26, 2025, <a href="https://logicballs.com/ai-tools/gpt-engineer">https://logicballs.com/ai-tools/gpt-engineer</a>  </li>
<li>From Prompt to Codebase: The Power of GPT Engineer - Kanaries Docs, accessed May 26, 2025, <a href="https://docs.kanaries.net/topics/ChatGPT/gpt-engineer">https://docs.kanaries.net/topics/ChatGPT/gpt-engineer</a>  </li>
<li>arxiv.org, accessed May 26, 2025, <a href="https://arxiv.org/html/2504.15228">https://arxiv.org/html/2504.15228</a>  </li>
<li>arXiv:2504.15228v1 [cs.AI] 21 Apr 2025, accessed May 26, 2025, <a href="https://arxiv.org/pdf/2504.15228">https://arxiv.org/pdf/2504.15228</a>  </li>
<li>DeepMind's AlphaDev Reinvents Algorithms | Enterprise AI Daily, accessed May 26, 2025, <a href="https://www.enterpriseaisolutions.io/p/beyond-human-limits-f2bc">https://www.enterpriseaisolutions.io/p/beyond-human-limits-f2bc</a>  </li>
<li>MuZero, AlphaZero, and AlphaDev: Optimizing computer systems - Google DeepMind, accessed May 26, 2025, <a href="https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/">https://deepmind.google/discover/blog/muzero-alphazero-and-alphadev-optimizing-computer-systems/</a>  </li>
<li>AlphaDev discovers faster sorting algorithms - Google DeepMind, accessed May 26, 2025, <a href="https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/">https://deepmind.google/discover/blog/alphadev-discovers-faster-sorting-algorithms/</a>  </li>
<li>Meta AI Introduces Meta LLM Compiler: A State-of-the-Art LLM that Builds upon Code Llama with Improved Performance for Code Optimization and Compiler Reasoning : r/machinelearningnews - Reddit, accessed May 26, 2025, <a href="https://www.reddit.com/r/machinelearningnews/comments/1dqn8to/meta_ai_introduces_meta_llm_compiler_a/">https://www.reddit.com/r/machinelearningnews/comments/1dqn8to/meta_ai_introduces_meta_llm_compiler_a/</a>  </li>
<li>Meta's LLM Compiler: Innovating Code Optimization with AI ..., accessed May 26, 2025, <a href="https://www.unite.ai/metas-llm-compiler-innovating-code-optimization-with-ai-powered-compiler-design/">https://www.unite.ai/metas-llm-compiler-innovating-code-optimization-with-ai-powered-compiler-design/</a>  </li>
<li>A Multi-AI Agent System for Autonomous Optimization of Agentic AI Solutions via Iterative Refinement and LLM-Driven Feedback Loops - arXiv, accessed May 26, 2025, <a href="https://arxiv.org/html/2412.17149v1">https://arxiv.org/html/2412.17149v1</a>  </li>
<li>Recursive self-improvement - Wikipedia, accessed May 26, 2025, <a href="https://en.wikipedia.org/wiki/Recursive_self-improvement">https://en.wikipedia.org/wiki/Recursive_self-improvement</a>  </li>
<li>Level 5 Autonomy: How Close Are We to Fully Self-Driving Cars? (Latest Industry Stats), accessed May 26, 2025, <a href="https://patentpc.com/blog/level-5-autonomy-how-close-are-we-to-fully-self-driving-cars-latest-industry-stats">https://patentpc.com/blog/level-5-autonomy-how-close-are-we-to-fully-self-driving-cars-latest-industry-stats</a>  </li>
<li>In response to critiques of Guaranteed Safe AI - AI Alignment Forum, accessed May 26, 2025, <a href="https://www.alignmentforum.org/posts/DZuBHHKao6jsDDreH/in-response-to-critiques-of-guaranteed-safe-ai">https://www.alignmentforum.org/posts/DZuBHHKao6jsDDreH/in-response-to-critiques-of-guaranteed-safe-ai</a>  </li>
<li>Part 1: How Sourcegraph scales with the Language Server Protocol, accessed May 26, 2025, <a href="https://sourcegraph.com/blog/part-1-how-sourcegraph-scales-with-the-language-server-protocol">https://sourcegraph.com/blog/part-1-how-sourcegraph-scales-with-the-language-server-protocol</a>  </li>
<li>JavaScript in Visual Studio Code, accessed May 26, 2025, <a href="https://code.visualstudio.com/docs/languages/javascript">https://code.visualstudio.com/docs/languages/javascript</a>  </li>
<li>Features - CodeWhisperer - AWS Documentation, accessed May 26, 2025, <a href="https://docs.aws.amazon.com/codewhisperer/latest/userguide/features.html">https://docs.aws.amazon.com/codewhisperer/latest/userguide/features.html</a>  </li>
<li>Code completion | IntelliJ IDEA Documentation - JetBrains, accessed May 26, 2025, <a href="https://www.jetbrains.com/help/idea/auto-completing-code.html">https://www.jetbrains.com/help/idea/auto-completing-code.html</a>  </li>
<li>IntelliJ IDEA | Features - JetBrains, accessed May 26, 2025, <a href="https://www.jetbrains.com/idea/features/">https://www.jetbrains.com/idea/features/</a>  </li>
<li>IntelliCode for Visual Studio | Microsoft Learn, accessed May 26, 2025, <a href="https://learn.microsoft.com/en-us/visualstudio/ide/intellicode-visual-studio?view=vs-2022">https://learn.microsoft.com/en-us/visualstudio/ide/intellicode-visual-studio?view=vs-2022</a>  </li>
<li>IntelliCode Whole-line autocompletions - Visual Studio (Windows) | Microsoft Learn, accessed May 26, 2025, <a href="https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-whole-line-completions?view=vs-2022">https://learn.microsoft.com/en-us/visualstudio/ide/visual-studio-whole-line-completions?view=vs-2022</a>  </li>
<li>GitHub Copilot features, accessed May 26, 2025, <a href="https://docs.github.com/en/copilot/about-github-copilot/github-copilot-features">https://docs.github.com/en/copilot/about-github-copilot/github-copilot-features</a>  </li>
<li>About individual Copilot plans and benefits - GitHub Docs, accessed May 26, 2025, <a href="https://docs.github.com/en/copilot/managing-copilot/managing-copilot-as-an-individual-subscriber/getting-started-with-copilot-on-your-personal-account/about-individual-copilot-plans-and-benefits">https://docs.github.com/en/copilot/managing-copilot/managing-copilot-as-an-individual-subscriber/getting-started-with-copilot-on-your-personal-account/about-individual-copilot-plans-and-benefits</a>  </li>
<li>GitHub Copilot Pros and Cons, accessed May 26, 2025, <a href="https://www.netguru.com/blog/github-copilot">https://www.netguru.com/blog/github-copilot</a>  </li>
<li>Best AI Code Assistants In 2025 - Top 5 Tools For Developers - Revoyant, accessed May 26, 2025, <a href="https://www.revoyant.com/blog/best-ai-code-assistants-2025-top-tools">https://www.revoyant.com/blog/best-ai-code-assistants-2025-top-tools</a>  </li>
<li>Introducing Codex - OpenAI, accessed May 26, 2025, <a href="https://openai.com/index/introducing-codex/">https://openai.com/index/introducing-codex/</a>  </li>
<li>How to Use Replit AI for free - Apidog, accessed May 26, 2025, <a href="https://apidog.com/blog/how-to-use-replit-ai-for-free/">https://apidog.com/blog/how-to-use-replit-ai-for-free/</a>  </li>
<li>Replit Ghostwriter vs. Copilot: Which is Better? - CodeStringers, accessed May 26, 2025, <a href="https://www.codestringers.com/insights/replit-ghostwriter-vs-copilot/">https://www.codestringers.com/insights/replit-ghostwriter-vs-copilot/</a>  </li>
<li>11 Best AI Coding Toolsâ€”Guide for Developers (2025 updated) - Golden Owl, accessed May 26, 2025, <a href="https://goldenowl.asia/blog/best-ai-for-coding">https://goldenowl.asia/blog/best-ai-for-coding</a>  </li>
<li>Replit â€” Announcing Ghostwriter Chat: The first conversational AI ..., accessed May 26, 2025, <a href="https://blog.replit.com/gw-chat-launch">https://blog.replit.com/gw-chat-launch</a>  </li>
<li>Agent mode 101: All about GitHub Copilot's powerful mode - The ..., accessed May 26, 2025, <a href="https://github.blog/ai-and-ml/github-copilot/agent-mode-101-all-about-github-copilots-powerful-mode/">https://github.blog/ai-and-ml/github-copilot/agent-mode-101-all-about-github-copilots-powerful-mode/</a>  </li>
<li>Complete Guide to GitHub Copilot Agent Mode: Transforming Development Paradigms, accessed May 26, 2025, <a href="https://blog.wadan.co.jp/en/tech/github-copilot-agent-mode">https://blog.wadan.co.jp/en/tech/github-copilot-agent-mode</a>  </li>
<li>Cursor AI Review: Best AI Code Editor in 2025?, accessed May 26, 2025, <a href="https://www.fahimai.com/cursor-ai">https://www.fahimai.com/cursor-ai</a>  </li>
<li>Cursor AI: An In-Depth Review (May 2025 Update) | Engine, accessed May 26, 2025, <a href="https://www.enginelabs.ai/blog/cursor-ai-an-in-depth-review-may-2025-update">https://www.enginelabs.ai/blog/cursor-ai-an-in-depth-review-may-2025-update</a>  </li>
<li>Guide to Cursor | Software.com, accessed May 26, 2025, <a href="https://www.software.com/ai-index/tools/cursor">https://www.software.com/ai-index/tools/cursor</a>  </li>
<li>docs.cursor.com, accessed May 26, 2025, <a href="https://docs.cursor.com/context/codebase-indexing#:~:text=For%20better%20and%20more%20accurate,initialize%20indexing%20for%20that%20workspace.">https://docs.cursor.com/context/codebase-indexing#:\~:text=For%20better%20and%20more%20accurate,initialize%20indexing%20for%20that%20workspace.</a>  </li>
<li>Codebase Indexing - Cursor, accessed May 26, 2025, <a href="https://docs.cursor.com/context/codebase-indexing">https://docs.cursor.com/context/codebase-indexing</a>  </li>
<li>Top 5 AI IDEs for Coding with Windsurf in 2025 By Girish Kot - Peerlist, accessed May 26, 2025, <a href="https://peerlist.io/gkotte/articles/top-5-ai-ides-for-coding-with-windsurf-in-2025">https://peerlist.io/gkotte/articles/top-5-ai-ides-for-coding-with-windsurf-in-2025</a>  </li>
<li>How I use Cursor (+ my best tips) - Builder.io, accessed May 26, 2025, <a href="https://www.builder.io/blog/cursor-tips">https://www.builder.io/blog/cursor-tips</a>  </li>
<li>Cursor AI Unleashed: The Agent-Powered Code Editor Transforming Developer Workflow, accessed May 26, 2025, <a href="https://savemyleads.com/blog/useful/cursor-ai">https://savemyleads.com/blog/useful/cursor-ai</a>  </li>
<li>Windsurf (formerly Codeium) - The most powerful AI Code Editor, accessed May 26, 2025, <a href="https://windsurf.com/">https://windsurf.com/</a>  </li>
<li>Windsurf Editor by Codeium for Revit: AI Automation in Revit - ArchiLabs, accessed May 26, 2025, <a href="https://archilabs.ai/posts/windsurf-for-revit">https://archilabs.ai/posts/windsurf-for-revit</a>  </li>
<li>Cascade - Windsurf Docs, accessed May 26, 2025, <a href="https://docs.windsurf.com/windsurf/cascade/cascade">https://docs.windsurf.com/windsurf/cascade/cascade</a>  </li>
<li>Windsurf Reviews, Ratings &amp; Features 2025 | Gartner Peer Insights, accessed May 26, 2025, <a href="https://www.gartner.com/reviews/market/ai-code-assistants/vendor/windsurf-exafunction/product/windsurf-exafunction">https://www.gartner.com/reviews/market/ai-code-assistants/vendor/windsurf-exafunction/product/windsurf-exafunction</a>  </li>
<li>Windsurf Editor Changelogs - Codeium, accessed May 26, 2025, <a href="https://codeium.com/changelog">https://codeium.com/changelog</a>  </li>
<li>Windsurf Reviews 2025: Details, Pricing, &amp; Features | G2, accessed May 26, 2025, <a href="https://www.g2.com/products/codeium/reviews">https://www.g2.com/products/codeium/reviews</a>  </li>
<li>Introducing Claude 4 - Anthropic, accessed May 26, 2025, <a href="https://www.anthropic.com/news/claude-4">https://www.anthropic.com/news/claude-4</a>  </li>
<li>Claude Code: Best practices for agentic coding - Anthropic, accessed May 26, 2025, <a href="https://www.anthropic.com/engineering/claude-code-best-practices">https://www.anthropic.com/engineering/claude-code-best-practices</a>  </li>
<li>Introducing Claude 4 \ Anthropic, accessed May 26, 2025, <a href="https://anthropic.com/news/claude-4">https://anthropic.com/news/claude-4</a>  </li>
<li>Claude Anthropic Reviews &amp; Ratings | Pros &amp; Cons - Software Finder, accessed May 26, 2025, <a href="https://softwarefinder.com/artificial-intelligence/claude-anthropic/reviews">https://softwarefinder.com/artificial-intelligence/claude-anthropic/reviews</a>  </li>
<li>15 Pros &amp; Cons of Claude [2025] - DigitalDefynd, accessed May 26, 2025, <a href="https://digitaldefynd.com/IQ/pros-cons-of-claude/">https://digitaldefynd.com/IQ/pros-cons-of-claude/</a>  </li>
<li>ChatGPT â€” Release Notes - OpenAI Help Center, accessed May 26, 2025, <a href="https://help.openai.com/en/articles/6825453-chatgpt-release-notes">https://help.openai.com/en/articles/6825453-chatgpt-release-notes</a>  </li>
<li>How to Use ChatGPT's New Code Interpreter - DevDynamics, accessed May 26, 2025, <a href="https://devdynamics.ai/blog/how-to-use-chatgpts-new-code-interpreter/">https://devdynamics.ai/blog/how-to-use-chatgpts-new-code-interpreter/</a>  </li>
<li>Why ChatGPT's Code Interpreter is the Future of Programming - BotPenguin, accessed May 26, 2025, <a href="https://botpenguin.com/blogs/why-chatgpt-code-interpreter-is-future-of-programming">https://botpenguin.com/blogs/why-chatgpt-code-interpreter-is-future-of-programming</a>  </li>
<li>10 of The Best ChatGPT Plugins to Get The Most From AI in 2024 | DataCamp, accessed May 26, 2025, <a href="https://www.datacamp.com/blog/best-chat-gpt-plugins">https://www.datacamp.com/blog/best-chat-gpt-plugins</a>  </li>
<li>The Top 9 ChatGPT Plugins for Developers in 2025 - ISHIR, accessed May 26, 2025, <a href="https://www.ishir.com/blog/119322/the-top-9-chatgpt-plugins-for-developers-in-2024.htm">https://www.ishir.com/blog/119322/the-top-9-chatgpt-plugins-for-developers-in-2024.htm</a>  </li>
<li>GitLab ChatGPT (OpenAI) Integration - Quick Connect - Zapier, accessed May 26, 2025, <a href="https://zapier.com/apps/gitlab/integrations/chatgpt">https://zapier.com/apps/gitlab/integrations/chatgpt</a>  </li>
<li>HighwayofLife/awesome-chatgpt-plugins - GitHub, accessed May 26, 2025, <a href="https://github.com/HighwayofLife/awesome-chatgpt-plugins">https://github.com/HighwayofLife/awesome-chatgpt-plugins</a>  </li>
<li>Explore the Top 10 Best Chatgpt Plugins of 2025 - Murf AI, accessed May 26, 2025, <a href="https://murf.ai/blog/best-chatgpt-plugins">https://murf.ai/blog/best-chatgpt-plugins</a>  </li>
<li>ChatGPT AI Tools Review 2025: Pros, Cons, and Pricing - Sonary, accessed May 26, 2025, <a href="https://sonary.com/b/open-ai/chatgpt-writing-tool+ai-tools/">https://sonary.com/b/open-ai/chatgpt-writing-tool+ai-tools/</a>  </li>
<li>Aider Documentation, accessed May 26, 2025, <a href="https://aider.chat/docs/">https://aider.chat/docs/</a>  </li>
<li>Best AI Coding Assistants as of May 2025 - Shakudo, accessed May 26, 2025, <a href="https://www.shakudo.io/blog/best-ai-coding-assistants">https://www.shakudo.io/blog/best-ai-coding-assistants</a>  </li>
<li>Amazon Q Developer announces a new CLI agent within the command line - AWS, accessed May 26, 2025, <a href="https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-developer-cli-agent-command-line/">https://aws.amazon.com/about-aws/whats-new/2025/03/amazon-q-developer-cli-agent-command-line/</a>  </li>
<li>A lightning fast, new agentic coding experience within the Amazon Q Developer CLI - AWS, accessed May 26, 2025, <a href="https://aws.amazon.com/blogs/devops/introducing-the-enhanced-command-line-interface-in-amazon-q-developer/">https://aws.amazon.com/blogs/devops/introducing-the-enhanced-command-line-interface-in-amazon-q-developer/</a>  </li>
<li>Amazon Q Developer Reviews 2025: Details, Pricing, &amp; Features | G2, accessed May 26, 2025, <a href="https://www.g2.com/products/amazon-q-developer/reviews">https://www.g2.com/products/amazon-q-developer/reviews</a>  </li>
<li>Best AI Coding Assistant 2025: Complete Guide to Cline and Cursor ..., accessed May 26, 2025, <a href="https://cline.bot/blog/best-ai-coding-assistant-2025-complete-guide-to-cline-and-cursor">https://cline.bot/blog/best-ai-coding-assistant-2025-complete-guide-to-cline-and-cursor</a>  </li>
<li>Qodo AI Reviews: Use Cases, Pricing &amp; Alternatives - Futurepedia, accessed May 26, 2025, <a href="https://www.futurepedia.io/tool/qodo">https://www.futurepedia.io/tool/qodo</a>  </li>
<li>Qodo Reviews 2025: Details, Pricing, &amp; Features | G2, accessed May 26, 2025, <a href="https://www.g2.com/products/qodo/reviews">https://www.g2.com/products/qodo/reviews</a>  </li>
<li>Google I/O 2025: Google's answer to Microsoft and OpenAI's AI coding agents, Jules is now available for everyone to try - The Times of India, accessed May 26, 2025, <a href="https://timesofindia.indiatimes.com/technology/tech-news/google-i/o-2025-googles-answer-to-microsoft-and-openais-ai-coding-agents-jules-is-now-available-for-everyone-to-try/articleshow/121298997.cms">https://timesofindia.indiatimes.com/technology/tech-news/google-i/o-2025-googles-answer-to-microsoft-and-openais-ai-coding-agents-jules-is-now-available-for-everyone-to-try/articleshow/121298997.cms</a>  </li>
<li>Google Counters GitHub &amp; Microsoft with Jules Agent &amp; Enhanced Gemini AI, accessed May 26, 2025, <a href="https://visualstudiomagazine.com/articles/2025/05/20/google-counters-github-microsoft-with-jules-agent-enhanced-gemini-ai.aspx">https://visualstudiomagazine.com/articles/2025/05/20/google-counters-github-microsoft-with-jules-agent-enhanced-gemini-ai.aspx</a>  </li>
<li>What Google I/O 2025's AI Announcements Mean for Developers - RisingStack Engineering, accessed May 26, 2025, <a href="https://blog.risingstack.com/google-io-2025-recap/">https://blog.risingstack.com/google-io-2025-recap/</a>  </li>
<li>Devin AI vs Cursor: Speed &amp; Accuracy Test Results - Trickle AI, accessed May 26, 2025, <a href="https://www.trickle.so/blog/devin-ai-or-cursor">https://www.trickle.so/blog/devin-ai-or-cursor</a>  </li>
<li>Generate Complete Apps with Ease: GPT Engineer Review and Setup - Toolify.ai, accessed May 26, 2025, <a href="https://www.toolify.ai/ai-news/generate-complete-apps-with-ease-gpt-engineer-review-and-setup-751744">https://www.toolify.ai/ai-news/generate-complete-apps-with-ease-gpt-engineer-review-and-setup-751744</a>  </li>
<li>Build Any App with One Prompt Using GPT-Engineer - YouTube, accessed May 26, 2025, <a href="https://m.youtube.com/watch?v=-W73zQr0rl4&amp;pp=ygUII21nY29kZXI%3D">https://m.youtube.com/watch?v=-W73zQr0rl4\&amp;pp=ygUII21nY29kZXI%3D</a>  </li>
<li>What I learned in 6 months of working on a CodeGen dev tool GPT Pilot, accessed May 26, 2025, <a href="https://dev.to/zvone187/what-i-learned-in-6-months-of-working-on-a-codegen-dev-tool-gpt-pilot-4fij">https://dev.to/zvone187/what-i-learned-in-6-months-of-working-on-a-codegen-dev-tool-gpt-pilot-4fij</a>  </li>
<li>AutoGPT - AI Agent Reviews, Features, Use Cases &amp; Alternatives (2025), accessed May 26, 2025, <a href="https://aiagentsdirectory.com/agent/autogpt">https://aiagentsdirectory.com/agent/autogpt</a>  </li>
<li>Autogpt Examples: Expert Tips for Success - Codoid, accessed May 26, 2025, <a href="https://codoid.com/ai/autogpt-examples-expert-tips-for-success/">https://codoid.com/ai/autogpt-examples-expert-tips-for-success/</a>  </li>
<li>What is AutoGPT and How to Use It? - GeeksforGeeks, accessed May 26, 2025, <a href="https://www.geeksforgeeks.org/what-is-autogpt-and-how-to-use-it/">https://www.geeksforgeeks.org/what-is-autogpt-and-how-to-use-it/</a>  </li>
<li>AutoGPT Example Guide: With Hands-On Applications - PageTraffic, accessed May 26, 2025, <a href="https://www.pagetraffic.com/blog/autogpt-example/">https://www.pagetraffic.com/blog/autogpt-example/</a>  </li>
<li>Multi-Agent Collaboration Mechanisms: A Survey of LLMs - arXiv, accessed May 26, 2025, <a href="https://arxiv.org/html/2501.06322v1">https://arxiv.org/html/2501.06322v1</a>  </li>
<li>Towards Effective GenAI Multi-Agent Collaboration: Design and Evaluation for Enterprise Applications - arXiv, accessed May 26, 2025, <a href="https://arxiv.org/html/2412.05449v1">https://arxiv.org/html/2412.05449v1</a>  </li>
<li>Agent-Oriented Programming Examples: Real-World Applications and Use Cases, accessed May 26, 2025, <a href="https://smythos.com/ai-agents/ai-agent-development/agent-oriented-programming-examples/">https://smythos.com/ai-agents/ai-agent-development/agent-oriented-programming-examples/</a>  </li>
<li>20 AI Agent Examples in 2025 - AutoGPT, accessed May 26, 2025, <a href="https://autogpt.net/20-ai-agents-examples/">https://autogpt.net/20-ai-agents-examples/</a>  </li>
<li>2025 AI predictions: The future of application development - OutSystems, accessed May 26, 2025, <a href="https://www.outsystems.com/blog/posts/ai-predictions/">https://www.outsystems.com/blog/posts/ai-predictions/</a>  </li>
<li>AI Agents in 2025: Expectations vs. Reality | IBM, accessed May 26, 2025, <a href="https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality">https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality</a>  </li>
<li>Revolutionary AI Coding Tool: Cody - Made for Efficient Programming, accessed May 26, 2025, <a href="https://www.toolify.ai/ai-news/revolutionary-ai-coding-tool-cody-made-for-efficient-programming-395707">https://www.toolify.ai/ai-news/revolutionary-ai-coding-tool-cody-made-for-efficient-programming-395707</a>  </li>
<li>The 9 best AI coding tools for developers of all levels - Lummi, accessed May 26, 2025, <a href="https://www.lummi.ai/blog/best-ai-coding-tools">https://www.lummi.ai/blog/best-ai-coding-tools</a>  </li>
<li>AI for Testing: Context &amp; Eval with Sourcegraph - AI Native Dev, accessed May 26, 2025, <a href="https://ainativedev.io/podcast/ai-testing-context-eval-sourcegraph">https://ainativedev.io/podcast/ai-testing-context-eval-sourcegraph</a>  </li>
<li>Agentic code generation: The future of software development - AI Accelerator Institute, accessed May 26, 2025, <a href="https://www.aiacceleratorinstitute.com/agentic-code-generation-the-future-of-software-development/">https://www.aiacceleratorinstitute.com/agentic-code-generation-the-future-of-software-development/</a></li>
</ol></section><section class="print-page" id="software-swe_agents_report"><h1 id="software-swe_agents_report-report-on-agent-based-frameworks-for-software-engineering">Report on Agent-Based Frameworks for Software Engineering<a class="headerlink" href="#software-swe_agents_report-report-on-agent-based-frameworks-for-software-engineering" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>Per previous sections, GenAI allows a shift from <a href="#software-introduction-from-code-centric-to-contract-centric-development">Code-Centric to Contract-Centric Development</a> where the upstream artifacts guide the code generation (per standard Software Engineering).</p>
<p>This section is a Research Report on Agent-Based Frameworks for <a href="#software-introduction-software-10-redux">Software Engineering 1.0 Redux</a> (aka Agent-Based Frameworks Supporting Upstream Software Engineering Artifacts)</p>
<ul>
<li>These are <a href="#software-code-code_assistant_agents-autonomy-levels-for-ai-coding-tools">Level 4 â€“ Highly Autonomous Coding</a>: "The AI can handle complex projects end-to-end, needing only minimal human input"</li>
</ul>
<p>Some of these build on existing solutions e.g. SuperClaude, ClaudeFlow build on ClaudeCode, and BMAD can build on ClaudeCode or other tools.</p>
<p>The report is from ChatGPT 4o DeepResearch with the following brief:</p>
<blockquote>
<p>Iâ€™ll get started on a report that surveys frameworks using agents for software engineering, particularly those that support upstream artifacts like requirements, design models, or architecture. Iâ€™ll include both open-source and commercial tools, and provide a high-level overview along with a comparison table highlighting key features and capabilities. </p>
</blockquote>
<p>Note that, technically, it is possible to use <a href="https://medium.com/@johnmunn/5-cursor-personas-your-whole-team-should-be-using-not-just-devs-a4c21c84b46b">Project Rules for modular persona design</a> e.g. .windsurfrules or .cursor/rules, but the focus here is on existing solutions that embody personas and associated artifacts to build a solution.</p>
</div>
<p>Software engineering is increasingly leveraging <strong>AI agent frameworks</strong> to assist not only with coding but also with <strong>upstream development artifacts</strong> like requirements documents, design models, and architectural specifications. Below, we survey several notable frameworks â€“ both open-source and commercial â€“ that employ autonomous or semi-autonomous agents across the software lifecycle. We describe each frameworkâ€™s high-level approach, the upstream artifacts it supports, its agent-based characteristics, integration with development tools, and current maturity. A comparison table at the end summarizes their features side-by-side.</p>
<hr />
<h2 id="software-swe_agents_report-comparison-of-agent-based-se-frameworks">Comparison of Agent-Based SE Frameworks<a class="headerlink" href="#software-swe_agents_report-comparison-of-agent-based-se-frameworks" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th><strong>Framework</strong></th>
<th><strong>Upstream Artifact Support</strong></th>
<th><strong>Agent-Based Approach</strong></th>
<th><strong>Integration</strong></th>
<th><strong>Maturity/Status</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>BMAD-Method</strong></td>
<td>PRDs, architecture docs, and user stories.</td>
<td>Specialized agents (Analyst, PM, Architect, Scrum Master, Dev, QA); checklist-driven.</td>
<td>CLI + Cursor IDE integration. NPM package.</td>
<td>Open-source; v4 active; moderate maturity (~2k GitHub stars).</td>
</tr>
<tr>
<td><strong>SuperClaude</strong></td>
<td>Architectural analysis, design ideas, implementation estimation.</td>
<td>One Claude instance with 9 cognitive personas (Architect, Security, QA, etc.).</td>
<td>Claude Code config layer; CLI/chat commands; Git memory; VS Code support planned.</td>
<td>Open-source; mature in niche (~5k stars); stable and growing.</td>
</tr>
<tr>
<td><strong>ChatDev</strong></td>
<td>User stories, architecture designs, test plans, project docs.</td>
<td>Simulated software team (CEO, CTO, CPO, Dev, Tester, Reviewer); sequential flow.</td>
<td>Python CLI; generates project folders; minimal IDE tooling.</td>
<td>Research-grade; very active (~27k stars); experimental features.</td>
</tr>
<tr>
<td><strong>MetaGPT</strong></td>
<td>User stories, requirements, data models, API specs, design diagrams.</td>
<td>Multi-agent system with SOPs for each role (PM, Architect, Engineer, QA).</td>
<td>Python CLI; flexible LLM backend; outputs markdown &amp; Mermaid diagrams.</td>
<td>Very mature; open-source; extremely popular (~57k stars).</td>
</tr>
<tr>
<td><strong>Claude Flow</strong></td>
<td>Requirements analysis, architectural design, test plans, pseudocode.</td>
<td>Parallel multi-agent workflow (SPARC phases); Memory Bank; agent coordination tools.</td>
<td>Claude Code shell script; CLI; Claude tools (BatchTool, WebFetch); Git auto-commits.</td>
<td>New but structured; open-source; early adoption; rapidly evolving.</td>
</tr>
<tr>
<td><strong>Tabnine AI Agents</strong></td>
<td>Jira issue descriptions (as requirements), plus test coverage and validation reports.</td>
<td>Specialized agents for Implementation, Validation, Testing, and Code Review. Works in human-in-the-loop cycles.</td>
<td>Deep IDE (VS Code, JetBrains) + Jira + CI integration. Supports enterprise/on-prem.</td>
<td>Commercial; generally available since 2024; mature for enterprise use.</td>
</tr>
<tr>
<td><strong>IBM SWE Agents</strong></td>
<td>Bug reports, change requests (as requirements). Test plans derived from fix/feature context.</td>
<td>Research-stage agents: Bug Fixer, Code Editor, Test Generator. Coordinated via orchestration layer.</td>
<td>GitHub-triggered (issue tags); future integration into watsonx / IBM DevOps expected.</td>
<td>Research prototype (2024); strong benchmarks; early enterprise trials.</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="software-swe_agents_report-bmad-method-open-source">BMAD-METHOD (Open-Source)<a class="headerlink" href="#software-swe_agents_report-bmad-method-open-source" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> The <strong>Breakthrough Method for Agile AI-Driven Development (BMAD)</strong> is an open-source framework that orchestrates multiple specialized AI agents to mimic an Agile software team. BMAD introduces custom agent personas for common software roles and guides a project through phases from initial idea to deployment. It was designed to solve problems in AI-assisted dev workflows (like context loss and planning drift) by front-loading planning with dedicated agents.</p>
<p><strong>Upstream Artifact Support:</strong> BMAD explicitly supports creation of upstream artifacts such as <strong>product requirements documents (PRDs)</strong> and <strong>architecture design documents</strong>. In the â€œplanningâ€ phase, specialized agents (Analyst, Product Manager, Architect, etc.) collaborate with the user to generate detailed and consistent specifications, including comprehensive PRDs and technical architecture documentation. These planning outputs are much richer than generic AI-generated tasks, providing a solid blueprint for development. BMAD can also produce a high-level <em>brief</em> (project summary) and even optional UX design outlines before coding begins.</p>
<p><strong>Agent Architecture and Coordination:</strong> BMADâ€™s agent roster mirrors an Agile team. In the planning phase, agents like <em>Business Analyst/Analyst</em>, <em>Product Manager</em>, and <em>Architect</em> work together (via prompt scripts) to produce the requirement and design artifacts. Once planning is done, the framework shifts to the IDE for implementation: a <em>Scrum Master</em> agent breaks the plan into â€œstoryâ€ files (detailed development tasks with embedded context), and a <em>Dev</em> agent then implements code based on these stories. A <em>QA</em> agent may verify the outputs. A central <strong>Orchestrator</strong> agent coordinates the hand-offs (ensuring each story contains all necessary context for the Dev agent) and runs <strong>checklists</strong> to audit consistency across artifacts. Notably, each agent operates in a turn-based sequence with human-in-the-loop checkpoints â€“ for example, agents pause for user feedback at certain steps. This structured multi-agent pipeline enforces consistency from requirements through design to code.</p>
<p><strong>Integration and Tooling:</strong> BMAD is implemented as a Node.js package with configuration files and prompt templates. It can be run in chat UIs (e.g. ChatGPT or a tool called Gemini) for the planning stage, then integrates with the <strong>Cursor IDE</strong> (an AI-enabled code editor) for coding. The planning artifacts (PRD, architecture doc, etc.) are saved as project files which the Scrum Master agent later â€œshardsâ€ into story files in the IDE. BMAD is designed to be flexible â€“ users can customize agent prompts or add â€œexpansion packsâ€ for domains beyond software (e.g. game development or DevOps).</p>
<p><strong>Maturity:</strong> BMAD is a vibrant open-source project (MIT-licensed) with an active community. It has gone through multiple iterations (V2, V3, now V4 as of mid-2025) and garnered significant interest (over 2k GitHub stars). Users report that BMADâ€™s approach can save substantial LLM usage costs by shifting work to the planning phase. Overall, BMAD provides a <strong>comprehensive AI-driven agile methodology</strong> â€“ it is relatively new but evolving rapidly, indicating a growing maturity and real-world experimentation.</p>
<h2 id="software-swe_agents_report-superclaude-open-source">SuperClaude (Open-Source)<a class="headerlink" href="#software-swe_agents_report-superclaude-open-source" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> <strong>SuperClaude</strong> is an open-source configuration framework that augments Anthropicâ€™s Claude (a large language model) with a <strong>team of specialized agent personas and command protocols</strong>. Rather than interacting with a single generalist AI, SuperClaude lets developers invoke different â€œcognitive archetypesâ€ (agents) tailored to specific software engineering tasks. The framework is defined by a set of rules (in <code>RULES.md</code>) and a <strong>Model Context Protocol (MCP)</strong> that gives the AI long-term memory, tool usage abilities, and an efficient communication style. SuperClaudeâ€™s goal is to turn a generic coding assistant into a <strong>context-aware, role-specialized development partner</strong>.</p>
<p><strong>Upstream Artifact Support:</strong> SuperClaude primarily targets the <strong>design and implementation</strong> stages, but it does facilitate upstream design thinking and planning. For example, it includes a persona called <strong>â€œThe Architectâ€</strong> (<code>/persona:architect</code>) whose sole focus is high-level system design and architecture. When activated, this agent will ask questions about scalability and maintainability and apply proven design patterns, effectively helping produce or critique an architectural model of the system. Using the <code>/design</code> command, SuperClaude can generate software designs â€“ for instance, it can output proposed data models or API specifications following a Domain-Driven Design approach. It does not explicitly generate a formal requirements document with its own persona, but it leverages the developerâ€™s input (e.g. user stories or feature descriptions) as the requirement and can <strong>estimate effort</strong> (<code>/user:estimate</code>) based on the design. In essence, SuperClaudeâ€™s upstream support lies in architecture and planning: it helps <strong>design the solution and plan implementation</strong> steps before writing code, though the initial requirements need to be provided by the user.</p>
<p><strong>Agent-Based Characteristics:</strong> SuperClaude features <strong>nine specialized AI personas</strong> that the user can switch between, each configured with different priorities and toolsets. These include roles like <em>Architect</em>, <em>Frontend Developer</em>, <em>Backend Developer</em>, <em>Security Expert</em>, <em>QA Tester</em>, <em>Analyzer</em> (debugger), and even a <em>Mentor</em> for explanations. Internally, all personas are powered by the same LLM (Claude), but SuperClaude uses <strong>modular configuration files</strong> and â€œflagâ€ commands to shape the LLMâ€™s behavior per role. The framework enforces collaboration and parallelism: for example, you can spawn a dedicated frontend and backend agent to work <strong>simultaneously</strong> on different components of a feature. Agents communicate implicitly via the shared context and the MCP tool outputs. SuperClaude emphasizes <strong>autonomy with oversight</strong> â€“ agents will perform tasks (like coding or testing) on their own, but important rules (e.g. never output insecure code) are baked into the persona profiles. A unique aspect is the <strong>Evidence-Based</strong> rule: agents must cite documentation for their decisions, reducing hallucinations. Coordination is handled by the MCPâ€™s decision matrix which decides which tool or persona to invoke based on triggers (user flags, natural language cues, or code context).</p>
<p><strong>Integration:</strong> SuperClaude is used alongside Claudeâ€™s coding interface (Claude Code) or via a CLI. It installs as a <code>.claude/</code> configuration on your system. Developers interact with it through chat commands (for example, in a terminal or chat UI that connects to Claude). The framework provides <strong>18 special â€œ/user:â€ commands</strong> for tasks like <code>/user:design</code>, <code>/user:build</code>, <code>/user:analyze</code>, <code>/user:test</code>, etc., each optionally combined with persona or tool flags. It currently relies on Anthropicâ€™s Claude models (Claude 2, Claude Instant, etc.), and a VS Code extension is on the roadmap. Integration with version control is notable: SuperClaude can checkpoint and roll back conversation/code state with Git commands, effectively maintaining memory across sessions. Overall, it acts as an <strong>overlay</strong> on top of your IDE or CLI, providing an agentic layer that controls Claude for multi-step, multi-role tasks.</p>
<p><strong>Maturity:</strong> SuperClaude is an MIT-licensed project launched in mid-2023 and has gained traction (5k+ GitHub stars). Itâ€™s actively maintained (v2.0.1 as of 2025) with a growing community of contributors. Many developers have praised its practical impact â€“ e.g. using the Architect persona to generate scalable designs, and the Git-based memory to manage iterative changes. Because it builds on a robust LLM (Claude) and adds pragmatic features (like token compression for long contexts), SuperClaude is considered a <strong>stable and useful</strong> addition to a developerâ€™s toolkit, albeit currently tied to Claudeâ€™s availability.</p>
<h2 id="software-swe_agents_report-chatdev-open-source-research">ChatDev (Open-Source Research)<a class="headerlink" href="#software-swe_agents_report-chatdev-open-source-research" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> <strong>ChatDev</strong> is an open-source research framework that demonstrates how multiple LLM-based agents can collaborate to <strong>autonomously develop a software application</strong>. Introduced by researchers in late 2023, ChatDev simulates an entire software startup (a â€œvirtual software companyâ€) with agents fulfilling different organizational roles. These agents communicate in natural language, following a structured <strong>workflow resembling the waterfall model</strong>: phases of designing, coding, testing, and documenting are carried out sequentially by the respective specialists. The core idea is to study collective intelligence â€“ how a team of AI agents can outperform a single agent by divide-and-conquer and collaboration.</p>
<p><strong>Upstream Artifact Support:</strong> ChatDev explicitly includes the <strong>design phase</strong> at the front of its lifecycle. It starts with a software concept or requirement provided by the user (e.g. a one-line idea for an app). The agents then elaborate this into upstream artifacts. For example, the <em>Chief Product Officer (CPO)</em> agent defines <strong>product requirements</strong>, user stories, and possibly a brief specification of features. The <em>Chief Technology Officer (CTO)</em> agent takes those requirements and produces a <strong>system design or architecture</strong>, determining the technical approach. Indeed, ChatDev is reported to output documents like <em>project requirements</em>, <em>UI design drafts</em>, and even <strong>competitive analyses</strong> of the idea. It can also generate technical design artifacts such as data model specifications or API designs, often represented as <strong>Mermaid diagrams</strong> for architecture. After the design is settled, other agents proceed to coding, but importantly ChatDev creates a persistent set of upstream documents (requirements and design docs) that guide the development. The presence of a <em>Reviewer</em> agent also implies it produces documentation or review reports (ensuring the final product aligns with initial requirements), and a <em>Tester</em> agent generates test plans or reports, which are downstream QA artifacts. In summary, ChatDevâ€™s design and planning outputs are a central feature â€“ it delivers <strong>comprehensive documentation from requirements to design models</strong>, before any code is written.</p>
<p><strong>Agent Roles and Collaboration:</strong> The framework organizes agents in a <strong>multi-agent collaboration network</strong> with distinct roles akin to job titles in a company. Key roles include: <strong>CEO</strong> (sets the high-level goal or approves plans), <strong>CPO</strong> (focus on user needs and requirements), <strong>CTO</strong> (technical design decisions), <strong>Programmer</strong> (writes code), <strong>Tester</strong> (tests the code), <strong>Reviewer</strong> (performs code review and documentation), and even an <strong>Art Designer</strong> (which could create UI/UX assets or design elements). These agents communicate in a series of â€œfunctional seminarsâ€ â€“ essentially structured chat rounds dedicated to specific tasks (brainstorming features, designing system, coding modules, etc.). The collaboration is typically organized as a chain: the output of the planning seminar (requirements from CPO) feeds into the design seminar (led by CTO), which then feeds coding (Programmer), then testing, and so forth. ChatDevâ€™s implementation uses a <strong>chain-of-messages orchestration</strong> (sometimes called ChatChain) where each agent gets to contribute and sees prior agentsâ€™ messages. Notably, the researchers implemented standard operating procedures (SOPs) for each role to ensure coherence (e.g. the CPO agent follows a template to produce requirement lists, the CTO agent follows a template to output design specs). This structured multi-agent dialogue allowed ChatDev to significantly outperform single-agent approaches (like GPT-Engineer) on quality metrics of the final software. Each agent is essentially an instance of an LLM (such as GPT-4) prompted to act in-role, and a controller script manages the turn-taking and information flow. There is no heavy tool use by agents in the published version (they primarily communicate and generate code), but the design ensures that <strong>each phaseâ€™s output becomes an artifact</strong> passed down the pipeline.</p>
<p><strong>Integration and Usage:</strong> ChatDev can be run as a Python program using open LLM APIs. Itâ€™s provided as a framework for research/experimentation, and the authors also offered a web demo (SaaS) for a period. Integration with developer tooling is minimal in the basic ChatDev â€“ itâ€™s more of an automated planning and coding engine that produces a project (code + docs) in a workspace folder. The outputs include code files, diagrams (as Mermaid markdown), and documentation files that one can open in an IDE. Because ChatDev agents can execute code (especially the Tester agent running the program), a Docker-based sandbox is used for safety.</p>
<p><strong>Maturity:</strong> As a research prototype, ChatDev is at the proof-of-concept stage (initial version released late 2023). It has received attention for demonstrating the feasibility of multi-agent automated development. IBM noted that ChatDev, along with similar framework MetaGPT, achieved better completeness and consistency in generated software than single-agent methods. Since release, ChatDevâ€™s team has been extending it with more advanced collaboration mechanisms (e.g. a graph-based agent network called MacNet for scalability). The project is active on GitHub under an Apache-2.0 license, with ongoing improvements in efficiency and support for more complex scenarios. While not production-ready for industry use, ChatDev provides a <strong>template for agentic SDLC automation</strong> and a benchmark for future frameworks.</p>
<h2 id="software-swe_agents_report-metagpt-open-source">MetaGPT (Open-Source)<a class="headerlink" href="#software-swe_agents_report-metagpt-open-source" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> <strong>MetaGPT</strong> is another open-source multi-agent framework that gained wide popularity as an â€œAI software company in a box.â€ It assigns different GPT-based agents to classic software team roles and coordinates their efforts to build software from a high-level specification. Released in mid-2023 (and quickly amassing thousands of users), MetaGPT proved that given a short prompt describing a desired application, a suite of agents can produce not only code but also a range of planning artifacts and documentation. It emphasizes carefully orchestrated <strong>Standard Operating Procedures (SOPs)</strong> for each role to ensure the agents collaborate effectively.</p>
<p><strong>Upstream Artifact Support:</strong> MetaGPT excels at generating upstream artifacts. Starting from a one-line requirement input, MetaGPTâ€™s agents will output: <strong>user stories</strong>, <strong>competitive analysis</strong>, <strong>detailed requirements</strong>, <strong>data structures and API designs</strong>, and other design documents. The framework explicitly lists that it produces <em>â€œuser stories / competitive analysis / requirements / data structures / APIs / documents, etc.â€</em> as part of its deliverables. For example, given a prompt to create a simple e-commerce app, MetaGPTâ€™s Product Manager agent might generate user personas and user stories; the Architect agent would design the database schema and component diagram; a Market Analyst agent (if included) might provide a brief competitive feature comparison. These artifacts are saved into a structured workspace (often as Markdown files or images for diagrams). Notably, MetaGPT uses <strong>Mermaid.js</strong> to create UML-like diagrams for architecture and workflows â€“ this means it actually visualizes the design model (class diagrams, flow charts) as part of its output. This comprehensive upstream support is a standout feature: MetaGPT doesnâ€™t jump straight to code, but first <strong>fleshes out specifications and designs</strong> to guide the coding stage. This results in a more organized project that a human can review (and modify) before implementation.</p>
<p><strong>Agent Roles and Mechanism:</strong> In MetaGPT, multiple GPT-4 (or similar) instances are each assigned a role such as <strong>Product Manager, Project Manager, Architect, Software Engineer, QA,</strong> etc.. At minimum, the published version included Product Manager, Architect, Project Manager, and Engineer roles. These agents follow a fixed coordination pattern: typically the Product Manager analyzes the raw requirement and expands it, the Architect plans the system design, the Project Manager organizes tasks, and the Engineer writes the code. Communication between agents is orchestrated so that each agentâ€™s output becomes input for the next. The project uses a prompt templating approach to enforce that, for example, the Architect agentâ€™s prompt includes the Product Managerâ€™s output (user stories, requirements) and then instructs, â€œAs the software architect, design the system based on these.â€ Each role has a predefined <strong>prompt template (SOP)</strong> to maintain structure. For instance, the Architectâ€™s SOP might ensure they produce a section on data schema, a section on module design, etc. MetaGPTâ€™s controller then runs these agents in sequence (with possible iterations if something is incomplete). This clear division of labor allowed MetaGPT to demonstrate high completeness and consistency in generated projects. It also can recruit additional agents dynamically if needed â€“ for example, if a specific specialized task comes up, it could spawn a new agent with an appropriate skill (the framework was designed to be extensible). However, by default, the core team handles most tasks. The outcome is that <strong>each agentâ€™s â€œdeliverableâ€ is saved</strong>: the Product Managerâ€™s user_stories.md, the Architectâ€™s design.md (with diagrams), the Engineerâ€™s code files, etc., giving a multi-perspective result.</p>
<p><strong>Integration:</strong> MetaGPT is primarily a CLI/command-line tool. Developers install it (Python and Node dependencies) and run it by providing a prompt. It then generates a new project directory with all the files. Because itâ€™s not tied to an IDE, one would typically open the resulting files in their preferred IDE for review. There isnâ€™t an interactive loop with human feedback in the default flow â€“ it attempts autonomy from requirement to final product. That said, users can intervene between phases if using it stepwise. MetaGPT can leverage external tools or APIs if configured (e.g. searching for information if needed), but most of its knowledge comes from the base LLM. The projectâ€™s documentation suggests using Docker for sandboxing if the agents need to execute code/tests. <strong>Comparison with ChatDev:</strong> Both are similar in concept; indeed, an evaluation by ChatDevâ€™s authors found MetaGPT performing well but noted ChatDevâ€™s communication mechanism yielded higher quality in some aspects. Regardless, MetaGPT integration is straightforward â€“ it acts as an <strong>automated software project generator</strong> one can run on a local machine.</p>
<p><strong>Maturity:</strong> MetaGPT is fairly mature as an open project â€“ it went viral (over 17k GitHub stars by late 2023) and has an active community of users and contributors. It inspired many derivative projects. As of 2024, it remains under active development (now part of the FoundationAgents organization). MetaGPT is mostly a demonstration; while it can produce a working app for simple requirements, real-world applications likely need iteration and refinement by human developers. However, its strength in producing structured documentation and multi-agent reasoning is a valuable contribution. The framework is often cited as <strong>revolutionary in showcasing multi-agent collaboration</strong> in SE. Itâ€™s open-source (MIT license) and is frequently updated with improvements in prompt strategies and support for new LLMs. Companies and researchers sometimes use MetaGPT as a baseline for agent-based software development experiments.</p>
<h2 id="software-swe_agents_report-tabnine-ai-agents-for-sdlc-commercial">Tabnine AI Agents for SDLC (Commercial)<a class="headerlink" href="#software-swe_agents_report-tabnine-ai-agents-for-sdlc-commercial" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> <strong>Tabnine</strong>, known for its AI code completion, has introduced a suite of AI agents to support various stages of the software development lifecycle (SDLC) in a commercial offering. In late 2024, Tabnine announced <strong>AI agents for Atlassian Jira</strong> â€“ specifically an â€œImplementation Agentâ€ and a â€œValidation Agentâ€ â€“ that work from issue descriptions to code and test changes. This is part of Tabnineâ€™s vision of â€œAI-driven developmentâ€ where AI agents and human engineers collaborate on tasks, with AI managing many aspects of the development workflow. In addition to the Jira-focused agents, Tabnine also has an <strong>AI Test Agent</strong> (for generating and running tests) and an AI Code Review Agent (for analyzing pull requests), extending agent support to QA and code quality steps.</p>
<p><strong>Upstream Artifact Support:</strong> Tabnineâ€™s approach uniquely ties into <strong>requirements as captured in issue trackers</strong>. The Jira Implementation Agent takes the natural-language <strong>requirements in a Jira issue</strong> (e.g. user story or bug description) and automatically generates the code to implement that issue. In doing so, it effectively reads an upstream artifact â€“ the issue text, which often contains acceptance criteria or a feature description â€“ and translates it into code changes. While it doesnâ€™t produce a separate requirements specification (the requirement is the Jira ticket itself), it ensures that the requirement is addressed. The <strong>Jira Validation Agent</strong> then acts on the <em>requirement</em> as well: it checks that the generated code indeed fulfills the issueâ€™s requirements. This agent will verify functional behavior and suggest fixes if the code diverges from the specified criteria. By doing this validation, Tabnine is effectively <em>formalizing the link</em> between requirements and implementation. Moreover, because Tabnineâ€™s agents can propose additional tests, one can view those tests as artifacts derived from requirements (testing each acceptance criterion). Tabnineâ€™s platform doesnâ€™t output design diagrams or full architecture documents; instead, it integrates into the agile process by going from <strong>user story to code and tests</strong>. For many teams, the Jira ticket itself is the upstream artifact, and Tabnineâ€™s agents ensure itâ€™s fully handled. In summary, Tabnine supports upstream artifacts in the sense of consuming and honoring them (Jira stories, bug reports) and automatically producing downstream results (code, validation) aligned to them.</p>
<p><strong>Agent Architecture:</strong> Tabnineâ€™s SDLC agents operate within the development pipeline as specialized AI services. The <strong>Implementation Agent</strong> is triggered by a user action (one-click from a Jira issue) and it performs multi-step planning internally: analyzing the issue, retrieving relevant repository context, and then generating code changes. The <strong>Validation Agent</strong> similarly analyzes code diffs and the issue text to ensure alignment. These can be seen as distinct agents with different objectives that communicate via shared context (the code changes and issue description). Tabnineâ€™s system likely uses large language models (possibly GPT-4 or proprietary models) under the hood for each agent. Coordination occurs in a closed-loop: after implementation, validation runs, and the developer is then presented with the combined outcome (new code plus a validation report). Tabnine also allows the developer to iteratively refine the output by asking the agent to adjust if something is off, effectively supporting a <strong>human-in-the-loop</strong> feedback cycle. Beyond Jira, the AI Test Agent can generate unit or integration tests automatically when pointed at code changes (using the code and possibly documentation as input). The Code Review Agent will examine a pull requestâ€™s diff and leave comments or suggestions, behaving like a static analysis + reviewer. These are separate agents focusing on artifacts like <em>pull request descriptions</em>, <em>commit diffs</em>, and <em>test coverage reports</em>, which are intermediate artifacts in the dev process. All Tabnine agents are orchestrated to keep the developer in control â€“ for instance, they do not auto-merge code; a human reviews suggestions from the Jira agents and decides to accept changes or not.</p>
<p><strong>Integration:</strong> Tabnineâ€™s agents integrate deeply with popular developer tools. The Jira agents integrate Atlassian Jira with the development environment: the developer can trigger the Implementation Agent from the Jira UI or IDE, and it will interface with the codebase (through the IDE or repository). The results (code changes) are delivered either as a Git branch/commit or as a patch the developer applies. The Validation Agent can run as part of CI or within the IDE to confirm the issue is resolved. Tabnineâ€™s IDE plugin (for VS Code, IntelliJ, etc.) is the primary user interface, now augmented with chat-based interactions for these agents. So a developer might open a Tabnine chat panel in VS Code, ask the Jira agent to implement a specific issue, and watch as the code appears. Tabnine emphasizes enterprise readiness: code stays private (the models can be self-hosted/on-premises if needed), addressing confidentiality. This makes it appealing for organizations that use Jira workflows. Essentially, Tabnine is bringing <strong>agentic automation into existing DevOps</strong> â€“ linking issue trackers to IDE to version control in a seamless flow.</p>
<p><strong>Maturity:</strong> Tabnineâ€™s agent features are relatively new (general availability announced in Sep 2024), but Tabnine itself is an established company in AI coding tools. The Jira Integration is likely in active use by early-adopter teams. As a commercial product, it is polished for professional environments (with considerations for code security, team settings, etc.). The concept of â€œissue-to-codeâ€ that Tabnine pioneered is a significant step forward, and no major competitor offered that at the time, which suggests a level of innovation and maturity in their implementation. Itâ€™s still evolving; future updates may expand the range of upstream artifacts (for instance, parsing design documents or architecture diagrams linked in tickets). In the current state, Tabnineâ€™s AI agents provide a <strong>production-ready assistive system</strong> that offloads routine coding from human devs, while ensuring requirement coverage. This is a commercially supported solution, making it one of the more <em>practical and immediately usable</em> frameworks in this list for industry teams.</p>
<h2 id="software-swe_agents_report-ibms-software-engineering-agent-suite-researchprototype">IBMâ€™s Software Engineering Agent Suite (Research/Prototype)<a class="headerlink" href="#software-swe_agents_report-ibms-software-engineering-agent-suite-researchprototype" title="Permanent link">&para;</a></h2>
<p><strong>Overview:</strong> IBM Research has been actively developing an <strong>AI agent suite for automating software engineering tasks</strong>. In late 2024, IBM announced an experimental set of <strong>Software Engineering (SWE) AI agents (v1.0)</strong> aimed at reducing developersâ€™ workload, particularly by addressing bug backlogs. These agents leverage multiple large language models and operate together to perform tasks such as <strong>bug discovery, code editing, and test generation</strong>. IBMâ€™s work is positioned within its larger <strong>watsonx</strong> initiative â€“ using IBMâ€™s Granite series foundation models and an orchestration framework to coordinate the agents. While still in testing, this effort is a key example of a commercial research-led framework, likely to be integrated into enterprise tooling in the near future.</p>
<p><strong>Upstream Artifact Support:</strong> The IBM SWE agents currently focus more on code maintenance and quality tasks than on early-phase artifacts. They do not appear to generate requirements or design models; instead, they take existing developer inputs (like bug reports or change requests) and act on them. For instance, a developer can tag a GitHub issue with a specific label (IBMâ€™s â€œSWEâ€) to hand it to the agent â€“ the agent will then analyze the described bug (an upstream artifact in the form of an issue report) and locate the problematic code and propose a fix. In this sense, the agent uses a <em>natural language bug description</em> (which is a kind of requirement for a fix) as input. Another agent IBM has built can create and execute tests, which means it takes a piece of code or a feature spec and produces <strong>test cases</strong> (test scripts are an artifact upstream of validation). These test-generation agents implicitly reason about the intended behavior (which overlaps with requirement understanding). We can surmise that as IBMâ€™s framework evolves, it might incorporate more design-level reasoning (IBM has a history of AI tools for architecture, e.g. past projects with UML models, but those have not been explicitly mentioned in this LLM-based context). For now, <strong>IBMâ€™s agents excel at reading and acting on software artifacts like bug reports, code diffs, and test results</strong>, but do not produce design documentation or formal requirement specs themselves.</p>
<p><strong>Agent-Based Characteristics:</strong> IBMâ€™s approach uses <strong>multiple specialized LLM agents coordinated for end-to-end tasks</strong>. For example, one agent focuses on <strong>bug localization and repair</strong> â€“ it likely parses an issue description, scans the repository (perhaps using a code-search tool) to find suspect functions, then generates a patch. Another agent focuses on <strong>code edit requests</strong> â€“ a developer can ask to refactor or modify code via a natural language instruction, and the agent will edit the lines accordingly using an IBM Granite model fine-tuned for code. There is also a <strong>test-generation agent</strong> that creates new tests and possibly runs them to ensure a bug fix didnâ€™t break anything. IBM is building an <strong>orchestration framework</strong> to chain these agents into workflows. For instance, an orchestration might be: when a bug report comes in, trigger bug-fix agent; then trigger test agent to generate regression tests; then perhaps trigger a code quality agent to review the fix. The agents communicate via shared artifacts (a diff produced by one is input for another, etc.). Coordination, according to IBMâ€™s chief scientist, is aimed at letting these agents handle tasks with minimal human intervention, reducing backlog and freeing developers for new feature work. IBM has reported metrics from benchmarks (SWE-Bench) indicating their agents can localize and fix issues quite efficiently (five minutes on average for a fix, with around 23.7% success on a standard test suite â€“ among the top performers on that benchmark). This indicates a fairly sophisticated interplay of analysis and action by the agents.</p>
<p><strong>Integration:</strong> As of the announcement, the IBM SWE agents were in a test phase with integration likely via GitHub (issue tagging) and potentially IDE plugins or CI tools in the future. IBM would presumably offer this through its <strong>watsonx.ai platform</strong> or Cloud services once ready, meaning it could integrate with enterprise Git repositories and project management systems. Thereâ€™s mention that tagging a GitHub issue triggers the agent, which suggests a developer workflow integration thatâ€™s quite seamless â€“ just mark an issue and let the AI handle it. For editing tasks, a developer might use a chat interface or command within an IDE (â€œIBM, implement this changeâ€¦â€). IBMâ€™s orchestration framework is intended to ease creating multi-agent workflows, so integration might also allow custom pipelines â€“ e.g. an organization could configure: static analysis agent -&gt; security fix agent -&gt; test agent, etc., as part of their DevOps pipeline. Because these agents use IBMâ€™s own LLM (Granite) on watsonx, adoption would involve accessing IBMâ€™s cloud or on-prem model deployments.</p>
<p><strong>Maturity:</strong> IBMâ€™s agent suite is still in <strong>research preview</strong> (as of late 2024). Itâ€™s not a generally available product yet, but IBMâ€™s communications imply they are moving towards that. Theyâ€™ve proven viability through benchmarks and are refining the system. IBM has a long history of transferring AI research to enterprise tools, so we can expect these multi-agent capabilities to appear in offerings like <strong>IBM ELM (Engineering Lifecycle Management)</strong> or cloud DevOps solutions. For now, itâ€™s a <strong>cutting-edge commercial framework</strong> being tested in real-world scenarios. Its strength lies in addressing well-defined tasks (bugs, edits, tests). If we compare to other frameworks: IBMâ€™s is less about full project generation and more about <strong>augmentation of the development pipeline</strong>. Itâ€™s also one of the few targeting bug fixing explicitly. In terms of upstream support, it is limited in this early stage, but as the framework grows, IBM might extend agents into design and requirement management (areas IBM has interest and tools in). Overall, IBMâ€™s work underscores that major industry players see value in <strong>teams of AI agents working alongside human developers</strong>, and they are investing to integrate that into software engineering practice.</p>
<hr />
<h2 id="software-swe_agents_report-claude-flow-formerly-claude-sparc"><strong>Claude Flow (formerly Claude-SPARC)</strong><a class="headerlink" href="#software-swe_agents_report-claude-flow-formerly-claude-sparc" title="Permanent link">&para;</a></h2>
<h3 id="software-swe_agents_report-high-level-overview"><strong>High-Level Overview</strong><a class="headerlink" href="#software-swe_agents_report-high-level-overview" title="Permanent link">&para;</a></h3>
<p><strong>Claude Flow</strong> is an agentic orchestration system designed to run on Anthropic's Claude Code platform. It formalizes the <strong>SPARC methodology</strong> (Specification, Pseudocode, Architecture, Refinement, Completion) in a practical multi-agent setup, optimized for scalable software delivery. It incorporates:</p>
<ul>
<li>Modular execution phases</li>
<li>A <strong>Memory Bank</strong> for state retention</li>
<li>Agent coordination protocols</li>
<li>Integrated tooling (e.g., <code>BatchTool</code>, <code>WebFetchTool</code>, Git commit hooks)</li>
<li>Optional modes (backend-only, frontend-only, full-stack)</li>
</ul>
<h3 id="software-swe_agents_report-upstream-artifact-support"><strong>Upstream Artifact Support</strong><a class="headerlink" href="#software-swe_agents_report-upstream-artifact-support" title="Permanent link">&para;</a></h3>
<p>Claude Flow explicitly supports:</p>
<ul>
<li>Requirements analysis (via project spec ingestion)</li>
<li>Architecture modeling (e.g. component breakdowns)</li>
<li>Design refinement (via pseudocode and system planning stages)
  All of this is structured via the SPARC methodology, with output artifacts stored in a project workspace.</li>
</ul>
<h3 id="software-swe_agents_report-agent-based-architecture"><strong>Agent-Based Architecture</strong><a class="headerlink" href="#software-swe_agents_report-agent-based-architecture" title="Permanent link">&para;</a></h3>
<ul>
<li><strong>Parallel multi-agent execution</strong> with Claude instances working across different SPARC stages.</li>
<li>An <strong>integration ledger</strong> and <strong>task assignment map</strong> coordinate responsibilities.</li>
<li>A <strong>shared memory mechanism</strong> ensures context is preserved and reused.</li>
<li>Emphasizes concurrency (e.g. backend and frontend workstreams) and agent learning.</li>
</ul>
<h3 id="software-swe_agents_report-integration-maturity"><strong>Integration &amp; Maturity</strong><a class="headerlink" href="#software-swe_agents_report-integration-maturity" title="Permanent link">&para;</a></h3>
<ul>
<li>Shell-based runner (<code>claude-flow.sh</code>) compatible with Claude Code.</li>
<li>Auto-commits changes and tracks output through Git.</li>
<li>Web research and code synthesis are integrated via Claudeâ€™s tools.</li>
<li>Still early-stage but more structured and production-ready than the prior gist version.</li>
<li>Open-source (MIT license) with growing interest and contributions.</li>
</ul>
<hr />
<h2 id="software-swe_agents_report-references">References<a class="headerlink" href="#software-swe_agents_report-references" title="Permanent link">&para;</a></h2>
<ol>
<li>
<p><strong>Claude Flow (formerly Claude-SPARC)</strong>
   <a href="https://github.com/ruvnet/claude-flow">https://github.com/ruvnet/claude-flow</a></p>
</li>
<li>
<p><strong>BMAD-METHOD GitHub Repository</strong>
   <a href="https://github.com/bmad-method/bmad">https://github.com/bmad-method/bmad</a></p>
</li>
<li>
<p><strong>BMAD Documentation: Agile AI Development Pipeline</strong>
   <a href="https://bmad-method.github.io/docs/pipeline">https://bmad-method.github.io/docs/pipeline</a></p>
</li>
<li>
<p><strong>SuperClaude GitHub Repository</strong>
   <a href="https://github.com/dsdanielpark/superclaude">https://github.com/dsdanielpark/superclaude</a></p>
</li>
<li>
<p><strong>SuperClaude: RULES.md (Agent Rules and Protocols)</strong>
   <a href="https://github.com/dsdanielpark/superclaude/blob/main/RULES.md">https://github.com/dsdanielpark/superclaude/blob/main/RULES.md</a></p>
</li>
<li>
<p><strong>SuperClaude: Model Context Protocol</strong>
   <a href="https://github.com/dsdanielpark/superclaude/blob/main/MCP.md">https://github.com/dsdanielpark/superclaude/blob/main/MCP.md</a></p>
</li>
<li>
<p><strong>BMAD V4 Design Docs</strong>
   <a href="https://github.com/bmad-method/bmad/discussions/33">https://github.com/bmad-method/bmad/discussions/33</a></p>
</li>
<li>
<p><strong>SuperClaude Quick Start &amp; Persona Command Reference</strong>
   <a href="https://github.com/dsdanielpark/superclaude#quick-start">https://github.com/dsdanielpark/superclaude#quick-start</a></p>
</li>
<li>
<p><strong>SuperClaude: Claude Code Tooling Integration</strong>
   <a href="https://github.com/dsdanielpark/superclaude/blob/main/claude-config.md">https://github.com/dsdanielpark/superclaude/blob/main/claude-config.md</a></p>
</li>
<li>
<p><strong>BMAD YouTube Channel</strong>
    <a href="https://www.youtube.com/@bmad-method">https://www.youtube.com/@bmad-method</a></p>
</li>
<li>
<p><strong>MetaGPT GitHub Repository</strong>
    <a href="https://github.com/geekan/MetaGPT">https://github.com/geekan/MetaGPT</a></p>
</li>
<li>
<p><strong>MetaGPT Paper: â€œMetaGPT: Meta Programming for Multi-Agent Collaborative Codingâ€</strong>
    <a href="https://arxiv.org/abs/2308.00352">https://arxiv.org/abs/2308.00352</a></p>
</li>
<li>
<p><strong>ChatDev GitHub Repository</strong>
    <a href="https://github.com/openbmb/ChatDev">https://github.com/openbmb/ChatDev</a></p>
</li>
<li>
<p><strong>ChatDev Web Demo</strong>
    <a href="https://chatdev.streamlit.app/">https://chatdev.streamlit.app/</a></p>
</li>
<li>
<p><strong>ChatDev Paper: â€œChatDev: Revolutionizing Software Development with AI Agentsâ€</strong>
    <a href="https://arxiv.org/abs/2310.01894">https://arxiv.org/abs/2310.01894</a></p>
</li>
<li>
<p><strong>ChatDev: MacNet and Collaboration Framework Update</strong>
    <a href="https://github.com/OpenBMB/ChatDev/pull/158">https://github.com/OpenBMB/ChatDev/pull/158</a></p>
</li>
<li>
<p><strong>MetaGPT: MGX Spin-off Platform</strong>
    <a href="https://github.com/geekan/mgx">https://github.com/geekan/mgx</a></p>
</li>
<li>
<p><strong>MetaGPT: SOP Design Templates</strong>
    <a href="https://github.com/geekan/MetaGPT/tree/master/meta/sop">https://github.com/geekan/MetaGPT/tree/master/meta/sop</a></p>
</li>
<li>
<p><strong>Claude Flow: Memory Bank and Agent Coordination</strong>
    <a href="https://github.com/ruvnet/claude-flow/blob/main/docs/memory.md">https://github.com/ruvnet/claude-flow/blob/main/docs/memory.md</a></p>
</li>
<li>
<p><strong>BMAD Expansion Packs (e.g., Game Dev, DevOps)</strong>
    <a href="https://github.com/bmad-method/bmad/discussions/27">https://github.com/bmad-method/bmad/discussions/27</a></p>
</li>
<li>
<p><strong>IBM SWE Agents â€“ Official Announcement</strong>
    <a href="https://research.ibm.com/blog/swe-agent-suite-ai">https://research.ibm.com/blog/swe-agent-suite-ai</a></p>
</li>
<li>
<p><strong>IBM SWE Agents on GitHub (Prototype)</strong>
    <a href="https://github.com/IBM/swe-agent">https://github.com/IBM/swe-agent</a></p>
</li>
<li>
<p><strong>IBM Granite Models Overview (Watsonx)</strong>
    <a href="https://www.ibm.com/blog/ibm-granite-open-source-models/">https://www.ibm.com/blog/ibm-granite-open-source-models/</a></p>
</li>
<li>
<p><strong>Tabnine AI Agents for Jira â€“ Product Page</strong>
    <a href="https://www.tabnine.com/blog/tabnine-jira-agents/">https://www.tabnine.com/blog/tabnine-jira-agents/</a></p>
</li>
<li>
<p><strong>Tabnine Test and Review Agents â€“ Announcement Blog</strong>
    <a href="https://www.tabnine.com/blog/tabnine-code-review-agent-and-test-agent/">https://www.tabnine.com/blog/tabnine-code-review-agent-and-test-agent/</a></p>
</li>
</ol></section><section class="print-page" id="software-swe_agents"><h1 id="software-swe_agents-software-engineering-with-genai">Software Engineering with GenAI<a class="headerlink" href="#software-swe_agents-software-engineering-with-genai" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section provides an overview of the context an agent (human or LLM) needs for Software Engineering.</p>
</div>
<h2 id="software-swe_agents-software-engineering">Software Engineering<a class="headerlink" href="#software-swe_agents-software-engineering" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/VandV.png" />
"Incremental Architecture-centric Validation &amp; Verification Improves Qualification Confidence"
Continuous Verification &amp; Validation of Critical Software via DevSecOps, <a href="https://apps.dtic.mil/sti/pdfs/AD1187382.pdf">https://apps.dtic.mil/sti/pdfs/AD1187382.pdf</a></p>
</figure>
<h2 id="software-swe_agents-how-anthropic-uses-claude-for-production-code">How Anthropic uses Claude for Production Code<a class="headerlink" href="#software-swe_agents-how-anthropic-uses-claude-for-production-code" title="Permanent link">&para;</a></h2>
<p><a href="https://www.youtube.com/watch?v=fHWFF_pnqDk">Informative talk from Anthropic</a> on how they responsibly merged a 22,000-line change, heavily written by Claude, into their production reinforcement learning codebase by employing several key strategies:</p>
<ul>
<li><strong>Embracing the Product Manager Role for Claude</strong>: This wasn't a single prompt but involved days of human work to define requirements and guide Claude<ul>
<li>The human team acted as product managers for Claude, providing the necessary context and direction</li>
</ul>
</li>
<li><strong>Focusing on Leaf Nodes</strong>: The change was largely concentrated in "leaf nodes" of the codebase</li>
<li>These are parts of the system where nothing else depends on them, making it acceptable for some technical debt to exist because they are unlikely to change or have further things built upon them</li>
<li><strong>Heavy Human Review for Core Architecture</strong><ul>
<li>For the parts of the codebase that were important and needed to be extensible, heavy human review was conducted</li>
</ul>
</li>
<li><strong>Designing for Verifiability</strong>:<ul>
<li>They carefully designed stress tests for stability and ran them for long durations, allowing stability to be measured without reading the code</li>
<li>The entire system was designed to have easily human-verifiable inputs and outputs, enabling correctness verification based on these without needing to read the full underlying implementation</li>
<li>These elements created verifiable checkpoints that allowed confidence in the change even without understanding the full code</li>
</ul>
</li>
</ul>
<p>By combining these methods, Anthropic was able to achieve the same level of confidence in this AI-generated change as any other change, but deliver it in a fraction of the time and effort it would have taken to write and review every line by hand. This approach allowed them to think differently about their engineering capabilities, realizing that larger features and changes could be undertaken more efficiently</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a href="https://youtu.be/fHWFF_pnqDk?t=220">The length of tasks AIs can do is doubling every 7 months</a>.</p>
<p>As at May 2025, we're at 1 hour.</p>
</div>
<h2 id="software-swe_agents-software-engineering-artifacts">Software Engineering Artifacts<a class="headerlink" href="#software-swe_agents-software-engineering-artifacts" title="Permanent link">&para;</a></h2>
<p><strong>Code is informed by upstream activities (requirements, architecture, design, components, etc.) and downstream activities (tests, user feedback).</strong></p>
<ul>
<li>The code itself is the source of truth for what was implemented, but not why it was implemented that way, nor whether it does the right thing or does it correctly.<ul>
<li>The source of truth for these aspects is captured in other <a href="https://www.google.com/search?q=software_artifacts/">Software Engineering Artifacts</a>.</li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>These Software Engineering Artifacts inform the code and should live with the code. This means they should be in sync with the code and accessible when code is generated. Specifically, they should be located in the same organization/repository as the code, in a format that is both LLM and human-friendly (<a href="#software-software_artifacts-artifact-formats-for-ai-integration">Software Engineering Artifact Formats</a>).</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>At Google, our most successful efforts have been when documentation is treated like code and incorporated into the traditional engineering workflow, making it easier for engineers to write and maintain simple documents. <a href="https://abseil.io/resources/swe-book/html/ch10.html#what_qualifies_as_documentationquestion">https://abseil.io/resources/swe-book/html/ch10.html#what_qualifies_as_documentationquestion</a></p>
<p>Documentation must be as close to the code as possible. It must be easy to maintain, easy to keep up to date, and easy to find.</p>
<p><a href="https://abseil.io/resources/swe-book">Software Engineering at Google</a></p>
</div>
</div>
<h2 id="software-swe_agents-software-engineering-knowledge">Software Engineering Knowledge<a class="headerlink" href="#software-swe_agents-software-engineering-knowledge" title="Permanent link">&para;</a></h2>
<h3 id="software-swe_agents-domain-knowledge">Domain Knowledge<a class="headerlink" href="#software-swe_agents-domain-knowledge" title="Permanent link">&para;</a></h3>
<p>Code is also informed by Domain Knowledge.</p>
<div class="admonition info">
<p class="admonition-title">Taking Security as an example Domain</p>
<p><a href="https://baxbench.com/">https://baxbench.com/</a> is a recent (2025) benchmark evaluating LLMs on secure and correct code generation. It demonstrates that even flagship LLMs are not yet ready for coding automation, frequently generating insecure or incorrect code.</p>
<p>Three levels of Security Reminder are provided to the models:</p>
<p><strong>No Security Reminder</strong>: The current highest score is 25% Insecure or Correct code generated.</p>
<ul>
<li>"The models are only prompted to complete the coding task. The prompt contains no security-specific instructions, reflecting a realistic interaction with a developer that does not make explicit security considerations."</li>
</ul>
<p><strong>Generic Security Reminder</strong>: The current highest score is 18.2% Insecure or Correct code generated.</p>
<ul>
<li>The models are prompted to complete the coding task and are explicitly reminded to make security considerations and follow security best practices.</li>
</ul>
<p><strong>Oracle Security Reminder</strong>: The current highest score is 10% Insecure or Correct code generated.</p>
<ul>
<li>The models are prompted to complete the coding task and are explicitly reminded to avoid specific security vulnerabilities that could occur in the given task. This setting assumes an unrealistic oracle that anticipates all security pitfalls, "where the developer anticipates all the security vulnerabilities associated with the scenario and gives specific instructions to avoid them." This prompt provides an upper bound on the models' security performance.</li>
</ul>
<p>The models are not provided with any security guidance or additional context (security knowledge for the specific task like threat models, security design patterns, or secure code guidelines).</p>
<ul>
<li>It is very likely that the models would achieve better benchmark results with the right context and guidance. This can be proven by evaluating such a setup against the benchmark.</li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">Domain knowledge must be available to the Agent</p>
<p>Even a simple reminder makes a significant difference, whereas context-specific reminders yield a much greater difference.</p>
<p>Taking Security as an example Domain:</p>
<ul>
<li>Security guidance or additional context (security knowledge for the specific task, such as threat models, security design patterns, or secure code guidelines) can significantly improve performance.</li>
</ul>
</div>
<h3 id="software-swe_agents-tacit-knowledge">Tacit Knowledge<a class="headerlink" href="#software-swe_agents-tacit-knowledge" title="Permanent link">&para;</a></h3>
<p>Tacit knowledge is knowledge that resides in personal experience, skills, and intuition rather than being explicitly documented. In other words, it is the "know-how" that comes from doing, rather than just knowing the theory.</p>
<div class="admonition tip">
<p class="admonition-title">Agents need a mechanism to build tacit knowledge</p>
<p>In addition to Software Engineering Artifacts and Domain Knowledge, agents need a mechanism to build tacit knowledge.</p>
</div>
<p>In a recent study, Developers report AI not utilizing important tacit knowledge or context as a factor likely to contribute to slowdown.</p>
<div class="admonition quote">
<p class="admonition-title">Implicit repository context (Limits AI performance, Raises developer performance)</p>
<p>One developer notes that AI often
acts like a new contributor to the repository, and that â€œAI doesnâ€™t pick the right location to make the
edits.â€ Another developer notes that while â€œwe [..] know the data that will interact with the code,
but the model doesnâ€™t know the data. It doesnâ€™t know we need to take care of this weird case of
backwards compatibility and [thus] keep this specific line. And this is very hard to give as [context
to the model].â€.</p>
<p><a href="https://arxiv.org/pdf/2507.09089#page=17">Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity</a>, "C.1.5 Implicit repository context (Limits AI performance, Raises developer performance)" July 2025</p>
</div>
<h2 id="software-swe_agents-takeaways">Takeaways<a class="headerlink" href="#software-swe_agents-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<p>The context an agent (human or LLM) needs for Software Engineering includes:</p>
<ul>
<li>Software Engineering Artifacts (including, but not limited to, Code)</li>
<li>Software Engineering Knowledge<ul>
<li>Domain Knowledge</li>
<li>Tacit Knowledge</li>
</ul>
</li>
</ul>
<p>A Software Engineering setup should have a way to manage this context and provide it to the agent when required.</p>
</div></section><section class="print-page" id="software-code-leaderboards"><h1 id="software-code-leaderboards-ai-coding-leaderboards">AI Coding Leaderboards<a class="headerlink" href="#software-code-leaderboards-ai-coding-leaderboards" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This page is a list of benchmarks for LLMs that are used to help with coding.</p>
<p>It covers both Coding Assistants and Autonomous Coding Agents</p>
</div>
<h2 id="software-code-leaderboards-leaderboards">Leaderboards<a class="headerlink" href="#software-code-leaderboards-leaderboards" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Leaderboard</th>
<th>Category</th>
<th>Tasks</th>
<th>Metrics</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://aider.chat/docs/leaderboards/">Aider LLM Leaderboards</a></td>
<td>Coding Assistant</td>
<td>225 Exercism exercises across C++, Go, Java, JavaScript, Python, Rust</td>
<td>Two-pass pass rates; cost per run; edit correctness</td>
</tr>
<tr>
<td><a href="https://evalplus.github.io/leaderboard.html">EvalPlus Leaderboard</a></td>
<td>Coding Assistant</td>
<td>HumanEval+ (164 hand-verified Python); MBPP+ (399 sanitized Python)</td>
<td>pass@1 (greedy); extended efficiency via EvalPerf</td>
</tr>
<tr>
<td><a href="https://leaderboard.tabbyml.com/">TabbyML Coding LLMs Leaderboard</a></td>
<td>Coding Assistant</td>
<td>Amazon CCEval next-line tasks in Python, JS, Goâ€¦</td>
<td>Next-line accuracy (exact-match of very next line)</td>
</tr>
<tr>
<td><a href="https://sparksofagi.github.io/MHPP/">MHPP Leaderboard</a></td>
<td>Coding Assistant</td>
<td>210 â€œMostly Hardâ€ multi-step Python problems</td>
<td>pass@1 (greedy); sampling (T=0.7, 100 runs)</td>
</tr>
<tr>
<td><a href="https://github.com/lmarena/copilot-arena">Copilot Arena</a></td>
<td>Coding Assistant</td>
<td>Paired autocomplete &amp; inline-editing comparisons</td>
<td>ELO-style rankings from user votes</td>
</tr>
<tr>
<td><a href="https://web.lmarena.ai/leaderboard">WebDev Arena Leaderboard</a></td>
<td>Coding Assistant</td>
<td>Real-time web development challenges between models</td>
<td>Win rate; task completion; user voting</td>
</tr>
<tr>
<td><a href="https://www.swebench.com/">SWE-bench</a></td>
<td>Autonomous Agent</td>
<td>2,294 real-world â€œFail-to-Passâ€ GitHub issues from 12 Python repos</td>
<td>% of issues resolved</td>
</tr>
<tr>
<td><a href="https://hal.cs.princeton.edu/">HAL (Holistic Agent Leaderboard)</a></td>
<td>Autonomous Agent</td>
<td>13 benchmarks (e.g., SWE-bench Verified, USACO, Cybench, TAU-bench) across many domains</td>
<td>Cost-controlled evaluations; success rates; Pareto fronts</td>
</tr>
<tr>
<td><a href="https://www.tbench.ai/">TBench</a></td>
<td>Autonomous Agent</td>
<td>Terminal-based complex tasks in realistic environments</td>
<td>Task success rate; command accuracy; time-to-completion</td>
</tr>
</tbody>
</table>
<h3 id="software-code-leaderboards-measuring-ai-ability-to-complete-long-tasks">Measuring AI Ability to Complete Long Tasks<a class="headerlink" href="#software-code-leaderboards-measuring-ai-ability-to-complete-long-tasks" title="Permanent link">&para;</a></h3>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p><strong>The length of tasks (measured by how long they take human professionals) that generalist
autonomous frontier model agents can complete with 50% reliability has been doubling approximately every 7 months for the last 6 years</strong></p>
<p><a href="https://arxiv.org/pdf/2503.14499">Measuring AI Ability to Complete Long Tasks</a></p>
<p><figure markdown>
<img alt="" src="../assets/images/metr.png" />
</figure></p>
</div>
<h2 id="software-code-leaderboards-other-evaluations">Other Evaluations<a class="headerlink" href="#software-code-leaderboards-other-evaluations" title="Permanent link">&para;</a></h2>
<p>In addition to leaderboards, it is useful to read about other evaluations and experiments e.g. </p>
<ul>
<li><a href="https://martinfowler.com/articles/pushing-ai-autonomy.html">How far can we push AI autonomy in code generation?</a>, Birgitta BÃ¶ckeler ThoughtWorks, August 2025</li>
</ul>
<h2 id="software-code-leaderboards-takeaways">Takeaways<a class="headerlink" href="#software-code-leaderboards-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Key Takeaways</p>
<p>Leaderboards are a good way to quantitatively and objectively compare solutions.</p>
<p>Comparison across multiple metrics and leaderboards avoids solutions that overfit to a benchmark.</p>
</div></section><h1 class='nav-section-title-end'>Ended: Software Engineering Agents</h1>
                        <h2 class='nav-section-title' id='section-software-engineering-1-0-redux'>
                            Software Engineering 1.0 Redux <a class='headerlink' href='#section-software-engineering-1-0-redux' title='Permanent link'>â†µ</a>
                        </h2>
                        <section class="print-page" id="software-swe_redux"><h1 id="software-swe_redux-software-engineering-10-redux">Software Engineering 1.0 Redux<a class="headerlink" href="#software-swe_redux-software-engineering-10-redux" title="Permanent link">&para;</a></h1>
<div class="admonition overview">
<p class="admonition-title">Overview</p>
<p>This section is hands on end2end turning the thoughts on Software Engineering 1.0 Redux from the previous pages into reality.</p>
<p><strong>Exploratory</strong></p>
<ul>
<li><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#additional-documentation">Pre-existing documentation</a>. </li>
<li><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/user_personas.md">user personas and Scenarios</a></li>
</ul>
<p><strong>Pre-Code</strong></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>All of these pre-code outputs were created with a <a href="https://gemini.google.com/gems/view">Gemini Gem</a> loaded with a <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/main/dist/teams/team-fullstack.txt">BMAD-Method Full Stack team loaded (modified to add a security agent)</a>. </p>
<ul>
<li>This gives a guided interactive experience with different Software Engineering roles.</li>
</ul>
</div>
<table>
<thead>
<tr>
<th><strong>Phase</strong></th>
<th><strong>Input</strong></th>
<th><strong>Chat History</strong></th>
<th><strong>Output</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Planning</strong></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#additional-documentation">Pre-existing documentation</a></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_planning_chat.md">Chat history</a></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#project-documentation">Product Brief, PRD, UX requirements, Architecture document.</a></td>
</tr>
<tr>
<td><strong>Security Review</strong></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#project-documentation">Product Brief, PRD, UX requirements, Architecture document.</a></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_security_agent_chat.md">Chat history</a></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security">Security review documents</a> <br>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/commit/ad8b50438cc669f3f16afee755756af5300db464">Changes to the architecture document  by the architect based on the security agent's findings</a></td>
</tr>
<tr>
<td><strong>Document Preparation</strong> for development consumption</td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#project-documentation">PRD</a> <br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/security/bmad_fullagent_security/security_story_report.md">Security Story Report from Security Analyst</a></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_user_stories.md">Chat history</a> <br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_security_stories.md">Chat history</a></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/stories">User Stories</a><br>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/stories">Security Stories</a> ("S-" prefix) <br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/security/bmad_fullagent_security/security_test_cases.md">Security Test Cases</a></td>
</tr>
<tr>
<td><strong>Security Review</strong></td>
<td><a href="https://genai.owasp.org/resource/securing-agentic-applications-guide-1-0/">Newly published Securing Agentic Applications Guide, OWASP Gen AI Security Project - Agentic Security Initiative Version 1.0 July 28, 2025</a></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_security_agent_owasp_new_ai_guide.md">Chat history</a></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/commit/848ab2133301efdf47e42c78b2762045aaca6019">Changes to the architecture document, and security documents, based on the security agent's review of the newly published OWASP guide</a> <br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/commit/1bdf204671db22af92d675d2a295144ecbd914af">Changes to 2 Security Stories</a></td>
</tr>
<tr>
<td><strong>GUI</strong></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/architecture.md">Architecture Document</a></td>
<td>-<a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/gui_bmad.md">BMAD UX Sally chat</a><br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/GUI.md">Gemini Pro 2.5 Chat to create mockup GUI</a></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/GUI">Interactive Mockup on Gemini Pro 2.5 Canvas</a></td>
</tr>
</tbody>
</table>
<p>Phases are shown in chronological order - note that a second security review was done based on a newly published OWASP guide.             </p>
<p><strong>Code</strong></p>
<table>
<thead>
<tr>
<th><strong>Phase</strong></th>
<th><strong>Input</strong></th>
<th><strong>Chat History</strong></th>
<th><strong>Output</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Kanban (via Gitbub Project) to plan and track work</strong></td>
<td>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/stories">User Stories</a><br>- <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/stories">Security Stories</a> ("S-" prefix) <br> - <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/security/bmad_fullagent_security/security_test_cases.md">Security Test Cases</a></td>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/github_add_stories.md">Chat history</a></td>
<td><a href="https://github.com/orgs/CWE-ChatBot/projects/1/views/1?filterQuery=">Kanban Board of Stories</a></td>
</tr>
<tr>
<td><strong>Code Review</strong></td>
<td><strong><a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/main/tests/agents/vulnerabilityTech/fixtures/python/vulnerable_app">Deliberately Vulnerable test app for test and demo purposes</a></strong></td>
<td>-</td>
<td><a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/main/tests/reports/consolidated-security-report.md">Vulnerability Report that includes independent analysis and triage of results, and confidence levels</a></td>
</tr>
<tr>
<td><strong>Docker Container</strong></td>
<td>-</td>
<td>-</td>
<td>-  <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/stories/1.2/DOCKERFILE_SECURITY_REVIEW_v2.md">Dockerfile Security Review Reviewer: Security-Reviewer Agent (AI)</a></td>
</tr>
</tbody>
</table>
</div>
<h2 id="software-swe_redux-phase-existing-exploratory-documentation">Phase: Existing Exploratory Documentation<a class="headerlink" href="#software-swe_redux-phase-existing-exploratory-documentation" title="Permanent link">&para;</a></h2>
<p>In the exploratory part of the project at the start I had some <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#additional-documentation">existing documentation</a>:</p>
<ol>
<li>A Cost Analysis was created by using <ol>
<li>ChatGPT and Gemini <strong>Reasoning</strong> models to create an analysis</li>
<li>Getting them to cross-review each other's output and amending their own output as a result</li>
<li>Then taking the amended ChatGPT version as it was more succinct which is what I was looking for.</li>
<li>The cost analysis was a back-of-napkin effort to understand likely operational costs early to see if these were a show-stopper or not.</li>
</ol>
</li>
<li>Research Documents using ChatGPT and Gemini <strong>Research</strong> models and Anthropic</li>
<li>ADRs using an existing competed example I liked, and redoing it for the architecture decisions I had made using ChatGPT and Gemini <strong>Reasoning</strong> models and Anthropic.</li>
<li>Some Functional Requirements and use cases and user stories (in a Doc format) from MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> team.</li>
</ol>
<h2 id="software-swe_redux-phase-bmad-the-planning-workflow">Phase: <a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/docs/core-architecture.md#51-the-planning-workflow">BMAD The Planning Workflow</a><a class="headerlink" href="#software-swe_redux-phase-bmad-the-planning-workflow" title="Permanent link">&para;</a></h2>
<p>Having reviewed and played with some of the <a href="#software-swe_agents_report">SWE agents</a>, the BMAD-Method was closest to my views on Software 1.0 Redux, so this is used here.</p>
<p>There's 2 <a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/docs/core-architecture.md#51-the-planning-workflow">BMad Workflows</a>:</p>
<ul>
<li><a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/docs/core-architecture.md#51-the-planning-workflow">The Planning Workflow</a> </li>
<li><a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/docs/core-architecture.md#52-the-core-development-cycle">The Core Development Cycle</a></li>
</ul>
<p>See the updated BMAD flows detailing the Security activities I added:</p>
<ul>
<li><a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-vulnerability-tech/docs/core-architecture.md#51-the-planning-workflow">The Planning Workflow</a> </li>
<li><a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-vulnerability-tech/docs/core-architecture.md#52-the-core-development-cycle">The Core Development Cycle</a></li>
</ul>
<h3 id="software-swe_redux-bmad-the-planning-workflow">BMAD The Planning Workflow<a class="headerlink" href="#software-swe_redux-bmad-the-planning-workflow" title="Permanent link">&para;</a></h3>
<p>BMAD method breaks down the requirements and other upstream artifacts into epics and stories, enabling Claude Code to generate structured code and docs with little human intervention (<a href="#software-code-code_assistant_agents-autonomy-levels-for-ai-coding-tools">Level 4 Autonomy</a>).</p>
<div class="admonition quote">
<p class="admonition-title">Key Planning Phases</p>
<ul>
<li>Optional Analysis: Analyst conducts market research and competitive analysis</li>
<li>Project Brief: Foundation document created by Analyst or user</li>
<li>PRD Creation: PM transforms brief into comprehensive product requirements</li>
<li>Architecture Design: Architect creates technical foundation based on PRD</li>
<li>Validation &amp; Alignment: PO ensures all documents are consistent and complete</li>
<li>Refinement: Updates to epics, stories, and documents as needed</li>
<li>Environment Transition: Critical switch from web UI to IDE for development workflow</li>
<li>Document Preparation: PO shards large documents for development consumption</li>
</ul>
</div>
<p>Here we build the <a href="#software-software_artifacts">Upstream Software Engineering Artifacts</a>.</p>
<p>Specifically these are the <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/README.md#project-documentation">artifacts</a> that are built with the workflow below.</p>
<h3 id="software-swe_redux-setup">Setup<a class="headerlink" href="#software-swe_redux-setup" title="Permanent link">&para;</a></h3>
<p>The <a href="#software-swe_agents_report">BMAD-METHOD</a> is used.</p>
<p>Specifically, the <a href="https://github.com/bmadcode/BMAD-METHOD?tab=readme-ov-file#fastest-start-web-ui-full-stack-team-at-your-disposal-2-minutes">Fastest Start: Web UI Full Stack Team at your disposal</a> part where you create a Gemini GEM with a <a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/dist/teams/team-fullstack.txt">BMAD-provided text file</a>.</p>
<ul>
<li>All these documents are created via a browser interface (Gemini GEM) so the process is IDE-independent!</li>
<li>Gemini's long-context window allows it to keep the various documents produced in context so it can make consistent changes across them all.</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The created files are available via </p>
<ul>
<li>the Google Gem Canvas </li>
<li>the prompt response when you request a specific document</li>
</ul>
</div>
<div class="admonition observation">
<p class="admonition-title">Observation</p>
<p>I was impressed how well this setup worked! </p>
<ul>
<li>following a logical workflow and prompting for choices or input at each stage (and not getting lost)</li>
<li>allowing me to request Gemini Gem to output a document at any time (so I could review and version control it before changes)</li>
<li>allowing me to refine the content or ask questions across all the documents as required e.g. if I suggested a change that impacted multiple documents then this was detected by Gemini and the updates made. This ensured consistency across the artefacts.</li>
</ul>
</div>
<p>Some choices / decisions were deliberately postponed e.g. data exchange formats and schemas per <a href="https://framework.scaledagile.com/assume-variability-preserve-options/">Principle #3 - Assume variability; preserve options</a>. This results in a PARTIAL Status at this point.</p>
<h3 id="software-swe_redux-interaction-with-bmad-gemini-gem">Interaction with BMAD Gemini Gem<a class="headerlink" href="#software-swe_redux-interaction-with-bmad-gemini-gem" title="Permanent link">&para;</a></h3>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>See the <strong><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_planning_chat.md">full chat history of creating a Product Brief, PRD, UX requirements, Architecture document.</a></strong> </p>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>I worked the pre-existing document content into the <a href="https://github.com/bmadcode/BMAD-METHOD/blob/main/docs/core-architecture.md#51-the-planning-workflow">The Planning Workflow</a> by providing the content to the BMAD Persona at the relevant time via the prompt.</p>
</div>
<h2 id="software-swe_redux-phase-security-review">Phase: Security Review<a class="headerlink" href="#software-swe_redux-phase-security-review" title="Permanent link">&para;</a></h2>
<p>BMAD-Method did not have a dedicated Security persona or security documents (but does include some basic security checks)</p>
<p>Other <a href="#software-threat_model">Threat Modeling</a> solutions could be used to create these security documents</p>
<ul>
<li>See example <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security">security artifacts</a> </li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The different <a href="#software-threat_model">Threat Modeling</a> solutions had different features I liked, so I decided to build a BMAD Method Security Agent with all the features I wanted.</p>
<p>The BMAD Method Security Agent fits in the BMAD Planning Workflow</p>
<ul>
<li>It reviews the existing documents, creates security documents including threat models, security test cases, and security updates to the architecture document.</li>
<li>Unlike the other solutions, this Security Agent can also be used during the code implementation phase.</li>
</ul>
</div>
<h3 id="software-swe_redux-adding-a-bmad-method-security-agent">Adding a BMAD Method Security Agent<a class="headerlink" href="#software-swe_redux-adding-a-bmad-method-security-agent" title="Permanent link">&para;</a></h3>
<p>I added a Security Agent to BMAD per <a href="https://github.com/CyberSecAI/BMAD-METHOD/commits/feature/add-new-agent-security">commits</a> from Crashedmind. The commit descriptions give the details.</p>
<p>You can browse through the files e.g.:</p>
<ul>
<li><a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-security/bmad-core/agents/security.md">Security Agent</a></li>
<li><a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/add-new-agent-security/bmad-core/tasks">Security Tasks</a></li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-security/bmad-core/agents/security.md">Security Agent</a> creates these <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security">Security review documents</a></p>
<table>
<thead>
<tr>
<th>Document</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/security_assessment.md">security_assessment.md</a></td>
<td>Initial security assessment and analysis</td>
</tr>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/threat_model.md">threat_model.md</a></td>
<td>Complete STRIDE threat model</td>
</tr>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/dread.md">dread.md</a></td>
<td>Quantitative DREAD risk assessment</td>
</tr>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/security_story_report.md">security_story_report.md</a></td>
<td>Actionable security user stories</td>
</tr>
<tr>
<td><a href="#software-swe_redux-security_test_cases.md">https://github.com/<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-ChatBot/<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-ChatBot/tree/main/docs/security/bmad_fullagent_security/security_test_cases.md</a></td>
<td>Security test cases and validation scenarios</td>
</tr>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/security_architecture_checklist.md">security_architecture_checklist.md</a></td>
<td>Architecture checklist validation</td>
</tr>
<tr>
<td><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security/compliance_audit.md">compliance_audit.md</a></td>
<td>GDPR compliance audit</td>
</tr>
</tbody>
</table>
</div>
<h3 id="software-swe_redux-building-the-bundles">Building the Bundles<a class="headerlink" href="#software-swe_redux-building-the-bundles" title="Permanent link">&para;</a></h3>
<p>The <a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/add-new-agent-security/tools/builders">builder</a> gathers all the relevant files for all the agents into single files in  <a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/add-new-agent-security/dist/teams">https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/add-new-agent-security/dist/teams</a></p>
<ul>
<li>e.g. <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-security/dist/teams/team-fullstack.txt">team-fullstack.txt</a> contains all the agents including security, and all the other files they need.</li>
</ul>
<h3 id="software-swe_redux-create-a-gemini-gem-with-the-fullstack-team">Create a Gemini Gem with the FullStack team<a class="headerlink" href="#software-swe_redux-create-a-gemini-gem-with-the-fullstack-team" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://gemini.google.com/">https://gemini.google.com/</a></li>
<li>Explore Gems</li>
<li>New Gems</li>
<li>CopyNPaste <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/add-new-agent-security/dist/teams/team-fullstack.txt">team-fullstack.txt</a> into instructions</li>
<li>Save</li>
</ul>
<h3 id="software-swe_redux-using-the-bmad-method-security-agent-via-the-gemini-gem-with-fullstack-team">Using the BMAD Method Security Agent via the Gemini Gem with FullStack team<a class="headerlink" href="#software-swe_redux-using-the-bmad-method-security-agent-via-the-gemini-gem-with-fullstack-team" title="Permanent link">&para;</a></h3>
<ol>
<li>Collate the project brief, prd, architecture etc... md files into one file (e.g. using gitingest)</li>
<li>At the prompt say "here's my existing documentation" and copyNpaste the collated md file into the prompt</li>
<li>Click the Submit Arrow</li>
<li>The workflow kicks off</li>
</ol>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>See the </p>
<ul>
<li><strong><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/blob/main/docs/chats/bmad_security_agent_chat.md">full chat history using the Security Agent</a></strong>.</li>
<li><strong><a href="https://www.youtube.com/watch?v=UdXLFQbogIU">full chat history creating and using the Security Agent (Video)</a></strong></li>
<li>output <a href="https://github.com/CWE-ChatBot/CWE-ChatBot/tree/main/docs/security/bmad_fullagent_security">security artifacts</a>. </li>
<li>
<p><a href="https://github.com/CWE-ChatBot/CWE-ChatBot/commit/ad8b50438cc669f3f16afee755756af5300db464">changes</a> to the architecture document by the architect based on the security agent's findings</p>
<ul>
<li>"| July 23, 2025 | 2.0 | Integrated security agent's findings (WAF, AI Guardrails, DoS Protection, Enhanced Logging). | Winston (Architect) |"</li>
</ul>
</li>
</ul>
</div>
<h2 id="software-swe_redux-document-preparation-for-development">Document Preparation for development<a class="headerlink" href="#software-swe_redux-document-preparation-for-development" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Key Planning Phases</p>
<p>When to move to the IDE: Once you have your PRD, Architecture, optional UX and Briefs - its time to switch over to the IDE to shard your docs, and start implementing the actual code! </p>
</div>
<p>Coming soon..</p>
<h2 id="software-swe_redux-phase-core-development-cycle">Phase: Core Development Cycle<a class="headerlink" href="#software-swe_redux-phase-core-development-cycle" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Vulnerability Assessment Analyst Tanya</p>
<p>"Use for performing security scans, identifying and documenting software vulnerabilities, analyzing code for weaknesses, validating patches, assessing system configurations, verifying compliance with security standards, and generating vulnerability reports for audit or remediation purposes."</p>
<p>The <a href="https://discord.com/channels/1377115244018532404/1394851634428903615/1396926639119794497">original brief</a> from a user AVSuun</p>
</div>
<h3 id="software-swe_redux-adding-a-vulnerability-assessment-analyst">Adding a Vulnerability Assessment Analyst<a class="headerlink" href="#software-swe_redux-adding-a-vulnerability-assessment-analyst" title="Permanent link">&para;</a></h3>
<p>I wanted to give the VulnerabilityTech agent access to tools for </p>
<ul>
<li>Static Analysis Security Testing (SAST) - combining traditional SAST tools with LLM review </li>
<li>Dependency checking</li>
</ul>
<p>I decided to use Claude Code Sub-agents for this (announced a few days ago <a href="https://docs.anthropic.com/en/docs/claude-code/sub-agents">https://docs.anthropic.com/en/docs/claude-code/sub-agents</a>). </p>
<ul>
<li>I only focused on Claude Code - not other environments that BMAD may work on.</li>
</ul>
<h4 id="software-swe_redux-bmad-agents-vs-claude-code-sub-agents">BMAD Agents vs Claude Code Sub-Agents<a class="headerlink" href="#software-swe_redux-bmad-agents-vs-claude-code-sub-agents" title="Permanent link">&para;</a></h4>
<h5 id="software-swe_redux-claude-code-sub-agents">Claude Code Sub-Agents<a class="headerlink" href="#software-swe_redux-claude-code-sub-agents" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>What They Are</strong>: Specialized AI assistants with custom system prompts and tool access</li>
<li><strong>Architecture</strong>: Defined as Markdown files with YAML frontmatter in <code>.claude/agents/</code></li>
<li><strong>Operation</strong>: Isolated context windows with specific expertise and granular tool permissions</li>
<li><strong>Delegation</strong>: Automatic selection by Claude Code or explicit user invocation</li>
<li><strong>Benefits</strong>: Focused expertise, faster analysis, parallel processing capabilities</li>
</ul>
<h5 id="software-swe_redux-bmad-framework-current-state">BMad Framework Current State<a class="headerlink" href="#software-swe_redux-bmad-framework-current-state" title="Permanent link">&para;</a></h5>
<ul>
<li><strong>12 Specialized Agents</strong>: Comprehensive personas in <code>bmad-core/agents/</code></li>
<li><strong>Complex Configuration</strong>: YAML-based with dependencies and external task references</li>
<li><strong>Full Context Maintenance</strong>: Complete operating instructions and workflow definitions</li>
<li><strong>Command Syntax</strong>: <code>*command</code> activation with extensive persona definitions</li>
</ul>
<h5 id="software-swe_redux-key-architectural-differences">Key Architectural Differences<a class="headerlink" href="#software-swe_redux-key-architectural-differences" title="Permanent link">&para;</a></h5>
<ol>
<li><strong>Complexity</strong>: BMad = comprehensive personas vs Claude = focused sub-agents</li>
<li><strong>Dependencies</strong>: BMad = external task references vs Claude = self-contained</li>
<li><strong>Context</strong>: BMad = full context maintenance vs Claude = isolated context windows</li>
<li><strong>Activation</strong>: BMad = explicit commands vs Claude = automatic delegation</li>
</ol>
<h4 id="software-swe_redux-claude-code-sub-agents-setup">Claude Code sub-agents Setup<a class="headerlink" href="#software-swe_redux-claude-code-sub-agents-setup" title="Permanent link">&para;</a></h4>
<p>See <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/claude-code-sub-agents-integration/.claude/README.md">how I setup Claude Code sub-agents</a> to work with BMAD agents that describes how BMAD agents call Claude Code sub-agents.</p>
<p>Four <a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/claude-code-sub-agents-integration/.claude/agents">Claude Code sub-agents</a> were added:</p>
<table>
<thead>
<tr>
<th><strong>Claude sub-agent</strong></th>
<th><strong>Purpose</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>dependency-scanner</strong></td>
<td>I am a specialized security analyst focused on third-party component security assessment and supply chain risk analysis. My expertise covers dependency vulnerability scanning, license compliance, and supply chain security validation according to NIST SSDF practices.</td>
</tr>
<tr>
<td><strong>pattern-analyzer</strong></td>
<td>I am a specialized security pattern analyst focused on detecting secure and insecure coding patterns across multiple programming languages. My expertise leverages language-specific security knowledge from expansion packs to validate secure coding practices and identify anti-patterns that introduce vulnerabilities.</td>
</tr>
<tr>
<td><strong>security-reviewer</strong></td>
<td>I am a Level 2 orchestrator sub-agent that coordinates comprehensive security analysis by leveraging specialized tool sub-agents. My role is to orchestrate hybrid SAST + LLM security analysis for maximum accuracy and coverage, focusing on practical, exploitable security issues that pose real risks to applications and systems.</td>
</tr>
<tr>
<td><strong>test-validator</strong></td>
<td>I am a specialized security testing analyst focused on validating the quality, coverage, and effectiveness of security tests within software projects. My expertise ensures that security testing meets NIST SSDF standards and provides robust protection against real-world threats.</td>
</tr>
</tbody>
</table>
<p>I also added a tests dir to BMAD be able to test this. </p>
<ul>
<li>This includes a <a href="https://github.com/CyberSecAI/BMAD-METHOD/tree/feature/claude-code-sub-agents-integration/tests/agents/vulnerabilityTech/fixtures/python/vulnerable_app">deliberately vulnerable app</a> to test: </li>
</ul>
<h4 id="software-swe_redux-vulnerabilitytech-agent-report">VulnerabilityTech Agent Report<a class="headerlink" href="#software-swe_redux-vulnerabilitytech-agent-report" title="Permanent link">&para;</a></h4>
<div class="admonition success">
<p class="admonition-title">Success</p>
<p>See example <a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/claude-code-sub-agents-integration/tests/reports/consolidated-security-report.md">output report</a>.</p>
<p><a href="https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/claude-code-sub-agents-integration/tests/reports/consolidated-security-report.md#%EF%B8%8F-nist-ssdf-compliance-assessment">https://github.com/CyberSecAI/BMAD-METHOD/blob/feature/claude-code-sub-agents-integration/tests/reports/consolidated-security-report.md#%EF%B8%8F-nist-ssdf-compliance-assessment</a></p>
</div>
<h2 id="software-swe_redux-other-claude-code-workflows">Other Claude Code Workflows<a class="headerlink" href="#software-swe_redux-other-claude-code-workflows" title="Permanent link">&para;</a></h2>
<p>There are other Claude Code workflows, some example are given here.</p>
<h5 id="software-swe_redux-ui-designer">UI Designer<a class="headerlink" href="#software-swe_redux-ui-designer" title="Permanent link">&para;</a></h5>
<p><a href="https://www.youtube.com/watch?v=TyGx277x9hQ">https://www.youtube.com/watch?v=TyGx277x9hQ</a></p>
<h5 id="software-swe_redux-retrospectives">Retrospectives<a class="headerlink" href="#software-swe_redux-retrospectives" title="Permanent link">&para;</a></h5>
<p><a href="https://www.youtube.com/watch?v=ai_sSQH1Pn4&amp;t=478s">https://www.youtube.com/watch?v=ai_sSQH1Pn4&amp;t=478s</a></p>
<h5 id="software-swe_redux-multitasking">Multitasking<a class="headerlink" href="#software-swe_redux-multitasking" title="Permanent link">&para;</a></h5>
<p><a href="https://www.geeky-gadgets.com/how-to-use-git-worktrees-with-claude-code-for-seamless-multitasking/">https://www.geeky-gadgets.com/how-to-use-git-worktrees-with-claude-code-for-seamless-multitasking/</a></p>
<p>There are UI tools built on GIT worktrees to support this.</p>
<h3 id="software-swe_redux-other-non-claude-code-workflows">Other non-Claude Code Workflows<a class="headerlink" href="#software-swe_redux-other-non-claude-code-workflows" title="Permanent link">&para;</a></h3>
<h4 id="software-swe_redux-accessibility">Accessibility<a class="headerlink" href="#software-swe_redux-accessibility" title="Permanent link">&para;</a></h4>
<p><a href="https://github.com/scragz/kornelius/blob/main/prompts/audit/a11y.prompt">https://github.com/scragz/kornelius/blob/main/prompts/audit/a11y.prompt</a></p>
<h2 id="software-swe_redux-references">References<a class="headerlink" href="#software-swe_redux-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/">https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/</a></li>
<li><a href="https://www.geeky-gadgets.com/how-to-use-git-worktrees-with-claude-code-for-seamless-multitasking/">https://www.geeky-gadgets.com/how-to-use-git-worktrees-with-claude-code-for-seamless-multitasking/</a></li>
<li><a href="https://github.com/ryoppippi/ccusage">https://github.com/ryoppippi/ccusage</a></li>
<li><a href="https://github.com/eyaltoledano/claude-task-master/blob/main/docs/tutorial.md">https://github.com/eyaltoledano/claude-task-master/blob/main/docs/tutorial.md</a></li>
<li><a href="https://www.reddit.com/r/vibecoding/comments/1lu37up/vibecoding_is_straight_chaos_without_instructions/">https://www.reddit.com/r/vibecoding/comments/1lu37up/vibecoding_is_straight_chaos_without_instructions/</a> </li>
<li><a href="https://www.reddit.com/r/vibecoding/comments/1l5o93n/lets_talk_about_security/">https://www.reddit.com/r/vibecoding/comments/1l5o93n/lets_talk_about_security/</a></li>
</ol></section><section class="print-page" id="software-swe_redux_security"><h1 id="software-swe_redux_security-software-engineering-10-redux-security">Software Engineering 1.0 Redux Security<a class="headerlink" href="#software-swe_redux_security-software-engineering-10-redux-security" title="Permanent link">&para;</a></h1>
<div class="admonition overview">
<p class="admonition-title">Overview</p>
<p>This section covers the Core Review Security touchpoint.</p>
<p>We touched on this point earlier in <a href="#notebooklm-notebooklm_secure_code">NotebookLM Secure Code</a>.</p>
</div>
<h2 id="software-swe_redux_security-software-security-touchpoints">Software Security Touchpoints<a class="headerlink" href="#software-swe_redux_security-software-security-touchpoints" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/swsectouch.png" />
Image from <a href="https://www.amazon.com/Secure-Programming-Static-Analysis-Brian/dp/0321424778">Secure Programming with Static Analysis by Brian Chess, Jacob West</a></p>
</figure>
<h2 id="software-swe_redux_security-finding-defects-in-source-code">Finding Defects in Source Code<a class="headerlink" href="#software-swe_redux_security-finding-defects-in-source-code" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/sast_quad.png" />
Image from <a href="https://www.amazon.com/Secure-Programming-Static-Analysis-Brian/dp/0321424778">Secure Programming with Static Analysis by Brian Chess, Jacob West</a></p>
<p>The best way to find a particular defect depends on whether it is generic or context specific, and whether 
it is visible in the code or only in the design.</p>
</figure>
<p><strong>LLMs can compliment the Static analysis sweetspot (Generic defects - Visible in the code)</strong></p>
<ul>
<li>"SAST tools often rely on predefined patterns and rules, which can result in high false-positive rates and an inability to detect novel or context-dependent vulnerabilities" per <a href="https://arxiv.org/html/2409.15735v2">ref</a>.</li>
<li>Additional context can be given to LLMs to improve their performance e.g. vulnerability reports on similar code
 <a href="https://arxiv.org/html/2409.15735v2">LSAST: Enhancing Cybersecurity through LLM-supported Static Application Security Testing</a></li>
</ul>
<h2 id="software-swe_redux_security-how-to-use-llms-and-sast-tools-together">How to use LLMs and SAST Tools Together<a class="headerlink" href="#software-swe_redux_security-how-to-use-llms-and-sast-tools-together" title="Permanent link">&para;</a></h2>
<p>LLMs can be used with Code Analysis Tools in different ways:</p>
<ol>
<li>Create a formatted report of findings: <ol>
<li>this is more an editorial activity - not code analysis</li>
</ol>
</li>
<li>Utilising LLMs for False Positive Mitigation (FPM) on SAST Warnings: <ol>
<li>Traditional SAST tools often generate a high volume of false positive alerts, which can be time-consuming and resource-intensive for developers to manually review. </li>
<li>LLMs can be integrated to automate this false positive mitigation process</li>
</ol>
</li>
<li>Direct Integration of SAST Results with LLMs:<ol>
<li>SAST tools provide initial insights into known vulnerabilities based on predefined rules and patterns. Their findings, including details like <abbr title="CWE Common Weakness Enumeration">CWE</abbr> IDs and line numbers, can be formatted and directly incorporated into the prompts provided to LLMs alongside the target code. </li>
<li>This approach, referred to as "<a href="https://arxiv.org/html/2409.15735v2">RAW LSAST</a>," has been shown to significantly enhance the LLMâ€™s ability to detect vulnerabilities that static scanners alone might miss, thereby improving overall detection accuracy </li>
</ol>
</li>
<li>Independently look for issues <ol>
<li>e.g. using an analysis of <a href="https://en.wikipedia.org/wiki/Code_property_graph">CPGs</a>.</li>
</ol>
</li>
<li>Actively exercise the code by creating or guiding test cases.</li>
</ol>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>While traditional tools like Bandit are valuable, our results show that LLMs provide a complementary advantage by analyzing fragmented and non-compilable code and detecting complex vulnerability patterns that existing tools may miss. Additionally, the ability of LLMs to generate security tests adds a useful layer of verification, potentially enhancing the accuracy of vulnerability assessments.</p>
<p><a href="https://arxiv.org/html/2505.15088v1">Leveraging Large Language Models for Command Injection Vulnerability Analysis in Python: An Empirical Study on Popular Open-Source Projects</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Our findings indicate that SAST tools exhibit low vulnerability detection ratios while maintaining a low marked function ratio, akin to a low false positive rate. In contrast, LLMs demonstrate high vulnerability detection ratios but are accompanied by elevated marked function ratios (akin to high false positive rates). Through ensemble approaches, we demonstrate that combining SAST tools and LLMs mitigates their respective limitations, resulting in improved overall vulnerability detection performance.</p>
<p><a href="https://arxiv.org/abs/2407.16235">Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection</a>  </p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Analysis reveals that the optimal approaches differ across programming languages.
The best choice will depend on the userâ€™s acceptance of the trade-off between detection ratios and marked function ratios.</p>
<p><a href="https://arxiv.org/html/2407.16235v1">Comparison of Static Application Security Testing Tools and Large Language Models for Repo-level Vulnerability Detection</a> </p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>The reasoning-oriented models consistently produced fewer false positives, suggesting that their internal steps for â€œvalidatingâ€ potential vulnerabilities lead to more precise outcomes.</p>
<p><a href="https://arxiv.org/html/2503.09433v1">CASTLE: Benchmarking Dataset for Static Code Analyzers and LLMs towards <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Detection</a></p>
</div>
<h3 id="software-swe_redux_security-code-context">Code Context<a class="headerlink" href="#software-swe_redux_security-code-context" title="Permanent link">&para;</a></h3>
<p>A challenge with using LLMs is to get the precise and complete code context to the LLM as described in <a href="https://arxiv.org/html/2411.03079v1">Utilizing Precise and Complete Code Context to Guide LLM in Automatic False Positive Mitigation</a>. They developed a tool to extract this code context.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<ul>
<li>First, we propose a line-level precise code slicer eCPG-Slicer. It constructs an extended Code Property Graph (eCPG) and then extracts line-level code context related to the warning within the given files.</li>
<li>Second, we propose a linear complexity algorithm, FARF, which is used to identify source files that have dependencies related to a warning, enabling the slicer to extract the complete code context.</li>
<li>Third, we integrate our eCPG-Slicer and FARF algorithm into our LLM4FPM framework. LLM4FPM can efficiently drive LLMs to give judgements for a given warning generated by SAST tools.</li>
</ul>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The source code for these does not appear to be publicly available. But Joern is an open source solution used <a href="https://arxiv.org/html/2404.14719v1">for such purposes</a>.</p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>A code property graph of a program is a graph representation of the program obtained by merging its abstract syntax trees (AST), control-flow graphs (CFG) and program dependence graphs (PDG) at statement and predicate nodes. 
<a href="https://en.wikipedia.org/wiki/Code_property_graph">https://en.wikipedia.org/wiki/Code_property_graph</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Joern is a platform for analyzing source code, bytecode, and binary executables. It generates code property graphs (CPGs), a graph representation of code for cross-language code analysis. Code property graphs are stored in a custom graph database.
<a href="https://github.com/joernio/joern">https://github.com/joernio/joern</a> </p>
</div>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<ol>
<li><strong>Precise Code Context</strong>. The extracted code snippet should focus on control flows and data flows relevant to the warning, capturing the precise code context while omitting unnecessary parts that might distract the LLM and lead to incorrect or ambiguous conclusions.</li>
<li><strong>Complete Code Context</strong>. The analysis should account for key information often missing from bug reports, such as references to global variables or invoked functions located in other files. Without this, the extracted context remains incomplete.</li>
<li><strong>Correct Conclusions</strong>. After obtaining precise and complete code context, there is an opportunity to more effectively guide the LLM to make accurate judgments on bug reports from SAST tools.</li>
</ol>
<p><a href="https://arxiv.org/html/2411.03079v1">Utilizing Precise and Complete Code Context to Guide LLM in Automatic False Positive Mitigation</a></p>
</div>
<h2 id="software-swe_redux_security-references">References<a class="headerlink" href="#software-swe_redux_security-references" title="Permanent link">&para;</a></h2>
<ol>
<li>AI Cyber Challenge (2025). AIxCC Open Source Archive. <ul>
<li><strong>Official archive providing open-source access to all seven finalist Cyber Reasoning Systems (CRSs), released to accelerate adoption of AIxCC-developed technology in cybersecurity and software development.</strong> <a href="https://archive.aicyberchallenge.com">https://archive.aicyberchallenge.com</a></li>
<li>See <strong><a href="#software-aixcc">DARPA AI Cyber Challenge Tools Comparison Report</a></strong> </li>
</ul>
</li>
<li>Brian, C., &amp; West, J. (2007). <em>Secure programming with static analysis</em>. Addison-Wesley.</li>
<li>McGraw, G. (2006). <em>Software security: Building security in</em>. Addison-Wesley.</li>
<li>Zhang, Y., Li, Y., Wang, T., et al. (2025). Towards effective complementary security analysis using large language models. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2506.16899v1">https://arxiv.org/html/2506.16899v1</a></li>
<li>Xu, H., Chen, M., &amp; Zhou, L. (2025). Leveraging large language models for command injection vulnerability analysis in Python: An empirical study on popular open-source projects. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2505.15088v1">https://arxiv.org/html/2505.15088v1</a></li>
<li>Li, J., Wang, P., &amp; Huang, K. (2025). LLM vs. SAST: A technical analysis on detecting coding bugs of GPT4-Advanced Data Analysis. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2506.15212v1">https://arxiv.org/html/2506.15212v1</a></li>
<li>MÃ¼ller, T., &amp; Kim, D. (2024). Comparison of static application security testing tools and large language models for repo-level vulnerability detection. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2407.16235">https://arxiv.org/abs/2407.16235</a></li>
<li>Shen, R., &amp; Zhao, F. (2024). LSAST: Enhancing cybersecurity through LLM-supported static application security testing. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2409.15735v2">https://arxiv.org/html/2409.15735v2</a></li>
<li>Kumar, V., &amp; Singh, A. (2025). CASTLE: Benchmarking dataset for static code analyzers and LLMs towards <abbr title="CWE Common Weakness Enumeration">CWE</abbr> detection. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2503.09433v1">https://arxiv.org/html/2503.09433v1</a></li>
<li>Li, C., &amp; Zhang, H. (2024). Source code vulnerability detection: Combining code language models and code property graphs. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2404.14719v1">https://arxiv.org/html/2404.14719v1</a></li>
<li>Kolla, H. (2024). SecLint: An agentic code vulnerability detection tool using RAG. <em>Substack</em>. <a href="https://harishkolla.substack.com/p/seclint-an-agentic-code-vulnerability">https://harishkolla.substack.com/p/seclint-an-agentic-code-vulnerability</a></li>
<li>Gross, C. (2025, August). Slice: SAST + LLM interprocedural context extractor. <em>noperator.dev</em>. <a href="https://noperator.dev/posts/slice/">https://noperator.dev/posts/slice/</a></li>
<li>Google Security Team. (2024). Google Big Sleep AI tool finds critical Chrome vulnerability. <em>LinkedIn</em>. <a href="https://lnkd.in/gSkA3kRC">https://lnkd.in/gSkA3kRC</a></li>
<li>Heelan, S. (2024). Using o3 to discover a remote zeroday vulnerability in the Linux kernelâ€™s SMB implementation. <em>LinkedIn</em>. <a href="https://lnkd.in/gHZqC_k3">https://lnkd.in/gHZqC_k3</a></li>
<li>Wang, Z., Shi, T., Song, D., et al. (2024). CyberGym: Evaluating AI agents' cybersecurity capabilities with real-world vulnerabilities at scale. <em>UC Berkeley</em>. <a href="https://www.cybergym.io/">https://www.cybergym.io/</a></li>
<li>Gaucher, R., Ermilov, V., &amp; [Author], A. (2024). Finding vulnerabilities in modern web apps using Claude Code and OpenAI Codex. <em>LinkedIn</em>. <a href="https://lnkd.in/gGWaZzHk">https://lnkd.in/gGWaZzHk</a></li>
<li>Li, Z., Li, Y., Wang, T., et al. (2024). IRIS: LLM-assisted static analysis for detecting security vulnerabilities. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2405.17238">https://arxiv.org/abs/2405.17238</a><ol>
<li><a href="https://openreview.net/forum?id=9LdJDU7E91">Open Review</a></li>
</ol>
</li>
<li>(2025). Harnessing the power of LLMs for vulnerability detection. <em>arXiv preprint</em>. <a href="https://arxiv.org/html/2504.18423v1">https://arxiv.org/html/2504.18423v1</a></li>
<li>(2025). Advancing software vulnerability detection with reasoning-enabled large language models. <em>Applied Sciences</em>. <a href="https://www.mdpi.com/2076-3417/15/12/6651">https://www.mdpi.com/2076-3417/15/12/6651</a></li>
<li>Khare, A., Dutta, S., Li, Z., Solko-Breslin, A., Alur, R., &amp; Naik, M. (2023). Understanding the effectiveness of large language models in detecting security vulnerabilities. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2311.16169">https://arxiv.org/abs/2311.16169</a></li>
<li>Yang, Y., Xu, B., Gao, X., &amp; Sun, H. (2025). Context-enhanced vulnerability detection based on large language models. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2504.16877">https://arxiv.org/abs/2504.16877</a></li>
<li>Kaniewski, S., Schmidt, F., Enzweiler, M., Menth, M., &amp; Heer, T. (2025). A systematic literature review on detecting software vulnerabilities with large language models. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2507.22659">https://arxiv.org/abs/2507.22659</a><ul>
<li>See <strong>Awesome-LLM4SVD for the surveyed papers, taxonomy, datasets</strong>: <a href="https://github.com/hs-esslingen-it-security/Awesome-LLM4SVD">https://github.com/hs-esslingen-it-security/Awesome-LLM4SVD</a></li>
</ul>
</li>
<li>Sheng, Z., Chen, Z., Gu, S., Huang, H., Gu, G., &amp; Huang, J. (2025). LLMs in software security: A survey of vulnerability detection techniques and insights. <em>arXiv preprint</em>. <a href="https://arxiv.org/abs/2502.07049">https://arxiv.org/abs/2502.07049</a></li>
<li>Klieber, W., &amp; Flynn, L. (2024, October 7). Evaluating static analysis alerts with LLMs. <em>Cybersecurity Engineering, SEI blog</em>. <a href="https://www.sei.cmu.edu/blog/evaluating-static-analysis-alerts-with-llms/">https://www.sei.cmu.edu/blog/evaluating-static-analysis-alerts-with-llms/</a></li>
<li>Ferro, A. (2024). Beyond static analysis: AI-powered vulnerability detection. <em>Medium</em>. <a href="https://medium.com/engaging-innovation/beyond-static-analysis-ai-powered-vulnerability-detection-690ff4e1f94c">https://medium.com/engaging-innovation/beyond-static-analysis-ai-powered-vulnerability-detection-690ff4e1f94c</a></li>
<li>(2024). Research on LLM for vulnerability detection â€“ Fernweh. <em>Blog post</em>. <a href="https://blog.wohin.me/posts/recent-llm-for-vuln-detection/">https://blog.wohin.me/posts/recent-llm-for-vuln-detection/</a><ol>
<li>Nice summary of 18 studies on LLM for vulnerability detection</li>
</ol>
</li>
</ol>
<h3 id="software-swe_redux_security-in-depth-articles-on-tools">In Depth Articles on Tools<a class="headerlink" href="#software-swe_redux_security-in-depth-articles-on-tools" title="Permanent link">&para;</a></h3>
<ol>
<li>Hakimian, P. (2025, October 31). WTF is â€¦ AI-Native SAST? <em>Hackermanâ€™s Hacking Tutorials</em>. <a href="https://parsiya.net/blog/wtf-is-ai-native-sast/">https://parsiya.net/blog/wtf-is-ai-native-sast/</a>.</li>
<li>scabench-org. (2025). Hound: Language-agnostic AI auditor that autonomously builds and refines adaptive knowledge graphs for deep, iterative code reasoning. <em>GitHub repository</em>. <a href="https://github.com/scabench-org/hound">https://github.com/scabench-org/hound</a>. <ol>
<li><a href="https://muellerberndt.medium.com/unleashing-the-hound-how-ai-agents-find-deep-logic-bugs-in-any-codebase-64c2110e3a6f">https://muellerberndt.medium.com/unleashing-the-hound-how-ai-agents-find-deep-logic-bugs-in-any-codebase-64c2110e3a6f</a></li>
<li><a href="https://muellerberndt.medium.com/hunting-for-security-bugs-in-code-with-ai-agents-a-full-walkthrough-a0dc24e1adf0">https://muellerberndt.medium.com/hunting-for-security-bugs-in-code-with-ai-agents-a-full-walkthrough-a0dc24e1adf0</a> </li>
</ol>
</li>
<li>Karger, R. (2024, November 1). How ZeroPath Works: Technical deep-dive into ZeroPathâ€™s SAST methodologyâ€”from AST generation to AI-powered vulnerability discovery and automated patch generation. <em>ZeroPath Blog</em>. <a href="https://zeropath.com/blog/how-zeropath-works">https://zeropath.com/blog/how-zeropath-works</a>. </li>
<li>Rogers, J. (2025, September 18). Hacking with AI SASTs: An overview of â€œAI Security Engineersâ€ / â€œLLM Security Scannersâ€ for Penetration Testers and Security Teams. <em>Joshua.Hu â€” Joshua Rogersâ€™ Scribbles</em>. <a href="https://joshua.hu/llm-engineer-review-sast-security-ai-tools-pentesters">https://joshua.hu/llm-engineer-review-sast-security-ai-tools-pentesters</a>. </li>
</ol></section><section class="print-page" id="software-pre_post_policy_as_code"><h1 id="software-pre_post_policy_as_code-policy-as-code-served-pre-and-post-coding">Policy-as-Code Served Pre and Post Coding<a class="headerlink" href="#software-pre_post_policy_as_code-policy-as-code-served-pre-and-post-coding" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This chapter explains how to turn large, static security documents into <em>working</em> policy-as-code that GenAI Security Agents can apply during design, coding, and review.
Instead of asking engineers to memorize external and internal standards and guidance, we:</p>
<ul>
<li>Break large documents into small, testable <strong>rule cards</strong>  </li>
<li>Compile those rule cards into reusable <strong>knowledge packs</strong>  </li>
<li>Expose the packs through <strong>security agents</strong> and <strong>interactive skills</strong>  </li>
<li>Wire them into <strong>software engineering workflows</strong> so guidance appears at the right time and place  </li>
</ul>
<p>The end goal is simple: security guidance lives as close as possible to the code, served automatically at the time of coding as pre-coding guidance and post-coding checksâ€”achieving Continuous Software Assurance.</p>
<p>ðŸ§‘ðŸ»â€ðŸ’» Source code: <a href="https://github.com/CyberSecAI/genai-sec-agents">https://github.com/CyberSecAI/genai-sec-agents</a></p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-goals">Goals<a class="headerlink" href="#software-pre_post_policy_as_code-goals" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/continuous_sw_ass.png" /></p>
</figure>
<p>The Policy-as-Code engine for GenAI Security Agents is designed to:</p>
<ul>
<li>
<p><strong>Operationalise standards</strong>
  Turn external frameworks and internal policies into concrete, testable rules.</p>
</li>
<li>
<p><strong>Embed security into workflows</strong>
  Make security checks first-class citizens in planning, design, coding, and review.</p>
</li>
<li>
<p><strong>Support both pre-code and post-code use</strong>
  Give guidance before the first line of code, and validation once code exists.
  In general, give guidance pre and post any artifact creation.</p>
</li>
<li>
<p><strong>Provide traceability</strong>
  Make it clear which requirement, from which document, led to each recommendation.</p>
</li>
<li>
<p><strong>Enable incremental adoption</strong>
  Start with pre-built knowledge packs, then extend with your own documentation over time.</p>
</li>
</ul>
<hr />
<h2 id="software-pre_post_policy_as_code-core-concept-from-documents-to-rule-cards">Core Concept: From Documents to Rule Cards<a class="headerlink" href="#software-pre_post_policy_as_code-core-concept-from-documents-to-rule-cards" title="Permanent link">&para;</a></h2>
<p>The core idea is simple:</p>
<blockquote>
<p>Take large security documents and convert them into small, testable <strong>rule cards</strong> that can be applied by <a href="#software-claude_code">Claude Code</a> agents and skills.</p>
</blockquote>
<h3 id="software-pre_post_policy_as_code-source-documents">Source Documents<a class="headerlink" href="#software-pre_post_policy_as_code-source-documents" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/gen_ai_guidance.png" /></p>
</figure>
<p>Typical sources include:</p>
<ul>
<li>OWASP and ASVS guidance as used in this example</li>
<li>Internal security policies and standards</li>
<li>Regulator rules and industry frameworks</li>
<li>Architecture decision records and security guidelines</li>
</ul>
<p>These are treated as <strong>source of truth</strong>, not something the LLM invents.</p>
<h3 id="software-pre_post_policy_as_code-atomic-rule-cards">Atomic Rule Cards<a class="headerlink" href="#software-pre_post_policy_as_code-atomic-rule-cards" title="Permanent link">&para;</a></h3>
<p>From those documents we create <strong>atomic rule cards</strong>:</p>
<ul>
<li>
<p>Each card represents a <strong>single, precise requirement</strong>
  (â€œAPI must use OAuth2 with short-lived access tokensâ€, not â€œuse strong authâ€)</p>
</li>
<li>
<p>Each card has:</p>
<ul>
<li>A clear <strong>condition</strong> (when it applies)</li>
<li>A <strong>requirement</strong> (what must be true)</li>
<li><strong>Rationale / references</strong> (why it matters, where it came from)</li>
<li><strong>Example checks</strong> or questions the agent should ask</li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Think of rule cards as â€œlinters for architecture and security designâ€ - small, focused rules that are easy to test and revise.</p>
</div>
<h3 id="software-pre_post_policy_as_code-compiled-knowledge-packs">Compiled Knowledge Packs<a class="headerlink" href="#software-pre_post_policy_as_code-compiled-knowledge-packs" title="Permanent link">&para;</a></h3>
<p>Rule cards are grouped and compiled into <strong>knowledge packs</strong>:</p>
<ul>
<li>Packs align with <strong>domains</strong> (authentication, secrets, logging, etc.)</li>
<li>
<p>Each pack can be:</p>
<ul>
<li>Loaded by a <strong>specialist security agent</strong></li>
<li>Queried via <strong>interactive skills</strong> or <strong>semantic search</strong> or <strong>grep</strong></li>
<li>Used in combinations for broader reviews</li>
</ul>
</li>
</ul>
<p>This compilation step normalises the content into a <strong>machine-friendly format</strong> that agents can load efficiently.</p>
<h3 id="software-pre_post_policy_as_code-agents-and-skills">Agents and Skills<a class="headerlink" href="#software-pre_post_policy_as_code-agents-and-skills" title="Permanent link">&para;</a></h3>
<figure>
<p><img alt="" src="../assets/images/doc_agents.png" /></p>
</figure>
<p>The <code>.claude/</code> folder in a project then becomes the delivery vehicle:</p>
<ul>
<li>
<p><strong>Security agents</strong>
  Deep specialists for cross-cutting reviews (e.g. "comprehensive security review", "authentication specialist").</p>
</li>
<li>
<p><strong>Interactive skills</strong>
  Specialized context modifiers that can be triggered via slash commands or automatically by Claude (e.g. <code>/authentication-security</code>, <code>/secrets-check</code>, <code>/logging-review</code>).</p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same underlying rule cards and packs power all of these entry points - you don't have to duplicate logic across agents and skills.</p>
</div>
<h4 id="software-pre_post_policy_as_code-when-to-use-skills-or-agents">When to Use Skills or Agents<a class="headerlink" href="#software-pre_post_policy_as_code-when-to-use-skills-or-agents" title="Permanent link">&para;</a></h4>
<div class="admonition note">
<p class="admonition-title">Skills vs Agents</p>
<p><strong>Skills</strong> are best for:</p>
<ul>
<li><strong>Automatic context injection</strong> - Claude detects when they're needed via pure LLM reasoning</li>
<li><strong>Interactive workflows</strong> - Progressive disclosure loads only what's needed when matched</li>
<li><strong>Token efficiency</strong> - Small discovery cost (name + description), larger only when activated</li>
<li><strong>Learning and exploration</strong> - Rich examples and guidance for understanding capabilities</li>
<li><strong>Multi-skill composition</strong> - Multiple skills can auto-activate together for complex requests</li>
</ul>
<p><strong>Agents</strong> are best for:</p>
<ul>
<li><strong>Explicit parallel execution</strong> - Multiple sub-agents run simultaneously via Agent SDK</li>
<li><strong>Programmatic invocation</strong> - CI/CD pipelines, pre-commit hooks, automated validation</li>
<li><strong>Deterministic workflows</strong> - User controls exactly which agents run and when</li>
<li><strong>Background execution</strong> - Long-running tasks with monitoring and output retrieval</li>
<li><strong>Orchestration patterns</strong> - Main agent delegates to specialist sub-agents</li>
</ul>
<p><strong>Critical distinction:</strong> 
- Skills are <strong>context modifiers</strong> that inject specialized instructions and can constrain allowed tools/model selection. Agents are <strong>task executors</strong> that run in separate contexts for parallel analysis. </p>
<p><strong>Complementary, not competing:</strong> Use skills for automatic context management in interactive workflows. Use agents for explicit parallel execution in programmatic workflows. Both share the same rule knowledge base via symlinks.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-access-patterns-six-ways-llms-use-security-knowledge">Access Patterns: Six Ways LLMs Use Security Knowledge<a class="headerlink" href="#software-pre_post_policy_as_code-access-patterns-six-ways-llms-use-security-knowledge" title="Permanent link">&para;</a></h2>
<p>The Policy-as-Code engine exposes <strong>six complementary access patterns</strong>. Each pattern balances:</p>
<ul>
<li>How predictable the invocation is</li>
<li>How much context it needs</li>
<li>How â€œdeepâ€ the analysis should be</li>
<li>How it affects the primary Claude Code CLI context</li>
</ul>
<h3 id="software-pre_post_policy_as_code-summary-of-patterns">Summary of Patterns<a class="headerlink" href="#software-pre_post_policy_as_code-summary-of-patterns" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>Pattern</th>
<th>Activation</th>
<th>Token Cost</th>
<th>Context Window Impact</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Slash Commands</strong></td>
<td>Deterministic (user-explicit)</td>
<td>Variable</td>
<td>Invokes skills or direct commands</td>
<td>Explicit developer-invoked guidance</td>
</tr>
<tr>
<td><strong>Skills</strong></td>
<td>LLM-triggered (based on description) or via slash command</td>
<td>1.5k-15k per invocation</td>
<td>Context modifier with progressive disclosure</td>
<td>Specialized instructions and tool/model constraints</td>
</tr>
<tr>
<td><strong>Agents</strong></td>
<td>Explicit (Task tool)</td>
<td>15k+</td>
<td>Separate context (not main window)</td>
<td>Parallel analysis, deep validation</td>
</tr>
<tr>
<td><strong>Semantic Search</strong></td>
<td>Explicit (tool)</td>
<td>Variable</td>
<td>On-demand reading into main context</td>
<td>Standards research, best practices lookup. No vector or RAG DB needed.</td>
</tr>
<tr>
<td><strong>Grep</strong></td>
<td>Explicit (tool)</td>
<td>Minimal</td>
<td>On-demand reading into main context</td>
<td>Direct pattern search in rules/corpus</td>
</tr>
<tr>
<td><strong>CLAUDE.md</strong></td>
<td>Automatic (every turn)</td>
<td>1-5k per turn (~15k per 5-turn conversation)</td>
<td>Always present in main context</td>
<td>Workflow orchestration, security enforcement</td>
</tr>
</tbody>
</table>
<p>Note: numbers are given as representative examples. YMMV!</p>
<div class="admonition note">
<p class="admonition-title">Skills vs Slash Commands</p>
<p><strong>Skills</strong> and <strong>Slash Commands</strong> work together, not as alternatives:</p>
<ul>
<li><strong>Skills</strong> are prompt-based context modifiers that inject specialized instructions and can constrain allowed tools and model selection</li>
<li><strong>Slash Commands</strong> are invocation methods that can trigger skills deterministically (user types <code>/skill-name</code>)</li>
<li><strong>Skills</strong> can ALSO be triggered automatically via pure LLM reasoning when Claude reads skill descriptions and decides they're relevant</li>
<li>A skill can be invoked both ways: explicitly via slash command OR automatically when the LLM detects the need</li>
</ul>
</div>
<div class="admonition warning">
<p class="admonition-title">Skills Auto-Activation is Probabilistic and Naive</p>
<p><strong>Automatic skill activation is hit-and-miss and heavily depends on skill description quality:</strong></p>
<p><strong>Naive Discovery Mechanism:</strong></p>
<ul>
<li>Skill matching uses substring and semantic matching on the <code>description</code> field in SKILL.md frontmatter</li>
<li>The matching algorithm is <strong>not sophisticated</strong> - no embedding models, no matching scores, no ranking</li>
<li>If your description is vague or lacks keywords matching the user's request, <strong>the skill won't activate at all</strong></li>
<li>Skills can fail to activate even when they seem clearly relevant</li>
</ul>
<p><strong>No Debug Capability:</strong></p>
<ul>
<li>There is <strong>no matching score</strong> or confidence metric available</li>
<li>There is <strong>no debug mode</strong> to see why a skill didn't activate</li>
<li>The only way to troubleshoot is trial-and-error refinement of descriptions</li>
</ul>
<p><strong>Critical Success Factors:</strong></p>
<ul>
<li><strong>Include specific keywords</strong> that users are likely to mention (e.g., "JWT", "OAuth2", "password hashing")</li>
<li><strong>List explicit use cases</strong> in the description ("Use this skill when reviewing login code, authentication flows, or credential handling")</li>
<li><strong>Add trigger phrases</strong> that map to common developer requests</li>
<li><strong>Test extensively</strong> with realistic user prompts to validate activation rates</li>
<li><strong>Quality of CLAUDE.md matters</strong> - clear instructions can guide Claude to prefer certain skills in specific contexts</li>
</ul>
<p><strong>Recommendation:</strong> For security-critical workflows, <strong>do NOT rely solely on automatic skill activation</strong>. Use explicit slash commands or deterministic agent invocation for mandatory security checks. Consider skills as helpful guidance that MAY activate, not guaranteed enforcement.</p>
</div>
<h3 id="software-pre_post_policy_as_code-when-to-use-which-pattern">When to Use Which Pattern<a class="headerlink" href="#software-pre_post_policy_as_code-when-to-use-which-pattern" title="Permanent link">&para;</a></h3>
<div class="admonition info">
<p class="admonition-title">Claude's Autonomy in Pattern Selection</p>
<p><strong>Claude Code can autonomously choose which access patterns to use</strong> based on task requirements and instructions in the <code>CLAUDE.md</code> file:</p>
<ul>
<li>The patterns described below are <strong>guidance for system designers</strong>, not rigid constraints on Claude's behavior</li>
<li>Claude may decide to use Skills, Agents, Semantic Search, or Grep based on what's most appropriate for the current task</li>
<li><code>CLAUDE.md</code> instructions can guide Claude to prefer certain patterns in specific contexts (e.g., "always use the security agent for authentication code")</li>
<li>Developers can invoke patterns explicitly via slash commands, OR Claude can choose them autonomously based on LLM reasoning</li>
<li>This flexibility allows Claude to adapt its approach based on context, task complexity, and available information</li>
</ul>
</div>
<ul>
<li>
<p><strong>Slash Commands</strong>
  Use when you want <em>deterministic</em>, user-controlled skill invocation:</p>
<ul>
<li>A developer explicitly calls <code>/secrets-security</code> while working on config to invoke a specific skill.</li>
<li>An architect explicitly asks <code>/api-authentication-review</code> to trigger authentication review skills on an ADR.</li>
</ul>
</li>
<li>
<p><strong>Skills</strong>
  Use when you want to inject <em>specialized context and constraints</em> into Claude's behavior:</p>
<ul>
<li>Define skills that Claude can automatically detect and invoke based on pure LLM reasoning.</li>
<li>Constrain which tools Claude can use during specific security reviews.</li>
<li>Modify Claude's model selection or execution permissions for specialized tasks.</li>
<li>Skills can be triggered either explicitly via slash commands OR automatically when Claude determines they're relevant.</li>
</ul>
</li>
<li>
<p><strong>Agents</strong>
  Use when you need <strong>broad, cross-cutting security analysis</strong>:</p>
<ul>
<li>â€œReview this PR against our security standards.â€</li>
<li>â€œAssess this architecture document for threats and missing controls.â€</li>
</ul>
</li>
<li>
<p><strong>Semantic Search</strong>
  Use when the question is primarily <strong>research</strong>:</p>
<ul>
<li>â€œWhat are our password policies?â€</li>
<li>â€œHow do we handle multi-tenant isolation?â€</li>
</ul>
</li>
<li>
<p><strong>Grep</strong>
  Use when you need <strong>exact phrase matching</strong>:</p>
<ul>
<li>â€œShow all rules that mention â€˜JWTâ€™.â€</li>
<li>â€œFind references to <code>SAMESITE</code> cookies.â€</li>
</ul>
</li>
<li>
<p><strong>CLAUDE.md</strong>
  Use to <strong>orchestrate when security runs at all</strong>:</p>
<ul>
<li>Automatically invoke a security agent when certain file types or keywords appear.</li>
<li>Ensure security checks become part of the default coding workflow, not an afterthought.</li>
</ul>
</li>
</ul>
<hr />
<h2 id="software-pre_post_policy_as_code-layered-architecture">Layered Architecture<a class="headerlink" href="#software-pre_post_policy_as_code-layered-architecture" title="Permanent link">&para;</a></h2>
<p>The Policy-as-Code engine follows a simple layered architecture:</p>
<ol>
<li>
<p><strong>Source Documents</strong></p>
<ul>
<li>Raw security content: standards, policies, guidelines.</li>
<li>Semantic search and Grep search these</li>
</ul>
</li>
<li>
<p><strong>Atomic Rule Cards</strong></p>
<ul>
<li>Normalised, testable rules with conditions and references.</li>
</ul>
</li>
<li>
<p><strong>Compiled Rule Sets (Knowledge Packs)</strong></p>
<ul>
<li>Grouped JSON bundles for efficient loading.</li>
</ul>
</li>
<li>
<p><strong>Agents &amp; Skills</strong></p>
<ul>
<li>Human-facing and Claude-code-facing entry points defined in <code>.claude/</code>.</li>
</ul>
</li>
</ol>
<p>This separation is important:</p>
<ul>
<li>Security experts can <strong>iterate on rule cards</strong> without touching agent wiring.</li>
<li>Developers only see the <strong>agents and skills</strong>, not the internal representation.</li>
<li>You can run <strong>validation</strong> on rule cards and packs independently from model behaviour.</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This layout is intentionally compatible with both current Claude Code workflows and other agent frameworks. The rule packs are just data - any agent that can load them can use them.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-two-modes-of-adoption">Two Modes of Adoption<a class="headerlink" href="#software-pre_post_policy_as_code-two-modes-of-adoption" title="Permanent link">&para;</a></h2>
<p>The repository supports two complementary adoption paths.</p>
<h3 id="software-pre_post_policy_as_code-1-use-pre-built-security-knowledge">1. Use Pre-Built Security Knowledge<a class="headerlink" href="#software-pre_post_policy_as_code-1-use-pre-built-security-knowledge" title="Permanent link">&para;</a></h3>
<p>For teams who want <strong>fast value with minimal setup</strong>:</p>
<ul>
<li>Copy the provided <code>.claude/</code> folder into your project.</li>
<li>
<p>You immediately get:</p>
<ul>
<li>A curated set of <strong>security skills</strong></li>
<li>A suite of <strong>security agents</strong></li>
<li>Pre-populated rule packs aligned to common standards (e.g. OWASP / ASVS families)</li>
</ul>
</li>
</ul>
<p>Typical uses:</p>
<ul>
<li>
<p><strong>Pre-code</strong>
  Use skills while drafting designs, ADRs, and user stories to catch issues early.</p>
</li>
<li>
<p><strong>Post-code</strong>
  Use agents to review pull requests, configuration files, Dockerfiles, etc.</p>
</li>
</ul>
<h3 id="software-pre_post_policy_as_code-2-build-your-own-knowledge-packs">2. Build Your Own Knowledge Packs<a class="headerlink" href="#software-pre_post_policy_as_code-2-build-your-own-knowledge-packs" title="Permanent link">&para;</a></h3>
<p>For organisations with <strong>strong internal standards</strong> or regulatory needs:</p>
<ul>
<li>
<p>Modify the provided tooling to:</p>
<ul>
<li>Ingest your internal security policies and standards</li>
<li>Shard them into rule cards</li>
<li>Compile them into custom knowledge packs</li>
<li>Wire those packs into new or existing agents and skills</li>
</ul>
</li>
<li>
<p>Requirements (high level):</p>
<ul>
<li>A Python environment</li>
<li>The ability to run the build scripts locally or in CI</li>
</ul>
</li>
</ul>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Start by extending the existing packs - add a <strong>small number of internal rules</strong> for your most critical risks (e.g. data residency, customer data handling) before attempting a full policy migration.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-how-it-fits-the-software-engineering-10-redux-flow">How It Fits the Software Engineering 1.0 Redux Flow<a class="headerlink" href="#software-pre_post_policy_as_code-how-it-fits-the-software-engineering-10-redux-flow" title="Permanent link">&para;</a></h2>
<p>This engine is designed to plug into the phases already described in the <a href="#software-swe_redux">Software Engineering 1.0 Redux</a> and <a href="#software-swe_redux_security">Software Engineering Security</a> sections.</p>
<h3 id="software-pre_post_policy_as_code-pre-code-planning-and-security-review">Pre-Code: Planning and Security Review<a class="headerlink" href="#software-pre_post_policy_as_code-pre-code-planning-and-security-review" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>Planning</strong></p>
<ul>
<li>Use skills to ensure PRDs and architecture docs include required security content.</li>
<li>Architect and Security roles can call targeted skills for authentication, secrets, logging, and data protection.</li>
</ul>
</li>
<li>
<p><strong>Security Review</strong></p>
<ul>
<li>
<p>Run a comprehensive security agent over:</p>
<ul>
<li>Product brief</li>
<li>Architecture document</li>
<li>Security stories</li>
</ul>
</li>
<li>
<p>Generate:</p>
<ul>
<li>Security assessment</li>
<li><a href="#software-threat_model">Threat model</a></li>
<li>Security test cases</li>
<li>Security stories to feed into the backlog</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="software-pre_post_policy_as_code-core-development-implementation-and-code-review">Core Development: Implementation and Code Review<a class="headerlink" href="#software-pre_post_policy_as_code-core-development-implementation-and-code-review" title="Permanent link">&para;</a></h3>
<ul>
<li>
<p><strong>During implementation</strong></p>
<ul>
<li>
<p>Developers call skills in-context in their IDE:</p>
<ul>
<li>â€œIs this JWT handling secure?â€</li>
<li>â€œCheck this API route for common auth issues.â€<ul>
<li>Agents can be invoked periodically for deeper checks on key modules.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Code review</strong></p>
<ul>
<li>
<p>Use a security agent as a specialized reviewer:</p>
</li>
<li>
<p>Run over diffs, not just whole files.</p>
</li>
<li>Map findings back to the rule cards that were violated.</li>
<li>Output concrete, testable recommendations (often directly convertible into security stories and test cases).</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This keeps the <strong>security source of truth</strong> in one place (rule cards and packs), while letting different roles access it in ways that match their workflows.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-personas-and-how-they-use-it">Personas and How They Use It<a class="headerlink" href="#software-pre_post_policy_as_code-personas-and-how-they-use-it" title="Permanent link">&para;</a></h2>
<p>The same knowledge packs are surfaced differently for different roles:</p>
<ul>
<li>
<p><strong>Architect</strong></p>
<ul>
<li>Uses skills to check architecture documents against security requirements.</li>
<li>Invokes a security agent for full design reviews.</li>
</ul>
</li>
<li>
<p><strong>Product Owner / PM</strong></p>
<ul>
<li>Ensures security requirements are explicitly captured in PRDs and stories.</li>
<li>Uses outputs (security stories, test cases) to plan and track work.</li>
</ul>
</li>
<li>
<p><strong>Security Engineer / Analyst</strong></p>
<ul>
<li>Curates rule cards and packs.</li>
<li>Owns the security validation of the agents.</li>
<li>Reviews high-risk findings and refines the rules.</li>
</ul>
</li>
<li>
<p><strong>Developer</strong></p>
<ul>
<li>Uses skills inline in the IDE for quick checks.</li>
<li>Treats the security agent as a specialised reviewer alongside human reviewers.</li>
</ul>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This aligns with the broader guideâ€™s stance: <strong>LLMs augment, not replace, the existing roles</strong>. The Policy-as-Code engine simply gives each role a more usable interface to the organizationâ€™s security brain.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-example-workflow-from-policy-to-actionable-checks">Example Workflow: From Policy to Actionable Checks<a class="headerlink" href="#software-pre_post_policy_as_code-example-workflow-from-policy-to-actionable-checks" title="Permanent link">&para;</a></h2>
<p>A concrete end-to-end flow might look like this:</p>
<ol>
<li>
<p><strong>Ingest standards</strong></p>
<ul>
<li>Security team selects a subset of OWASP / ASVS and internal standards as initial scope.</li>
</ul>
</li>
<li>
<p><strong>Create rule cards</strong></p>
<ul>
<li>Rule cards are authored and reviewed for clarity, conditions, and references.</li>
</ul>
</li>
<li>
<p><strong>Build knowledge packs</strong></p>
<ul>
<li>Packs are compiled by domain (auth, secrets, etc.) and validated.</li>
</ul>
</li>
<li>
<p><strong>Wire into agents and skills</strong></p>
<ul>
<li>Security agents load the full set of relevant packs.</li>
<li>Skills are exposed for common queries (â€œcheck my authâ€, â€œreview my loggingâ€).</li>
</ul>
</li>
<li>
<p><strong>Connect to engineering workflows</strong></p>
<ul>
<li><code>.claude/</code> is added to the repo.</li>
<li>
<p>CLAUDE.md is updated so that:</p>
<ul>
<li>Certain files trigger automatic security checks.</li>
<li>Developers have easy access to security skills.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Iterate based on findings</strong></p>
<ul>
<li>False positives and gaps feed back into rule card revisions.</li>
<li>New standards or guidance become new or updated cards.</li>
</ul>
</li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Success</p>
<p>Once this loop is running, your security standards stop being static irrelevant documents and become a <strong>living, executable policy-as-code system</strong> that evolves along with your software.</p>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-takeaways">Takeaways<a class="headerlink" href="#software-pre_post_policy_as_code-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ul>
<li>Large, static security documents are converted into <strong>atomic rule cards</strong> and <strong>knowledge packs</strong>.</li>
<li>The same packs power <strong>skills</strong>, <strong>agents</strong>, search, and workflow automation via <code>CLAUDE.md</code>.</li>
<li>Teams can start quickly with <strong>pre-built security content</strong> and then extend with internal policies.</li>
<li>The engine fits naturally into the <strong>Software Engineering 1.0 Redux</strong> lifecycle: planning, design, implementation, and review.</li>
<li>Security becomes <strong>embedded and executable</strong>, not a separate after-the-fact checklist.</li>
</ul>
</div>
<hr />
<h2 id="software-pre_post_policy_as_code-glossary">Glossary<a class="headerlink" href="#software-pre_post_policy_as_code-glossary" title="Permanent link">&para;</a></h2>
<p><strong>Rule Cards</strong>
: Small, testable units representing a single, precise security requirement. Each card contains a condition (when it applies), a requirement (what must be true), rationale/references (why it matters), and example checks. Think of them as "linters for architecture and security design."</p>
<p><strong>Knowledge Packs</strong>
: Compiled collections of rule cards grouped by security domain (authentication, secrets, logging, etc.). Packs are normalized into machine-friendly JSON format that can be efficiently loaded by agents and skills.</p>
<p><strong>Context Injection</strong>
: The process by which skills and CLAUDE.md automatically insert specialized instructions and security rules into Claude's conversation context. Skills use progressive disclosure to load minimal metadata initially, then full content when semantically matched.</p>
<p><strong>Progressive Disclosure</strong>
: A token-efficiency strategy where skills load information incrementally: (1) discovery phase loads only name + description, (2) activation phase loads full skill instructions when matched, (3) on-demand phase loads detailed rules (JSON) only if needed.</p>
<p><strong>Context Modifiers</strong>
: Skills that inject specialized instructions and can constrain Claude's behavior by modifying allowed tools, model selection, and execution permissions. Distinguished from agents which are task executors in separate contexts.</p>
<p><strong>LLM Reasoning</strong>
: The mechanism by which Claude autonomously decides when to activate skills. Based purely on language understanding of skill descriptions and user requestsâ€”not algorithmic pattern matching, embeddings, or ML-based intent detection.</p>
<p><strong>Agent SDK</strong>
: Claude Code's framework for explicit parallel execution of multiple sub-agents. Agents run in separate contexts (not the main conversation window) and enable programmatic invocation for CI/CD pipelines and automated validation.</p>
<hr />
<h2 id="software-pre_post_policy_as_code-references">References<a class="headerlink" href="#software-pre_post_policy_as_code-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://github.com/CyberSecAI/genai-sec-agents">GenAI Security Agents Repository</a> - Source code for policy-as-code engine with rule cards and knowledge packs (2025)</li>
<li><a href="https://leehanchung.github.io/blogs/2025/10/26/claude-skills-deep-dive/">Claude Skills Deep Dive</a> - Technical analysis of skills architecture and activation mechanisms (October 26, 2025)</li>
<li><a href="https://agiflow.io/blog/claude-code-internals-reverse-engineering-prompt-augmentation/">Claude Code Internals Analysis</a> - Reverse engineering of context injection and prompt augmentation (2025)</li>
<li><a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills">Agent Skills for the Real World</a> - Anthropic's official documentation on agent skills (2024)</li>
<li><a href="https://medium.com/data-science-collective/claude-skills-a-technical-deep-dive-into-context-injection-architecture-ee6bf30cf514">Technical Deep Dive into Context Injection</a> - Detailed architecture analysis (2025)</li>
</ol></section><section class="print-page" id="software-aixcc"><h1 id="software-aixcc-darpa-ai-cyber-challenge-tools-comparison">DARPA AI Cyber Challenge Tools Comparison<a class="headerlink" href="#software-aixcc-darpa-ai-cyber-challenge-tools-comparison" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This report is auto-generated by ChatGPT 5.</p>
<div class="admonition quote">
<p class="admonition-title">Prompt</p>
<p>I want a report on the tools listed on <a href="https://archive.aicyberchallenge.com">https://archive.aicyberchallenge.com</a> comparing their operation and features. I want a table comparison and a detailed comparison. I want to highlight what traditional non-AI tools were used - and what AI tools were used and how.</p>
</div>
</div>
<h1 id="software-aixcc-aixcc-finalists-and-tools-comparison">AIxCC Finalists and Tools Comparison<a class="headerlink" href="#software-aixcc-aixcc-finalists-and-tools-comparison" title="Permanent link">&para;</a></h1>
<h2 id="software-aixcc-introduction">Introduction<a class="headerlink" href="#software-aixcc-introduction" title="Permanent link">&para;</a></h2>
<p>The <strong>DARPA AI Cyber Challenge (AIxCC)</strong> tasked teams with building fully automated Cyber Reasoning Systems (CRSs) to find and fix vulnerabilities in real-world open-source software<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20was%20a%20two,Human%20interaction%20was%20strictly%20prohibited">[1]</a><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20AI%20Cyber%20Challenge%20asks,asked%20to%20submit%20their%20assessment">[2]</a>. Seven finalist teams advanced from the 2024 semifinals to the 2025 finals, each open-sourcing their CRS. These systems varied in design â€“ some enhanced traditional program analysis techniques with AI, while others were <em>AI-first</em> in their approach<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Enhancing%20traditional%20security%20tools%20with,AI">[3]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>. This report compares all finalist tools (including their semifinal and final iterations) on their core operation, technical approach, key features, use of traditional vs. AI techniques, performance results, and documentation. We also include <strong>SHERPA</strong>, an AIxCC-developed harness-generation tool released alongside the finalists. Table 1 summarizes the tools and their characteristics, followed by detailed analyses of each.</p>
<h2 id="software-aixcc-comparison-table-of-aixcc-tools">Comparison Table of AIxCC Tools<a class="headerlink" href="#software-aixcc-comparison-table-of-aixcc-tools" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th style="text-align: left;">Tool (Team)</th>
<th style="text-align: left;">Core Approach &amp; Features</th>
<th style="text-align: left;">AI-Based Techniques</th>
<th style="text-align: left;">Traditional Techniques</th>
<th style="text-align: left;">Performance (Finals)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>Atlantis (TeamÂ Atlanta)</strong></td>
<td style="text-align: left;"><em>Ensemble of multiple CRSs</em> for C, Java, etc., run in parallel (N-version design) for robustness<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Our%20answer%3A%20N,orthogonal%20approaches">[5]</a>. Integrates diverse strategies (fuzzing, concolic, static) for <em>max coverage</em><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[6]</a>.</td>
<td style="text-align: left;">LLMs in three modes: <em>Augmented</em> (assist fuzz/tools), <em>Opinionated</em> (provide hints), <em>Driven</em> (autonomous agents)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L4.%20LLM">[7]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L293%20LLM,from%20diffs%20or%20SARIF%20reports">[8]</a>. Fine-tuned custom <strong>Llama2-7B</strong> models specialized for C code analysis<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a>. LLM-generated input mutators, grammar dictionaries and PoV exploit agents<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[10]</a>.</td>
<td style="text-align: left;">Heavy use of <em>fuzzing</em> (LibAFL, libFuzzer, AFL++ ensembles) and <em>concolic execution</em> (extended SymCC)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a>. Custom directed fuzzers for C/Java<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a>. Kubernetes-based scaling; disabled non-PoV patching to avoid false patches<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>.</td>
<td style="text-align: left;"><strong>1st place</strong> â€“ <em>43</em> vulns found, <em>31</em> patched<a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%94%E2%80%94,31%20Total%20Score%20%E2%86%92%20393">[13]</a>. Highest overall score (393)<a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%94%E2%80%94,31%20Total%20Score%20%E2%86%92%20393">[13]</a>. Most â€œreal-worldâ€ vulns patched (achievement: <em>Prince of the Patch</em><a href="https://aicyberchallenge.com/#:~:text=,PoV%20percentage%20higher%20than%2095">[14]</a>).</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Buttercup (Trail of Bits)</strong></td>
<td style="text-align: left;"><em>Hybrid fuzzing+analysis pipeline</em> with <em>LLM-assisted input generation</em> and multi-agent patching. Emphasizes accuracy (90%+)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[15]</a> and broad <abbr title="CWE Common Weakness Enumeration">CWE</abbr> coverage<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20challenged%20competitors%20to%20find,safety%20issues%20to%20injection%20flaws">[16]</a>. Cost-efficient design using cheaper LLMs<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[17]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[18]</a>.</td>
<td style="text-align: left;"><em>LLM-generated test cases</em> augment libFuzzer/Jazzer to hit complex conditions (e.g. SQLi, path traversal)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a>. Multi-agent patching with separate agents for vulnerability analysis and fix generation<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. Used â€œnon-reasoningâ€ LLMs at scale (100k+ queries) for efficiency<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=1,bundled%20SARIF%2C%20PoV%2C%20and%20Patches">[21]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[17]</a>.</td>
<td style="text-align: left;">Integrated <em>coverage-guided fuzzers</em> (libFuzzer for C/C++, Jazzer for Java) with grammar and dictionary inputs<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. <em>Static analysis</em> (tree-sitter parsing, code queries) to locate bug patterns<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a>. Conservative patch strategy: no patch submitted without a triggering PoV<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>.</td>
<td style="text-align: left;"><strong>2nd place</strong> â€“ <em>28</em> vulns found, <em>19</em> patched<a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[23]</a>. Score 219. Achieved 90%+ accuracy and 20 unique <abbr title="CWE Common Weakness Enumeration">CWE</abbr> exploits<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20challenged%20competitors%20to%20find,safety%20issues%20to%20injection%20flaws">[16]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a>. Noted for largest patch (300+ lines, <em>â€œLOC Ness Monsterâ€</em> award)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[25]</a>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>RoboDuck (Theori)</strong></td>
<td style="text-align: left;"><em>â€œLLM-firstâ€ autonomous CRS</em> that minimizes classical fuzzing<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Our%20Approach">[26]</a>. Uses an agent-based workflow to <em>find, exploit, and patch</em> bugs without human input<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>. Uniquely capable of generating proofs of vulnerability <em>without traditional fuzzing or symbolic execution</em><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>.</td>
<td style="text-align: left;">Heavy use of <em>LLM agents</em> for code understanding, exploit generation, and patching. Two different LLMs scan code: one per function, one on large code chunks<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=While%20only%20a%20piece%20of,shot%20LLM%20completions">[28]</a>. Agents follow reverse-engineering style playbooks constrained to stay on task<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a>. LLMs generate PoVs for complex formats (URLs, binary protocols) by reasoning about program semantics<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20generates%20approximately%2090,as%20a%20fallback%20validation%20mechanism">[30]</a>.</td>
<td style="text-align: left;">Used static analyzer <strong>Infer</strong> to surface bug candidates (interprocedural null derefs, overflows, etc.)<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20first%20step%20our%20system,performed%20by%20two%20different%20LLMs">[31]</a>. Basic fuzzing as backup (leveraging OSS-Fuzz harnesses with libFuzzer)<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=">[32]</a>. Some integration of SARIF static reports for validation. Aggressive patch strategy: allowed submitting speculative patches (up to 2 without PoV per confirmed PoV) to maximize scores<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=capabilities%20before%20the%20finals%20to,avoid%20accuracy%20penalties">[33]</a>.</td>
<td style="text-align: left;"><strong>3rd place</strong> â€“ <em>34</em> vulns found, <em>20</em> patched<a href="https://aicyberchallenge.com/#:~:text=Theori%20%E2%80%94%E2%80%94,20%20Total%20Score%20%E2%86%92%20211">[34]</a>. Score 211. Earned <em>â€œSecret Sauceâ€</em> for uniquely exploited challenge<a href="https://aicyberchallenge.com/#:~:text=,else%20submitted%20a%20POV%20for">[35]</a>. Spent \~half the top teamsâ€™ LLM budget yet remained competitive<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Each%20AIxCC%20team%20was%20given,two%20winners%20on%20LLM%20queries">[36]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Fuzzingâ€¯Brain (All You Need)</strong></td>
<td style="text-align: left;"><em>AI-centric â€œbrainâ€ directs fuzzing</em> and analysis. <strong>Most AI-driven system</strong> â€“ LLMs handle vulnerability reasoning, strategic decisions, and code writing (â‰ˆ90% of codebase written with AI aid)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>. Emphasizes quick finds (scored within 5 minutes on a task, â€œFaster Than Pizza Deliveryâ€) and high SARIF accuracy<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>.</td>
<td style="text-align: left;">Uses thousands of concurrent LLM <em>agents</em> in parallel to analyze code and hypothesize exploits<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. Primary vulnerability detection via AI reasoning; traditional fuzzers only kick in as a fallback validation<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. LLMs used for system architecture decisions and patch generation. Achieved &gt;80% correctness in static finding classification (SARIF) via AI triage<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>.</td>
<td style="text-align: left;">Leveraged <em>fuzzing pipelines</em> (implied by team name and achievements) as secondary confirmation for AI findings. Likely used standard fuzzers and runtime instrumentation to verify AI-identified bugs and patches (the system won â€œ-Ofastâ€ first-to-find real C bug award)<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. Patching likely also AI-driven with some traditional compile/test loops for validation.</td>
<td style="text-align: left;"><strong>4th place</strong> â€“ <em>28</em> vulns found, <em>14</em> patched<a href="https://aicyberchallenge.com/#:~:text=ALL%20YOU%20NEED%20IS%20A,14%20Total%20Score%20%E2%86%92%20154">[40]</a>. Score 154. Earned achievements for fastest find and high SARIF precision<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. Demonstrated extremely AI-forward methodology<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>, though with higher cost per point due to massive parallelism<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Artiphishell (Shellphish)</strong></td>
<td style="text-align: left;"><em>Massively multi-agent CRS</em> (60+ AI agents coordinating)<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a> built by an academic hacker collective. Agent-based architecture tackles tasks in parallel (parsing, fuzzing, exploit generation, patching) with minimal human tuning<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>. Enhances classic fuzzing with AI-driven grammar inference (â€œGrammar Guyâ€ subsystem)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. Focus on telemetry and reliability.</td>
<td style="text-align: left;">Agents use OpenAI, Anthropic, and Google Gemini LLM APIs (multi-LLM)<a href="https://github.com/shellphish/artiphishell#:~:text=Configure%20LLM%20Secrets">[43]</a> for various roles. <em>Grammar Guy</em> LLM agent evolves input grammars from coverage feedback to fuzz complex formats (SQL, URLs, binary data)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a> â€“ a major LLM budget consumer that boosted bug-finding. Other agents monitor and â€œbabysitâ€ LLM outputs to keep them on track (role-based prompting, etc.)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L3,Jack">[44]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L253%20improvements,agent%20specifically%20for%20this%20task">[45]</a>. AI also used for rich telemetry logging of CRS reasoning steps (earned â€œBest Telemetryâ€ honor)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>.</td>
<td style="text-align: left;">Built on years of CRS experience (Shellphish was a CGC 2016 finalist). Uses traditional <em>fuzzers</em> (e.g., AFL-based or QEMU-based) guided by AI-generated grammars<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. Likely employed symbolic execution or static analysis modules from prior frameworks (angr/Driller heritage) enhanced with AI. Very cautious patch policy â€“ <strong>no patches without PoV</strong> to ensure 95%+ patch accuracy<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>.</td>
<td style="text-align: left;"><strong>5th place</strong> â€“ <em>28</em> vulns found, <em>11</em> patched<a href="https://aicyberchallenge.com/#:~:text=Shellphish%20%E2%80%94%E2%80%94,11%20Total%20Score%20%E2%86%92%20136">[47]</a>. Score 136. Extremely high patch correctness (over 95% success)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a> by design. Won â€œThe Limit Does Not Existâ€ for creating a PoV over 1Â MB<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[48]</a>. Heavy use of AI (multi-LLM) yielded solid finds, but slower patch output kept score lower.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Bugâ€¯Buster (42â€‘b3yondâ€‘6ug)</strong></td>
<td style="text-align: left;"><em>High-scalability fuzzing platform</em> with advanced scheduling and some AI assistance. Employed <strong>BandFuzz</strong> reinforcement-learning scheduler to coordinate up to \~2,000 fuzzer instances in parallel<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[49]</a> for maximal coverage. Explored static program <em>slicing</em> to focus fuzzing on bug-prone code (though faced toolchain challenges)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=repair">[50]</a>. Introduced â€œsuper patchâ€ concept to fix multiple bugs in one go<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>.</td>
<td style="text-align: left;">Applied AI in specific roles: <em>RL-based orchestration</em> of fuzzers (learned which targets to fuzz more)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a>, LLM-generated fuzzing seeds (the team trained an LLM to propose interesting inputs)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=integration">[53]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a>, and LLM-assisted patch generalization (â€œsuper patchesâ€ that address root causes of multiple crashes)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>. Also used LLMs to analyze crash reports into structured â€œvulnerability objectsâ€ for triage planning<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>.</td>
<td style="text-align: left;">Relied on a wide array of <em>traditional techniques</em>: large-scale AFL++-based fuzzing (3 independent fuzz pipelines)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[56]</a>, plus static analysis integration (SARIF parsing, CodeQL queries, etc. for validation)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a>. Program slicing/static path analysis was attempted to guide fuzzing but had compatibility issues<a href="https://www.whexy.com/en/posts/aixcc#:~:text=repair">[50]</a>. Used a mix of kernel fuzzing and user-space targets; implemented crash deduplication logic to cluster same root cause. Patching was ambitious but buggy â€“ their â€œsuper patchesâ€ fixed multiple vulnerabilities at once when it worked<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>.</td>
<td style="text-align: left;"><strong>6th place</strong> â€“ <em>41</em> vulns found, <em>3</em> patched<a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,3%20Total%20Score%20%E2%86%92%20105">[57]</a>. Score 105. Second-highest PoV points (strong bug-finding), <strong>top SARIF accuracy</strong><a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>, but patch failures hurt overall rank<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>. Achieved <em>â€œCzar of the SARIFâ€</em> (most correct static assessments) and <em>â€œHunger for Knowledgeâ€</em> (peaked at 1K+ LLM requests/min)<a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[59]</a> â€“ demonstrating brute-force scale. Final result marred by a patch pipeline bug, illustrating the fragility of such a complex system<a href="https://www.whexy.com/en/posts/aixcc#:~:text=What%20went%20wrong">[60]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>.</td>
</tr>
<tr>
<td style="text-align: left;"><strong>Lacrosse</strong> (SIFT)</td>
<td style="text-align: left;"><em>Modernized legacy CRS</em> (evolved from a 10-year-old platform)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AIxCC%20finals%3A%20Tale%20of%20the,about%20its%20ability%20to">[61]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=LACROSSE%3A%20This%20team%20gave%20its,about%20its%20ability%20to">[62]</a>, augmented with AI. Emphasized proven fuzzing techniques: deployed <em>300â€“500 fuzzing agents</em> (comparable scale to ToB) orchestrated by a central agent â€œOptimusÂ Zeroâ€<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. Focused on stability and slow-but-steady analysis.</td>
<td style="text-align: left;">Used LLMs for higher-level reasoning and crash analysis. For each crash, an LLM created a detailed <em>â€œvulnerability objectâ€</em> describing the bug, classification, and patch plan<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. LLMs provided semantic guidance to fuzzers and consensus-based patch decisions (multiple AI models had to agree before a fix)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a>.</td>
<td style="text-align: left;">Strong bias toward <em>traditional fuzzing</em> for PoV generation (minimized fancy AI bug-hunting)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a>. Many fuzzers running in parallel with a global state manager (Optimus Zero) to distribute tasks<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. Employed standard static tools to triage crashes. Patch submissions used a confidence algorithm and LLM consensus to avoid incorrect fixes<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a>, reflecting a cautious, engineering-driven approach.</td>
<td style="text-align: left;"><strong>7th place</strong> â€“ <em>1</em> vuln found, <em>1</em> patched<a href="https://aicyberchallenge.com/#:~:text=Lacrosse%20%E2%80%94%E2%80%94,1%20Total%20Score%20%E2%86%92%2010">[65]</a>. Score 10. Despite limited scored results, received <em>â€œConsensus Contributorâ€</em> for most submissions (albeit mostly duplicates) and <em>â€œRaiders of the Lost PoVâ€</em> for finding a unique real bug others missed<a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a>. Suggests the system was robust but perhaps too conservative and slow to compete within time limits.</td>
</tr>
</tbody>
</table>
<p><strong>Table 1:</strong> Summary of AIxCC finalist tools (with team names) and their characteristics in the final competition. All tools were open-sourced<a href="https://aicyberchallenge.com/#:~:text=used%20to%20secure%20our%20critical,infrastructure%20and%20beyond">[67]</a>. Performance metrics are from the final scored round at DEF CONÂ 33<a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%94%E2%80%94,31%20Total%20Score%20%E2%86%92%20393">[13]</a><a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[23]</a>. "PoV" = proof-of-vulnerability exploit.</p>
<h2 id="software-aixcc-detailed-tool-analysis-and-comparison">Detailed Tool Analysis and Comparison<a class="headerlink" href="#software-aixcc-detailed-tool-analysis-and-comparison" title="Permanent link">&para;</a></h2>
<p>In this section, we examine each tool in depth, highlighting how they work, their unique strengths or weaknesses, and noteworthy differences. We also note documentation availability (e.g. open-source repositories or papers) and any evolution from semifinal to final round.</p>
<h3 id="software-aixcc-atlantis-team-atlanta-multi-engine-ensemble-crs">Atlantis (Team Atlanta) â€“ Multi-Engine Ensemble CRS<a class="headerlink" href="#software-aixcc-atlantis-team-atlanta-multi-engine-ensemble-crs" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>Atlantis</em> is an ensemble system composed of multiple specialized CRSs that run in parallel<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Our%20answer%3A%20N,orthogonal%20approaches">[5]</a>. Team Atlanta split efforts into independent engines for C/C++ bugs, Java bugs, a language-agnostic â€œMultilangâ€ engine, plus separate components for patching and SARIF (static analysis report) handling<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Atlantis%20isn%E2%80%99t%20a%20single%20CRS%E2%80%94it%E2%80%99s,both%20coverage%20and%20fault%20tolerance">[68]</a>. This <em>N-version programming</em> design maximized fault tolerance and coverage â€“ if one approach failed or crashed, others continued unaffected<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=By%20maintaining%20minimal%20sharing%20between,true%20fault%20tolerance%20through%20diversity">[69]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=design%20decisions%2C%20we%20ensured%20that,true%20fault%20tolerance%20through%20diversity">[70]</a>. For example, <strong>Atlantis-C</strong> aggressively instrumented code with heavy compile-time modifications to find memory errors, whereas <strong>Atlantis-Multilang</strong> took a lighter, instrumentation-free approach better suited for rapid, general bug discovery<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=ImageDesign%20Overview%20of%20Atlantis%20,tuned%20for%20our%20Technical%20Report">[71]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=These%20CRSs%20deliberately%20made%20orthogonal,time%20instrumentation">[72]</a>. By diversifying strategies, Atlantis achieved robust overall performance. Team Atlanta prioritized engineering rigor and stability â€“ a critical bug in a patch-skip heuristic nearly derailed them hours before the deadline, underscoring their emphasis on robustness testing<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=of%20code%20nearly%20destroyed%20our,chances">[73]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L0,1">[74]</a>.</p>
<p><strong>Traditional Techniques:</strong> Unlike some competitors that abandoned classic program analysis, Atlantis invested heavily in traditional methods, scaled up to real-world software. They integrated multiple <strong>fuzzing engines</strong> (both coverage-guided and directed fuzzers) and even ran them concurrently (<em>ensemble fuzzing</em>), as research shows this finds more bugs than any single fuzzer<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Java%2C%20we%20developed%20three%20categories%3A">[75]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Each%20tool%20required%20non,world%20scale">[76]</a>. Their toolkit included <strong>LibAFL</strong> (with custom mutators for C and Java), <strong>AFL++</strong>, and <strong>Jazzer</strong> for Java fuzzing<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a>. They also extended <strong>SymCC</strong> (a symbolic execution tool) to work on large codebases and built custom concolic executors for Java<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a>. Each of these components required significant engineering to handle the scale of OSS projects<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=We%20initially%20hoped%20to%20stand,ready">[77]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Ultimately%2C%20we%20invested%20heavily%20in,Java%2C%20we%20developed%20three%20categories">[78]</a>. Atlantis also employed directed fuzzing guided by static analysis: static analyzers would flag potential bug locations, and fuzzers then specifically targeted those functions or code paths<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[79]</a>. In short, Team Atlanta did <em>not</em> give up on conventional program analysis â€“ they adapted and scaled it, supplementing with AI rather than replacing it<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=This%20shift%20changes%20everything,complexity%20would%20doom%20any%20CRS">[80]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Ultimately%2C%20we%20invested%20heavily%20in,Java%2C%20we%20developed%20three%20categories">[81]</a>. For patching, they took a conservative stance; they completely disabled any patch submission that wasnâ€™t backed by a PoV exploit, to avoid penalties for incorrect patches<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>. This caution paid off with a high patch success rate.</p>
<p><strong>AI-Based Techniques:</strong> Although rich in traditional tooling, Atlantis strategically infused AI at multiple levels. They describe three tiers of LLM integration<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L4.%20LLM">[7]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Harness%20Reverser%20operate%20with%20calculated,hints%E2%80%94similar%20to%20optimistic%20concurrency%20control">[82]</a>: (1) <strong>LLM-Augmented</strong> components, where AI assists existing tools (e.g. generating seed inputs for fuzzers, suggesting likely vulnerable API calls that fuzzers should focus on, summarizing static analysis output); (2) <strong>LLM-Opinionated</strong> components, where AI provides hints or â€œopinionsâ€ that the system treats as suggestions â€“ for instance, a <em>Harness Reverser</em> AI that guesses input file formats or network protocols used by the target software, to help fuzzers produce valid inputs<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L286%20Harness%20Reverser,hints%E2%80%94similar%20to%20optimistic%20concurrency%20control">[83]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Harness%20Reverser%20operate%20with%20calculated,hints%E2%80%94similar%20to%20optimistic%20concurrency%20control">[82]</a>; and (3) <strong>LLM-Driven</strong> components, where an agentic AI has autonomy to navigate the codebase. An example of the last is <em>MLLA</em> (Machine Learning Lab Assistant) â€“ an AI agent that reads through a repository and autonomously crafts exploit inputs (â€œblobsâ€) for suspected bugs, especially for challenges in â€œdelta modeâ€ (where a recent code diff may contain the bug)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L293%20LLM,from%20diffs%20or%20SARIF%20reports">[8]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=LLM,from%20diffs%20or%20SARIF%20reports">[84]</a>. Team Atlanta uniquely leveraged <strong>fine-tuned LLMs</strong>: they fine-tuned a 7-billion-parameter Llama2 model on security-relevant data (especially for C language analysis) to use as an internal reasoning engine<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a>. This gave them a proprietary AI tuned for vulnerability patterns in C/C++ code (buffer overflows, use-after-free, etc.), potentially with lower latency and cost than calling large external APIs. LLMs were also used in <strong>directed test generation</strong> â€“ e.g. Atlantis had language-specific prompt templates to generate exploit code or inputs once a vulnerability was suspected<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[79]</a>. Another novel use was creating function-level <em>dictionaries</em> of sensitive values: their AI would analyze a function and output a list of keywords or values (e.g. special file names, command strings) that a fuzzer could mutate with<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[79]</a>. Overall, Atlantis treated AI as powerful assistants that were carefully â€œbabysatâ€ and orchestrated. The team developed an abstraction layer called <em>LiteLLM</em> to interface with multiple AI providers and to handle failures (rate limits, token limits, etc.) gracefully<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=improvements,agent%20specifically%20for%20this%20task">[85]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=To%20avoid%20vendor%20lock,across%20different%20LLM%20providers%20for">[86]</a>. This prevented vendor lock-in and let them switch between models like GPT-4, Claude, and others as needed, or even use their fine-tuned model in place of an API call.</p>
<p><strong>Performance &amp; Results:</strong> <em>Atlantis</em> delivered the strongest performance of the finals, outscoring all others by a wide margin. It discovered <strong>43 vulnerabilities and successfully patched 31</strong> of them, earning a total of 393 points â€“ the highest of any team<a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%94%E2%80%94,31%20Total%20Score%20%E2%86%92%20393">[13]</a>. Notably, Atlantis excelled in both quantity and quality of patches. It earned the special award <em>â€œBundle Baronâ€</em> for submitting the most bundle (PoV+patch) combinations that scored<a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[87]</a>, and <em>â€œMost Real-World Vulns Patchedâ€</em> (the <strong>Prince of the Patch</strong> title) for fixing the greatest number of genuine vulnerabilities<a href="https://aicyberchallenge.com/#:~:text=,PoV%20percentage%20higher%20than%2095">[14]</a>. The systemâ€™s diversity paid off â€“ it was able to find bugs across many categories (<abbr title="CWE Common Weakness Enumeration">CWE</abbr> coverage) and did so quickly enough to also gain a â€œProfessional Assassinâ€ achievement for having over 95% of its PoVs be successful<a href="https://aicyberchallenge.com/#:~:text=,PoV%20percentage%20higher%20than%2095">[88]</a>. Interestingly, Atlantis found a few 0-day vulnerabilities in real open-source code (3 in Java, 3 in C) that were not planted by DARPA<a href="https://aicyberchallenge.com/#:~:text=match%20at%20L194%20Team%20Atlanta,%E2%80%93%20ZERO%20DAYS%20DISCOVERED">[89]</a><a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%93%20ZERO%20DAYS,DISCOVERED">[90]</a>, showing its real-world efficacy. In terms of efficiency, Team Atlanta used the largest compute budget (nearly \<span class="arithmatex">\(74k) and a substantial LLM budget (\~\\\)</span>29k) during the finals<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[18]</a>, reflecting their at-scale approach. The cost per point for Atlantis was about \$263<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[91]</a> â€“ higher than some more cost-optimized teams, but still reasonable given the victory. Documentation-wise, Team Atlanta has provided extensive resources: they published a technical report on their blog with system design insights<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Our%20answer%3A%20N,orthogonal%20approaches">[5]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=ImageDesign%20Overview%20of%20Atlantis%20,tuned%20for%20our%20Technical%20Report">[92]</a> and have open-sourced their code (organized into components like Atlantis-C, Atlantis-Java, etc. on GitHub<a href="https://github.com/Team-Atlanta/aixcc-afc-atlantis#:~:text=Team,">[93]</a>). The comprehensive approach of combining â€œall of the aboveâ€ â€“ classical analysis with cutting-edge AI â€“ was validated by their win.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> Atlantisâ€™ strength was clearly its <em>balance and thoroughness</em>. It left no stone unturned: fuzzers, static analyzers, custom AIs, all worked in concert. This resulted in a top score and high reliability (very few incorrect patches). A possible weakness of this approach is complexity â€“ maintaining multiple CRSs and integration between them is a heavy engineering lift, evidenced by the one-line bug that almost broke the system<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=We%20discovered%20this%20critical%20bug%2C,heuristic%20to%20avoid%20false%20positives">[94]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L0,1">[74]</a>. However, Team Atlanta mitigated that through aggressive testing and redundancy. Another challenge is cost: they threw significant computing resources at the problem, which might be hard to replicate outside of a funded competition. But overall, Atlantis demonstrated that <em>hybrid systems</em> can outperform purely AI or purely traditional ones, and its design to â€œnot trust any single method too muchâ€ proved very effective.</p>
<h3 id="software-aixcc-buttercup-trail-of-bits-ai-augmented-fuzzing-patching">Buttercup (Trail of Bits) â€“ AI-Augmented Fuzzing &amp; Patching<a class="headerlink" href="#software-aixcc-buttercup-trail-of-bits-ai-augmented-fuzzing-patching" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>Buttercup</em> (Trail of Bitsâ€™ CRS) is built on the idea of <strong>augmenting classic vulnerability discovery tools with AI</strong>, in a focused and cost-effective way. The systemâ€™s core loop still resembles a traditional fuzzing and static analysis pipeline, but nearly every stage is turbocharged by machine learning. For instance, Buttercup uses <strong>libFuzzer</strong> (for C/C++) and <strong>Jazzer</strong> (for Java) on each target program, but it improves their effectiveness by <em>supplying intelligent inputs</em> generated by LLMs rather than relying purely on random mutations<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. The team specifically calls out that their LLMs could generate inputs capturing complex attack patterns that simple fuzzers might miss â€“ e.g. a well-formed SQL injection string or a malicious file path â€“ which were then fed into the fuzzersâ€™ corpus<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a>. This approach significantly sped up code coverage and bug trigger time (an important factor given limited competition time)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a>. Buttercup also integrated <em>static code analysis</em>: it used parsers (like Tree-sitter) and custom query scripts to identify suspicious code constructs (e.g. unsafe uses of strcpy, or use of exec() calls)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a>. These were used to guide fuzzing or to prioritize which issues to patch.</p>
<p>Where Buttercup truly innovated was in <strong>patching</strong>. Trail of Bits built a <em>multi-agent patch generation system</em> that emphasizes separation of concerns<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. For example, one agent might specialize in <em>isolating the buggy code snippet</em>, another in <em>drafting a fix</em>, and a third in <em>evaluating the fixâ€™s correctness</em>. They intentionally avoided using the most expensive, â€œgeneralistâ€ AI models (like GPT-4) in favor of what they call <strong>â€œnon-reasoning LLMsâ€</strong><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[17]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a> â€“ presumably smaller or fine-tuned models that are cheaper to run at scale. This is reflected in their costs: Buttercup made over 100k LLM requests during the finals but still only spent \~$21k on LLM API usage, far less than Team Atlanta<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=1,bundled%20SARIF%2C%20PoV%2C%20and%20Patches">[21]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>. The team noted that the top two finishers (Atlanta and ToB) spent the most on AI queries, suggesting that judicious use of LLMs <em>was</em> â€œmoney well-spentâ€ in terms of points<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Each%20AIxCC%20team%20was%20given,two%20winners%20on%20LLM%20queries">[36]</a>.</p>
<p><strong>Traditional Techniques:</strong> Despite the AI enhancements, Buttercup is grounded in well-understood tools. It leans heavily on <strong>coverage-guided fuzzing</strong> (libFuzzer for native code, Jazzer for JVM) to generate concrete PoVs. The fuzzing campaigns were likely distributed across multiple cores/nodes for speed. They also utilized static bug-finding tools: although not explicitly named in sources, Buttercupâ€™s use of tree-sitter implies they were parsing source code abstract syntax trees to find patterns (like searching for known dangerous functions, etc.)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a>. These static findings could then be confirmed by fuzzing or passed to the patcher. Another classic tool category Buttercup likely used is <em>sanitizers</em> (AddressSanitizer, etc.) to catch memory errors, given their background in security research. For exploit generation (PoVs), Buttercup seems to have relied mostly on fuzzers to create crashing inputs, rather than symbolic execution or manual exploit crafting, as no mention of those is made â€“ instead, they improved fuzzers via AI seeds. On the patch side, Trail of Bits exercised caution: like Team Atlanta, they <strong>never submitted a patch without an accompanying PoV</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>. Their blog suggests they believed patch accuracy was a key differentiator in winning second place<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a>. To further ensure quality, they built cross-validation: Buttercup would test its candidate patches against known exploits (its own and perhaps even those of other teams if it obtained them) to avoid releasing a faulty patch<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a>. This strategy aligns with Trail of Bitsâ€™ strength in secure coding â€“ they treated each patch almost like a mini code review, aided by automation.</p>
<p><strong>AI-Based Techniques:</strong> Buttercupâ€™s motto could be <em>â€œuse AI to play to our toolsâ€™ strengths.â€</em> A prime example is their use of LLMs to generate <strong>specialized fuzzing inputs</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a>. Instead of having an AI blindly hunt for bugs, Buttercup asks it to produce inputs that exercise tricky code paths. The LLM likely has some understanding of what input format or API might reach deep into the code â€“ for instance, if fuzzing an HTTP server, an LLM could generate a variety of HTTP request packets with unusual headers to trigger parsing edge cases. These AI-crafted inputs are then incorporated into the fuzzersâ€™ corpus, after which libFuzzerâ€™s fast mutation engine takes over to refine and find a crashing payload<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a>. This human-inspired but machine-augmented approach improved <em>harness saturation time</em>, meaning the time to hit interesting code was reduced<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a>. Another AI aspect is <strong>multi-agent coordination</strong> for patching<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. Buttercupâ€™s architecture separates vulnerability detection from repair: one agent (or LLM prompt) can focus on understanding what the bug is and marking its location, while another focuses only on generating a fix in code<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a>. By dividing the task, they reduce the likelihood of one large model hallucinating or making a complex error. They also mention using <em>cheaper models that lack chain-of-thought reasoning</em><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[17]</a>; this implies they might use multiple simpler completions or a fine-tuned code model (like Codex or Code Llama) for tasks like patch generation, rather than an expensive generalist model. Impressively, Buttercup managed these AI resources to achieve the <strong>lowest cost-per-point</strong> among top teams â€“ \$181/point, indicating high efficiency<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[91]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Cost%20per%20point%20shows%20the,doesn%E2%80%99t%20require%20massive%20infrastructure%20investments">[95]</a>. In addition, an <em>AI crash analysis</em> component likely triaged fuzzer crashes: similar to others, Buttercup probably used an LLM to read sanitizer logs or stack traces and group crashes by root cause, filtering out false positives (like benign out-of-memory errors). This kind of AI filtering improves precision by automatically discarding non-security crashes, so the team only spends time patching real issues<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=progressive%20grammars%20based%20on%20a,categorize%2C%20and%20plan%20for%20patching">[96]</a> (Buttercup indeed scored high on accuracy).</p>
<p><strong>Performance &amp; Results:</strong> Buttercup finished as the <strong>runner-up (2nd place)</strong>, with <strong>28 vulnerabilities found and 19 patches applied</strong> in the finals<a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[23]</a>. Its total score (219 points) narrowly edged out Theori for the second spot<a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,6ug%207%20Lacrosse">[97]</a><a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[98]</a>. The breadth of bugs Buttercup found was remarkable: it successfully produced proof-of-vulnerabilities across <em>20 distinct <abbr title="CWE Common Weakness Enumeration">CWE</abbr> categories</em>, ranging from memory errors to injection flaws<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20challenged%20competitors%20to%20find,safety%20issues%20to%20injection%20flaws">[16]</a>. This earned them the <em>â€œCornucopiaâ€</em> achievement for diversity of CWEs<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[15]</a>. Moreover, Buttercup maintained \~90% accuracy, meaning very few of its submissions were incorrect or invalid<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=1,was%20not%20inserted%20into%20the">[99]</a>. The system even patched one challenge with a huge 300+ line fix, winning the quirky <em>â€œLOC Ness Monsterâ€</em> award<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[25]</a> â€“ demonstrating its ability to handle complex issues requiring substantial code changes. The teamâ€™s focus on correctness over sheer quantity likely contributed to their success over teams that found more bugs but lost points to bad patches (e.g. 42-b3yond). In terms of timeline, Buttercup was also quick â€“ it scored its first points in under 5 minutes on at least one task (achievement: <em>â€œFaster Than Pizza Deliveryâ€</em>, which actually went to FuzzingBrain<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a> but Buttercup also achieved a \&lt;5min score per their blog<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Digging%20more%20into%20the%20results,we%20learned%20that%20Buttercup%20also">[100]</a>). All these indicate a well-rounded performance. For documentation, Trail of Bits provided an excellent post-mortem blog post<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=On%20August%208%2C%202025%2C%20it,place%20finisher">[101]</a> detailing these insights and even an earlier â€œtale of the tapeâ€ analysis<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Enhancing%20traditional%20security%20tools%20with,AI">[3]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. Their open-source code is available on GitHub and is said to be runnable on a laptop<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=As%20a%20cybersecurity%20services%20company,run%20it%20on%20your%20laptop">[102]</a> â€“ illustrating their emphasis on practical, lightweight design.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> Buttercupâ€™s strength lies in <em>augmented automation</em> â€“ it took dependable techniques (fuzzing, static checks) and made them better with AI, rather than trying to reinvent the wheel entirely. This made it efficient and accurate. A key strength was resource management: using cheaper LLMs and fewer compute cycles but still achieving results. If thereâ€™s a weakness, it might be that Buttercup might miss bugs that require deep reasoning beyond input generation â€“ for instance, logic flaws or complex exploit scenarios that fuzzing canâ€™t easily uncover. Their reliance on simpler models might also limit some capabilities (they explicitly avoided â€œreasoningâ€ models, which might be less effective for patches that need creative insight, though their results show little evidence of struggle there). Another potential drawback is that by not submitting speculative patches, they may have left some points on the table â€“ Theoriâ€™s strategy of patching without PoV could find latent vulnerabilities, but Buttercup chose not to risk it. Nonetheless, their second place indicates this strategy was wise. In summary, Buttercup was an exemplary demonstration of <em>human-in-the-loop AI design</em>: it encoded a lot of security expertise and let AI handle the tedious or large-scale parts, leading to a very balanced system.</p>
<h3 id="software-aixcc-roboduck-theori-llm-first-autonomous-security-agent">RoboDuck (Theori) â€“ LLM-First Autonomous Security Agent<a class="headerlink" href="#software-aixcc-roboduck-theori-llm-first-autonomous-security-agent" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>RoboDuck</em> is Theoriâ€™s cyber reasoning system, notable for being <em>highly AI-centric</em>. The team explicitly set out with an <strong>â€œLLM-firstâ€ design philosophy</strong>, using large language models for <em>all aspects</em> of the challenge and only falling back on traditional techniques as a safety net<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=From%20the%20outset%2C%20team%20Theori,produce%20inputs%20or%20grammars%20to">[103]</a><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Although%20we%20have%20extensive%20experience,static%20analysis%20techniques%20available%20for">[104]</a>. This was a bold approach: unlike others that started from fuzzers or static analyzers, Theori treated the LLM as the primary engine driving bug discovery, exploit development, and patch writing. In fact, Theoriâ€™s blog mentions their CRS can produce working PoV exploits <strong>without using fuzzing or symbolic execution</strong> at all<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>, which is quite unique. They implemented a full pipeline of autonomous agents that read the code, reason about potential vulnerabilities, <em>generate an input to trigger each bug</em>, and then create a patch<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>. This means RoboDuck behaves almost like a team of virtual security researchers collaborating.</p>
<p>The system pipeline can be summarized as: <strong>Bug Finding â†’ Bug Filtering â†’ PoV Generation â†’ Patch Generation â†’ â€œScaffolding &amp; Glueâ€</strong> (integration)<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Contents">[105]</a>. For <em>bug finding</em>, RoboDuck actually does use a bit of traditional analysis: Theori leveraged <strong>Facebookâ€™s Infer</strong> static analyzer to find memory issues and null dereferences in C/C++ code<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20first%20step%20our%20system,performed%20by%20two%20different%20LLMs">[31]</a>. However, Inferâ€™s reports were extremely noisy (99.9% false positives in their workflow)<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=operation%20is%20safe,we%20fixed%20for%20our%20CRS">[106]</a>, so the LLM agents were tasked with reviewing Inferâ€™s output and deciding which reports likely represent real bugs<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=While%20only%20a%20piece%20of,shot%20LLM%20completions">[28]</a>. Separately, they employed two distinct LLM-based static analysis methods: one agent looked at code <strong>function-by-function</strong> to spot potential bugs, and another looked at larger <strong>â€œblobâ€ chunks of code</strong> (spanning multiple functions or files) to catch issues that manifest in broader context<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=engineering%20behind%20it,shot%20LLM%20completions">[107]</a>. This dual strategy was probably to mitigate LLM context window limits and vantage â€“ fine-grained vs. coarse-grained. After initial bug candidates were identified, a <strong>filtering agent</strong> would cross-check them to eliminate duplicates or those deemed non-exploitable.</p>
<p>For <em>PoV generation</em>, RoboDuck did something truly novel: it had <strong>LLM agents craft exploits (inputs) directly</strong> for the suspected bugs<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Theori%E2%80%99s%20LLM%20agents%20use%20semantic,insights%20inform%20traditional%20validation%20methods">[108]</a>. This is challenging because it requires the AI to understand how to trigger the bug in practice. Theoriâ€™s advantage was to treat this like a reverse engineering problem â€“ their agents would simulate the steps a human exploit developer might take, but entirely in code and memory space. They constrained the LLMs with what they call â€œreverse engineering workflowsâ€ to prevent the AI from going off-track<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a>. For example, an agent might perform these steps: <em>Read the vulnerable function; Identify what input parameters or file data influence the vulnerability; Then propose a concrete input that would hit the vulnerability.</em> If the vulnerability was, say, a buffer overflow when parsing a certain file format, the agent would try to produce a file in that format that overflows the buffer. Notably, Theori did <em>not</em> rely on random fuzzing to find the exact trigger â€“ they tried to reason it out with the modelâ€™s knowledge. This is where they saved a lot of the fuzzing budget that others spent; Theoriâ€™s LLM query spend (\~\<span class="arithmatex">\(11.5k) was half that of Buttercup, and they spent a moderate amount on compute (\~\\\)</span>20k), meaning they werenâ€™t running huge fuzzer farms<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[18]</a>. They did have fuzzing â€œavailable for backupâ€<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=From%20the%20outset%2C%20team%20Theori,produce%20inputs%20or%20grammars%20to">[103]</a> â€“ likely they still ran some fuzzers using existing harnesses to ensure that if the AI missed something, it could be caught. But the emphasis was clearly on AI.</p>
<p><em>Patch generation</em> in RoboDuck was done via (unsurprisingly) LLMs as well. Once an exploit and bug were confirmed, an agent would modify the code to fix the vulnerability, ensuring it doesnâ€™t break functionality. The blog implies most teams, including Theori, used similar high-level approaches for patching â€“ essentially instructing an LLM to produce a code diff that addresses the problem<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=assist%20existing%20techniques%20like%20fuzzing">[109]</a>. The interesting twist is Theoriâ€™s risk-taking on patches: they developed a model to decide when to submit patches without PoVs, implementing an aggressive <strong>2:1 patch to PoV ratio strategy</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=capabilities%20before%20the%20finals%20to,avoid%20accuracy%20penalties">[33]</a>. This means if RoboDuck thought a piece of code was buggy but couldnâ€™t immediately produce a PoV, it might still submit a speculative patch (but capped at two such speculative fixes for each confirmed bug). This was meant to maximize points under the scoring rules. It was a calculated risk, as bad patches hurt the accuracy multiplier, but Theori bet that their AI could identify real bugs even if it failed to exploit them in time â€“ a bet that seems to have paid off moderately well.</p>
<p><strong>Traditional Techniques:</strong> Although de-emphasized, Theoriâ€™s CRS did incorporate traditional methods in supporting roles. Weâ€™ve mentioned <strong>Infer</strong> static analysis for C/C++ bug hints<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20first%20step%20our%20system,performed%20by%20two%20different%20LLMs">[31]</a> â€“ they even patched some bugs in Infer itself to improve its output for AIxCCâ€™s needs<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=operation%20is%20safe,we%20fixed%20for%20our%20CRS">[106]</a>. They also mention using some <em>fuzzing and static analysis as backup</em><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=From%20the%20outset%2C%20team%20Theori,produce%20inputs%20or%20grammars%20to">[103]</a>. Specifically, they would run the standard <strong>OSS-Fuzz harnesses</strong> for each challenge with libFuzzer, mainly to ensure they didnâ€™t miss any crashes; but interestingly, Theori notes that no other system they know of can use LLMs at repository scale to generate inputs that <em>trigger</em> bugs, which RoboDuck did<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=here">[110]</a><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Although%20advances%20have%20been%20going,operates%20with%20zero%20human%20input">[111]</a>. This suggests that their fuzzers might not have been the primary source of PoVs. They likely also used sanitizers (ASan, UBSan) to catch memory violations when running either fuzzers or AI-generated tests, to know when a bug was triggered. The static analysis results were integrated via SARIF as well, since they had to assess provided static analyzer reports from the organizers â€“ Theori presumably leaned on their LLM to evaluate those too (the competition provided some SARIF that could be false positives, worth 1 point each if correctly assessed<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20AI%20Cyber%20Challenge%20asks,asked%20to%20submit%20their%20assessment">[2]</a>). On the exploit side, Theori did not explicitly mention any use of symbolic execution or concolic testing â€“ they appear to have consciously avoided those, focusing on LLM reasoning instead<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=of%20Vulnerability%20,trajectories%2C%20check%20out%20this%20post">[112]</a>. Finally, for patch testing, they likely did run the patched program against the PoV to verify it stops the crash (common to all teams). Theoriâ€™s approach to traditional tech can be seen as <em>â€œtrust the AI, use classical tools as verification.â€</em> Itâ€™s the inverse of teams like Lacrosse or 42-beyond, which trusted fuzzers and used AI as an assistant.</p>
<p><strong>AI-Based Techniques:</strong> RoboDuckâ€™s entire DNA is AI. The system uses multiple LLMs, possibly from different vendors (they referenced multi-LLM usage for static analysis)<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=engineering%20behind%20it,shot%20LLM%20completions">[107]</a>. A notable design choice: They used <em>two different LLMs in static bug finding</em>, which hints they might have used e.g. GPT-4 for one pass and Claude or a fine-tuned model for another, to get varied â€œopinionsâ€ on what code is risky<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=engineering%20behind%20it,shot%20LLM%20completions">[107]</a>. This is akin to having two experts review the code. The results of those were likely merged. The <em>agentic</em> aspect is key: Theoriâ€™s blog posts (and follow-up ones they published on their site) describe how they built effective LLM agents with constrained behavior<a href="https://x.com/theori_io/status/1955886400953589901#:~:text=Theori%20on%20X%3A%20,co%2FVF7MbwpViD%20Exploring%20Traces">[113]</a><a href="https://x.com/theori_io/status/1953978623360397373#:~:text=Theori%20on%20X%3A%20,Theori%20BLOG">[114]</a>. For example, they might use a pseudo-code interpreter or step-by-step prompting to force the agent to reason systematically about an exploit (â€œIf the buffer is of size N and input length is M, choose M = N+1 to overflowâ€¦â€). They also mention preventing the AI from â€œwanderingâ€ by constraining workflows<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a> â€“ perhaps by breaking tasks into smaller prompts or using guardrail code to stop nonsense actions.</p>
<p>One major advantage of AI they exploited was handling <em>complex input formats</em>. Traditional fuzzers often struggle to generate inputs that are valid enough to pass basic parsing (e.g., a correct image file header). Theoriâ€™s agents, with their knowledge base, could generate syntactically correct and semantically plausible inputs for these formats<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Theori%E2%80%99s%20LLM%20agents%20use%20semantic,insights%20inform%20traditional%20validation%20methods">[108]</a>. For instance, if the target was an XML parser, an AI can produce a well-structured XML that still triggers a bug deep inside â€“ something a dumb fuzzer might not achieve quickly. The AIâ€™s capability to understand protocols (like a well-formed URL or PDF) was a differentiator for RoboDuck<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Theori%E2%80%99s%20LLM%20agents%20use%20semantic,insights%20inform%20traditional%20validation%20methods">[108]</a>. Additionally, Theori built an entire public <em>GitHub repository (theori-io/aixcc-public)</em> with logs and agent traces for transparency<a href="https://github.com/theori-io/aixcc-public#:~:text=theori,with%20a%20viewable%20interface">[115]</a>, implying confidence in their AI agent approach and a desire to analyze it post-competition.</p>
<p><strong>Performance &amp; Results:</strong> RoboDuck placed <strong>3rd in the final competition</strong>. It found <strong>34 vulnerabilities</strong> and patched <strong>20</strong> of them<a href="https://aicyberchallenge.com/#:~:text=Theori%20%E2%80%94%E2%80%94,20%20Total%20Score%20%E2%86%92%20211">[34]</a>, for a total score of 211 points. This was just slightly behind Trail of Bitsâ€™ 219 points, a very close race for second. Theoriâ€™s system had a strong showing in vulnerability finding â€“ it actually found the second-most vulns after Team Atlanta. Its patch count was a bit lower proportionally (perhaps due to their riskier patch strategy or some speculative patches not yielding points). Still, they demonstrated the viability of an AI-heavy approach. The stats also reveal Theori used about half the LLM budget of the top two teams but achieved \~95% of their scores<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Each%20AIxCC%20team%20was%20given,two%20winners%20on%20LLM%20queries">[36]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>, indicating good efficiency. Achievements Theori earned include <em>â€œThriftyâ€</em> (they had the least dollars spent per vuln patched among teams)<a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[116]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a> â€“ a testament to their economical use of AI and compute. They also got <em>â€œSecret Sauceâ€</em> for submitting a unique PoV that no one else did<a href="https://aicyberchallenge.com/#:~:text=,else%20submitted%20a%20POV%20for">[117]</a>, likely attributable to their creative AI-driven exploit generation finding a scenario others missed. Theori didnâ€™t snag the SARIF or speed trophies, implying their approach was potent but perhaps a bit slower early on or not as focused on static warnings (understandable since they had so many false positives to filter through Infer). Documentation from Theori is extensive: they published multiple blog posts (overview, LLM agent design, agent trajectory examples) sharing their methodology<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=AI%20Cyber%20Challenge%20and%20Theori%27s,RoboDuck">[118]</a><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>, and their code (though somewhat curated) is on GitHub.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> The strength of RoboDuck is clear â€“ it showed that <strong>AI agents can perform end-to-end hacking tasks</strong> with minimal human intervention. This is a preview of what AI-driven security might become. It excelled at complex logical reasoning tasks (like exploit generation for tricky formats) and wasnâ€™t limited by needing an instrumented harness for everything â€“ a smart agent can find a bug in any part of the code. Additionally, it achieved a lot with fewer resources (cost-effective). However, the weaknesses are the flip side: an LLM-first system can be unpredictable. Theori themselves likely struggled with managing the â€œcreativityâ€ of the AI â€“ hence the need to babysit and constrain it<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L221%20L3,Jack">[119]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L253%20improvements,agent%20specifically%20for%20this%20task">[45]</a>. When their AI agents were right, they were brilliant; when they were wrong, valuable time could be wasted chasing phantom bugs or formulating a PoV that doesnâ€™t quite work. Another weakness was patch accuracy: by pushing more speculative fixes, they risked penalties. If their AI misjudged a bug and patched something incorrectly, that would hurt their score multiplier (though they evidently balanced this with the 2:1 model). In finals, Theoriâ€™s accuracy multiplier was a bit lower than teams like ToB or Shellphish (since they submitted some patches without proof)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>. But Theoriâ€™s daring approach clearly paid dividends, and it underscores how far pure AI reasoning has come â€“ nearly matching a top security firmâ€™s tool with half the bug-finding being done by classical fuzzers.</p>
<h3 id="software-aixcc-all-you-need-is-a-fuzzing-brain-massively-scaled-ai-system">All You Need is a Fuzzing Brain â€“ Massively Scaled AI System<a class="headerlink" href="#software-aixcc-all-you-need-is-a-fuzzing-brain-massively-scaled-ai-system" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>All You Need is a Fuzzing Brain</em> (often shortened to <em>FuzzingBrain</em>) was the most <strong>AI-forward</strong> system among the finalists<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>. This team treated the CRS as a large-scale AI orchestration problem. According to Trail of Bitsâ€™ analysis, FuzzingBrain used <em>thousands of concurrent AI agents in parallel</em> to reason about vulnerabilities, essentially brute-forcing the unreliability of individual LLMs by sheer quantity and diversity<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. In other words, instead of one very smart agent, they had many â€œpretty smartâ€ agents trying different approaches simultaneously. The team integrated these agents with an underlying fuzzing platform â€“ the name suggests a focus on fuzzing, and indeed they did have traditional fuzzers in the loop, but in a secondary role. The architecture likely involved an AI <strong>coordinator</strong> that would spin up subtasks (like analyzing a particular source file or function) and assign them to AI workers. These workers might generate possible inputs or identify suspect code paths. Then, some of those hypotheses would be validated either by running the program or by cross-checking with other agents.</p>
<p>The teamâ€™s emphasis on AI is highlighted by the claim that <strong>90% of their entire codebase was written using AI assistance</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>. This is a fascinating detail: they apparently dogfooded AI to even build their CRS (e.g., using Copilot or ChatGPT to generate large chunks of their code). It implies the team culture was to lean into AI at every opportunity. They also gave the AI high-level strategic roles â€“ for instance, using AI for â€œsystem architecture and decision-makingâ€<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a>. Possibly, they had an agent monitoring the performance of various components and re-balancing resources (maybe deciding to allocate more CPUs to fuzzing vs. static analysis on the fly, based on AI suggestions).</p>
<p>Despite the AI-heavy design, the system did incorporate fuzzing â€“ after all, itâ€™s in their name. Achievements show they won <em>â€œSARIF Masteryâ€</em> for high accuracy on static analysis reports<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>, and <em>â€œ-OFastâ€</em> for being first to find a real (non-seeded) C vulnerability<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a> (which suggests they had a very fast detection on at least one target, possibly via static analysis or a quick AI insight). They also scored early in tasks (â€œFaster than Pizza Deliveryâ€)<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>, indicating a fast pipeline in some cases. The core idea was likely: throw a <strong>large swarm of AI agents</strong> at the code, have them propose potential bugs (with reasoning), then use <em>fuzzers to verify</em> those that need confirmation. This flips the typical approach â€“ here AI is finding bugs and fuzzing is double-checking, rather than fuzzing finding and AI triaging. Given that they placed mid-pack, this approach had mixed success, but itâ€™s noteworthy.</p>
<p><strong>Traditional Techniques:</strong> FuzzingBrain did not entirely discard traditional methods. It sounds like they still ran fuzzers and other analyses when appropriate, but perhaps triggered by AI. For example, if an AI agent flagged a function as vulnerable (say, a buffer copy with no bounds checking), they might then launch a focused fuzzing campaign on that function or module to produce a concrete crash (or use a directed fuzzing mode). They presumably used the <strong>OSS-Fuzz harnesses</strong> for targets where available, similar to others, but possibly under the guidance of the AI (e.g., picking which harness to prioritize). Because they got the SARIF accuracy award, they clearly processed the static analyzer outputs given by the organizers very effectively<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. This likely involved a classical component: maybe they wrote a script to filter out SARIF warnings that didnâ€™t correlate to any dynamic findings, or they used AI to decide which SARIF entries to mark true/false. But an 80%+ accuracy on SARIF suggests a systematic method, since random guessing would be worse. They might have cross-referenced SARIF with code context using an LLM, which is semi-traditional (static analysis result + AI).</p>
<p>On fuzzing, they likely used a variety of fuzzers (AFL++, libFuzzer, etc.), given their team composition might include academic fuzzing experts. They didnâ€™t win any achievements for huge fuzzing scale or such, so their fuzz infrastructure might have been modest (especially compared to Team Atlanta or 42-beyond). Instead, they applied fuzzing more tactically as a backup. For patching, not much is published, but presumably they did similar to others: prompt an LLM to fix the code, perhaps with multiple agents voting (since they like scale, they could generate multiple patch candidates with different LLMs or prompts and choose the best). Thereâ€™s mention in ToBâ€™s blog that FuzzingBrainâ€™s patching was largely AI-driven with minimal validation â€“ since they prioritized speed (score quickly) sometimes at expense of mistakes, their cost per point was relatively high ($490) and accuracy might have suffered<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>. However, they avoided catastrophic failures and ended in 4th place, which is respectable for a newer team.</p>
<p><strong>AI-Based Techniques:</strong> This team embraced <em>AI at scale</em>. If Shellphish used 60 agents, FuzzingBrain used <strong>â€œthousandsâ€</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. They leveraged model <strong>diversity</strong> â€“ running different types of models in parallel. This could mean using different prompts or even entirely different AI systems (OpenAI vs. Anthropic vs. open-source models) concurrently, under the theory that what one model misses, another might catch. The phrase â€œovercome AI unreliability through scale and model diversityâ€<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a> directly implies that by sheer volume of agents, the systemâ€™s overall output becomes robust (the wisdom of crowds, but for AIs). This is an intriguing strategy: if one has the budget to do thousands of LLM calls in parallel, one can then filter their outputs for the best ones. Indeed, they had agents whose job was likely to <em>evaluate the outputs of other agents</em> â€“ a hierarchy where some AI judges othersâ€™ findings (maybe by cross-checking with program semantics or known bug patterns). The result was that <strong>\~90% of their PoVs came from direct AI reasoning</strong> (not fuzzers)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. In cases where those AI-born PoVs failed or were uncertain, only then did they turn on traditional fuzzing as a â€œfallback validation mechanismâ€<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>. That indicates extreme reliance on AI.</p>
<p>Additionally, the team might have used <strong>reinforcement learning or planning</strong> for their AI agents. The name itself is a play on â€œAll you need is a <em>brain</em>â€ â€“ possibly they attempted some brain-like global strategy (maybe a central AI that learned which agents to trust). Itâ€™s known one team in finals (Team Atlanta) fine-tuned models; itâ€™s possible FuzzingBrain also fine-tuned or trained a custom model, but no evidence here. Instead, they likely leveraged existing APIs heavily. Their large compute spend (\<span class="arithmatex">\(63k, second highest) and significant LLM spend (\\\)</span>12k)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a> show they poured resources into this massive parallel AI approach. They actually had the <em>highest cost per point</em> among top teams<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a>, suggesting a bit of inefficiency â€“ the AI swarm found a lot but also wasted effort on false leads, it seems. Documentation on their methods is scarce (no public blog from them as of writing), but one can infer they were testing the limits of how far multi-agent AI can go in this domain.</p>
<p><strong>Performance &amp; Results:</strong> FuzzingBrain secured <strong>4th place</strong>, finding <strong>28 vulnerabilities</strong> and patching <strong>14</strong><a href="https://aicyberchallenge.com/#:~:text=ALL%20YOU%20NEED%20IS%20A,14%20Total%20Score%20%E2%86%92%20154">[40]</a>, for a score of 154. This put them just behind the top three, and notably ahead of Shellphish and others in total points<a href="https://aicyberchallenge.com/#:~:text=2%20Trail%20of%20Bits%203,6ug%207%20Lacrosse">[121]</a><a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,6ug%207%20Lacrosse">[122]</a>. The performance indicates their approach was effective at discovering bugs â€“ tying Shellphish in finds and even Theori (28 vs 34, not far off). Their patch count was moderate; some patches likely failed or they didnâ€™t patch everything they found. The fact that they scored lower suggests either slower patching or accuracy penalties. Indeed, their cost per point and anecdotal evidence imply they may have submitted some incorrect patches that hurt their multiplier (though they didnâ€™t come last in patch points by any means). However, their notable achievements show strength in specific areas: They were the <strong>fastest</strong> to score on at least one challenge (the â€œpizzaâ€ speed achievement) and excelled at the static analysis portion with <strong>SARIF Mastery (&gt;=80% accuracy)</strong><a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. The first-to-find real vuln (-OFast) award indicates a keen eye for an actual bug (maybe found by an AI reading source code before any fuzzer could even compile the program)<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. These honors underscore that a swarming AI can outpace and outperform some manual or traditional methods, at least initially. The trade-off was possibly coordination and focus â€“ more isnâ€™t always better if it floods the system with noise. But overall, their 4th-place finish as a likely independent or new team (the name suggests perhaps a group of students or researchers) is impressive. The teamâ€™s code is on GitHub under an organization o2lab<a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=o2lab%20%20%20%20%2F,53%20%20Public">[123]</a>, hinting they might be an academic lab (perhaps at Northwestern or another university, since one search result connected a Wang Xuezhen with this team). The repository contains directories for crs, cp_config, etc., and even a proprietary folder<a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=cp_config">[124]</a><a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=mock_crs">[125]</a>, which suggests some components (perhaps the LLM models or data) were not fully open-sourced or are placeholders.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> The clear strength of FuzzingBrain was <em>mass parallelism and AI depth</em>. It essentially brute-forced the problem with AI, leveraging a â€œmore is moreâ€ philosophy. This likely uncovered some non-obvious bugs quickly and provided resilience (if one agent got stuck, another completely different approach was also running). It also allowed them to be extremely AI-centric without being derailed by one modelâ€™s quirks â€“ consensus or majority voting among agents could surface correct answers. The approachâ€™s weakness is efficiency and coherence. Running so many agents risks duplicating work and requires very good aggregation logic to make sense of their outputs. The high cost per point suggests a lot of wasted cycles on fruitless inquiries<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a>. Also, managing thousands of AIs is complex; perhaps the integration and debugging of such a system is difficult, and timing issues or race conditions could occur. In the final scoring, they did well but not enough to beat more targeted approaches â€“ indicating that while you can throw AIs at the wall to see what sticks, a clever strategy (like Team Atlantaâ€™s multi-engine or ToBâ€™s guided fuzzing) can still have an edge. In terms of documentation, FuzzingBrain is less visible; they might share insights later, but currently we rely on the observations of others for their description. In summary, All You Need is a Fuzzing Brain demonstrated the power of <strong>massively parallel AI</strong> in cybersecurity, achieving solid results but at great expense â€“ a classic time vs. money vs. reliability trade-off.</p>
<h3 id="software-aixcc-artiphishell-shellphish-academic-multi-agent-system">Artiphishell (Shellphish) â€“ Academic Multi-Agent System<a class="headerlink" href="#software-aixcc-artiphishell-shellphish-academic-multi-agent-system" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>ARTIPHISHELL</em>, by the veteran hacking team Shellphish, is an <strong>agent-based CRS</strong> where a large number of specialized AI agents collaborate to find and fix bugs<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>. Over 60 independent AI agents were programmed, each with distinct roles (hence the name a pun on â€œartificial shellphishâ€)<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>. This architecture draws on Shellphishâ€™s extensive experience building automated hacking systems (they competed in the original 2016 DARPA Cyber Grand Challenge). The ethos was to decompose the immense task of securing a codebase into smaller subtasks, handled by <em>expert agents</em>. For example, one agent (nicknamed â€œGrammar Guyâ€) focused on inferring input grammars and generating complex test inputs<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>, another might focus on monitoring program telemetry or feedback, another on generating patches for memory errors, and so on. This way, Artiphishellâ€™s design mimics a team of hackers with different specialties working together â€“ but automated.</p>
<p>Shellphishâ€™s CRS heavily emphasizes <strong>autonomy and scale</strong>. They wanted minimal human intervention; once deployed, the agents communicate and iterate on their own. They set up extensive <em>telemetry logging</em> and monitoring of the AI decisions (even earning the â€œBest Telemetryâ€ award)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>, which suggests they instrumented their CRS to record agent actions, LLM prompts, responses, etc., both for debugging and perhaps for scoring bonus (if they shared useful data with DARPA). Being an academic team, Shellphish likely experimented with various approaches: fuzzing, concolic execution (their open-source angr framework is for symbolic execution), static analysis (their members have research in that area too), and integrated LLMs on top. The repository indicates a complex infrastructure (with Azure deployment scripts, etc.)<a href="https://github.com/shellphish/artiphishell#:~:text=5,Application">[126]</a><a href="https://github.com/shellphish/artiphishell#:~:text=Development">[127]</a>, and environment variables for multiple AI APIs<a href="https://github.com/shellphish/artiphishell#:~:text=Configure%20LLM%20Secrets">[43]</a>. The multi-agent approach was validated by their professors: quotes show they view this architecture as a representation of â€œhow much AI has changed the way we attack difficult problemsâ€<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=Added%20Vigna%2C%20%E2%80%9COur%20AI%20system,%E2%80%9D">[128]</a><a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=Over%20the%20past%20two%20years%2C,exploited%20by%20malicious%20threat%20actors">[129]</a>.</p>
<p><strong>Traditional Techniques:</strong> Shellphish has a pedigree in program analysis, so Artiphishell certainly didnâ€™t ditch those methods. They augmented <strong>fuzzing</strong> significantly through AI. The â€œGrammar Guyâ€ subsystem is essentially a smart fuzzing assistant: it uses LLMs to generate input grammars and progressively refine them based on coverage feedback<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. This means Artiphishell did run fuzzers (likely AFL or libFuzzer or their own legacy fuzzers from CGC days), but instead of relying on random mutations, they had grammar rules to produce more structured inputs (e.g., if testing a SQL parser, Grammar Guy might learn the SQL syntax and feed fuzzing with valid but tricky SQL queries). According to ToB, this <em>grammar-based fuzzing approach significantly increased their bug-finding capability</em> for complex formats<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>, at the cost of a large portion of their LLM budget (likely a worthy trade-off). Aside from fuzzing, Shellphish historically use symbolic execution; itâ€™s not confirmed, but they possibly integrated their <strong>angr</strong> framework to systematically explore some code paths or to solve inputs for certain conditions, with AI guiding the target selection. They also likely used <em>static analysis tools</em>, perhaps parsing the code with their own tools or open-source analyzers to supply hints to the agents.</p>
<p>For exploitation (PoVs), Shellphishâ€™s strategy was somewhat middle-ground. They did manage to create at least one enormous PoV payload (earning â€œThe Limit Does Not Existâ€ for &gt;1MB exploit)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[48]</a>, meaning they had the capability to generate complex exploits. Itâ€™s possible they used some concolic or brute-force method to build that payload, or an agent just concatenated a huge input together to overwhelm something. Patching-wise, Shellphish took a <strong>conservative approach</strong> like Trail of Bits and Team Atlanta: they only submitted patches when they had a corresponding PoV to prove the fix<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a>. In fact, they boasted one of the highest patch accuracies â€“ over 95% of their patches were correct<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>. This indicates they avoided speculative fixes and carefully validated each patch (likely by rerunning all known PoVs on the patched program as part of their pipeline). As a result, they may have left some vulnerabilities unpatched if they couldnâ€™t reliably confirm a fix in time, which might have limited their score, but it kept their penalties minimal.</p>
<p><strong>AI-Based Techniques:</strong> Artiphishellâ€™s multi-agent system employed a variety of LLMs â€“ as evidenced by environment keys for OpenAI, Anthropic, and Gemini (Google) models<a href="https://github.com/shellphish/artiphishell#:~:text=Configure%20LLM%20Secrets">[43]</a>. This suggests they dynamically chose models for tasks: perhaps using GPT-4 for complex reasoning, Claude for long-text analysis, and Gemini (PaLM) for code generation, etc., exploiting each modelâ€™s strengths. Over 60 AI agents implies a <strong>wide range of AI roles</strong>. Some hypothesized roles: code summarizer agents (to distill large code into manageable chunks for others), vulnerability hypothesis agents (scanning for common bug patterns), exploit agents (like a simplified version of what Theori did, but maybe not as central), patch agents (given a location and bug type, draft a code change), verification agents (review a patch diff to ensure it addresses the bug and doesnâ€™t introduce others), and coordination agents (deciding which agent should work on what). They likely implemented a message-passing or blackboard system for agents to share information, which is non-trivial engineering. Given the â€œwe had to babysit LLMsâ€ comment referenced at DEF CON by a member<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L3,Jack">[130]</a>, Shellphish found that you canâ€™t just let 60 agents run wild â€“ you need oversight logic. They possibly had a scheduler that monitored agent outputs and killed or re-assigned tasks if an agent got stuck or hallucinated too much.</p>
<p>One specifically cited agent, <strong>Grammar Guy</strong>, was a standout AI feature<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. This agent would generate grammar rules (likely in a format like ANTLR or a simple BNF) to describe input formats of targets, then evolve them. For example, if fuzzing found some new code coverage when sending \&lt;script&gt; tags, Grammar Guy might infer that the input is HTML-like and add more HTML grammar rules. Over time, the inputs get more sophisticated, allowing fuzzers to explore deeper states of the program. This is a clever synergy of AI with fuzzing: the AI provides intuition on input structure (like a human writing a grammar for Peach fuzzer), but automatically. Shellphish also built agents for <em>telemetry</em>, which implies some AI(s) were summarizing what the system was doing in human-readable form or detecting anomalies (they reported LLM and CRS activity to organizers, possibly for that Best Telemetry award)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>.</p>
<p>In terms of heavy AI usage, Shellphishâ€™s LLM budget was actually relatively low (\~\<span class="arithmatex">\(2.9k, lowest among finalists) and their compute was high (\~\\\)</span>54.9k)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Theori%2411.5k%2420.3k%2431.8k%24151%20fuzzing_brain%2412.2k%2463.2k%2475.4k%24490%20Shellphish%242.9k%2454.9k%2457.8k%24425%2042">[131]</a>. This suggests they self-hosted a lot of models (compute cost) or relied more on local analysis than API calls. Maybe they ran some open models on GPUs for cheaper per-query cost, or they used smaller models extensively which cost less per call. The multi-agent approach might have emphasized many shallow AI tasks (which might align with using smaller models in parallel rather than a few giant model calls). Their â€œHunger for Knowledgeâ€ achievement about 1K+ LLM requests/minute actually went to 42-beyond, not Shellphish<a href="https://aicyberchallenge.com/#:~:text=,Knowledge%20%2F%2F%2F%201K%2B%20LLM%20requests%2Fmin">[132]</a>, so Shellphish wasnâ€™t spamming external APIs as heavily. Instead, they might have had optimized uses or local instances.</p>
<p><strong>Performance &amp; Results:</strong> Artiphishell finished <strong>5th place</strong>, with <strong>28 bugs found and 11 patches applied</strong><a href="https://aicyberchallenge.com/#:~:text=Shellphish%20%E2%80%94%E2%80%94,11%20Total%20Score%20%E2%86%92%20136">[47]</a>, totaling 136 points. The placement belies the sophistication of their system â€“ they clearly built something advanced and it did successfully operate (finding and fixing a good number of issues), but it didnâ€™t score as high as expected. There are a few possible reasons: one, they may have <strong>focused on quality over quantity</strong>, given their very high patch accuracy (they won <em>â€œThe Doctor is Inâ€</em> for patch success &gt;95%)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>. That means they likely passed on patching some bugs they werenâ€™t sure about, costing them potential points but avoiding penalties. Two, multi-agent coordination overhead might have slowed them down; they found as many bugs as Theori and FuzzingBrain (28 vs 34/28), but patched significantly fewer. This suggests maybe their patch pipeline was a bottleneck or some agents underperformed. For example, itâ€™s possible they identified many crashes but couldnâ€™t develop PoVs for all (since they wouldnâ€™t patch without PoV). If an exploit agent fails to deliver, those bugs remain unpatched and earn minimal points (just SARIF maybe). The scoreboard shows Shellphishâ€™s PoV count was decent but patch count lagged.</p>
<p>However, Shellphish still had notable accomplishments. They handled at least one scenario requiring an enormous input (1MB+ PoV)<a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[48]</a> â€“ maybe an AI agent decided to flood an input to trigger a worst-case behavior or memory issue, which worked. They also had a telemetric insight into their system which presumably helped them debug and iterate on it quickly. Their 5th place came with a significant points gap below 4th, but a <em>huge</em> gap above 6th (136 vs 105), showing they were clearly more effective than the bottom two teams. As an academic team, the knowledge gained might be as important; indeed, their mentors considered the breakthroughs and learning itself a reward<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=%E2%80%9CAs%20the%20competition%20is%20coming,and%20the%20lifelong%20bonds%20such">[133]</a>. Documentation on Artiphishell is currently limited â€“ the UCSB news piece provides a high-level view<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>, and a DEF CON talk was given by team members (CTF Radio podcast) shedding more technical light, including some post-mortem analysis via an X/Twitter thread<a href="https://x.com/wenboguo4#:~:text=Wenbo%20Guo%20,is%20not%20very%20well">[134]</a>. The code is open on GitHub, though it may not include all private data (thereâ€™s mention of a private wiki and CI system)<a href="https://github.com/shellphish/artiphishell#:~:text=Development">[127]</a>.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> Artiphishellâ€™s main strength is its <em>comprehensive AI-agent ecosystem</em>. It attempted to emulate a full cybersecurity team with AI, which likely made it very flexible â€“ it could handle many different types of challenges (any language, any bug type) by delegating to appropriate agents. Its integration of grammar-based fuzzing was cutting-edge and gave it an edge in handling complex input software (like those requiring well-formed inputs)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a>. Additionally, Shellphishâ€™s cautious approach to patching meant their systemâ€™s outputs were highly reliable (a valuable trait outside competition). On the flip side, the complexity of managing 60+ agents is a weakness â€“ overhead and inter-agent communication can slow things down or cause failures if not perfectly tuned. Indeed, team members mentioned having to babysit the AI (keeping the â€œJack-Jackâ€ multi-powerful LLM under control)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L3,Jack">[130]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L231%20Like%20Jack,even%20researchers%20from%20Google%20DeepMind">[135]</a>. Another weakness is that a multi-agent system can sometimes have blind spots if agents donâ€™t share info effectively; e.g., an exploit agent might not realize another agent already explored a path, etc. This could lead to duplicate work or missed optimizations. Shellphishâ€™s lower LLM usage suggests they might have under-utilized some AI potential, relying more on internal logic â€“ possibly a deliberate cost-saving measure, but it may have limited the raw power available compared to others who spent more. In conclusion, Artiphishell was an ambitious melding of classic hacking techniques with AI teamwork. It didnâ€™t top the scoreboard, but it validated the multi-agent approach and no doubt provided numerous insights (and future research directions) to its creators. The tool is available for the community, and given Shellphishâ€™s academic roots, we may see research papers or open data coming from this effort in the future.</p>
<h3 id="software-aixcc-bug-buster-42b3yond6ug-scalable-fuzzing-with-ai-scheduling-and-super-patching">Bug Buster (42â€b3yondâ€6ug) â€“ Scalable Fuzzing with AI Scheduling and Super-Patching<a class="headerlink" href="#software-aixcc-bug-buster-42b3yond6ug-scalable-fuzzing-with-ai-scheduling-and-super-patching" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>Bug Buster</em>, by team 42-b3yond-6ug (a team of academics from Northwestern and others<a href="https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402#:~:text=AI%20Security%20Tools%20%E2%80%94%20August,to%20Uncover%20Hidden%20Cache">[136]</a><a href="https://arpa-h.gov/news-and-events/arpa-h-join-darpa-announcing-ai-cyber-challenge-winners-def-con-33#:~:text=...%20arpa,and%20professors%20from%20five">[137]</a>), built a CRS optimized for <strong>massive scale fuzzing</strong> and clever patching techniques. Their philosophy leaned on proven methods like fuzz testing and then amplified them using AI. They put significant effort into scaling out fuzzing infrastructure: their system ran <em>three parallel fuzzing pipelines</em> during the semifinal and continued to expand, ultimately coordinating up to \~2000 fuzzing instances cluster-wide in the finals<a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[56]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[138]</a>. This was orchestrated via a custom scheduler named <strong>BandFuzz</strong>, which employed reinforcement learning (RL) to allocate resources to fuzzers in real-time<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[139]</a>. Essentially, BandFuzz would monitor which fuzzers were yielding coverage or crashes and dynamically decide which fuzzing jobs to prioritize or spawn next, learning optimal scheduling policies. The teamâ€™s prior research on BandFuzz even won a fuzzing competition, indicating that part of their system was state-of-the-art in fuzz management<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a>.</p>
<p>Apart from raw fuzzing power, 42-b3yond integrated <em>static program analysis</em> to guide their efforts. One key tool was a <strong>program slicer</strong> â€“ a static analysis that can narrow down which parts of the code influence a certain point (like a crash point or a target variable)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=One%20of%20our%20key%20tools,in%20the%20new%20C23%20syntax">[140]</a>. They used slicing to map out paths to target locations (e.g., to focus fuzzing on code that leads to a potential bug). However, during the competition, this slicer ran into issues (written for LLVM 14, it broke on C23 code)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=One%20of%20our%20key%20tools,in%20the%20new%20C23%20syntax">[141]</a>, which hampered their Round 1 performance and occupied developers with porting efforts unsuccessfully<a href="https://www.whexy.com/en/posts/aixcc#:~:text=One%20of%20our%20key%20tools,in%20the%20new%20C23%20syntax">[141]</a>. This anecdote shows the risk of relying on certain tools that might not scale to new languages or standards â€“ a valuable lesson they learned.</p>
<p>Another highlight of Bug Busterâ€™s approach is what they called <strong>â€œsuper patches.â€</strong> Instead of patching each bug individually, they attempted to create patches that <strong>fix multiple vulnerabilities at once</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>. The system could detect when different crashes actually stemmed from the same root cause, or even if unrelated bugs could be solved by one general hardening change<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>. For example, if two different out-of-bounds crashes in code could both be prevented by adding an array bounds check in one location, theyâ€™d deploy a single patch for both. This turned accuracy penalties on their head â€“ a patch that fixes two bugs yields double benefit with one potential penalty. Itâ€™s a creative tactic: by â€œholisticallyâ€ addressing issues, they aimed to maximize the patch score multiplier. Itâ€™s unclear how often this succeeded, but it was innovative enough to impress other teams<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Aggressive%3A%20Theori%20developed%20a%20mathematical,based%20patch">[142]</a>. It likely involved AI assistance to generalize a fix and recognize patterns among crashes.</p>
<p><strong>Traditional Techniques:</strong> 42-b3yond-6ugâ€™s foundation was <em>fuzzing</em>. They used established fuzzers (probably AFL++, libFuzzer, and possibly others like Honggfuzz) in large numbers. They mention <em>kernel fuzzing</em> and <em>directed fuzzing</em> as separate efforts in their narrative<a href="https://www.whexy.com/en/posts/aixcc#:~:text=integration">[53]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[143]</a>, so they even attempted to fuzz an OS kernel (they found a Linux kernel bug in semifinals) â€“ thatâ€™s ambitious given kernel fuzzingâ€™s complexity. They also wrote <em>CodeQL queries</em> (a static analysis query language) to find vulnerabilities in source code quickly (the blog says â€œeveryone was writing CodeQLâ€ during development)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=integration">[53]</a>, meaning they automated searches for known bug patterns (like spotting suspicious uses of functions, integer overflow patterns, etc.). Additionally, they implemented <em>triaging pipelines</em>: when fuzzers found crashes, their system automatically triaged them (by reproducing the crash, deduplicating it, classifying it by type). This is where they integrated with SARIF (static analysis reports) and other data â€“ they had a SARIF integration to validate static warnings, matching them with dynamic evidence of a bug<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a>.</p>
<p>They also took reliability seriously: their story recounts how in semifinals many components crashed but their system had backups and â€œabsorbed the hitsâ€<a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[56]</a>. This resilience came from redundancy â€“ e.g., three independent fuzzing pipelines means if one fuzzer process dies, two others are still running. They also logged component status in a key-value store (KV cache) to recover state if something failed<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Here%E2%80%99s%20where%20a%20bit%20of,They%20all%20works%20fine">[144]</a>. They had to address scaling issues, like their seed synchronization service bottlenecking when 2000 fuzzers generated new inputs too quickly<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Our%20program%20slicer%20crashed%20again,three%20people%20stuck%20on%20it">[145]</a>. They solved it via a MapReduce style approach to distribute the syncing load<a href="https://www.whexy.com/en/posts/aixcc#:~:text=So%20we%20redesigned%20the%20whole,query%20fetched%20only%20distinct%20seeds">[146]</a>. This level of engineering shows strong software development to handle large workloads, arguably more so than AI specialization. For patching, beyond the super patch idea, they likely used typical methods of running regression tests and cross-testing PoVs with patches to ensure fixes worked (though anecdotally a late bug in their patch component cost them â€“ more below).</p>
<p><strong>AI-Based Techniques:</strong> Bug Buster integrated AI in a few focused ways instead of everywhere. One was the <strong>BandFuzz RL scheduler</strong> â€“ this was essentially applying reinforcement learning to maximize fuzzing output (coverage/crashes)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a>. The RL agent would consider the â€œstateâ€ (maybe which programs or which seeds have yielded results) and allocate â€œactionsâ€ (which target to fuzz next, or which seed to mutate) to maximize reward (new coverage or crashes). They found this outperformed static scheduling in fuzzing competitions<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a>. Another AI use was <strong>seed generation via LLMs</strong>. They mention training an â€œLLM seed generatorâ€ and writing a paper on it (which got initially rejected)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=integration">[53]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=Not%20long%20after%20we%20made,%E2%80%9D">[147]</a>. This tool presumably uses an LLM to suggest initial seeds for fuzzers â€“ similar in spirit to what Buttercup did, but possibly with a custom model trained for it. It might generate inputs especially for structured formats. The fact a student spent two months writing a paper on it shows they had a dedicated AI component for it, which might have been key in early bug findings.</p>
<p>For patching, their concept of <strong>â€œsuper patchesâ€</strong> likely involved AI help. Recognizing that two crashes relate might be done via static analysis clustering, but coming up with a single fix that addresses multiple issues without regression is tricky. It sounds like an LLM could have been asked: â€œGiven these two crash locations, is there a single code change that would prevent both?â€ â€“ a task requiring semantic understanding. The Trail of Bits blog confirms they had an LLM-based patching process to do this multi-bug fix<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a>. If it worked, it could yield big points, but if it backfired (fixes one bug but not fully, or introduces new issues), it could hurt.</p>
<p>Additionally, they used AI for crash analysis: after generating a crash, an LLM could turn the raw data (addresses, dumps) into a structured description, which they call vulnerability objects (like a JSON with type of bug, location, etc.)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. This would help in triaging and planning patches. They might also have used LLMs to assist writing CodeQL queries or to translate static analysis results, though not explicitly stated. Interestingly, 42-b3yondâ€™s LLM budget was minimal (\<span class="arithmatex">\(1.1k) while their compute was high (\\\)</span>38k)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Theori%2411.5k%2420.3k%2431.8k%24151%20fuzzing_brain%2412.2k%2463.2k%2475.4k%24490%20Shellphish%242.9k%2454.9k%2457.8k%24425%2042">[131]</a>. This suggests they ran AI mostly on-premise or used open models. Indeed, they hammered some local model with 1000+ requests/minute (earning â€œHunger for Knowledgeâ€)<a href="https://aicyberchallenge.com/#:~:text=,Knowledge%20%2F%2F%2F%201K%2B%20LLM%20requests%2Fmin">[132]</a>, which aligns with running a smaller model many times. This could have been for the vulnerability object creation or static analysis tasks, which can be done with a fine-tuned local model repetitively, keeping API costs low.</p>
<p><strong>Performance &amp; Results:</strong> Bug Buster ended up <strong>6th place</strong> (out of 7 finalists). In the final round, it found an impressive <strong>41 vulnerabilities</strong> â€“ the second-highest count â€“ but only <strong>3 patches succeeded</strong><a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,3%20Total%20Score%20%E2%86%92%20105">[57]</a>. This massive disparity is what sank their score to 105 points<a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,3%20Total%20Score%20%E2%86%92%20105">[57]</a>. It indicates that while their <em>finding</em> mechanism (fuzzers + AI scheduling) was top-notch, their <em>fixing</em> mechanism struggled. In fact, their raw PoV score was the 2nd best and they were 1st in SARIF (static) points<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>. But patch points were very low (6th among 7)<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>, so the patches either failed or were never submitted for many bugs. The teamâ€™s postmortem confirms this: internally their patch success in tests was \~90% for mitigating PoVs, but something went wrong during the actual competition causing patch submissions to fail unexpectedly<a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=,%E2%80%94%206th%20place">[148]</a>. They suspect a system bug was responsible â€“ a painful lesson that â€œevery system has cracks, and in a competition like this, you only get one chanceâ€<a href="https://www.whexy.com/en/posts/aixcc#:~:text=match%20at%20L427%20No%20matter,you%20only%20get%20one%20chance">[149]</a>.</p>
<p>Despite the low placement, 42-b3yond-6ug had notable achievements: they received <em>â€œCzar of the SARIFâ€</em> for most correct static analysis evaluations and <em>â€œGiant Slayerâ€</em> for tackling a huge repo (5M+ lines)<a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[59]</a>. The latter suggests they scored on one of the largest projects (maybe the Linux kernel or another large codebase) where others struggled. This indicates their system could handle scale better than some (fuzzing at scale helps on giant code). They also got <em>â€œHunger For Knowledgeâ€</em> for their heavy LLM query rate<a href="https://aicyberchallenge.com/#:~:text=,Knowledge%20%2F%2F%2F%201K%2B%20LLM%20requests%2Fmin">[132]</a>. Their semifinal performance was actually top-tier (they were among top scoring teams in semis)<a href="https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402#:~:text=Tactics%2C%20Payloads%20and%20Real,to%20Uncover%20Hidden%20Cache">[150]</a><a href="https://www.darpa.mil/news/2024/small-business-ai-cyber-challenge#:~:text=DARPA%20Selects%20Small%20Businesses%20to,Track%20have%20been%20automatically">[151]</a>, which earned them the finalist spot and funding. In finals, ironically, their heavy focus on patch innovation might have backfired due to a critical implementation bug (their narrative of a patch component rushed in last week without full review stands out<a href="https://www.whexy.com/en/posts/aixcc#:~:text=The%20idea%20was%20clever%20%E2%80%94,Simple%2C%20elegant%20in%20theory">[152]</a>). So, the system found many bugs (some even in Linux which most teams found none<a href="https://www.openwall.com/lists/oss-security/2024/08/19/2#:~:text=You%20can%20see%20that%20the,as%20part%20of%20the%20challenge">[153]</a>), but the patcher collapsing meant low final score. The team lead expressed admiration for Theoriâ€™s LLM-first approach later<a href="https://www.whexy.com/en/posts/aixcc#:~:text=match%20at%20L469%20I%20really,genuinely%20enjoyed%20reading%20their%20code">[154]</a>, indicating a recognition that their traditional-heavy approach had limitations in comparison.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> Bug Busterâ€™s strength was <em>raw vulnerability finding power</em>. They arguably built the best bug-finding machine among all teams â€“ 41 vulns is testament to that. Their RL-driven fuzzing and extensive engineering on scaling paid off in triggering lots of crashes, even in hard targets like Linux. They also nailed static analysis, meaning they werenâ€™t fooled by many false alarms. Another strength was creativity in patching (super patches) â€“ although it didnâ€™t reflect in points, the idea is solid for real-world use where you want minimal patches that solve maximum issues. However, weaknesses were evident: the patch pipelineâ€™s fragility was a huge Achillesâ€™ heel. It shows that balancing the two halves (find &amp; fix) is crucial; their find outran their fix. Possibly too many crashes overwhelmed their patching process or they over-engineered patch strategies when a simpler per-bug patch might have sufficed. Additionally, the slicing tool distraction in Round 1 and integration struggles suggest they faced project management challenges â€“ tackling many complex components (fuzzing, RL, slicing, concolic, patching, etc.) with a limited team can stretch resources thin. In terms of AI, while they used it smartly in places, one could argue they could have benefited from using more advanced LLM reasoning in patching or exploit generation, rather than relying so heavily on fuzzing (which finds crashes but doesnâ€™t inherently prioritize them). Documentation from this team is very rich â€“ one memberâ€™s personal blog gave a detailed, candid account of their journey<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[56]</a>, and the team has likely academic papers in the works on BandFuzz and LLM seed generation. They open-sourced their code (archived on GitHub)<a href="https://github.com/42-b3yond-6ug/42-b3yond-6ug-asc#:~:text=This%20repository%20hosts%20our%20team%E2%80%99s,AI%20Cyber%20Challenge%20Semifinal%20Competition">[155]</a> and are reflective about what went wrong, which provides valuable lessons. In summary, Bug Buster was a <em>high-risk, high-complexity system</em> that excelled in discovery but faltered in remediation, showing the need to weight both equally in such competitions.</p>
<h3 id="software-aixcc-lacrosse-legacy-crs-with-ai-enhancements">Lacrosse â€“ Legacy CRS with AI Enhancements<a class="headerlink" href="#software-aixcc-lacrosse-legacy-crs-with-ai-enhancements" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <em>Lacrosse</em> was a bit of an outlier among finalists. It appears to have been built on a <strong>legacy CRS codebase</strong> from nearly a decade ago, updated for AIxCC<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AIxCC%20finals%3A%20Tale%20of%20the,about%20its%20ability%20to">[61]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=LACROSSE%3A%20This%20team%20gave%20its,about%20its%20ability%20to">[62]</a>. This likely refers to technology from the original DARPA Cyber Grand Challenge (2016) or similar competitions. The team behind it (possibly a company like SIFT or a government lab, as suggested by interviews<a href="https://www.youtube.com/watch?v=YdJ6NoxzuKs#:~:text=DEF%20CON%2033%20Video%20Team,look%20behind%20the%20contest%20curtain">[156]</a><a href="https://www.youtube.com/watch?v=uO1LnENZV_4#:~:text=LACROSSE%27s%20AIxCC%20Final%20Submission%20,SIFT%20on%20their%20AIxCC">[157]</a>) essentially took a tried-and-true automated vulnerability discovery system and gave it a â€œglow-upâ€ with some modern AI additions<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AIxCC%20finals%3A%20Tale%20of%20the,about%20its%20ability%20to">[61]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=LACROSSE%3A%20This%20team%20gave%20its,about%20its%20ability%20to">[62]</a>. The core remained <em>fuzzing-centric and reliability-focused</em>. Lacrosse deployed on the order of <strong>300â€“500 fuzzing agents</strong> in parallel, which is comparable to Trail of Bitsâ€™ scale and shows a significant commitment to fuzzing horsepower<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. These fuzzers were orchestrated by a central intelligence called <strong>â€œOptimus Zeroâ€</strong><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. Optimus Zero managed global state and distributed tasks among fuzzers and analysis components, prioritizing tasks much like a general might in the field. This suggests a design similar to older CRS where a central controller divides work (some to fuzzers, some to static analyzers, etc., based on what's left to do).</p>
<p>Lacrosse prioritized <em>proven techniques</em> over experimental AI. As the Trail of Bits blog noted, they favored â€œfocusing on agent orchestration rather than AI-driven vulnerability discoveryâ€<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a>. In practice, this means Lacrosse relied on fuzzing with robust engineering (ensuring fuzzers run properly, outputs are collected, etc.) and didnâ€™t take as many risks with untested AI logic that might mislead or crash. The approach is akin to running a well-oiled fuzzing farm with careful oversight. That said, they did integrate AI in specific supportive roles (next section).</p>
<p><strong>Traditional Techniques:</strong> Being based on an older CRS, Lacrosse almost certainly employed <em>classical symbolic execution</em> and <em>static analysis components</em> from that era. Many CGC-era systems had custom symbolic executors (to generate PoVs by solving path constraints), plus things like taint analysis to see what input bytes influence a crash. If Lacrosseâ€™s base was one of those, it likely retained those capabilities. However, open-source critical infrastructure code (Linux, Apache, etc.) is far bigger and more complex than CGCâ€™s synthetic binaries, so they probably leaned more on fuzzing which scales better. They also adhered to <em>traditional PoV generation via fuzzing</em>: meaning they largely used fuzzers to generate crashing inputs and did not attempt AI generative exploits for format compliance<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a>.</p>
<p>Lacrosse also did static analysis of a sort: their achievements show <em>â€œConsensus Contributorâ€</em> (most POVs/vulns submitted) which implies they detected a lot of potential issues and tried to submit many, even if duplicates<a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a>. This could mean they had an aggressive static analysis that flagged many possible bugs and they attempted many PoVs (some might have been redundant or invalid, hence most submissions but not high score). It could be due to an older system not having as refined a triage mechanism for modern code, so it oversubmitted. Another achievement, <em>â€œProfessional Assassinâ€</em> (POV success &gt;95%)<a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a>, is interesting: how do you reconcile submitting the most POVs with 95% success? Possibly they submitted a ton of static-analysis-based SARIF issues (counted as â€œvulnsâ€) and a smaller number of PoVs which mostly worked. Or maybe they attempted many PoVs but only a handful scored, and those gave them the &gt;95% success ratio because others failing might not count if not considered valid submissions? It's a bit contradictory, but maybe the key is they were careful to only officially submit PoVs once they were pretty sure (leading to high success rate), and they hammered static vuln reports (since those cost little to be wrong besides 0 points).</p>
<p>The <em>â€œRaiders of the Lost POVâ€</em> award suggests Lacrosse found at least one genuine vulnerability that DARPA did not plant in the code<a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a>. Thatâ€™s a credit to their thoroughness; likely their fuzzers or symbolic execution uncovered a 0-day in a target (maybe the one bug they did patch successfully). For patching, Lacrosse took a middle-of-the-road strategy: not as conservative as Shellphish, not as aggressive as Theori. They used <strong>LLM consensus and a confidence algorithm</strong> to decide on patches<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a>. This implies they might generate a patch with AI, then have multiple AI models or runs evaluate it, and if they all (or a majority) agree itâ€™s a good fix, they submit it. This is a smart way to reduce hallucinations â€“ essentially a voting scheme among AI â€œopinions.â€ They didnâ€™t have the fastest or most numerous patches, but this approach likely aimed to avoid accuracy penalties while still patching whenever they had enough confidence.</p>
<p><strong>AI-Based Techniques:</strong> Lacrosse integrated AI in a <em>supporting role</em> rather than core. First, they used LLMs for <strong>higher-level reasoning tasks</strong>. This included analyzing crash reports to produce <em>â€œvulnerability objectsâ€</em> â€“ structured descriptions of a crashâ€™s root cause, type, etc., and even suggestions for patching<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a>. Such an object might say, for example: â€œHeap buffer overflow in function parse_image() when handling BMP files. Cause: misuse of memcpy length.â€ This gives the developers (or automated system) a clear picture. Having AI create these likely helped Optimus Zero to decide how to patch or whether to prioritize that bug.</p>
<p>They also used AI for <strong>semantic understanding</strong> tasks that classical tools struggle with. For instance, figuring out input formats or protocol details might be handled by an AI reading the documentation or inferring from code. Lacrosse might have had an AI agent to reverse-engineer input format if needed (similar to Shellphishâ€™s Grammar Guy, but probably less central). Another key AI usage is in their patching process: <em>LLM consensus</em>. They might generate several patch options with GPT or similar, then evaluate each with one or multiple models to pick the best. Or, they might have one LLM propose a patch and another review it for correctness. That aligns with a careful, consensus-driven approach<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a>.</p>
<p>The orchestrator, Optimus Zero, probably also had some AI logic. It might have used heuristic or learned (AI) strategies to assign tasks â€“ e.g., using machine learning to predict which module is likely vulnerable based on past data, and thus allocate more fuzzing there. But given the limited performance, it might have been rule-based rather than learned, as they emphasized reliability over new techniques.</p>
<p>The cost data shows Lacrosse spent <strong>very little</strong>: \<span class="arithmatex">\(631 on LLMs and \\\)</span>7.1k on compute (the lowest by far)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Theori%2411.5k%2420.3k%2431.8k%24151%20fuzzing_brain%2412.2k%2463.2k%2475.4k%24490%20Shellphish%242.9k%2454.9k%2457.8k%24425%2042">[131]</a>. Thatâ€™s maybe because they didnâ€™t utilize external AI much (maybe some small model usage or minimal queries) and their scale was smaller than others (if 300â€“500 agents, possibly not running full throttle or not all heavy processes). Their cost per point was highest, \$751, meaning the approach was not resource-efficient in terms of score<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a>. But they likely aimed for a robust system within modest budget, possibly as a small business track team or similar.</p>
<p><strong>Performance &amp; Results:</strong> Lacrosse finished <strong>7th (last) in the finals</strong>, with only <strong>1 vulnerability found and 1 patched</strong><a href="https://aicyberchallenge.com/#:~:text=Lacrosse%20%E2%80%94%E2%80%94,1%20Total%20Score%20%E2%86%92%2010">[65]</a>, for 10 points. This is a stark drop from others and indicates something went wrong or underperformed. Itâ€™s possible their system actually found more but maybe didnâ€™t get credit due to duplicates or timing. The fact they submitted the most vulns/PoVs (consensus contributor) suggests they tried many, but they only successfully <em>scored</em> one. This likely means many of their submissions were duplicates of othersâ€™ findings or came too late. In the DEF CON final format, when multiple teams find the same bug, the one who submits first (with PoV or patch) gets more points, and late patches to a bug someone else already patched can reduce accuracy if the bug is already fixed. Lacrosse might have identified bugs slower than others, so by the time they submitted, another team had patched it, making their patch either unnecessary or harmful to their score. This is speculation, but fits the data: lots of attempts, little payoff, could be due to lateness.</p>
<p>On the positive side, the one bug they did patch gave them those achievements (because it was a unique real bug that only they found). So their conservative thorough approach did yield one unique discovery. But competitively, speed and volume are key, and they fell behind. Possibly their legacy system, while stable, wasnâ€™t designed for the complexity of real modern code and needed more AI infusion to be competitive, but they perhaps ran out of time to modernize everything. The TOT blogâ€™s admiration: â€œThis says a lot about its ability to â€¦â€ (it cuts off, but likely to stick around or adapt) suggests respect that an old system could still make finals<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AIxCC%20finals%3A%20Tale%20of%20the,about%20its%20ability%20to">[61]</a>.</p>
<p>Team Lacrosseâ€™s documentation is limited publicly, but DARPA posted a YouTube team interview<a href="https://www.youtube.com/watch?v=ULJcATTuT9U#:~:text=DARPA%20AI%20Cyber%20Challenge%20,views%20%C2%B7%201%20month%20ago">[158]</a>, and a CTF Radio podcast exists with their team members discussing their final submission<a href="https://www.youtube.com/watch?v=uO1LnENZV_4#:~:text=LACROSSE%27s%20AIxCC%20Final%20Submission%20,SIFT%20on%20their%20AIxCC">[157]</a>. These likely elaborate on their approach and motivations (e.g., perhaps a DARPA legacy or a focus on integration with government systems). The open-source archive shows their code on GitHub as well.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> Lacrosseâ€™s strength was <em>stability and low risk</em>. By using a known architecture and scaling it moderately, they avoided catastrophic failures â€“ their system did run end-to-end and didnâ€™t bomb out (evidenced by their achievements and at least one success). The orchestration by Optimus Zero indicates good control over their processes, likely leading to fewer crashes of the CRS itself (something even Team Atlanta worried about â€“ one bug can kill a CRS<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L0,1">[74]</a>). They also achieved near-perfect PoV success ratio, meaning they rarely submitted a PoV that didnâ€™t work<a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a>. That suggests strong validation and correctness checking on their part â€“ a valuable trait in real deployments, where false positives are a waste of time. And finding a unique bug shows they did have capability beyond trivial finds.</p>
<p>However, their weaknesses were speed and adaptability. They were <em>too conservative and slow</em> in a game that rewarded fast exploitation. Possibly their fuzzers found crashes but maybe they waited too long to confirm them or to generate PoVs. Or they might have targeted the wrong things first (maybe they spent time on a huge codebase and only found one bug, while ignoring easier targets early on). The minimal use of AI meant they didnâ€™t take advantage of leaps in reasoning or analysis that others did â€“ an old system might not catch subtle logic bugs or might drown in false positives without an AI to filter. Also, having fewer fuzzers than others (500 vs thousands) and not pushing them as hard (given the low compute cost) meant generating less coverage and crashes overall.</p>
<p>In essence, Lacrosse was a testament to <em>reliability over novelty</em>, which in this first-of-its-kind AI challenge, wasnâ€™t enough to score high. They effectively demonstrated that an older CRS, even with some LLM help, can still function on modern code, but to win, embracing more AI and aggressive strategies is necessary. For real-world transition, though, some of Lacrosseâ€™s philosophies (like patch confidence algorithms and not overspending resources) could be beneficial.</p>
<h3 id="software-aixcc-sherpa-automated-fuzz-harness-generation-auxiliary-tool">SHERPA â€“ Automated Fuzz Harness Generation (Auxiliary Tool)<a class="headerlink" href="#software-aixcc-sherpa-automated-fuzz-harness-generation-auxiliary-tool" title="Permanent link">&para;</a></h3>
<p><strong>Core Operation &amp; Approach:</strong> <strong>SHERPA</strong> (Security Harness Engineering for Robust Program Analysis) is an open-source tool released alongside the competition, focused on a specific but crucial problem: generating fuzzing harnesses for <em>attacker-controlled entry points</em> in software<a href="https://archive.aicyberchallenge.com/#:~:text=SHERPA">[159]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a>. In simpler terms, SHERPA automates the creation of the glue code that lets a fuzzer target the <em>highest-level interfaces</em> of a program â€“ those that real attackers would use â€“ rather than internal helper functions. This addresses a big gap: fuzzers often test library APIs or internal functions because thatâ€™s where harnesses exist (like OSS-Fuzz provides many harnesses at low-level APIs), but <em>real attacks typically go through top-level entry points</em> (like feeding a whole file or network packet into the program)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Why%20This%20Changes%20Everything">[161]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Paradigm%20Shift">[162]</a>. SHERPA shifts fuzzing â€œup the stackâ€ to these entry points<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Paradigm%20Shift">[162]</a>, meaning it tries to fuzz the program in a way that mirrors actual usage (e.g., fuzz the main() or the request handler rather than just a parsing subroutine).</p>
<p>To do this, SHERPAâ€™s workflow is: given a large project (say an open-source server or utility), <strong>analyze its coverage gaps</strong> â€“ identify parts of code not exercised by existing fuzzers<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Stage%201%3A%20Intelligent%20Target%20Selection">[163]</a>, focus on those that are <em>attacker-controlled entry points</em> (like functions reading external input)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=The%20Problem%3A%20Traditional%20fuzzing%20targets,controlled%20files%2C%20packets%2C%20and%20streams">[164]</a>, and then <strong>use LLMs to generate fuzz harness code</strong> for those entry points<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%EF%B8%8F%20How%20It%20Works">[165]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L553%20Key%20Prompt,Engineering%20Innovations">[166]</a>. The harness code is basically a piece of C/C++ (or Java) that calls into the target code in the right way with some fuzzer-provided data. SHERPA then compiles this harness, runs a fuzzing campaign on it, and monitors for crashes<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=flowchart%20TD%20A%5B%20OSS,Identify%20Unfuzzed%20Entry%20Points">[167]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=G%20">[168]</a>. If compilation fails or linking issues arise, SHERPA has an <em>auto-fix loop</em> where an LLM tries to fix build errors in the harness code and rebuild<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=C%20,E">[169]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=D%20,E">[170]</a>. This is very useful because writing correct harnesses can be tricky with dependencies and type matching â€“ SHERPA essentially iterates until the harness compiles (<em>â€œBuild-Until-Greenâ€</em>)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=1,bug%20reports%20with%20repro%20steps">[171]</a>.</p>
<p>When fuzzing finds crashes with these new harnesses, SHERPA again invokes an LLM for <strong>crash analysis</strong>. It automatically triages crashes, filtering out false positives (like if the harness itself was flawed or a benign bug) by using AI to analyze stack traces and error patterns<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=False%20Positives%20%26%20Quality%20Control">[172]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=We%20encountered%20,These%20were%20automatically%20triaged">[173]</a>. The LLM can discard &gt;80% of raw crashes as not real bugs<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,false%20positives%20before%20human%20review">[175]</a>, achieving a \~67% precision of real bugs in those that remain<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a> â€“ a huge efficiency gain. Finally, SHERPA outputs <em>maintainer-friendly artifacts</em>: for each validated bug, it provides a reproducible test case, an analysis of the bug, and even patch guidance<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,to%20maintainers%20with%20coordinated%20timelines">[177][178]</a>. The idea is to make it easy for open-source maintainers to understand and fix the issue, bridging the gap from raw fuzzer crash to actionable report.</p>
<p><strong>Traditional Techniques:</strong> SHERPA stands on existing fuzzing technology â€“ it doesnâ€™t replace fuzzers like AFL/libFuzzer; it <em>augments them</em>. It uses coverage analysis (likely via coverage traces from existing tests or fuzzers) to see what parts of code are <em>not fuzzed yet</em><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a>. Then it picks those areas, specifically focusing on code that handles untrusted input (for instance, functions that parse file formats or process network data â€“ essentially anything that reads from an external source). This targeting may use static analysis or simple heuristics (like function names containing â€œparseâ€ or pointer arguments that look like data buffers).</p>
<p>Once a target function is chosen, writing a harness is partly straightforward (calling the function with fuzzer data), but often needs some scaffolding: e.g., if the function expects a complex object, SHERPA might need to construct one (maybe by calling initializers or setting global state). It likely uses static analysis to see what that function requires (like what global variables need to be set, or what format the input should be). Some static analysis could be analyzing function signatures or reading comments (LLM can help here by reading code and inferring usage). SHERPA then fuzzes with libFuzzer or AFL (itâ€™s integrated into OSS-Fuzz style pipelines)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20Approach%20SHERPA%20Approach%20Target%3A,controlled%20entry%20points">[179]</a>. The harnesses it generates are OSS-Fuzz compliant, so they can be contributed back to OSS-Fuzz easily if desired<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L650%20Unharnessed%20Fuzzing">[180]</a>.</p>
<p>For triage, beyond LLM, it uses sanitizer output and likely checks if a crash is <em>unique</em> (deduplicating by crash stack or ASan report). It filtered 100+ raw crashes to 27 high-signal ones, from which 18 were confirmed real bugs<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Image%3A%20Kudu%20Logo">[181]</a>. Those numbers indicate heavy filtering. It also uses an interesting trick: if a harness or crash is due to misuse of API or unreachable condition, they filter that out (some automated logic likely flags known harness errors or unreachable states)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=False%20Positives%20%26%20Quality%20Control">[172]</a>.</p>
<p><strong>AI-Based Techniques:</strong> SHERPAâ€™s power comes from integrating LLMs at two key points: <strong>harness generation</strong> and <strong>crash analysis</strong>. For harness generation, SHERPA uses LLM <em>agents that understand code context</em>. The LLM is fed with information about the target function and possibly surrounding code (maybe function docstrings or definitions)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Solution%3A%20An%20LLM%20pipeline,packets%2C%20and%20handle%20file%20uploads">[182]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20Approach%20SHERPA%20Approach%20Target%3A,controlled%20entry%20points">[179]</a>. It then outputs a candidate harness in C/C++ code. Essentially, the LLM is writing new code â€“ a fuzz entry function that calls into the target code appropriately. This is where prompt engineering matters: they likely instruct the LLM to only use safe calls, how to structure a fuzz harness, and provide an example. They mention <em>â€œKey Prompt Engineering Innovations: Security-First Target Selectionâ€</em><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Key%20Prompt%20Engineering%20Innovations">[183]</a>, meaning the prompt emphasizes picking real attack surfaces. Also, <em>â€œMulti-Stage AI Pipelineâ€</em> is referenced<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L521%20Multi,Pipeline">[184]</a> â€“ Stage 1: target selection (maybe LLM helps identify which functions are entry points), Stage 2: harness code generation, Stage 3: build fix, Stage 5: crash triage by LLM<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Multi">[185]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L553%20Key%20Prompt,Engineering%20Innovations">[166]</a>. Stage 4 (fuzzing) is non-AI.</p>
<p>For <strong>build fixing</strong>, when the harness fails to compile, an LLM is given the compiler error output and the harness code, and asked to adjust the code to fix the error<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=A%5B%20OSS,Identify%20Unfuzzed%20Entry%20Points">[186]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=C%20,E">[169]</a>. This is a common use of codex-like models and can save a lot of human time. SHERPA keeps iterating this until it compiles or maybe a limit is reached. This automated debug loop is crucial for scaling to many targets without manual intervention.</p>
<p>During <strong>crash analysis</strong>, an LLM is tasked with reading sanitizer logs or core dumps to decide if a crash is likely a legit security bug or a false positive. It filtered out \~100 false positives automatically<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=False%20Positives%20%26%20Quality%20Control">[172]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=We%20encountered%20,These%20were%20automatically%20triaged">[173]</a>. The LLM also categorizes the bug (<abbr title="CWE Common Weakness Enumeration">CWE</abbr> type, severity) and possibly suggests a patch (the readme says each bug comes with patch guidance<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,to%20maintainers%20with%20coordinated%20timelines">[187]</a>). That suggests the LLM might even point out â€œchecking this length before copying would fix itâ€ or similar. SHERPAâ€™s readme lists a summary of bug types it found (<abbr title="CWE Common Weakness Enumeration">CWE</abbr>-770 uncontrolled mem alloc, etc.)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Bug%20Type%20CWE%20Repo%20Count,415%201">[188][189]</a>, which shows it can find a variety, many denial-of-service type issues (out-of-memory, infinite loops, etc.) that typical fuzzing might find but not prioritize.</p>
<p>SHERPAâ€™s use of AI is targeted and effective: rather than trying to analyze entire program flows, it uses AI to solve specific subproblems (writing harness code and interpreting crashes) that humans normally have to do. This dramatically speeds up fuzzing on new code sections (it found 18 new bugs across multiple OSS-Fuzz projects in minutes to hours, which might take humans weeks)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,false%20positives%20before%20human%20review">[175]</a>.</p>
<p><strong>Performance &amp; Results:</strong> SHERPA is not a competitor system but a tool produced (apparently by a collaboration including team members from Shellphish/Trail of Bits â€“ contributors include â€œblue-orbiter Alexâ€ (possibly Alex Groce?) and Matt Lehman of Trail of Bits<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Contributors%204">[190]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,Obsecurus%20Matt%20Lehman">[191]</a>). It was presented as a big success: it uncovered <strong>18 confirmed real vulnerabilities</strong> (in widely-used projects) from 27 high-signal crashes, out of 127+ raw crashes found<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Image%3A%20Kudu%20Logo">[181]</a>. Thatâ€™s 18 bugs that presumably were unknown before (the text says <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-class bugs, presumably candidates for CVEs) in production software. These include multiple memory safety issues (overflows, double-free, etc.) and several algorithmic complexity or DoS issues<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Bug%20Type%20CWE%20Repo%20Count,415%201">[188][189]</a>. The precision of \~67% from crash to real bug<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a> is far better than typical fuzzing (1-5% per their note)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=What%20makes%20this%20significant%3A">[192]</a>. And the speed is noted: minutes of targeted fuzzing to find these vs. weeks of coverage fuzzing normally<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,false%20positives%20before%20human%20review">[175]</a>. This is a huge improvement indicating how focusing on entry points pays off.</p>
<p>The SHERPA approach â€œchanges everythingâ€ in their words because it targets bugs that attackers actually exploit, not just obscure internal errors<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Why%20This%20Changes%20Everything">[161]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a>. For example, many fuzzers find crashes deep in libraries that might not be reachable in actual use, whereas SHERPA finds issues in how an app handles a whole file or request, which are more directly exploitable (like memory blowups or overflow on real inputs)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Why%20This%20Changes%20Everything">[161]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a>.</p>
<p>Documentation for SHERPA is thorough â€“ the GitHub readme reads like a whitepaper with motivation, methodology, and even a case study (LevelDB)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%3E%20">[193]</a>. Itâ€™s open-source (MIT licensed) and intended to be extended (they invite adding YAML configs for more targets)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L621%20Ways%20to,Contribute">[194]</a>. Itâ€™s a tool likely to be widely useful beyond the competition.</p>
<p><strong>Strengths &amp; Weaknesses:</strong> SHERPAâ€™s strength is <em>enabling fuzzing where it previously wasnâ€™t feasible</em>. It leverages AI to dramatically reduce the manual labor of writing harnesses and triaging fuzz results, which are two big bottlenecks in fuzzing adoption. By moving fuzz targets to real entry points, it finds high-impact bugs quickly<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Why%20This%20Changes%20Everything">[161]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a>. The combination of coverage analysis and AI ensures it focuses on un-fuzzed code that matters, making it efficient. The automated build-fix loop with AI is also a strength â€“ itâ€™s like having a junior engineer fix your code under supervision. Another strength is that SHERPA outputs actionable artifacts that can directly help maintainers fix issues, bridging the gap between security researchers and developers.</p>
<p>One possible weakness is that LLM-generated harnesses might sometimes be imperfect â€“ for example, the LLM could write a harness that <em>assumes</em> something about the code that isnâ€™t true, or doesnâ€™t correctly initialize some structure, which could lead to false crashes or missed bugs. However, SHERPAâ€™s iterative fixes and AI triage presumably catch many such issues (false crash = filter out). The accuracy of LLM in understanding complex APIs might also vary â€“ if a project requires deep domain knowledge to initialize properly, the harness might not hit the bug in a correct way. But since SHERPA still found many bugs, it indicates it worked well for the targets they tried.</p>
<p>Another challenge could be <em>scaling to extremely large projects</em> â€“ the coverage analysis and target identification might be slow for huge codebases, and the LLM context might not fit if a target requires reading a lot of code. They did mention applying it to multiple OSS-Fuzz projects and specifically call out a new harness for LevelDB as an example (with a detailed write-up included)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=About">[195]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%3E%20">[193]</a>. It likely works best for modular projects with clear entry points.</p>
<p>Overall, SHERPA is an <strong>impressive marriage of AI and fuzzing</strong>, automating a critical but tedious part of vulnerability discovery. Itâ€™s not a direct competitorâ€™s CRS, but rather a tool that any team (and now the public) can use to improve fuzz coverage on real software. It shows how the innovations from AIxCC can be spun off to benefit the broader ecosystem immediately<a href="https://aicyberchallenge.com/#:~:text=groundbreaking%20technology%20created%20by%20the,our%20critical%20infrastructure%20and%20beyond">[196]</a><a href="https://aicyberchallenge.com/#:~:text=Each%20of%20the%207%20finalist,competition%20infrastructure%2C%20challenges%20and%20more">[197]</a>.</p>
<h2 id="software-aixcc-conclusion-comparative-insights">Conclusion â€“ Comparative Insights<a class="headerlink" href="#software-aixcc-conclusion-comparative-insights" title="Permanent link">&para;</a></h2>
<p>The AIxCC finalists collectively demonstrated a spectrum of approaches combining traditional cybersecurity techniques with AI, each with unique strengths:</p>
<ul>
<li>
<p><strong>Team Atlantaâ€™s Atlantis</strong> proved that an <em>ensemble-of-tools</em> strategy augmented by targeted LLM integration can yield the most robust results. Its strength was balancing innovation (custom models, multi-agent LLM use) with proven methods (fuzzing, concolic execution)<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Ultimately%2C%20we%20invested%20heavily%20in,Java%2C%20we%20developed%20three%20categories">[81]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a>, resulting in top scores across the board. Atlantis highlighted that <em>engineering reliability and diversity</em> in approach (multiple independent CRSs) is as important as raw AI prowess<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=robustness%20with%20novel%20research%20needed,to%20win">[198]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Atlantis%20isn%E2%80%99t%20a%20single%20CRS%E2%80%94it%E2%80%99s,both%20coverage%20and%20fault%20tolerance">[68]</a>.</p>
</li>
<li>
<p><strong>Trail of Bitsâ€™ Buttercup</strong> showed the value of <em>AI-assisted efficiency</em>. By inserting AI where it adds clear value â€“ generating smarter inputs and assisting patch generation â€“ Buttercup achieved high accuracy and breadth with less expenditure<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>. It underscored that one can leverage AI to boost traditional tools (<em>LLM-generated seeds for fuzzers, multi-agent patching</em>) without over-relying on expensive models, thus optimizing cost/benefit<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[15]</a>.</p>
</li>
<li>
<p><strong>Theoriâ€™s RoboDuck</strong> pushed the envelope on <em>LLM-driven autonomy</em>, confirming that an AI-first system can indeed find and exploit real bugs with minimal human-like heuristics<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=From%20the%20outset%2C%20team%20Theori,produce%20inputs%20or%20grammars%20to">[103]</a><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=here">[110]</a>. Its success in 3rd place validated the concept of chaining LLM â€œagentsâ€ to perform tasks like static analysis, exploit development, and patching in a loop<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20generates%20approximately%2090,as%20a%20fallback%20validation%20mechanism">[30]</a>. RoboDuckâ€™s performance suggests that as AI models improve, this approach could become even more dominant â€“ though Theori had to carefully constrain its agents to keep them on track<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a>.</p>
</li>
<li>
<p><strong>All You Need is a Fuzzing Brain</strong> demonstrated the power (and cost) of <em>massively parallel AI</em>. It found and fixed bugs by orchestrating an army of AI workers in parallel<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>, achieving notable wins in speed and static accuracy<a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>. The lesson from FuzzingBrain is that scaling out AI can brute-force results, but efficiency suffers (highest cost per point)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a>. This approach might be more viable as AI inference costs drop, but for now it was an expensive route to fourth place â€“ albeit one that shows AI â€œswarm intelligenceâ€ can rival more methodical strategies.</p>
</li>
<li>
<p><strong>Shellphishâ€™s Artiphishell</strong> embodied a <em>comprehensive multi-agent ecosystem</em>. With 60+ agents dividing every sub-task<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>, it was arguably the most ambitious integration of AI and security expertise. It excelled in patches correctness and complex input fuzzing (via Grammar Guy)<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a><a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a>, though it lagged in volume of outputs. The takeaway is that highly modular AI systems can work and ensure quality, but coordinating them is complex â€“ a single bottleneck or miscoordination can slow the whole system. Artiphishellâ€™s design will likely inspire future research into multi-agent autonomy and how to optimize it.</p>
</li>
<li>
<p><strong>42-b3yond-6ugâ€™s Bug Buster</strong> emphasized <em>extreme scale fuzzing and clever patching</em>, finding the most bugs after the winner<a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,3%20Total%20Score%20%E2%86%92%20105">[57]</a>. It proved that given enough compute and refined scheduling (RL-based), fuzzers remain incredibly potent<a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[139]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a>. However, their stumble in patching (â€œsuper patchesâ€ with a bug) highlights that novel AI ideas need rigorous testing â€“ an insightful lesson that <em>development speed and code quality</em> can be a deciding factor even with great algorithms<a href="https://www.whexy.com/en/posts/aixcc#:~:text=The%20idea%20was%20clever%20%E2%80%94,Simple%2C%20elegant%20in%20theory">[152]</a><a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a>. Bug Busterâ€™s journey also illustrated the difficulty of integrating multiple advanced components (fuzzing, RL, static slicing, etc.) under time pressure â€“ a more focused scope might have yielded a higher rank.</p>
</li>
<li>
<p><strong>Lacrosse</strong> showed a <em>conservative, legacy-informed approach</em>, which, while yielding minimal points, serves as a baseline: an earlier-generation CRS updated with modest AI can still operate on modern targets<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=LACROSSE%3A%20This%20team%20gave%20its,about%20its%20ability%20to">[62]</a>, but it will likely be outpaced by more aggressive AI integration<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a>. Lacrosseâ€™s strong reliability yet low score tells us that in this new era, <em>playing it safe is not enough</em> â€“ AI and automation are required to achieve state-of-the-art results, even if the traditional methods give a stable foundation.</p>
</li>
<li>
<p><strong>SHERPA</strong>, finally, is a standout contribution that, while not a competitorâ€™s CRS, complements the above by addressing a practical gap with AI. It exemplifies how AI can be <em>surgically applied to automate tedious security tasks</em> (harness writing, triage)<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=The%20Problem%3A%20Traditional%20fuzzing%20targets,controlled%20files%2C%20packets%2C%20and%20streams">[164]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=flowchart%20TD%20A%5B%20OSS,Identify%20Unfuzzed%20Entry%20Points">[167]</a>, dramatically amplifying human ability to secure code. The fact that SHERPA found numerous bugs quickly in real software<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a> underscores the real-world impact potential of these AIxCC innovations.</p>
</li>
</ul>
<p>In summary, the competition affirmed that <strong>AI is now an indispensable part of automated cybersecurity</strong>: all top teams used machine learning in some form to achieve results unattainable by classical techniques alone. However, it also showed that <em>hybrid approaches</em> â€“ blending AI with time-tested methods â€“ currently have an edge over purely AI or purely traditional systems. The winning teams were those who managed that blend most effectively (or in Theoriâ€™s case, tamed an AI-first approach with enough guardrails).</p>
<p>Key comparative takeaways include:</p>
<ul>
<li>
<p><strong>Core Approaches:</strong> Teams like Atlanta and Shellphish that combined multiple approaches (fuzzing + static + concolic + AI) performed extremely well, suggesting that diversity equals strength in CRS design<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=robustness%20with%20novel%20research%20needed,to%20win">[198]</a><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Java%2C%20we%20developed%20three%20categories%3A">[75]</a>. In contrast, a single-technique focus (e.g., fuzzing-heavy 42-beyond or AI-heavy FuzzingBrain) had either patch or cost issues.</p>
</li>
<li>
<p><strong>AI Usage:</strong> Using AI <em>to assist and enhance</em> (Buttercup, Shellphish) tended to yield high accuracy and efficient use of budget<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a>. Fully AI-driven systems (Theori, FuzzingBrain) found lots of bugs but required careful constraint or heavy resources<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a>. A striking point was how <strong>all teams used AI for patching</strong> â€“ there was broad consensus that LLMs are suitable for generating code fixes<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=assist%20existing%20techniques%20like%20fuzzing">[109]</a>. The differentiator was how much trust and autonomy they gave those AI in the overall loop.</p>
</li>
<li>
<p><strong>Traditional Techniques:</strong> The competition reinforced that techniques like fuzzing are not obsolete â€“ in fact, they were central to every teamâ€™s success, but often turbocharged by AI. Teams that extended and scaled traditional methods (Atlantaâ€™s multi-fuzzers, ToBâ€™s static queries, 42â€™s RL fuzzing) ended up in the top half<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a>. Traditional static analysis alone was insufficient due to noise â€“ but integrated with AI (Theori, FuzzingBrain, Shellphish SARIF handling), it became useful<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Theori%E2%80%99s%20LLM%20agents%20use%20semantic,insights%20inform%20traditional%20validation%20methods">[108]</a><a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a>.</p>
</li>
<li>
<p><strong>Performance Metrics:</strong> Final scores aside, different tools excelled in different metrics. For instance, 42-beyond led in raw finds, Shellphish led in patch accuracy, FuzzingBrain in speed of first find, ToB in <abbr title="CWE Common Weakness Enumeration">CWE</abbr> coverage<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20challenged%20competitors%20to%20find,safety%20issues%20to%20injection%20flaws">[16]</a><a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[48]</a>. This suggests each CRS carved out a niche of strength. A future ideal system might integrate the strengths of all â€“ the coverage of Buttercup, the depth of RoboDuck, the thoroughness of Atlantis, the harness generation of SHERPA â€“ to cover all metrics.</p>
</li>
<li>
<p><strong>Documentation &amp; Usability:</strong> Most teams have open-sourced their code and provided documentation or blogs, but complexity varies. Buttercup appears relatively turnkey (they emphasize one can run it on a laptop)<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=As%20a%20cybersecurity%20services%20company,run%20it%20on%20your%20laptop">[102]</a>, whereas Atlantis and Artiphishell are complex distributed systems that require cloud infrastructure and careful configuration<a href="https://github.com/shellphish/artiphishell#:~:text=5,Application">[126]</a><a href="https://github.com/shellphish/artiphishell#:~:text=Development">[127]</a>. Usability will be key for these CRSs to be adopted outside the competition. In that sense, SHERPA and Buttercup set good examples by focusing on being accessible and well-documented<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=As%20a%20cybersecurity%20services%20company,run%20it%20on%20your%20laptop">[102]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%3E%20">[193]</a>.</p>
</li>
</ul>
<p>In conclusion, the AIxCC finalists collectively advanced the state-of-the-art by demonstrating that <strong>AI and traditional program analysis can be fused to automatically secure real-world software</strong> at scale and speed previously impossible. Each tool brought a unique innovation: Atlantis with multi-engine fault tolerance<a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Our%20answer%3A%20N,orthogonal%20approaches">[5]</a>, Buttercup with cost-effective LLM integration<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[18]</a>, RoboDuck with end-to-end AI reasoning<a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a>, FuzzingBrain with massive agent parallelism<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a>, Artiphishell with large-scale agent collaboration<a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a>, Bug Buster with RL-guided fuzzing and multi-bug patches<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a>, and Lacrosse with a demonstration of stability vs. innovation trade-offs<a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a>. And supporting all, SHERPA showcased a immediately applicable tool for the community<a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=What%20makes%20this%20significant%3A">[199]</a><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Solution%3A%20An%20LLM%20pipeline,packets%2C%20and%20handle%20file%20uploads">[182]</a>.</p>
<p>The competition may be over, but its impact is just beginning: these open-source CRSs and tools can now be <em>tested, combined, and built upon</em> by the broader cybersecurity community<a href="https://aicyberchallenge.com/#:~:text=groundbreaking%20technology%20created%20by%20the,our%20critical%20infrastructure%20and%20beyond">[196]</a><a href="https://aicyberchallenge.com/#:~:text=Each%20of%20the%207%20finalist,competition%20infrastructure%2C%20challenges%20and%20more">[197]</a>. The strengths of each can potentially compensate for the weaknesses of others. The future likely lies in <strong>hybrid systems</strong> that use AI intelligently â€“ neither ignoring its power nor using it blindly â€“ to cover the full spectrum of software security tasks. AIxCC has indeed marked â€œa pivotal inflection pointâ€ for cyber defense<a href="https://aicyberchallenge.com/semifinal-competition/#:~:text=During%20the%20AIxCC%20Semifinals%2C%2042,discovering%20and%20patching%20software%20vulnerabilities">[200]</a>, showing that automated systems augmented by AI are not just a research dream but a practical reality that can find and fix critical vulnerabilities at scale<a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20was%20a%20two,Human%20interaction%20was%20strictly%20prohibited">[1]</a><a href="https://aicyberchallenge.com/#:~:text=AIxCC%20CRS%20technology%20represents%20a,Repository%20and%20subscribe%20to%20our">[201]</a>. The tools compared in this report are the first generation of that reality; with continued development and community involvement, we can expect even more robust AI-driven security solutions in the coming years. Each of these systems, in its own way, contributes to that vision of <strong>â€œSecurity-AGIâ€</strong> â€“ autonomous agents defending code, faster than attackers can find bugs<a href="https://team-atlanta.github.io/#:~:text=POSTECH%2C%20with%20proven%20success%20at,world%20approaches%20software%20security%20through">[202]</a><a href="https://team-atlanta.github.io/#:~:text=cyber%20reasoning%20system%20Atlantis%2C%20which,software%20security%20through%20intelligent%20automation">[203]</a>.</p>
<hr />
<p><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20was%20a%20two,Human%20interaction%20was%20strictly%20prohibited">[1]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[15]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=AIxCC%20challenged%20competitors%20to%20find,safety%20issues%20to%20injection%20flaws">[16]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[17]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[18]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[20]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=1,bundled%20SARIF%2C%20PoV%2C%20and%20Patches">[21]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=So%20how%20does%20Buttercup%20work%3F,graphs%2C%20dependencies%2C%20and%20vulnerability%20contexts">[22]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Other%20teams%20also%20had%20good,place%20win">[24]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Image%3A%20Buttercup%E2%80%99s%20standout%20achievements%20at,reasoning%20LLMs">[25]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Each%20AIxCC%20team%20was%20given,two%20winners%20on%20LLM%20queries">[36]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[37]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Team%20LLM%20spend%20Compute%20spend,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[91]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Cost%20per%20point%20shows%20the,doesn%E2%80%99t%20require%20massive%20infrastructure%20investments">[95]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=1,was%20not%20inserted%20into%20the">[99]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Digging%20more%20into%20the%20results,we%20learned%20that%20Buttercup%20also">[100]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=On%20August%208%2C%202025%2C%20it,place%20finisher">[101]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=As%20a%20cybersecurity%20services%20company,run%20it%20on%20your%20laptop">[102]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Trail%20of%20Bits%2421,6ug%241.1k%2438.7k%2439.8k%24379%20LACROSSE%24631%247.1k%247.2k%24751">[120]</a> <a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/#:~:text=Theori%2411.5k%2420.3k%2431.8k%24151%20fuzzing_brain%2412.2k%2463.2k%2475.4k%24490%20Shellphish%242.9k%2454.9k%2457.8k%24425%2042">[131]</a> Trail of Bits' Buttercup wins 2nd place in AIxCC Challenge -The Trail of Bits Blog</p>
<p><a href="https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/">https://blog.trailofbits.com/2025/08/09/trail-of-bits-buttercup-wins-2nd-place-in-aixcc-challenge/</a></p>
<p><a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20AI%20Cyber%20Challenge%20asks,asked%20to%20submit%20their%20assessment">[2]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Our%20Approach">[26]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=As%20part%20of%20Theori%E2%80%99s%20open,check%20out%20this%20%2010">[27]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=While%20only%20a%20piece%20of,shot%20LLM%20completions">[28]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=The%20first%20step%20our%20system,performed%20by%20two%20different%20LLMs">[31]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=">[32]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=From%20the%20outset%2C%20team%20Theori,produce%20inputs%20or%20grammars%20to">[103]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Although%20we%20have%20extensive%20experience,static%20analysis%20techniques%20available%20for">[104]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Contents">[105]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=operation%20is%20safe,we%20fixed%20for%20our%20CRS">[106]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=engineering%20behind%20it,shot%20LLM%20completions">[107]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=assist%20existing%20techniques%20like%20fuzzing">[109]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=here">[110]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=Although%20advances%20have%20been%20going,operates%20with%20zero%20human%20input">[111]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=of%20Vulnerability%20,trajectories%2C%20check%20out%20this%20post">[112]</a> <a href="https://theori.io/blog/aixcc-and-roboduck-63447#:~:text=AI%20Cyber%20Challenge%20and%20Theori%27s,RoboDuck">[118]</a> AI Cyber Challenge and Theori's RoboDuck - Theori BLOG</p>
<p><a href="https://theori.io/blog/aixcc-and-roboduck-63447">https://theori.io/blog/aixcc-and-roboduck-63447</a></p>
<p><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Enhancing%20traditional%20security%20tools%20with,AI">[3]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20and%20Theori%20use%20LLMs,agents%20use%20reasoning%20to%20determine">[4]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20and%2042,from%20the%20same%20underlying%20vulnerability">[9]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[10]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Conservative%3A%20Trail%20of%20Bits%2C%20Shellphish%2C,finals%20to%20avoid%20accuracy%20penalties">[12]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Trail%20of%20Bits%20uses%20LLMs,traditional%20mutational%20fuzzing%20struggles%20with">[19]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=approach%2C%20using%20LLMs%20for%20vulnerability,vulnerabilities%20and%20reduce%20false%20positives">[29]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=all_you_need_is_a_fuzzing_brain%20generates%20approximately%2090,as%20a%20fallback%20validation%20mechanism">[30]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=capabilities%20before%20the%20finals%20to,avoid%20accuracy%20penalties">[33]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AI">[39]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=fuzzing%20struggles%20with">[42]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=speculative%20patches%20for%20every%20confirmed,based%20patch">[51]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=42,based%20scheduling">[52]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=vulnerabilities,categorize%2C%20and%20plan%20for%20patching">[55]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=AIxCC%20finals%3A%20Tale%20of%20the,about%20its%20ability%20to">[61]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=LACROSSE%3A%20This%20team%20gave%20its,about%20its%20ability%20to">[62]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Strategic%3A%20Trail%20of%20Bits%20implemented,consensus%20and%20a%20confidence%20algorithm">[63]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Traditional%20fuzzing">[64]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Team%20Atlanta%20deploys%20language,level%20dictionaries%20for%20targeted%20mutation">[79]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=progressive%20grammars%20based%20on%20a,categorize%2C%20and%20plan%20for%20patching">[96]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Theori%E2%80%99s%20LLM%20agents%20use%20semantic,insights%20inform%20traditional%20validation%20methods">[108]</a> <a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/#:~:text=Aggressive%3A%20Theori%20developed%20a%20mathematical,based%20patch">[142]</a> AIxCC finals: Tale of the tape -The Trail of Bits Blog</p>
<p><a href="https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/">https://blog.trailofbits.com/2025/08/07/aixcc-finals-tale-of-the-tape/</a></p>
<p><a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Our%20answer%3A%20N,orthogonal%20approaches">[5]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[6]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L4.%20LLM">[7]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L293%20LLM,from%20diffs%20or%20SARIF%20reports">[8]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=,implementations%20for%20C%20and%20Java">[11]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L3,Jack">[44]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L253%20improvements,agent%20specifically%20for%20this%20task">[45]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Atlantis%20isn%E2%80%99t%20a%20single%20CRS%E2%80%94it%E2%80%99s,both%20coverage%20and%20fault%20tolerance">[68]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=By%20maintaining%20minimal%20sharing%20between,true%20fault%20tolerance%20through%20diversity">[69]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=design%20decisions%2C%20we%20ensured%20that,true%20fault%20tolerance%20through%20diversity">[70]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=ImageDesign%20Overview%20of%20Atlantis%20,tuned%20for%20our%20Technical%20Report">[71]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=These%20CRSs%20deliberately%20made%20orthogonal,time%20instrumentation">[72]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=of%20code%20nearly%20destroyed%20our,chances">[73]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L0,1">[74]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Java%2C%20we%20developed%20three%20categories%3A">[75]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Each%20tool%20required%20non,world%20scale">[76]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=We%20initially%20hoped%20to%20stand,ready">[77]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Ultimately%2C%20we%20invested%20heavily%20in,Java%2C%20we%20developed%20three%20categories">[78]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=This%20shift%20changes%20everything,complexity%20would%20doom%20any%20CRS">[80]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Ultimately%2C%20we%20invested%20heavily%20in,Java%2C%20we%20developed%20three%20categories">[81]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=Harness%20Reverser%20operate%20with%20calculated,hints%E2%80%94similar%20to%20optimistic%20concurrency%20control">[82]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L286%20Harness%20Reverser,hints%E2%80%94similar%20to%20optimistic%20concurrency%20control">[83]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=LLM,from%20diffs%20or%20SARIF%20reports">[84]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=improvements,agent%20specifically%20for%20this%20task">[85]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=To%20avoid%20vendor%20lock,across%20different%20LLM%20providers%20for">[86]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=ImageDesign%20Overview%20of%20Atlantis%20,tuned%20for%20our%20Technical%20Report">[92]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=We%20discovered%20this%20critical%20bug%2C,heuristic%20to%20avoid%20false%20positives">[94]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L221%20L3,Jack">[119]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=L3,Jack">[130]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=match%20at%20L231%20Like%20Jack,even%20researchers%20from%20Google%20DeepMind">[135]</a> <a href="https://team-atlanta.github.io/blog/post-afc/#:~:text=robustness%20with%20novel%20research%20needed,to%20win">[198]</a> AIxCC Final and Team Atlanta</p>
<p><a href="https://team-atlanta.github.io/blog/post-afc/">https://team-atlanta.github.io/blog/post-afc/</a></p>
<p><a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%94%E2%80%94,31%20Total%20Score%20%E2%86%92%20393">[13]</a> <a href="https://aicyberchallenge.com/#:~:text=,PoV%20percentage%20higher%20than%2095">[14]</a> <a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[23]</a> <a href="https://aicyberchallenge.com/#:~:text=Theori%20%E2%80%94%E2%80%94,20%20Total%20Score%20%E2%86%92%20211">[34]</a> <a href="https://aicyberchallenge.com/#:~:text=,else%20submitted%20a%20POV%20for">[35]</a> <a href="https://aicyberchallenge.com/#:~:text=%2A%20,SARIF%20accuracy">[38]</a> <a href="https://aicyberchallenge.com/#:~:text=ALL%20YOU%20NEED%20IS%20A,14%20Total%20Score%20%E2%86%92%20154">[40]</a> <a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[46]</a> <a href="https://aicyberchallenge.com/#:~:text=Shellphish%20%E2%80%94%E2%80%94,11%20Total%20Score%20%E2%86%92%20136">[47]</a> <a href="https://aicyberchallenge.com/#:~:text=,Reporting%20LLM%20and%20CRS%20activity">[48]</a> <a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,3%20Total%20Score%20%E2%86%92%20105">[57]</a> <a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[59]</a> <a href="https://aicyberchallenge.com/#:~:text=Lacrosse%20%E2%80%94%E2%80%94,1%20Total%20Score%20%E2%86%92%2010">[65]</a> <a href="https://aicyberchallenge.com/#:~:text=,artificially%20inserted%20into%20the%20Challenge">[66]</a> <a href="https://aicyberchallenge.com/#:~:text=used%20to%20secure%20our%20critical,infrastructure%20and%20beyond">[67]</a> <a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[87]</a> <a href="https://aicyberchallenge.com/#:~:text=,PoV%20percentage%20higher%20than%2095">[88]</a> <a href="https://aicyberchallenge.com/#:~:text=match%20at%20L194%20Team%20Atlanta,%E2%80%93%20ZERO%20DAYS%20DISCOVERED">[89]</a> <a href="https://aicyberchallenge.com/#:~:text=Team%20Atlanta%20%E2%80%93%20ZERO%20DAYS,DISCOVERED">[90]</a> <a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,6ug%207%20Lacrosse">[97]</a> <a href="https://aicyberchallenge.com/#:~:text=SCORED%20ROUND%20Vulnerabilites%20Found%20%E2%86%92,19%20Total%20Score%20%E2%86%92%20219">[98]</a> <a href="https://aicyberchallenge.com/#:~:text=ACHIEVEMENTS">[116]</a> <a href="https://aicyberchallenge.com/#:~:text=,else%20submitted%20a%20POV%20for">[117]</a> <a href="https://aicyberchallenge.com/#:~:text=2%20Trail%20of%20Bits%203,6ug%207%20Lacrosse">[121]</a> <a href="https://aicyberchallenge.com/#:~:text=%E2%80%94%E2%80%94,6ug%207%20Lacrosse">[122]</a> <a href="https://aicyberchallenge.com/#:~:text=,Knowledge%20%2F%2F%2F%201K%2B%20LLM%20requests%2Fmin">[132]</a> <a href="https://aicyberchallenge.com/#:~:text=groundbreaking%20technology%20created%20by%20the,our%20critical%20infrastructure%20and%20beyond">[196]</a> <a href="https://aicyberchallenge.com/#:~:text=Each%20of%20the%207%20finalist,competition%20infrastructure%2C%20challenges%20and%20more">[197]</a> <a href="https://aicyberchallenge.com/#:~:text=AIxCC%20CRS%20technology%20represents%20a,Repository%20and%20subscribe%20to%20our">[201]</a> aicyberchallenge.com</p>
<p><a href="https://aicyberchallenge.com/">https://aicyberchallenge.com/</a></p>
<p><a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=agent,exploited%20by%20malicious%20threat%20actors">[41]</a> <a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=Added%20Vigna%2C%20%E2%80%9COur%20AI%20system,%E2%80%9D">[128]</a> <a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=Over%20the%20past%20two%20years%2C,exploited%20by%20malicious%20threat%20actors">[129]</a> <a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition#:~:text=%E2%80%9CAs%20the%20competition%20is%20coming,and%20the%20lifelong%20bonds%20such">[133]</a> Shellphish Submits ARTIPHISHELL to the Final Round of the DARPA AI Cyber Competition | The Robert Mehrabian College of Engineering - UC Santa Barbara</p>
<p><a href="https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition">https://engineering.ucsb.edu/news/shellphish-submits-artiphishell-final-round-darpa-ai-cyber-competition</a></p>
<p><a href="https://github.com/shellphish/artiphishell#:~:text=Configure%20LLM%20Secrets">[43]</a> <a href="https://github.com/shellphish/artiphishell#:~:text=5,Application">[126]</a> <a href="https://github.com/shellphish/artiphishell#:~:text=Development">[127]</a> GitHub - shellphish/artiphishell</p>
<p><a href="https://github.com/shellphish/artiphishell">https://github.com/shellphish/artiphishell</a></p>
<p><a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[49]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=repair">[50]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=integration">[53]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20had%20tried%20using%20reinforcement,2024%2C%20and%20won%20first%20prize">[54]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[56]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=Looking%20closer%2C%20our%20team%E2%80%99s%20performance,was">[58]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=What%20went%20wrong">[60]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[138]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=I%20also%20took%20the%20time,when%20reinforcement%20learning%20really%20shines">[139]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=One%20of%20our%20key%20tools,in%20the%20new%20C23%20syntax">[140]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=One%20of%20our%20key%20tools,in%20the%20new%20C23%20syntax">[141]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=We%20survived%20Round%201,so%20nothing%20broke%20beyond%20repair">[143]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=Here%E2%80%99s%20where%20a%20bit%20of,They%20all%20works%20fine">[144]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=Our%20program%20slicer%20crashed%20again,three%20people%20stuck%20on%20it">[145]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=So%20we%20redesigned%20the%20whole,query%20fetched%20only%20distinct%20seeds">[146]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=Not%20long%20after%20we%20made,%E2%80%9D">[147]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=,%E2%80%94%206th%20place">[148]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=match%20at%20L427%20No%20matter,you%20only%20get%20one%20chance">[149]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=The%20idea%20was%20clever%20%E2%80%94,Simple%2C%20elegant%20in%20theory">[152]</a> <a href="https://www.whexy.com/en/posts/aixcc#:~:text=match%20at%20L469%20I%20really,genuinely%20enjoyed%20reading%20their%20code">[154]</a> We lost the AIxCC. So, what now?</p>
<p><a href="https://www.whexy.com/en/posts/aixcc">https://www.whexy.com/en/posts/aixcc</a></p>
<p><a href="https://github.com/Team-Atlanta/aixcc-afc-atlantis#:~:text=Team,">[93]</a> Team-Atlanta/aixcc-afc-atlantis - GitHub</p>
<p><a href="https://github.com/Team-Atlanta/aixcc-afc-atlantis">https://github.com/Team-Atlanta/aixcc-afc-atlantis</a></p>
<p><a href="https://x.com/theori_io/status/1955886400953589901#:~:text=Theori%20on%20X%3A%20,co%2FVF7MbwpViD%20Exploring%20Traces">[113]</a> Theori on X: "So, how did our #AIxCC finalist RoboDuck actually pull ...</p>
<p><a href="https://x.com/theori_io/status/1955886400953589901">https://x.com/theori_io/status/1955886400953589901</a></p>
<p><a href="https://x.com/theori_io/status/1953978623360397373#:~:text=Theori%20on%20X%3A%20,Theori%20BLOG">[114]</a> Theori on X: "Find the full breakdown of how RoboDuck works, from ...</p>
<p><a href="https://x.com/theori_io/status/1953978623360397373">https://x.com/theori_io/status/1953978623360397373</a></p>
<p><a href="https://github.com/theori-io/aixcc-public#:~:text=theori,with%20a%20viewable%20interface">[115]</a> theori-io/aixcc-public: Public results and products from ... - GitHub</p>
<p><a href="https://github.com/theori-io/aixcc-public">https://github.com/theori-io/aixcc-public</a></p>
<p><a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=o2lab%20%20%20%20%2F,53%20%20Public">[123]</a> <a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=cp_config">[124]</a> <a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain#:~:text=mock_crs">[125]</a> GitHub - o2lab/asc-crs-all-you-need-is-a-fuzzing-brain</p>
<p><a href="https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain">https://github.com/o2lab/asc-crs-all-you-need-is-a-fuzzing-brain</a></p>
<p><a href="https://x.com/wenboguo4#:~:text=Wenbo%20Guo%20,is%20not%20very%20well">[134]</a> Wenbo Guo (@WenboGuo4) / X</p>
<p><a href="https://x.com/wenboguo4">https://x.com/wenboguo4</a></p>
<p><a href="https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402#:~:text=AI%20Security%20Tools%20%E2%80%94%20August,to%20Uncover%20Hidden%20Cache">[136]</a> <a href="https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402#:~:text=Tactics%2C%20Payloads%20and%20Real,to%20Uncover%20Hidden%20Cache">[150]</a> AI Security Tools â€” August 2025 - Medium</p>
<p><a href="https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402">https://medium.com/@taleliyahu/ai-security-tools-august-2025-9a6c449f0402</a></p>
<p><a href="https://arpa-h.gov/news-and-events/arpa-h-join-darpa-announcing-ai-cyber-challenge-winners-def-con-33#:~:text=...%20arpa,and%20professors%20from%20five">[137]</a> ARPA-H to join DARPA in announcing AI Cyber Challenge winners ...</p>
<p><a href="https://arpa-h.gov/news-and-events/arpa-h-join-darpa-announcing-ai-cyber-challenge-winners-def-con-33">https://arpa-h.gov/news-and-events/arpa-h-join-darpa-announcing-ai-cyber-challenge-winners-def-con-33</a></p>
<p><a href="https://www.darpa.mil/news/2024/small-business-ai-cyber-challenge#:~:text=DARPA%20Selects%20Small%20Businesses%20to,Track%20have%20been%20automatically">[151]</a> DARPA Selects Small Businesses to Compete in the AI Cyber ...</p>
<p><a href="https://www.darpa.mil/news/2024/small-business-ai-cyber-challenge">https://www.darpa.mil/news/2024/small-business-ai-cyber-challenge</a></p>
<p><a href="https://www.openwall.com/lists/oss-security/2024/08/19/2#:~:text=You%20can%20see%20that%20the,as%20part%20of%20the%20challenge">[153]</a> oss-security - Re: AI Cyber Challenge (AIxCC) semi-final results from DEF CON 32 (2024)</p>
<p><a href="https://www.openwall.com/lists/oss-security/2024/08/19/2">https://www.openwall.com/lists/oss-security/2024/08/19/2</a></p>
<p><a href="https://github.com/42-b3yond-6ug/42-b3yond-6ug-asc#:~:text=This%20repository%20hosts%20our%20team%E2%80%99s,AI%20Cyber%20Challenge%20Semifinal%20Competition">[155]</a> GitHub - 42-b3yond-6ug/42-b3yond-6ug-asc: This repository hosts our teamâ€™s submission to the AI Cyber Challenge Semifinal Competition.</p>
<p><a href="https://github.com/42-b3yond-6ug/42-b3yond-6ug-asc">https://github.com/42-b3yond-6ug/42-b3yond-6ug-asc</a></p>
<p><a href="https://www.youtube.com/watch?v=YdJ6NoxzuKs#:~:text=DEF%20CON%2033%20Video%20Team,look%20behind%20the%20contest%20curtain">[156]</a> DEF CON 33 Video Team - DEFCON AIxCC Lacrosse Team</p>
<p><a href="https://www.youtube.com/watch?v=YdJ6NoxzuKs">https://www.youtube.com/watch?v=YdJ6NoxzuKs</a></p>
<p><a href="https://www.youtube.com/watch?v=uO1LnENZV_4#:~:text=LACROSSE%27s%20AIxCC%20Final%20Submission%20,SIFT%20on%20their%20AIxCC">[157]</a> LACROSSE's AIxCC Final Submission | 01C CTF Radiooo - YouTube</p>
<p><a href="https://www.youtube.com/watch?v=uO1LnENZV_4">https://www.youtube.com/watch?v=uO1LnENZV_4</a></p>
<p><a href="https://www.youtube.com/watch?v=ULJcATTuT9U#:~:text=DARPA%20AI%20Cyber%20Challenge%20,views%20%C2%B7%201%20month%20ago">[158]</a> DARPA AI Cyber Challenge - Team Lacrosse - YouTube</p>
<p><a href="https://www.youtube.com/watch?v=ULJcATTuT9U">https://www.youtube.com/watch?v=ULJcATTuT9U</a></p>
<p><a href="https://archive.aicyberchallenge.com/#:~:text=SHERPA">[159]</a> AIxCC Competition Archive | AIxCC Competition Archive</p>
<p><a href="https://archive.aicyberchallenge.com/">https://archive.aicyberchallenge.com/</a></p>
<p><a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20fuzzing%20finds%20bugs%20that,finds%20bugs%20that%20attackers%20exploit">[160]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Why%20This%20Changes%20Everything">[161]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Paradigm%20Shift">[162]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Stage%201%3A%20Intelligent%20Target%20Selection">[163]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=The%20Problem%3A%20Traditional%20fuzzing%20targets,controlled%20files%2C%20packets%2C%20and%20streams">[164]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%EF%B8%8F%20How%20It%20Works">[165]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L553%20Key%20Prompt,Engineering%20Innovations">[166]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=flowchart%20TD%20A%5B%20OSS,Identify%20Unfuzzed%20Entry%20Points">[167]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=G%20">[168]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=C%20,E">[169]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=D%20,E">[170]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=1,bug%20reports%20with%20repro%20steps">[171]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=False%20Positives%20%26%20Quality%20Control">[172]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=We%20encountered%20,These%20were%20automatically%20triaged">[173]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,disclosed%20responsibly%20to%20maintainers%20with">[174]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,false%20positives%20before%20human%20review">[175]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Impact%3A%20Real%20Bugs%20in%20Production,Software">[176]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,to%20maintainers%20with%20coordinated%20timelines">[177]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,to%20maintainers%20with%20coordinated%20timelines">[178]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Traditional%20Approach%20SHERPA%20Approach%20Target%3A,controlled%20entry%20points">[179]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L650%20Unharnessed%20Fuzzing">[180]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Image%3A%20Kudu%20Logo">[181]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=SHERPA%27s%20Solution%3A%20An%20LLM%20pipeline,packets%2C%20and%20handle%20file%20uploads">[182]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Key%20Prompt%20Engineering%20Innovations">[183]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L521%20Multi,Pipeline">[184]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Multi">[185]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=A%5B%20OSS,Identify%20Unfuzzed%20Entry%20Points">[186]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,to%20maintainers%20with%20coordinated%20timelines">[187]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Bug%20Type%20CWE%20Repo%20Count,415%201">[188]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Bug%20Type%20CWE%20Repo%20Count,415%201">[189]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=Contributors%204">[190]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=,Obsecurus%20Matt%20Lehman">[191]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=What%20makes%20this%20significant%3A">[192]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=%3E%20">[193]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=match%20at%20L621%20Ways%20to,Contribute">[194]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=About">[195]</a> <a href="https://github.com/AIxCyberChallenge/sherpa#:~:text=What%20makes%20this%20significant%3A">[199]</a> GitHub - AIxCyberChallenge/sherpa: Security Harness Engineering for Robust Program Analysis</p>
<p><a href="https://github.com/AIxCyberChallenge/sherpa">https://github.com/AIxCyberChallenge/sherpa</a></p>
<p><a href="https://aicyberchallenge.com/semifinal-competition/#:~:text=During%20the%20AIxCC%20Semifinals%2C%2042,discovering%20and%20patching%20software%20vulnerabilities">[200]</a> AIxCC Semifinal Competition (ASC) - AI Cyber Challenge</p>
<p><a href="https://aicyberchallenge.com/semifinal-competition/">https://aicyberchallenge.com/semifinal-competition/</a></p>
<p><a href="https://team-atlanta.github.io/#:~:text=POSTECH%2C%20with%20proven%20success%20at,world%20approaches%20software%20security%20through">[202]</a> <a href="https://team-atlanta.github.io/#:~:text=cyber%20reasoning%20system%20Atlantis%2C%20which,software%20security%20through%20intelligent%20automation">[203]</a> Team Atlanta</p>
<p><a href="https://team-atlanta.github.io/">https://team-atlanta.github.io/</a></p></section><section class="print-page" id="software-threat_model"><h1 id="software-threat_model-ai-powered-threat-modeling-for-secure-system-design">AI-Powered Threat Modeling for Secure System Design<a class="headerlink" href="#software-threat_model-ai-powered-threat-modeling-for-secure-system-design" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section covers AI-powered threat modeling for secure system design, focusing on open-source tools and prompt-based solutions. Below is a comparison of features across notable open-source tools that assist in early design-time threat modeling.</p>
</div>
<h2 id="software-threat_model-threat-modeling">Threat Modeling<a class="headerlink" href="#software-threat_model-threat-modeling" title="Permanent link">&para;</a></h2>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<ul>
<li>The best use of threat modeling is to improve the security and privacy of a system through early and frequent analysis.</li>
<li>Threat modeling must align with an organizationâ€™s development practices and follow design changes in iterations that are each scoped to manageable portions of the system.</li>
<li>The outcomes of threat modeling are meaningful when they are of value to stakeholders.</li>
<li>Dialog is key to establishing the common understandings that lead to value, while documents record those understandings, and enable measurement.</li>
</ul>
<p><a href="https://www.threatmodelingmanifesto.org/">Threat Modeling Manifesto</a> </p>
</div>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Threat modeling is an investmentâ€”in my view, itâ€™s a good one, because finding and mitigating threats in the design phase of your workload feature can reduce the relative cost of mitigation, compared to finding the threats later. Consistently implementing threat modeling will likely also improve your security posture over time.</p>
<p><a href="https://aws.amazon.com/blogs/security/threat-modeling-your-generative-ai-workload-to-evaluate-security-risk/">https://aws.amazon.com/blogs/security/threat-modeling-your-generative-ai-workload-to-evaluate-security-risk/</a></p>
</div>
<h2 id="software-threat_model-open-source-tools-comparison">Open Source Tools Comparison<a class="headerlink" href="#software-threat_model-open-source-tools-comparison" title="Permanent link">&para;</a></h2>
<p>Comparison of features and capabilities of open-source AI-driven threat modeling tools (focused on early design-phase usage, except AI Security Analyzer which also supports code-level analysis).</p>
<table>
<thead>
<tr>
<th><strong>Tool</strong></th>
<th><strong>Focus &amp; Approach</strong></th>
<th><strong>Key Features</strong></th>
<th><strong>AI / Model Integration</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AWS Threat Designer</strong></td>
<td>Design-phase <strong>automated</strong> threat modeling; Web UI (AWS Cloud stack). Users upload system architecture info (including diagrams) to generate threat models.</td>
<td>â€“ <strong>Architecture diagram analysis:</strong> Multi-modal LLM analyzes system diagrams to identify components and relationships.<br>â€“ <strong>Threat catalog:</strong> Generates a comprehensive list of potential threats with interactive filtering and refinement.<br>â€“ <strong>Iterative replay:</strong> Allows rerunning the model after design changes to see updated risk postures.<br>â€“ <strong>Exports &amp; history:</strong> Supports exporting results to PDF/DOCX and browsing past models in a catalog.</td>
<td>Uses AWS Bedrock with large models (Anthropic Claude 4 Sonnet by default) for NLP and vision; serverless backend. Multimodal <strong>LLM</strong> interprets text and diagrams to generate threats.</td>
</tr>
<tr>
<td><strong>AWS Threat Composer</strong></td>
<td>Design-phase <strong>guided</strong> threat modeling; Web app or VS Code extension. Emphasizes manual brainstorming with structured guidance (â€œthreat model as codeâ€).</td>
<td>â€“ <strong>Data capture:</strong> Records system description, architecture and dataflow diagrams, assumptions, etc., as part of the model.<br>â€“ <strong>Threat grammar:</strong> Uses a prescriptive template to iteratively craft threat statements (with examples and suggestions) instead of starting from scratch.<br>â€“ <strong>Insights dashboard:</strong> Highlights gaps like threats without mitigations, unprioritized threats, category coverage, etc., to answer â€œdid we do enough?â€.<br>â€“ <strong>Packs &amp; export:</strong> Supports reusable threat/mitigation packs for bulk addition (in self-hosted mode), and can generate a consolidated threat model document.</td>
<td>No built-in generative model â€“ focuses on human-driven input with static guidance. <em>(Uses local storage; no data leaves the browser. â€œThreat Grammarâ€ framework provides structure rather than AI generation.)</em></td>
</tr>
<tr>
<td><strong>StrideGPT</strong></td>
<td>Design-phase <strong>automated</strong> STRIDE threat modeling; Streamlit web app or Docker CLI. Given an app description (and optionally diagrams or repo link), it auto-generates a full threat model.</td>
<td>â€“ <strong>STRIDE threats generation:</strong> Uses LLM to output threats categorized by STRIDE (Spoofing, Tampering, etc.) for the provided system description.<br>â€“ <strong><abbr title="The likelihood of a vulnerability being exploited and the potential impact of such an exploit on an organization.">Risk</abbr> &amp; mitigations:</strong> Automatically provides DREAD risk scores and suggests mitigation steps for each identified threat.<br>â€“ <strong>Attack trees &amp; tests:</strong> Produces potential attack paths (attack trees) and even Gherkin-style security test cases based on threats.<br>â€“ <strong>Multi-modal input:</strong> Can accept architecture diagrams or flowcharts for analysis with vision-capable models; also can analyze a projectâ€™s repository (e.g. README) to enrich the threat model.<br>â€“ <strong>No data retention:</strong> Does not store inputs or results on the server, focusing on privacy.</td>
<td>Supports multiple <strong>LLMs</strong> via API or local runtime: OpenAI GPT-4 (and newer GPT-4.1), Anthropic Claude 3/4, Google Gemini (2.0/2.5) and others. Also compatible with self-hosted local models (Ollama, LM Studio). This flexible backend allows using the best available model for analysis.</td>
</tr>
<tr>
<td><strong>AI Security Analyzer</strong></td>
<td>Code-centered <strong>security analyzer</strong> with threat modeling output; CLI tool (Python) that scans an existing codebase to produce security documentation. Geared toward integrating threat modeling in later stages (after code exists) as well as design review.</td>
<td>â€“ <strong>Multi-faceted analysis:</strong> Generates a <em>Security Design Review</em> document which includes threat modeling, attack surface analysis, attack trees, mitigation strategies, and identified vulnerabilities.<br>â€“ <strong>Code-aware threat identification:</strong> Parses project source code (multiple languages: Python, Java, JavaScript, Go, Android, etc.) to find assets, entry points, and potential threats specific to the implementation.<br>â€“ <strong>Automated documentation:</strong> Outputs comprehensive Markdown reports (e.g. <code>security_design.md</code>) that consolidate the security findings and model.<br>â€“ <strong>Flexible deployment:</strong> Can run via Python (Poetry) or Docker; cross-platform support (Windows, MacOS, Linux).</td>
<td>Leverages <strong>LLMs</strong> to analyze code and generate text. Supports multiple model providers: OpenAI API (GPT-4 family), Anthropic (Claude), Google PaLM/Gemini via API, and OpenRouter. The user supplies an API key for the chosen model, and the tool orchestrates prompts to produce the security docs.</td>
</tr>
</tbody>
</table>
<h2 id="software-threat_model-open-source-tools-details">Open Source Tools Details<a class="headerlink" href="#software-threat_model-open-source-tools-details" title="Permanent link">&para;</a></h2>
<h3 id="software-threat_model-aws-threat-designer">AWS Threat Designer<a class="headerlink" href="#software-threat_model-aws-threat-designer" title="Permanent link">&para;</a></h3>
<p>AWS Threat Designer: AI-powered threat modeling for secure system design.</p>
<ul>
<li>See blogpost: <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-threat-modeling-with-generative-ai/">Accelerate threat modeling with generative AI</a> for an in-depth overview of the solution.</li>
</ul>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Effective threat modeling examines data flows, trust boundaries, and potential attack vectors to create a comprehensive security strategy tailored to the specific system.</p>
<p>In a shift-left approach to security, threat modeling serves as a critical early intervention. By implementing <strong>threat modeling during the design phaseâ€”before a single line of code is written</strong>â€”organizations can identify and address potential vulnerabilities at their inception point. </p>
<p>AWS <a href="https://aws.amazon.com/blogs/machine-learning/accelerate-threat-modeling-with-generative-ai/">Accelerate threat modeling with generative AI</a>, JUN 2025 </p>
</div>
<p>Each function generates specialized prompts for different phases of the threat modeling process, including:</p>
<ul>
<li>Asset identification</li>
<li>Data flow analysis</li>
<li>Gap analysis</li>
<li>Threat identification and improvement</li>
<li>Response structuring</li>
</ul>
<p><a href="https://github.com/awslabs/threat-designer/tree/main?tab=readme-ov-file#prerequisites">https://github.com/awslabs/threat-designer/tree/main?tab=readme-ov-file#prerequisites</a></p>
<p>The backend is written in python: threat-designer/backend/threat_designer/</p>
<p>The associated prompts are <a href="https://github.com/awslabs/threat-designer/blob/0554b6a97c08e38bb92504ba13768780adb0301f/backend/threat_designer/prompts.py">https://github.com/awslabs/threat-designer/blob/0554b6a97c08e38bb92504ba13768780adb0301f/backend/threat_designer/prompts.py</a></p>
<p>See also 
1. <a href="https://aws-samples.github.io/threat-technique-catalog-for-aws/Techniques/">https://aws-samples.github.io/threat-technique-catalog-for-aws/Techniques/</a>
2. <a href="https://awssecuritydigest.com/articles/threat-modelling-in-aws">https://awssecuritydigest.com/articles/threat-modelling-in-aws</a></p>
<h4 id="software-threat_model-aws-threat-composer">AWS Threat Composer<a class="headerlink" href="#software-threat_model-aws-threat-composer" title="Permanent link">&para;</a></h4>
<p>A simple threat modeling tool to help humans to reduce time-to-value when threat modeling
<a href="https://github.com/awslabs/threat-composer#readme">https://github.com/awslabs/threat-composer#readme</a></p>
<h3 id="software-threat_model-stride-gpt">STRIDE GPT<a class="headerlink" href="#software-threat_model-stride-gpt" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Features:</p>
<ul>
<li>Simple and user-friendly interface</li>
<li>Generates threat models based on the STRIDE methodology</li>
<li>Multi-modal: Use architecture diagrams, flowcharts, etc. as inputs for threat modelling across all supported vision-capable models</li>
<li>Generates attack trees to enumerate possible attack paths</li>
<li>Suggests possible mitigations for identified threats</li>
<li>Supports DREAD risk scoring for identified threats</li>
<li>Generates Gherkin test cases based on identified threats</li>
<li>GitHub repository analysis for comprehensive threat modelling</li>
<li>No data storage; application details are not saved</li>
<li>Supports models accessed via OpenAI API, Azure OpenAI Service, Google AI API, Mistral API, or locally hosted models via Ollama and ðŸ†• LM Studio Server</li>
<li>Available as a Docker container image for easy deployment</li>
<li>Environment variable support for secure configuration </li>
</ul>
<p><a href="https://github.com/mrwadams/stride-gpt">https://github.com/mrwadams/stride-gpt</a></p>
</div>
<p>The app <a href="https://stridegpt.streamlit.app/">https://stridegpt.streamlit.app/</a> has these tabs</p>
<ul>
<li><a href="https://github.com/mrwadams/stride-gpt/blob/master/threat_model.py">Threat Model</a></li>
<li><a href="https://github.com/mrwadams/stride-gpt/blob/master/attack_tree.py">Attack Tree</a></li>
<li><a href="https://github.com/mrwadams/stride-gpt/blob/master/mitigations.py">Mitigations</a></li>
<li><a href="https://github.com/mrwadams/stride-gpt/blob/master/dread.py">DREAD</a></li>
<li><a href="https://github.com/mrwadams/stride-gpt/blob/master/test_cases.py">Test Cases</a></li>
</ul>
<p>It supports a Bring Your Own LLM Key i.e. you chose the LLM and provide your API key.</p>
<h3 id="software-threat_model-ai-security-analyzer">AI Security Analyzer<a class="headerlink" href="#software-threat_model-ai-security-analyzer" title="Permanent link">&para;</a></h3>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>AI Security Analyzer is a Python-based tool that analyzes your project's codebase and automatically generates detailed security documentation. It supports multiple analysis types:</p>
<ul>
<li>ðŸ”’ Security Design Documentation</li>
<li>ðŸŽ¯ Threat Modeling</li>
<li>ðŸ” Attack Surface Analysis</li>
<li>ðŸŒ³ Attack Tree Analysis</li>
<li>ðŸ›¡ï¸ Mitigation Strategies</li>
<li>ðŸ› Vulnerabilities</li>
</ul>
<p><a href="https://github.com/xvnpw/ai-security-analyzer">https://github.com/xvnpw/ai-security-analyzer</a></p>
<p>generate four different types of security documents:</p>
<ul>
<li>ðŸ”’ Security Design Documentation: Generating detailed security design review.</li>
<li>ðŸŽ¯ Threat Modeling: Performing threat modeling analysis.</li>
<li>ðŸ” Attack Surface Analysis: Identifying potential entry points and vulnerabilities in the projectâ€™s attack surface.</li>
<li>ðŸŒ³ Attack Tree Analysis: Visualizing potential attack vectors and their hierarchies through attack tree.</li>
</ul>
<p><a href="https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/">https://xvnpw.github.io/posts/scaling-threat-modeling-with-ai/</a></p>
</div>
<p>The associated prompts are </p>
<ul>
<li><a href="https://github.com/xvnpw/ai-security-analyzer/blob/dabfc57b6e5da9d99b3df5229fd496a224dac862/ai_security_analyzer/prompts.py">https://github.com/xvnpw/ai-security-analyzer/blob/dabfc57b6e5da9d99b3df5229fd496a224dac862/ai_security_analyzer/prompts.py</a></li>
</ul>
<h2 id="software-threat_model-additional-prompt-resources">Additional Prompt Resources<a class="headerlink" href="#software-threat_model-additional-prompt-resources" title="Permanent link">&para;</a></h2>
<p>Beyond full tools, there are also open-source prompt libraries focused on security threat modeling:</p>
<ul>
<li><strong>Fabric by Daniel Miessler:</strong> A crowdsourced collection of AI prompt â€œpatterns.â€ It includes a <a href="https://github.com/danielmiessler/Fabric/blob/main/data/patterns/create_stride_threat_model/system.md">create_stride_threat_model</a> pattern to guide an LLM in producing a STRIDE-based threat model from a system description and a <a href="https://github.com/danielmiessler/Fabric/blob/main/data/patterns/create_threat_scenarios/system.md">create_threat_scenarios</a> pattern for generating detailed attack scenarios. These patterns can be used with various GPT-based systems to jump-start threat modeling exercises.</li>
<li><strong>Kornelius Security Audit Prompt:</strong> An <a href="https://github.com/scragz/kornelius/blob/main/prompts/audit/security.prompt">open prompt</a> (from the Kornelius project) that provides a template for security auditing via LLMs. This prompt script can be adapted to evaluate a systemâ€™s security posture by enumerating threats and checks.</li>
</ul>
<p>Each of the above resources provides ready-made prompt structures that practitioners can use with their AI of choice to conduct threat modeling, complementing the dedicated tools compared in the table.</p></section><section class="print-page" id="software-claude_code"><h1 id="software-claude_code-overview">Overview<a class="headerlink" href="#software-claude_code-overview" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Abstract</p>
<p>This section looks at some Claude Code setups I use.</p>
<p>I'll add more over time when I'm done playing with them...</p>
</div>
<h2 id="software-claude_code-claude-code-cli-god-mode">Claude Code CLI God Mode<a class="headerlink" href="#software-claude_code-claude-code-cli-god-mode" title="Permanent link">&para;</a></h2>
<p>I use Claude Code CLI as my main tool. </p>
<p>I wanted a way to use other models via Claude Code to </p>
<ul>
<li>reduce Claude Code token usage / cost (currently on Pro plan)</li>
<li>
<p>use the <a href="#introduction-models">best tool for the job</a> but maintain context in Claude Code</p>
<ul>
<li>Gemini is good for large code bases or data given its large context window</li>
<li>ChatGPT is good for debugging </li>
</ul>
</li>
</ul>
<p>There are different ways to achieve this:</p>
<ul>
<li>using proxy routers per <a href="https://youtu.be/EkNfythQNRg">https://youtu.be/EkNfythQNRg</a></li>
<li>using Claude Code as the router via a <a href="https://github.com/alexsmedile/god-cli/blob/main/god-cli.md">Claude Code command</a></li>
</ul>
<p>Having played with the former, I settled on the latter as it worked better </p>
<div class="admonition quote">
<p class="admonition-title">Highlights from the Reddit Community</p>
<p>â€œGemini CLI feels like garbageâ€¦ but it has that huge context window we all love. So I added instructions to CLAUDE.md to have Claude use [Gemini CLI in nonâ€‘interactive mode] when it needs to gather information about a large part of the codebase.â€ </p>
<p>â€œGemini is good at explaining single, independent things â€¦ Claude is good at doing complex tasks that require a lot of memory, deep thinking, reasoning.â€ </p>
<p><a href="https://www.reddit.com/r/ChatGPTCoding/comments/1lm3fxq/gemini_cli_is_awesome_but_only_when_you_make">https://www.reddit.com/r/ChatGPTCoding/comments/1lm3fxq/gemini_cli_is_awesome_but_only_when_you_make</a></p>
</div>
<p>This was then extended as a Claude Code command <code>god-cli</code> to support OpenAI Codex also
<a href="https://github.com/alexsmedile/god-cli/blob/main/god-cli.md">https://github.com/alexsmedile/god-cli/blob/main/god-cli.md</a>.</p>
<p>So a "<a href="https://github.com/alexsmedile/god-cli/blob/main/TEST.md#test-3--multi-agent-sequence">Map repo architecture, find cause of memory leak, and propose a precise patch</a>" prompt to Claude Code would </p>
<ul>
<li>Route to Gemini â†’ architecture map.</li>
<li>Route to Codex â†’ debugging/diagnosis.</li>
<li>Route to Claude â†’ minimal diff patch.</li>
</ul>
<h2 id="software-claude_code-breakthrough-method-of-agile-ai-driven-development">Breakthrough Method of Agile AI-Driven Development<a class="headerlink" href="#software-claude_code-breakthrough-method-of-agile-ai-driven-development" title="Permanent link">&para;</a></h2>
<p>I researched and evaluated different Agent-Based Frameworks for Software Engineering.
<a href="#software-swe_agents_report">Breakthrough Method of Agile AI-Driven Development</a> was the one I selected as being closest to my <a href="#software-introduction-software-10-redux">views</a>.</p>
<p><a href="#software-swe_redux">Software Engineering 1.0 Redux</a> shows this in action with the inputs, chat history, output artifacts.</p>
<p>I added several features that I will merge back:</p>
<ul>
<li>a security architect (Chris)</li>
<li>a vulnerability tech (Tanja) for code analysis<ul>
<li>uses sub-agents to combine traditional SAST, Dependency tools with LLMs</li>
</ul>
</li>
</ul>
<h2 id="software-claude_code-claudemd">CLAUDE.md<a class="headerlink" href="#software-claude_code-claudemd" title="Permanent link">&para;</a></h2>
<p>This <a href="https://gist.githubusercontent.com/dwillitzer/d3d103b850a1ef8ddc14e9b5d99a46f1/raw/3ae752ac06e4c6c07e81d38b98bc566887a58f3b/claude_development_policy.md">CLAUDE.md</a> addresses some of the undesirable behaviors I observed:</p>
<ol>
<li>sycophancy - I prefer my reality raw </li>
<li>code without test - so TDD approach</li>
<li>code without checking for existing code or being overly eager to code</li>
<li>doing something to get the job done - but not the actual documented plan e.g. <ol>
<li>mocks or stubs </li>
<li>instead of installing a documented needed dependency, working around it with a lesser alternative.</li>
</ol>
</li>
</ol>
<h2 id="software-claude_code-takeaways">Takeaways<a class="headerlink" href="#software-claude_code-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Key Takeaways</p>
<ol>
<li>By instructing Claude Code (via a god-cli Command) to route specific tasks to specific CLI tools (Google Gemini CLI, OpenAI Codex CLI), you get the best tool for the job, while saving $.</li>
<li>Breakthrough Method of Agile AI-Driven Development (with my security additions) fits my current views of Software Engineering with GenAI.</li>
<li><a href="https://gist.githubusercontent.com/dwillitzer/d3d103b850a1ef8ddc14e9b5d99a46f1/raw/3ae752ac06e4c6c07e81d38b98bc566887a58f3b/claude_development_policy.md">CLAUDE.md</a> addresses some of the undesirable behaviors I observed.</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: Software Engineering 1.0 Redux</h1><h1 class='nav-section-title-end'>Ended: Software Engineering</h1>
                        <h1 class='nav-section-title' id='section-cybersecurity-models'>
                            CyberSecurity Models <a class='headerlink' href='#section-cybersecurity-models' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="cti_models-cyber_security_models"><h1 id="cti_models-cyber_security_models-overview">Overview<a class="headerlink" href="#cti_models-cyber_security_models-overview" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>CyberSecurity Models are those that are optimized and configured specifically for the CyberSecurity domain via knowledge.</p>
</div>
<h2 id="cti_models-cyber_security_models-benchmark">Benchmark<a class="headerlink" href="#cti_models-cyber_security_models-benchmark" title="Permanent link">&para;</a></h2>
<p><a href="https://arxiv.org/html/2406.07599v3">CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence</a> is a suite of benchmark tasks and datasets to evaluate LLMs in Cyber Threat Intelligence (<abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>). </p>
<figure>
<p><img alt="" src="../assets/images/CTIBench.png" /></p>
</figure>
<p>It consists of:</p>
<ul>
<li>(a) <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-MCQ, a knowledge evaluation dataset comprising multiple-choice questions aimed at testing LLMsâ€™ understanding of crucial <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr> concepts, including standards, threat identification, detection strategies, mitigation techniques, and best practices</li>
<li>(b) <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM, which involves mapping Common Vulnerabilities and Exposures (<abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>) descriptions to Common Weakness Enumeration (<abbr title="CWE Common Weakness Enumeration">CWE</abbr>) categories</li>
<li>(c) <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-VSP, which requires calculating Common Vulnerability Scoring System (<abbr title="Common Vulnerability Scoring System Standard. A framework for scoring the severity of vulnerabilities based on factors such as exploitability and impact.">CVSS</abbr>) scores </li>
<li>(d) <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-ATE, which focuses on extracting MITRE ATT&amp;CK techniques from threat descriptions </li>
<li>(e) <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-TAA, where LLMs are tasked with analyzing publicly available threat reports and attributing them to specific threat actors or malware families</li>
</ul>
<h3 id="cti_models-cyber_security_models-benchmark-usage">Benchmark Usage<a class="headerlink" href="#cti_models-cyber_security_models-benchmark-usage" title="Permanent link">&para;</a></h3>
<p><a href="https://arxiv.org/html/2406.07599v3">CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence</a> is being used by some vendors for their <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr> models e.g.</p>
<ol>
<li>Google <a href="https://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html">https://security.googleblog.com/2025/04/google-launches-sec-gemini-v1-new.html</a> </li>
<li>Cisco <a href="https://huggingface.co/fdtn-ai/Foundation-Sec-8B">https://huggingface.co/fdtn-ai/Foundation-Sec-8B</a></li>
<li>Trend Micro <a href="https://huggingface.co/trend-cybertron">https://huggingface.co/trend-cybertron</a></li>
</ol>
<h3 id="cti_models-cyber_security_models-cti-rcm"><abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM<a class="headerlink" href="#cti_models-cyber_security_models-cti-rcm" title="Permanent link">&para;</a></h3>
<p>The Cyber Threat Intelligence Root Cause Mapping (<abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM) benchmark evaluates an LLM's ability to understand the nuances of vulnerability descriptions, identify vulnerabilities underlying root causes, and accurately classify them according to the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> taxonomy.</p>
<p><abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM includes 1000 <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> --&gt; <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Mappings using the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description only (not <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Reference link content). </p>
<ul>
<li>The 1000 is a random sample of vulnerabilities reported in the year 2024: <a href="https://github.com/xashru/cti-bench/blob/main/data/cti-rcm.tsv">https://github.com/xashru/cti-bench/blob/main/data/cti-rcm.tsv</a> </li>
<li>It also includes 1000 CVES from 2021 <a href="https://github.com/xashru/cti-bench/blob/main/data/cti-rcm-2021.tsv">https://github.com/xashru/cti-bench/blob/main/data/cti-rcm-2021.tsv</a></li>
</ul>
<h3 id="cti_models-cyber_security_models-cti-rcm-exploratory-data-analysis"><abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM Exploratory Data Analysis<a class="headerlink" href="#cti_models-cyber_security_models-cti-rcm-exploratory-data-analysis" title="Permanent link">&para;</a></h3>
<div class="admonition example">
<p class="admonition-title">Exploratory Data Analysis of the <abbr title="CTI Cyber Threat Intelligence.">CTI</abbr>-RCM dataset with code</p>
<p>An Exploratory Data Analysis of the dataset is available in <a href="https://github.com/CyberSecAI/cti_bench_rcm">https://github.com/CyberSecAI/cti_bench_rcm</a>.</p>
</div>
<h4 id="cti_models-cyber_security_models-limitations">Limitations<a class="headerlink" href="#cti_models-cyber_security_models-limitations" title="Permanent link">&para;</a></h4>
<ol>
<li>The dataset is not "known-good" i.e. how do we know the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-<abbr title="CWE Common Weakness Enumeration">CWE</abbr> mappings are correct?<ol>
<li>For comparison, the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Top25 2023 identified <a href="https://www.youtube.com/watch?v=AtBZIAikdL0&amp;list=PLBAUUhONOrO_aB01lOv6XNRTHD4ueFVTp&amp;t=1142s">a significant number of CWEs that were incorrect</a> </li>
</ol>
</li>
<li>The dataset contains a limited number of CWEs per <a href="https://github.com/CyberSecAI/cti_bench_rcm">https://github.com/CyberSecAI/cti_bench_rcm</a><ol>
<li>For comparison, the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Top25 2023 contains ~400 unique CWEs</li>
</ol>
</li>
<li>The dataset contains a limited number of CVEs per <a href="https://github.com/CyberSecAI/cti_bench_rcm">https://github.com/CyberSecAI/cti_bench_rcm</a><ol>
<li>For comparison, the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Top25 2022, 2023 include ~~7K <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>-<abbr title="CWE Common Weakness Enumeration">CWE</abbr> mappings each</li>
</ol>
</li>
<li>The dataset contains 1 <abbr title="CWE Common Weakness Enumeration">CWE</abbr> per <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> <ol>
<li>For comparison, the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Top25 2022, 2023 datasets contain many CWEs with more than 1 <abbr title="CWE Common Weakness Enumeration">CWE</abbr> per <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr></li>
</ol>
</li>
<li>The dataset is highly imbalanced per <a href="https://github.com/CyberSecAI/cti_bench_rcm">https://github.com/CyberSecAI/cti_bench_rcm</a><ol>
<li>Some CWEs appear a lot more than others per <a href="https://github.com/CyberSecAI/cti_bench_rcm">https://github.com/CyberSecAI/cti_bench_rcm</a></li>
</ol>
</li>
<li>The dataset contains the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description only i.e. not the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Reference Information in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> links<ol>
<li>This generally contains more information than the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description alone.</li>
<li>A benchmark dataset should use the full <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> info available in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> including the Reference Content.</li>
<li>For comparison, the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Top25 2022, 2023 mappings relied on the Reference content in many cases because the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description was not sufficient.</li>
</ol>
</li>
<li>The evaluation is a binary equals per <a href="https://github.com/xashru/cti-bench/blob/main/evaluation/evaluation.ipynb">https://github.com/xashru/cti-bench/blob/main/evaluation/evaluation.ipynb</a> i.e. correct if the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> assigned by the model equals the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> in the benchmark dataset. <ol>
<li>Based on my work with the MITRE <abbr title="CWE Common Weakness Enumeration">CWE</abbr>-RCMWG, a model may assign CWEs that are (correctly) more specific (childOf) than the <abbr title="CWE Common Weakness Enumeration">CWE</abbr> in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>. Does this make it "wrong" or "more right"?</li>
<li>An evaluation metric should support this e.g. use distance between benchmark and assigned CWEs, where exact match is distance 0, parent/child is distance 1, grandparent/grandchild or cousin is distance 2.</li>
<li>An evaluation metric should support the case where there is more that one <abbr title="CWE Common Weakness Enumeration">CWE</abbr> for a <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr>.</li>
</ol>
</li>
</ol></section><section class="print-page" id="agents-agents"><h1 id="agents-agents-agents">Agents<a class="headerlink" href="#agents-agents-agents" title="Permanent link">&para;</a></h1>
<h2 id="agents-agents-why-agents">Why Agents?<a class="headerlink" href="#agents-agents-why-agents" title="Permanent link">&para;</a></h2>
<p><a href="https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/why-agents-are-the-next-frontier-of-generative-ai">Why agents are the next frontier of generative AI, July 2024</a></p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>"If one agent can't work well, then why is multi-agent useful?"</p>
<ul>
<li>Grouping tools/responsibilities can give better results. An agent is more likely to succeed on a focused task than if it has to select from dozens of tools.</li>
<li>Separate prompts can give better results. Each prompt can have its own instructions and few-shot examples. Each agent could even be powered by a separate fine-tuned LLM!</li>
<li>Helpful conceptual model to develop. You can evaluate and improve each agent individually without breaking the larger application.</li>
</ul>
<p>Multi-agent designs allow you to divide complicated problems into tractable units of work that can be targeted by specialized agents and LLM programs.</p>
<p><a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/">https://blog.langchain.dev/langgraph-multi-agent-workflows/</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Using Agents can significantly improve performance</p>
<p><figure markdown>
<img alt="" src="../assets/images/agents.webp" />
</figure></p>
<p>GPT-3.5 (zero shot) was 48.1% correct. GPT-4 (zero shot) does better at 67.0%. However, the improvement from GPT-3.5 to GPT-4 is dwarfed by incorporating an iterative agent workflow. Indeed, wrapped in an agent loop, GPT-3.5 achieves up to 95.1%.
 <a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance">https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance</a></p>
<p>An agentic workflow in which the LLM is prompted to focus on one thing at a time can give better performance.
<a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Agentic AI Design Patterns</p>
<ol>
<li><strong><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection?ref=dl-staging-website.ghost.io">Reflection</a></strong>: The LLM examines its own work to come up with ways to improve it. </li>
<li><strong><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use">Tool Use</a></strong>: The LLM is given tools such as web search, code execution, or any other function to help it gather information, take action, or process data.</li>
<li><strong><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io">Planning</a></strong>: The LLM comes up with, and executes, a multistep plan to achieve a goal (for example, writing an outline for an essay, then doing online research, then writing a draft, and so on).</li>
<li><strong><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io">Multi-agent collaboration</a></strong>: More than one AI agent work together, splitting up tasks and discussing and debating ideas, to come up with better solutions than a single agent would.</li>
</ol>
<p><a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance">https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance</a></p>
</div>
<div class="admonition quote">
<p class="admonition-title">Reflection using a multi-agent framework</p>
<p>Further, we can implement Reflection using a multi-agent framework. I've found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent's output. The resulting discussion between the two agents leads to improved responses.</p>
<p><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/</a></p>
<p>Like the design pattern of Planning, I find the output quality of multi-agent collaboration hard to predict, especially when allowing agents to interact freely and providing them with multiple tools. The more mature patterns of Reflection and Tool Use are more reliable.</p>
<p><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/</a></p>
</div>
<h2 id="agents-agents-llms-in-production">LLMs in Production<a class="headerlink" href="#agents-agents-llms-in-production" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://www.louisbouchard.ai/book-towards-ai/">Building LLMs for Production: Enhancing LLM Abilities and Reliability with Prompting, Fine-Tuning, and RAG</a>, October 2024, Louis-Francois Bouchard and Louie Peters</li>
<li><a href="https://www.manning.com/books/llms-in-production">LLMs in Production From language models to successful products</a>, December 2024, Christopher Brousseau and Matthew Sharp</li>
<li><a href="https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/">The Shift from Models to Compound AI Systems</a>, Feb 18, 2024</li>
<li><a href="https://github.com/PacktPublishing/LLM-Engineers-Handbook">LLM Engineer's Handbook</a>, by Paul Iusztin and Maxime Labonne, Oct 2024</li>
<li><a href="https://applied-llms.org/">What Weâ€™ve Learned From A Year of Building with LLMs. A practical guide to building successful LLM products, covering the tactical, operational, and strategic.</a>, June 2024</li>
<li><a href="https://research.google/pubs/an-introduction-to-googles-approach-for-secure-ai-agents/">Google's Approach for Secure AI Agents</a>, Santiago (Sal) DÃ­az Christoph Kern Kara Olive, Google (2025)</li>
</ol>
<h2 id="agents-agents-agents-in-production">Agents in Production<a class="headerlink" href="#agents-agents-agents-in-production" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://www.anthropic.com/research/building-effective-agents">Building effective agents (Anthropic)</a>, Dec 19, 2024</li>
<li>Pitfalls and Best Practices â€” 5 lessons from LLMs in Production, Raza Habib, LLMs in Prod Con 2 <a href="https://www.youtube.com/watch?v=TRAUNcPj8KU">https://www.youtube.com/watch?v=TRAUNcPj8KU</a> </li>
<li>Generative AI Agents in Production: Best Practices and Lessons Learned, Patrick Marlow <a href="https://www.youtube.com/watch?v=3y17VO3C8jo">https://www.youtube.com/watch?v=3y17VO3C8jo</a> and whitepaper <a href="https://www.kaggle.com/whitepaper-agents">https://www.kaggle.com/whitepaper-agents</a></li>
<li>Fine-Tuning LLMs: Best Practices and When to Go Small, Mark Kim-Huang, MLOps Meetup <a href="https://www.youtube.com/watch?v=1WSUfWojoe0">https://www.youtube.com/watch?v=1WSUfWojoe0</a> </li>
<li>Everything you ever wanted to know about LLMOps Maturity Models, Alex Strick van Linschoten
Nov 26, 2024 <a href="https://www.zenml.io/blog/everything-you-ever-wanted-to-know-about-llmops-maturity-models">https://www.zenml.io/blog/everything-you-ever-wanted-to-know-about-llmops-maturity-models</a></li>
<li>A comprehensive collection of over 300 real-world generative AI implementations that showcases how organizations are successfully deploying LLMs in production <a href="https://www.zenml.io/blog/demystifying-llmops-a-practical-database-of-real-world-generative-ai-implementations">https://www.zenml.io/blog/demystifying-llmops-a-practical-database-of-real-world-generative-ai-implementations</a></li>
<li><a href="https://www.youtube.com/watch?v=kJLiOGle3Lw">Stanford Webinar - Agentic AI: A Progression of Language Model Usage</a> and a <a href="https://www.linkedin.com/posts/maryammiradi_the-1-hour-stanford-agentic-ai-webinar-is-activity-7340100313997012994-Ax4B">list of 40 takeaways</a> </li>
</ol>
<h2 id="agents-agents-references">References<a class="headerlink" href="#agents-agents-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://huggingface.co/spaces/galileo-ai/agent-leaderboard">https://huggingface.co/spaces/galileo-ai/agent-leaderboard</a> "How do top LLMs perform in real-world agentic scenarios?"</li>
<li><a href="https://github.com/Jason2Brownlee/awesome-llm-books">https://github.com/Jason2Brownlee/awesome-llm-books</a> a list of "Awesome LLM Books"</li>
<li><a href="https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance">https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance</a><ol>
<li><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection</a></li>
<li><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use</a></li>
<li><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning</a></li>
<li><a href="https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration">https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration</a></li>
</ol>
</li>
<li><a href="https://www.linkedin.com/pulse/potential-impact-future-ai-agents-agentic-series-part-44-techwards-84h3f">https://www.linkedin.com/pulse/potential-impact-future-ai-agents-agentic-series-part-44-techwards-84h3f</a></li>
<li><a href="https://www.resilientcyber.io/p/agentic-ais-intersection-with-cybersecurity">https://www.resilientcyber.io/p/agentic-ais-intersection-with-cybersecurity</a></li>
<li><a href="https://blog.langchain.dev/langgraph-multi-agent-workflows/">https://blog.langchain.dev/langgraph-multi-agent-workflows/</a></li>
<li>Mixture-of-Agents Enhances Large Language Model Capabilities, June 2024, <a href="https://arxiv.org/abs/2406.04692">https://arxiv.org/abs/2406.04692</a></li>
<li>Data Interpreter: An LLM Agent For Data Science, Mar 2024, <a href="https://arxiv.org/abs/2402.18679">https://arxiv.org/abs/2402.18679</a></li>
<li>AgentCoder: Multi-Agent Code Generation with Effective Testing and Self-optimisation, May 2024, <a href="https://arxiv.org/html/2312.13010v3">https://arxiv.org/html/2312.13010v3</a> </li>
<li>The COMPLETE TRUTH About AI Agents (2024) <a href="https://www.youtube.com/watch?v=HGS5LfyxLUU">https://www.youtube.com/watch?v=HGS5LfyxLUU</a></li>
<li>Securing Agentic AI: A Comprehensive Threat Model and Mitigation Framework for Generative AI Agents, Apr 2025, <a href="https://arxiv.org/html/2504.19956v1">https://arxiv.org/html/2504.19956v1</a></li>
</ol></section><section class="print-page" id="agents-build_agents"><h1 id="agents-build_agents-building-multi-agent-systems">Building Multi Agent Systems<a class="headerlink" href="#agents-build_agents-building-multi-agent-systems" title="Permanent link">&para;</a></h1>
<div class="admonition overview">
<p class="admonition-title">Overview</p>
<p>Here we will discuss how to build a multi agent system using LangChain and LangGraph.</p>
<p>We will illustrate the architecture of the system using a Mermaid diagram (generated via a GPT).</p>
<p>We will then convert the diagram to LangChain and LangGraph code (using a GPT)</p>
</div>
<div class="admonition tip">
<p class="admonition-title">No code solutions to building Multi Agent Systems are also available</p>
<p>Some examples:</p>
<ul>
<li><a href="https://github.com/LangChain-ai/langgraph-studio">LangGraph Studio</a> </li>
<li><a href="https://github.com/FlowiseAI/Flowise">Flowise</a> </li>
</ul>
</div>
<div class="admonition tip">
<p class="admonition-title">The building/coding of these agents was AI-assisted</p>
<ol>
<li><strong>Architecture Diagram</strong>: Bootstrap Mermaid diagram was created (using Claude 3.5 Sonnet)</li>
<li><strong>Code</strong>: Bootstrap code was generated from the Architecture Diagram (using Claude 3.5 Sonnet)</li>
<li><strong>Code Editor</strong>: Cursor AI was used (with Claude 3.5 Sonnet)</li>
<li><strong>Documentation</strong>: CrewAI.com <a href="https://chatg.pt/DWjSBZn">Chat with our docs</a> link (ChatGPT agent). This was also used to generate code snippets as an answer to a question.</li>
</ol>
</div>
<h2 id="agents-build_agents-multi-agent-systems-problem-and-solution-space">Multi Agent Systems Problem and Solution Space<a class="headerlink" href="#agents-build_agents-multi-agent-systems-problem-and-solution-space" title="Permanent link">&para;</a></h2>
<p>For open-ended problems, <a href="https://react-lm.github.io/">ReAct</a> is appropriate.</p>
<p>But for smaller Problem and Solution Spaces (more bounded), agents and their tools can be more defined and deterministic, and this allows for more optimization.</p>
<h2 id="agents-build_agents-multi-agent-systems-frameworks">Multi Agent Systems Frameworks<a class="headerlink" href="#agents-build_agents-multi-agent-systems-frameworks" title="Permanent link">&para;</a></h2>
<p>There are several frameworks for building Multi Agent Systems (MAS), and many more being developed.</p>
<p>Example popular frameworks:</p>
<ul>
<li><a href="https://www.crewai.com/">CrewAI</a> (built on LangChain)</li>
<li><a href="https://microsoft.github.io/autogen/">AutoGen</a> (by Microsoft)</li>
<li><a href="https://github.com/kyegomez/swarms">Swarms</a></li>
</ul>
<p>Some frameworks are best suited to more complex multi agent use cases - where autonomy and conversation is required. 
    * Chatty can be expensive in time and money as its more LLM calls.
* they can also be useful for rapid prototyping and development of Multi Agent Systems - getting a working system quickly, that can then be optimized and customized with a lower level framework.</p>
<p>For simpler use cases, where we want to prescribe/control how agents interact with each other, we can use LangChain and LangGraph (or no-code solution based on LangGraph).</p>
<ul>
<li>LangChain does have <a href="https://python.langchain.com/v0.1/docs/expression_language/">LCEL (LangChain Expression Language)</a> but <a href="https://www.youtube.com/watch?v=_yFfc5YB5Xc">LangGraph on LangChain may be a better option</a>.  </li>
<li>Another option again is to write (and maintain) your own plumbing to get a simpler Multi Agent System. And it seems like lots of people are rolling their own.</li>
</ul>
<p>My requirements here are:</p>
<ol>
<li>Minimal Time-To-Value and Time-To-Learning from the initial solution</li>
<li>Support by tools</li>
<li>including Observability tooling e.g. <a href="https://langfuse.com/">LangFuse</a>, <a href="https://www.langchain.com/langsmith">LangSmith</a>, <a href="https://www.langtrace.ai/">LangTrace</a> </li>
<li>Representation and support for production Deployment on Cloud platforms (AWS, GCP)</li>
</ol>
<h2 id="agents-build_agents-architecture">Architecture<a class="headerlink" href="#agents-build_agents-architecture" title="Permanent link">&para;</a></h2>
<pre  class="mermaid"><code>
graph TD
    Start((Start)) --> A[Get Vulnerability Description]
    A --> |Vulnerability Description| C[Extract vulnerability keyphrases from Vulnerability Description]
    C --> |Vulnerability KeyPhrases| D[Get CVEs with similar weakness keyphrases \nfrom CWE Observed Examples]
    C --> |Vulnerability KeyPhrases| E[Get CVEs with similar weakness keyphrases \nfrom Top25 CWE Mappings]
    C --> |Vulnerability KeyPhrases| I[Get CVEs with similar weakness keyphrases \nfrom NVD]
    A-. Vulnerability Description .-> R

    D --> R[Create report]
    E --> R[Create report]
    I --> R[Create report]
    R --> |Draft Report|G[Review Report]
    G -->|Human feedback| G
    G --> |Final Report|End((End))
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Text from the <abbr title="National Vulnerability Database">NVD</abbr> References could also be retrieved to augment the report input, as sometimes they contain information that is not in the <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Description. </p>
<p>That has not been done here (yet) and is not shown in the diagram.</p>
</div>
<p>Diagram Code
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#agents-build_agents-__codelineno-0-1"></a>graph TD
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#agents-build_agents-__codelineno-0-2"></a>    Start((Start)) --&gt; A[Vulnerability Description]
<a id="__codelineno-0-3" name="__codelineno-0-3" href="#agents-build_agents-__codelineno-0-3"></a>    A --&gt; |Vulnerability Description| C[Extract vulnerability keyphrases from Vulnerability Description]
<a id="__codelineno-0-4" name="__codelineno-0-4" href="#agents-build_agents-__codelineno-0-4"></a>    C --&gt; |Vulnerability Description\nVulnerability KeyPhrases| D[Get CVEs with similar weakness keyphrases \nfrom CWE Observed Examples]
<a id="__codelineno-0-5" name="__codelineno-0-5" href="#agents-build_agents-__codelineno-0-5"></a>    C --&gt; |Vulnerability Description\nVulnerability KeyPhrases| E[Get CVEs with similar weakness keyphrases \nfrom Top25 CWE Mappings]
<a id="__codelineno-0-6" name="__codelineno-0-6" href="#agents-build_agents-__codelineno-0-6"></a>    C --&gt; |Vulnerability Description\nVulnerability KeyPhrases| I[Get CVEs with similar weakness keyphrases \nfrom NVD]
<a id="__codelineno-0-7" name="__codelineno-0-7" href="#agents-build_agents-__codelineno-0-7"></a>    D --&gt; R[Create report]
<a id="__codelineno-0-8" name="__codelineno-0-8" href="#agents-build_agents-__codelineno-0-8"></a>    E --&gt; R[Create report]
<a id="__codelineno-0-9" name="__codelineno-0-9" href="#agents-build_agents-__codelineno-0-9"></a>    I --&gt; R[Create report]
<a id="__codelineno-0-10" name="__codelineno-0-10" href="#agents-build_agents-__codelineno-0-10"></a>    R --&gt; |Draft Report|G[Review Report]
<a id="__codelineno-0-11" name="__codelineno-0-11" href="#agents-build_agents-__codelineno-0-11"></a>    G --&gt;|Human feedback| G
<a id="__codelineno-0-12" name="__codelineno-0-12" href="#agents-build_agents-__codelineno-0-12"></a>    G --&gt; |Final Report|End((End))
</code></pre></div></p>
<h2 id="agents-build_agents-architecture-to-code">Architecture to Code<a class="headerlink" href="#agents-build_agents-architecture-to-code" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#agents-build_agents-__codelineno-1-1"></a>I want to create a LangGraph multi agent system based on this diagram
</code></pre></div>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#agents-build_agents-__codelineno-2-1"></a>I want to create a CrewAI multi agent system based on this diagram
</code></pre></div>
Claude 3.5 Sonnet</p>
<h2 id="agents-build_agents-multi-agent-system-skeleton-code">Multi Agent System Skeleton Code<a class="headerlink" href="#agents-build_agents-multi-agent-system-skeleton-code" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#agents-build_agents-__codelineno-3-1"></a>#from typing import TypedDict, Annotated, Sequence
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#agents-build_agents-__codelineno-3-2"></a>from langchain_core.messages import BaseMessage
<a id="__codelineno-3-3" name="__codelineno-3-3" href="#agents-build_agents-__codelineno-3-3"></a>from langgraph.graph import StateGraph, Graph
<a id="__codelineno-3-4" name="__codelineno-3-4" href="#agents-build_agents-__codelineno-3-4"></a>from langchain_core.runnables import RunnableBinding
<a id="__codelineno-3-5" name="__codelineno-3-5" href="#agents-build_agents-__codelineno-3-5"></a>from langchain.pydantic_v1 import BaseModel, Field
<a id="__codelineno-3-6" name="__codelineno-3-6" href="#agents-build_agents-__codelineno-3-6"></a>from langchain_core.prompts import ChatPromptTemplate
<a id="__codelineno-3-7" name="__codelineno-3-7" href="#agents-build_agents-__codelineno-3-7"></a>from langchain_openai import ChatOpenAI
<a id="__codelineno-3-8" name="__codelineno-3-8" href="#agents-build_agents-__codelineno-3-8"></a>import asyncio
<a id="__codelineno-3-9" name="__codelineno-3-9" href="#agents-build_agents-__codelineno-3-9"></a>
<a id="__codelineno-3-10" name="__codelineno-3-10" href="#agents-build_agents-__codelineno-3-10"></a># Define the state
<a id="__codelineno-3-11" name="__codelineno-3-11" href="#agents-build_agents-__codelineno-3-11"></a>class AgentState(TypedDict):
<a id="__codelineno-3-12" name="__codelineno-3-12" href="#agents-build_agents-__codelineno-3-12"></a>    messages: Annotated[Sequence[BaseMessage], &quot;The messages in the conversation&quot;]
<a id="__codelineno-3-13" name="__codelineno-3-13" href="#agents-build_agents-__codelineno-3-13"></a>    vulnerability_description: Annotated[str, &quot;The original vulnerability description&quot;]
<a id="__codelineno-3-14" name="__codelineno-3-14" href="#agents-build_agents-__codelineno-3-14"></a>    vulnerability_keyphrases: Annotated[list, &quot;Extracted keyphrases from the vulnerability description&quot;]
<a id="__codelineno-3-15" name="__codelineno-3-15" href="#agents-build_agents-__codelineno-3-15"></a>    cwe_observed_cves: Annotated[list, &quot;CVEs from CWE Observed Examples&quot;]
<a id="__codelineno-3-16" name="__codelineno-3-16" href="#agents-build_agents-__codelineno-3-16"></a>    top25_cwe_cves: Annotated[list, &quot;CVEs from Top25 CWE Mappings&quot;]
<a id="__codelineno-3-17" name="__codelineno-3-17" href="#agents-build_agents-__codelineno-3-17"></a>    nvd_cves: Annotated[list, &quot;CVEs from NVD&quot;]
<a id="__codelineno-3-18" name="__codelineno-3-18" href="#agents-build_agents-__codelineno-3-18"></a>    draft_report: Annotated[str, &quot;The draft report&quot;]
<a id="__codelineno-3-19" name="__codelineno-3-19" href="#agents-build_agents-__codelineno-3-19"></a>    final_report: Annotated[str, &quot;The final report&quot;]
<a id="__codelineno-3-20" name="__codelineno-3-20" href="#agents-build_agents-__codelineno-3-20"></a>
<a id="__codelineno-3-21" name="__codelineno-3-21" href="#agents-build_agents-__codelineno-3-21"></a># Initialize the language model
<a id="__codelineno-3-22" name="__codelineno-3-22" href="#agents-build_agents-__codelineno-3-22"></a>llm = ChatOpenAI(temperature=0)
<a id="__codelineno-3-23" name="__codelineno-3-23" href="#agents-build_agents-__codelineno-3-23"></a>
<a id="__codelineno-3-24" name="__codelineno-3-24" href="#agents-build_agents-__codelineno-3-24"></a># Define the agents
<a id="__codelineno-3-25" name="__codelineno-3-25" href="#agents-build_agents-__codelineno-3-25"></a>
<a id="__codelineno-3-26" name="__codelineno-3-26" href="#agents-build_agents-__codelineno-3-26"></a>def extract_keyphrases(state):
<a id="__codelineno-3-27" name="__codelineno-3-27" href="#agents-build_agents-__codelineno-3-27"></a>    prompt = ChatPromptTemplate.from_template(
<a id="__codelineno-3-28" name="__codelineno-3-28" href="#agents-build_agents-__codelineno-3-28"></a>        &quot;Extract key phrases related to the vulnerability from the following description: {vulnerability_description}&quot;
<a id="__codelineno-3-29" name="__codelineno-3-29" href="#agents-build_agents-__codelineno-3-29"></a>    )
<a id="__codelineno-3-30" name="__codelineno-3-30" href="#agents-build_agents-__codelineno-3-30"></a>    chain = prompt | llm
<a id="__codelineno-3-31" name="__codelineno-3-31" href="#agents-build_agents-__codelineno-3-31"></a>    response = chain.invoke({&quot;vulnerability_description&quot;: state[&quot;vulnerability_description&quot;]})
<a id="__codelineno-3-32" name="__codelineno-3-32" href="#agents-build_agents-__codelineno-3-32"></a>    keyphrases = response.content.split(&quot;, &quot;)
<a id="__codelineno-3-33" name="__codelineno-3-33" href="#agents-build_agents-__codelineno-3-33"></a>    return {&quot;vulnerability_keyphrases&quot;: keyphrases}
<a id="__codelineno-3-34" name="__codelineno-3-34" href="#agents-build_agents-__codelineno-3-34"></a>
<a id="__codelineno-3-35" name="__codelineno-3-35" href="#agents-build_agents-__codelineno-3-35"></a>async def get_cwe_observed_cves(state):
<a id="__codelineno-3-36" name="__codelineno-3-36" href="#agents-build_agents-__codelineno-3-36"></a>    # Simulating an asynchronous API call
<a id="__codelineno-3-37" name="__codelineno-3-37" href="#agents-build_agents-__codelineno-3-37"></a>    await asyncio.sleep(1)
<a id="__codelineno-3-38" name="__codelineno-3-38" href="#agents-build_agents-__codelineno-3-38"></a>    # In a real scenario, you would query a CVE database here
<a id="__codelineno-3-39" name="__codelineno-3-39" href="#agents-build_agents-__codelineno-3-39"></a>    return {&quot;cwe_observed_cves&quot;: [&quot;CVE-2021-1234&quot;, &quot;CVE-2022-5678&quot;]}
<a id="__codelineno-3-40" name="__codelineno-3-40" href="#agents-build_agents-__codelineno-3-40"></a>
<a id="__codelineno-3-41" name="__codelineno-3-41" href="#agents-build_agents-__codelineno-3-41"></a>async def get_top25_cwe_cves(state):
<a id="__codelineno-3-42" name="__codelineno-3-42" href="#agents-build_agents-__codelineno-3-42"></a>    await asyncio.sleep(1)
<a id="__codelineno-3-43" name="__codelineno-3-43" href="#agents-build_agents-__codelineno-3-43"></a>    return {&quot;top25_cwe_cves&quot;: [&quot;CVE-2020-9876&quot;, &quot;CVE-2023-4321&quot;]}
<a id="__codelineno-3-44" name="__codelineno-3-44" href="#agents-build_agents-__codelineno-3-44"></a>
<a id="__codelineno-3-45" name="__codelineno-3-45" href="#agents-build_agents-__codelineno-3-45"></a>async def get_nvd_cves(state):
<a id="__codelineno-3-46" name="__codelineno-3-46" href="#agents-build_agents-__codelineno-3-46"></a>    await asyncio.sleep(1)
<a id="__codelineno-3-47" name="__codelineno-3-47" href="#agents-build_agents-__codelineno-3-47"></a>    return {&quot;nvd_cves&quot;: [&quot;CVE-2019-8765&quot;, &quot;CVE-2024-1111&quot;]}
<a id="__codelineno-3-48" name="__codelineno-3-48" href="#agents-build_agents-__codelineno-3-48"></a>
<a id="__codelineno-3-49" name="__codelineno-3-49" href="#agents-build_agents-__codelineno-3-49"></a>def create_report(state):
<a id="__codelineno-3-50" name="__codelineno-3-50" href="#agents-build_agents-__codelineno-3-50"></a>    prompt = ChatPromptTemplate.from_template(
<a id="__codelineno-3-51" name="__codelineno-3-51" href="#agents-build_agents-__codelineno-3-51"></a>        &quot;Create a comprehensive report based on the following information:\n&quot;
<a id="__codelineno-3-52" name="__codelineno-3-52" href="#agents-build_agents-__codelineno-3-52"></a>        &quot;Vulnerability Description: {vulnerability_description}\n&quot;
<a id="__codelineno-3-53" name="__codelineno-3-53" href="#agents-build_agents-__codelineno-3-53"></a>        &quot;Key Phrases: {vulnerability_keyphrases}\n&quot;
<a id="__codelineno-3-54" name="__codelineno-3-54" href="#agents-build_agents-__codelineno-3-54"></a>        &quot;CVEs from CWE Observed Examples: {cwe_observed_cves}\n&quot;
<a id="__codelineno-3-55" name="__codelineno-3-55" href="#agents-build_agents-__codelineno-3-55"></a>        &quot;CVEs from Top25 CWE Mappings: {top25_cwe_cves}\n&quot;
<a id="__codelineno-3-56" name="__codelineno-3-56" href="#agents-build_agents-__codelineno-3-56"></a>        &quot;CVEs from NVD: {nvd_cves}\n&quot;
<a id="__codelineno-3-57" name="__codelineno-3-57" href="#agents-build_agents-__codelineno-3-57"></a>        &quot;Provide a detailed analysis and recommendations.&quot;
<a id="__codelineno-3-58" name="__codelineno-3-58" href="#agents-build_agents-__codelineno-3-58"></a>    )
<a id="__codelineno-3-59" name="__codelineno-3-59" href="#agents-build_agents-__codelineno-3-59"></a>    chain = prompt | llm
<a id="__codelineno-3-60" name="__codelineno-3-60" href="#agents-build_agents-__codelineno-3-60"></a>    response = chain.invoke(state)
<a id="__codelineno-3-61" name="__codelineno-3-61" href="#agents-build_agents-__codelineno-3-61"></a>    return {&quot;draft_report&quot;: response.content}
<a id="__codelineno-3-62" name="__codelineno-3-62" href="#agents-build_agents-__codelineno-3-62"></a>
<a id="__codelineno-3-63" name="__codelineno-3-63" href="#agents-build_agents-__codelineno-3-63"></a>def review_report(state):
<a id="__codelineno-3-64" name="__codelineno-3-64" href="#agents-build_agents-__codelineno-3-64"></a>    prompt = ChatPromptTemplate.from_template(
<a id="__codelineno-3-65" name="__codelineno-3-65" href="#agents-build_agents-__codelineno-3-65"></a>        &quot;Review and improve the following report:\n{draft_report}\n&quot;
<a id="__codelineno-3-66" name="__codelineno-3-66" href="#agents-build_agents-__codelineno-3-66"></a>        &quot;Provide any necessary corrections or additions.&quot;
<a id="__codelineno-3-67" name="__codelineno-3-67" href="#agents-build_agents-__codelineno-3-67"></a>    )
<a id="__codelineno-3-68" name="__codelineno-3-68" href="#agents-build_agents-__codelineno-3-68"></a>    chain = prompt | llm
<a id="__codelineno-3-69" name="__codelineno-3-69" href="#agents-build_agents-__codelineno-3-69"></a>    response = chain.invoke(state)
<a id="__codelineno-3-70" name="__codelineno-3-70" href="#agents-build_agents-__codelineno-3-70"></a>    return {&quot;final_report&quot;: response.content}
<a id="__codelineno-3-71" name="__codelineno-3-71" href="#agents-build_agents-__codelineno-3-71"></a>
<a id="__codelineno-3-72" name="__codelineno-3-72" href="#agents-build_agents-__codelineno-3-72"></a># Define the graph
<a id="__codelineno-3-73" name="__codelineno-3-73" href="#agents-build_agents-__codelineno-3-73"></a>workflow = StateGraph(AgentState)
<a id="__codelineno-3-74" name="__codelineno-3-74" href="#agents-build_agents-__codelineno-3-74"></a>
<a id="__codelineno-3-75" name="__codelineno-3-75" href="#agents-build_agents-__codelineno-3-75"></a># Add nodes
<a id="__codelineno-3-76" name="__codelineno-3-76" href="#agents-build_agents-__codelineno-3-76"></a>workflow.add_node(&quot;extract_keyphrases&quot;, extract_keyphrases)
<a id="__codelineno-3-77" name="__codelineno-3-77" href="#agents-build_agents-__codelineno-3-77"></a>workflow.add_node(&quot;get_cwe_observed_cves&quot;, get_cwe_observed_cves)
<a id="__codelineno-3-78" name="__codelineno-3-78" href="#agents-build_agents-__codelineno-3-78"></a>workflow.add_node(&quot;get_top25_cwe_cves&quot;, get_top25_cwe_cves)
<a id="__codelineno-3-79" name="__codelineno-3-79" href="#agents-build_agents-__codelineno-3-79"></a>workflow.add_node(&quot;get_nvd_cves&quot;, get_nvd_cves)
<a id="__codelineno-3-80" name="__codelineno-3-80" href="#agents-build_agents-__codelineno-3-80"></a>workflow.add_node(&quot;create_report&quot;, create_report)
<a id="__codelineno-3-81" name="__codelineno-3-81" href="#agents-build_agents-__codelineno-3-81"></a>workflow.add_node(&quot;review_report&quot;, review_report)
<a id="__codelineno-3-82" name="__codelineno-3-82" href="#agents-build_agents-__codelineno-3-82"></a>
<a id="__codelineno-3-83" name="__codelineno-3-83" href="#agents-build_agents-__codelineno-3-83"></a># Add edges
<a id="__codelineno-3-84" name="__codelineno-3-84" href="#agents-build_agents-__codelineno-3-84"></a>workflow.add_edge(&quot;extract_keyphrases&quot;, &quot;get_cwe_observed_cves&quot;)
<a id="__codelineno-3-85" name="__codelineno-3-85" href="#agents-build_agents-__codelineno-3-85"></a>workflow.add_edge(&quot;extract_keyphrases&quot;, &quot;get_top25_cwe_cves&quot;)
<a id="__codelineno-3-86" name="__codelineno-3-86" href="#agents-build_agents-__codelineno-3-86"></a>workflow.add_edge(&quot;extract_keyphrases&quot;, &quot;get_nvd_cves&quot;)
<a id="__codelineno-3-87" name="__codelineno-3-87" href="#agents-build_agents-__codelineno-3-87"></a>workflow.add_edge(&quot;get_cwe_observed_cves&quot;, &quot;create_report&quot;)
<a id="__codelineno-3-88" name="__codelineno-3-88" href="#agents-build_agents-__codelineno-3-88"></a>workflow.add_edge(&quot;get_top25_cwe_cves&quot;, &quot;create_report&quot;)
<a id="__codelineno-3-89" name="__codelineno-3-89" href="#agents-build_agents-__codelineno-3-89"></a>workflow.add_edge(&quot;get_nvd_cves&quot;, &quot;create_report&quot;)
<a id="__codelineno-3-90" name="__codelineno-3-90" href="#agents-build_agents-__codelineno-3-90"></a>workflow.add_edge(&quot;create_report&quot;, &quot;review_report&quot;)
<a id="__codelineno-3-91" name="__codelineno-3-91" href="#agents-build_agents-__codelineno-3-91"></a>
<a id="__codelineno-3-92" name="__codelineno-3-92" href="#agents-build_agents-__codelineno-3-92"></a># Set entry point
<a id="__codelineno-3-93" name="__codelineno-3-93" href="#agents-build_agents-__codelineno-3-93"></a>workflow.set_entry_point(&quot;extract_keyphrases&quot;)
<a id="__codelineno-3-94" name="__codelineno-3-94" href="#agents-build_agents-__codelineno-3-94"></a>
<a id="__codelineno-3-95" name="__codelineno-3-95" href="#agents-build_agents-__codelineno-3-95"></a># Compile the graph
<a id="__codelineno-3-96" name="__codelineno-3-96" href="#agents-build_agents-__codelineno-3-96"></a>app = workflow.compile()
<a id="__codelineno-3-97" name="__codelineno-3-97" href="#agents-build_agents-__codelineno-3-97"></a>
<a id="__codelineno-3-98" name="__codelineno-3-98" href="#agents-build_agents-__codelineno-3-98"></a># Run the graph
<a id="__codelineno-3-99" name="__codelineno-3-99" href="#agents-build_agents-__codelineno-3-99"></a>config = {&quot;vulnerability_description&quot;: &quot;A buffer overflow vulnerability in the XYZ software allows remote attackers to execute arbitrary code.&quot;}
<a id="__codelineno-3-100" name="__codelineno-3-100" href="#agents-build_agents-__codelineno-3-100"></a>result = app.invoke(config)
<a id="__codelineno-3-101" name="__codelineno-3-101" href="#agents-build_agents-__codelineno-3-101"></a>
<a id="__codelineno-3-102" name="__codelineno-3-102" href="#agents-build_agents-__codelineno-3-102"></a>print(result[&quot;final_report&quot;])
</code></pre></div></section><h1 class='nav-section-title-end'>Ended: CyberSecurity Models</h1>
                        <h1 class='nav-section-title' id='section-topicmodeling'>
                            TopicModeling <a class='headerlink' href='#section-topicmodeling' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="topicmodeling-berttopic"><h1 id="topicmodeling-berttopic-bertopic">BERTopic<a class="headerlink" href="#topicmodeling-berttopic-bertopic" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>Topic modeling can be used to discover the underlying themes and patterns in a collection of documents (e.g. <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> Descriptions, or <abbr title="CWE Common Weakness Enumeration">CWE</abbr> Descriptions,...).</p>
<p>It is an unsupervised machine learning technique thatâ€™s capable of scanning a set of documents, detecting word and phrase patterns within them, and automatically clustering word groups and similar expressions that best characterize the set of documents.</p>
<p>The output is collections of documents that the algorithm has grouped together, as well as clusters of words and expressions that it used to infer these relations.</p>
</div>
<h2 id="topicmodeling-berttopic-bertopic_1">BERTopic<a class="headerlink" href="#topicmodeling-berttopic-bertopic_1" title="Permanent link">&para;</a></h2>
<p>BERTopic is a topic modeling technique that leverages ðŸ¤— transformers and c-TF-IDF. In general, it outperforms other methods (statistical vs Language Model based) e.g. LSA, LDA. </p>
<div class="admonition quote">
<p class="admonition-title">Quote</p>
<p>Before diving into a classification task, text clustering allows for getting an intuitive understanding of the task but also of its complexity.</p>
<p>BERTopic is a topic modeling technique that assumes that clusters of semantically similar documents are a powerful way of generating and describing clusters. The documents in each cluster are expected to describe a major theme and combined they might represent a topic.</p>
<p>Extracts from book co-authored by BertTopic creator: <a href="https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/">https://www.oreilly.com/library/view/hands-on-large-language/9781098150952/</a></p>
</div>
<h2 id="topicmodeling-berttopic-topic-model-cwes">Topic Model CWEs<a class="headerlink" href="#topicmodeling-berttopic-topic-model-cwes" title="Permanent link">&para;</a></h2>
<p>I've used BERTopic to Topic Model lots of datasets to quickly get an intuition for the data.</p>
<p>In this example, we'll look at CWEs. </p>
<ul>
<li>Specifically, generate a Topic Model of the ~1000 CWEs in <a href="https://cwe.mitre.org/data/definitions/1400.html">1400 View</a>, so we can better understand the underlying patterns and themes.</li>
</ul>
<p>I did this initially as part of a <a href="https://www.linkedin.com/feed/update/urn:li:activity:7186373368344920064?commentUrn=urn%3Ali%3Acomment%3A%28activity%3A7186373368344920064%2C7186485198996353024%29&amp;dashCommentUrn=urn%3Ali%3Afsd_comment%3A%287186485198996353024%2Curn%3Ali%3Aactivity%3A7186373368344920064%29">LinkedIn Thread</a>, to illustrate Topic Modeling as a solution, but also the ease and speed at which it could be done.</p>
<h2 id="topicmodeling-berttopic-code">Code<a class="headerlink" href="#topicmodeling-berttopic-code" title="Permanent link">&para;</a></h2>
<div class="admonition example">
<p class="admonition-title">Source Code</p>
<p>The starting point code is deliberately chosen as unrelated to CyberSecurity: <a href="https://github.com/splevine/harnessing-nlp-cx-demo">https://github.com/splevine/harnessing-nlp-cx-demo</a> Mar 2024 (where this repo gives an excellent overview of NLP and BERTopic and SetFit).</p>
<p>The main changes I made were:</p>
<ol>
<li>Don't use wandb (Weights and Balances) service as it was not needed for the demo</li>
<li>Use the 1400 <abbr title="CWE Common Weakness Enumeration">CWE</abbr> view <a href="https://cwe.mitre.org/data/csv/1400.csv.zip">1400.csv</a> as the input Data</li>
<li>Use SentenceTransformer("basel/ATTACK-BERT") as the embedding_model so that CyberSecurity embeddings are used.</li>
</ol>
<p>The code and visualizations are available here: <a href="https://colab.research.google.com/drive/168i3oHekL4Cva2s2w01KMq6mnffDgxIS?usp=sharing">https://colab.research.google.com/drive/168i3oHekL4Cva2s2w01KMq6mnffDgxIS?usp=sharing</a>
No effort was made to optimize the topic modeling i.e. it was completely unsupervised.</p>
</div>
<h2 id="topicmodeling-berttopic-topic-model-of-the-1000-cwes-in-1400-view">Topic Model of the ~1000 CWEs in 1400 View<a class="headerlink" href="#topicmodeling-berttopic-topic-model-of-the-1000-cwes-in-1400-view" title="Permanent link">&para;</a></h2>
<figure>
<p><img alt="" src="../assets/images/1400_classes.png" />
The top level categorizations of <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> 1400 per <a href="https://cwe.mitre.org/data/definitions/1400.html">https://cwe.mitre.org/data/definitions/1400.html</a>.</p>
</figure>
<figure>
<p><img alt="" src="../assets/images/1400_topic_model_data_map.png" />
The Topic Model of 1400 <abbr title="CWE Common Weakness Enumeration">CWE</abbr> view <a href="https://cwe.mitre.org/data/csv/1400.csv.zip">1400.csv</a> with the top level categorizations overlayed in bold to allow comparison of the top level groupings assigned by MITRE and the Topic Modeling.</p>
</figure>
<p>Other visualizations are available in the <a href="https://colab.research.google.com/drive/168i3oHekL4Cva2s2w01KMq6mnffDgxIS?usp=sharing">Colab Notebook</a>.</p>
<h2 id="topicmodeling-berttopic-takeaways">Takeaways<a class="headerlink" href="#topicmodeling-berttopic-takeaways" title="Permanent link">&para;</a></h2>
<div class="admonition success">
<p class="admonition-title">Takeaways</p>
<ol>
<li>Topic Modeling with BERTopic is a powerful unsupervised learning approach to quickly and easily get an intuition for a set of documents.</li>
</ol>
</div></section><h1 class='nav-section-title-end'>Ended: TopicModeling</h1>
                        <h1 class='nav-section-title' id='section-references'>
                            References <a class='headerlink' href='#section-references' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="research-research"><h1 id="research-research-talks-and-research">Talks and Research<a class="headerlink" href="#research-research-talks-and-research" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section highlights relevant talks and research.</p>
</div>
<h2 id="research-research-my-talks-and-research">My Talks and Research<a class="headerlink" href="#research-research-my-talks-and-research" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th><strong>Title</strong></th>
<th><strong>Venue</strong></th>
<th><strong>Author(s)</strong></th>
<th><strong>Date</strong> (YYYY/M)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.youtube.com/watch?v=XBjLAJsm5LA">Leveraging generative AI for efficient <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> enrichment</a></td>
<td>CyberRisk Summit</td>
<td>Chris Madden</td>
<td>2024/11</td>
</tr>
<tr>
<td><a href="https://www.first.org/conference/vulncon2025/program#pVulnerability-Root-Cause-Mapping-with-CWE-Challenges-Solutions-and-Insights-from-Grounded-LLM-based-Analysis">Vulnerability Root Cause Mapping with <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: Challenges, Solutions, and Insights from Grounded LLM-based Analysis</a>. Available soon on <a href="https://www.youtube.com/@FIRSTdotorg">FIRST YouTube</a>.</td>
<td><a href="https://www.first.org/conference/vulncon2025">FIRST VulnCon</a></td>
<td>Chris Madden, Alec Summers</td>
<td>2025/4</td>
</tr>
</tbody>
</table>
<h2 id="research-research-llms-for-cybersecurity-references">LLMs For CyberSecurity References<a class="headerlink" href="#research-research-llms-for-cybersecurity-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://arxiv.org/pdf/2405.12750">Generative AI and Large Language Models for Cyber Security: All Insights You Need</a>, May 2024</li>
<li><a href="https://www.researchgate.net/publication/384500263_A_Comprehensive_Review_of_Large_Language_Models_in_Cyber_Security">A Comprehensive Review of Large Language Models in Cyber Security</a>, September 2024 </li>
<li><a href="https://arxiv.org/pdf/2402.00891">Large Language Models in Cybersecurity: State-of-the-Art</a>, January 2024</li>
<li><a href="https://elie.net/talk/ai-for-cybersecurity-get-started-today">How Large Language Models Are Reshaping the Cybersecurity Landscape</a> | Global AI Symposium talk, September 2024</li>
<li><a href="https://arxiv.org/pdf/2405.04760">Large Language Models for Cyber Security: A Systematic Literature Review</a>, July 2024</li>
<li><a href="https://cloudsecurityalliance.org/artifacts/using-ai-for-offensive-security">Using AI for Offensive Security</a>, June 2024 </li>
</ol>
<h2 id="research-research-llms-and-genai-in-general">LLMs and GenAI in General<a class="headerlink" href="#research-research-llms-and-genai-in-general" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th><strong>Title</strong></th>
<th><strong>Venue</strong></th>
<th><strong>Author(s)</strong></th>
<th><strong>Date</strong> (YYYY/M)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/NFWReport2023_v5.pdf">Microsoft New Future of Work Report 2023</a></td>
<td>Report</td>
<td>Microsoft</td>
<td>2023/12</td>
</tr>
<tr>
<td><a href="https://www.gartner.com/en/articles/intelligent-agent-in-ai">Intelligent Agents in AI Really Can Work Alone. Hereâ€™s How.</a></td>
<td>Post</td>
<td>Gartner</td>
<td>2024/10</td>
</tr>
</tbody>
</table></section><h1 class='nav-section-title-end'>Ended: References</h1>
                        <h1 class='nav-section-title' id='section-annex'>
                            Annex <a class='headerlink' href='#section-annex' title='Permanent link'>â†µ</a>
                        </h1>
                        <section class="print-page" id="annex-learning"><h1 id="annex-learning-learning">Learning<a class="headerlink" href="#annex-learning-learning" title="Permanent link">&para;</a></h1>
<h2 id="annex-learning-books">Books<a class="headerlink" href="#annex-learning-books" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://learning.oreilly.com/api/v1/continue/9781098153427/">Prompt Engineering for Generative AI</a> James Phoenix, Mike Taylor</li>
<li><a href="https://learning.oreilly.com/library/view/hands-on-large-language/9781098150952/">Hands-On Large Language Models</a>   Jay Alammar, Maarten Grootendorst </li>
<li><a href="https://www.manning.com/books/ai-agents-in-action">AI Agents in Action</a>, Publication in Early 2025 (estimated)</li>
<li><a href="https://www.manning.com/books/prompt-engineering-in-practice">Prompt Engineering in Practice</a>, Publication in Spring 2025 (estimated)</li>
<li><a href="https://www.manning.com/books/llms-in-production">LLMs in Production From language models to successful products</a></li>
<li><a href="https://www.manning.com/books/ai-apps-with-langchain">AI Apps with LangChain</a> </li>
<li><a href="https://www.manning.com/books/natural-language-processing-in-action-second-edition">Natural Language Processing in Action, 2nd ed.</a></li>
<li><a href="https://www.manning.com/books/data-storytelling-with-generative-ai">Data Storytelling with Generative AI using Altair and Python</a></li>
<li>langchain in your pocket</li>
</ol>
<h2 id="annex-learning-newsletters">Newsletters<a class="headerlink" href="#annex-learning-newsletters" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://www.deeplearning.ai/the-batch/issue-260/">https://www.deeplearning.ai/the-batch/issue-260/</a></li>
</ol>
<h2 id="annex-learning-lists">Lists<a class="headerlink" href="#annex-learning-lists" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://start.me/p/9oJvxx/applying-llms-genai-to-cyber-security">Applying LLMs &amp; GenAI to Cyber Security (list of resources)</a> Dylan Williams </li>
<li><a href="https://joelbooks.medium.com/top-8-books-about-generative-ai-2024-llms-gpts-diffusion-models-b70663f72686">https://joelbooks.medium.com/top-8-books-about-generative-ai-2024-llms-gpts-diffusion-models-b70663f72686</a></li>
<li><a href="https://emt.gartnerweb.com/ngw/globalassets/en/cybersecurity/documents/predicts-2024-cybersecurity-ai.pdf">https://emt.gartnerweb.com/ngw/globalassets/en/cybersecurity/documents/predicts-2024-cybersecurity-ai.pdf</a></li>
<li><a href="https://www.wardsauto.com/industry/gartner-predicts-highs-and-lows-of-ai-in-cybersecurity">https://www.wardsauto.com/industry/gartner-predicts-highs-and-lows-of-ai-in-cybersecurity</a></li>
</ol>
<h2 id="annex-learning-courses">Courses<a class="headerlink" href="#annex-learning-courses" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://www.deeplearning.ai/">AI and GenAI Courses</a>     |  Andrew Ng and others| </li>
<li>HugginFace courses</li>
</ol></section><section class="print-page" id="annex-glossary"><p><strong>~</strong>: shorthand for "approximately"</p>
<p><strong>~~</strong>: shorthand for "very approximately"</p></section><section class="print-page" id="research-research"><h1 id="research-research-talks-and-research">Talks and Research<a class="headerlink" href="#research-research-talks-and-research" title="Permanent link">&para;</a></h1>
<div class="admonition abstract">
<p class="admonition-title">Overview</p>
<p>This section highlights relevant talks and research.</p>
</div>
<h2 id="research-research-my-talks-and-research">My Talks and Research<a class="headerlink" href="#research-research-my-talks-and-research" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th><strong>Title</strong></th>
<th><strong>Venue</strong></th>
<th><strong>Author(s)</strong></th>
<th><strong>Date</strong> (YYYY/M)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.youtube.com/watch?v=XBjLAJsm5LA">Leveraging generative AI for efficient <abbr title="CVE Common Vulnerability and Exposures. A standardized list of publicly known vulnerabilities and exposures maintained by the MITRE Corporation.">CVE</abbr> enrichment</a></td>
<td>CyberRisk Summit</td>
<td>Chris Madden</td>
<td>2024/11</td>
</tr>
<tr>
<td><a href="https://www.first.org/conference/vulncon2025/program#pVulnerability-Root-Cause-Mapping-with-CWE-Challenges-Solutions-and-Insights-from-Grounded-LLM-based-Analysis">Vulnerability Root Cause Mapping with <abbr title="CWE Common Weakness Enumeration">CWE</abbr>: Challenges, Solutions, and Insights from Grounded LLM-based Analysis</a>. Available soon on <a href="https://www.youtube.com/@FIRSTdotorg">FIRST YouTube</a>.</td>
<td><a href="https://www.first.org/conference/vulncon2025">FIRST VulnCon</a></td>
<td>Chris Madden, Alec Summers</td>
<td>2025/4</td>
</tr>
</tbody>
</table>
<h2 id="research-research-llms-for-cybersecurity-references">LLMs For CyberSecurity References<a class="headerlink" href="#research-research-llms-for-cybersecurity-references" title="Permanent link">&para;</a></h2>
<ol>
<li><a href="https://arxiv.org/pdf/2405.12750">Generative AI and Large Language Models for Cyber Security: All Insights You Need</a>, May 2024</li>
<li><a href="https://www.researchgate.net/publication/384500263_A_Comprehensive_Review_of_Large_Language_Models_in_Cyber_Security">A Comprehensive Review of Large Language Models in Cyber Security</a>, September 2024 </li>
<li><a href="https://arxiv.org/pdf/2402.00891">Large Language Models in Cybersecurity: State-of-the-Art</a>, January 2024</li>
<li><a href="https://elie.net/talk/ai-for-cybersecurity-get-started-today">How Large Language Models Are Reshaping the Cybersecurity Landscape</a> | Global AI Symposium talk, September 2024</li>
<li><a href="https://arxiv.org/pdf/2405.04760">Large Language Models for Cyber Security: A Systematic Literature Review</a>, July 2024</li>
<li><a href="https://cloudsecurityalliance.org/artifacts/using-ai-for-offensive-security">Using AI for Offensive Security</a>, June 2024 </li>
</ol>
<h2 id="research-research-llms-and-genai-in-general">LLMs and GenAI in General<a class="headerlink" href="#research-research-llms-and-genai-in-general" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th><strong>Title</strong></th>
<th><strong>Venue</strong></th>
<th><strong>Author(s)</strong></th>
<th><strong>Date</strong> (YYYY/M)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/12/NFWReport2023_v5.pdf">Microsoft New Future of Work Report 2023</a></td>
<td>Report</td>
<td>Microsoft</td>
<td>2023/12</td>
</tr>
<tr>
<td><a href="https://www.gartner.com/en/articles/intelligent-agent-in-ai">Intelligent Agents in AI Really Can Work Alone. Hereâ€™s How.</a></td>
<td>Post</td>
<td>Gartner</td>
<td>2024/10</td>
</tr>
</tbody>
</table></section><h1 class='nav-section-title-end'>Ended: Annex</h1></div>









  




                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; Contributors to the CyberSecAI Guide.
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="https://github.com/CyberSecAI/CyberSecAI.github.io" target="_blank" rel="noopener" title="Guide" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M575.8 255.5c0 18-15 32.1-32 32.1h-32l.7 160.2c0 2.7-.2 5.4-.5 8.1v16.2c0 22.1-17.9 40-40 40h-16c-1.1 0-2.2 0-3.3-.1-1.4.1-2.8.1-4.2.1L416 512h-24c-22.1 0-40-17.9-40-40v-88c0-17.7-14.3-32-32-32h-64c-17.7 0-32 14.3-32 32v88c0 22.1-17.9 40-40 40h-55.9c-1.5 0-3-.1-4.5-.2-1.2.1-2.4.2-3.6.2h-16c-22.1 0-40-17.9-40-40V360c0-.9 0-1.9.1-2.8v-69.7h-32c-18 0-32-14-32-32.1 0-9 3-17 10-24L266.4 8c7-7 15-8 22-8s15 2 21 7l255.4 224.5c8 7 12 15 11 24z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/CyberSecAI/CyberSecAI.github.io/issues/" target="_blank" rel="noopener" title="Report an Issue or Suggest a Change" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M256 0c53 0 96 43 96 96v3.6c0 15.7-12.7 28.4-28.4 28.4H188.5c-15.7 0-28.4-12.7-28.4-28.4V96c0-53 43-96 96-96zM41.4 105.4c12.5-12.5 32.8-12.5 45.3 0l64 64c.7.7 1.3 1.4 1.9 2.1 14.2-7.3 30.4-11.4 47.5-11.4h112c17.1 0 33.2 4.1 47.5 11.4.6-.7 1.2-1.4 1.9-2.1l64-64c12.5-12.5 32.8-12.5 45.3 0s12.5 32.8 0 45.3l-64 64c-.7.7-1.4 1.3-2.1 1.9 6.2 12 10.1 25.3 11.1 39.5h64.3c17.7 0 32 14.3 32 32s-14.3 32-32 32h-64c0 24.6-5.5 47.8-15.4 68.6 2.2 1.3 4.2 2.9 6 4.8l64 64c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0l-63.1-63.1c-24.5 21.8-55.8 36.2-90.3 39.6V240c0-8.8-7.2-16-16-16s-16 7.2-16 16v239.2c-34.5-3.4-65.8-17.8-90.3-39.6l-63.1 63c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3l64-64c1.9-1.9 3.9-3.4 6-4.8C101.5 367.8 96 344.6 96 320H32c-17.7 0-32-14.3-32-32s14.3-32 32-32h64.3c1.1-14.1 5-27.5 11.1-39.5-.7-.6-1.4-1.2-2.1-1.9l-64-64c-12.5-12.5-12.5-32.8 0-45.3z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/CyberSecAI/CyberSecAI.github.io" target="_blank" rel="noopener" title="source on Github" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/CyberSecAI/CyberSecAI.github.io/print_page/" target="_blank" rel="noopener" title="Save as HTML or print to PDF / paper" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M288 32c0-17.7-14.3-32-32-32s-32 14.3-32 32v242.7l-73.4-73.4c-12.5-12.5-32.8-12.5-45.3 0s-12.5 32.8 0 45.3l128 128c12.5 12.5 32.8 12.5 45.3 0l128-128c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0L288 274.7V32zM64 352c-35.3 0-64 28.7-64 64v32c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64v-32c0-35.3-28.7-64-64-64H346.5l-45.3 45.3c-25 25-65.5 25-90.5 0L165.5 352H64zm368 56a24 24 0 1 1 0 48 24 24 0 1 1 0-48z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "/CyberSecAI/CyberSecAI.github.io/", "features": ["navigation.expand", "navigation.footer", "search.highlight", "search.share", "search.suggest"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.af256bd8.min.js"></script>
      
        <script src="../js/print-site.js"></script>
      
        <script src="https://unpkg.com/tablesort@5.3.0/dist/tablesort.min.js"></script>
      
        <script src="../javascripts/tablesort.js"></script>
      
    
  </body>
</html>